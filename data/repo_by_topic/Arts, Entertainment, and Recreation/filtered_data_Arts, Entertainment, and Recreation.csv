repo,user,organization,url (HTML),url (API),description,readme,stargazer count,watcher count,subscriber count,open issue count,topic (search),topics,NAICS Code
fogleman,primitive,,https://github.com/fogleman/primitive,https://api.github.com/repos/primitive/fogleman,Reproducing images with geometric primitives.,"# Primitive Pictures

Reproducing images with geometric primitives.

![Example](https://www.michaelfogleman.com/static/primitive/examples/16550611738.200.128.4.5.png)

### How it Works

A target image is provided as input. The algorithm tries to find the single most optimal shape that can be drawn to minimize the error between the target image and the drawn image. It repeats this process, adding *one shape at a time*. Around 50 to 200 shapes are needed to reach a result that is recognizable yet artistic and abstract.

### Primitive for macOS

Now available as a native Mac application!

https://primitive.lol/

### Twitter

Follow [@PrimitivePic](https://twitter.com/PrimitivePic) on Twitter to see a new primitive picture every 30 minutes!

The Twitter bot looks for interesting photos using the Flickr API, runs the algorithm using randomized parameters, and
posts the picture using the Twitter API.

You can tweet a picture to the bot and it will process it for you.

### Command-line Usage

Run it on your own images! First, [install Go](https://golang.org/doc/install).

    go get -u github.com/fogleman/primitive
    primitive -i input.png -o output.png -n 100

Small input images should be used (like 256x256px). You don't need the detail anyway and the code will run faster.

| Flag | Default | Description |
| --- | --- | --- |
| `i` | n/a | input file |
| `o` | n/a | output file |
| `n` | n/a | number of shapes |
| `m` | 1 | mode: 0=combo, 1=triangle, 2=rect, 3=ellipse, 4=circle, 5=rotatedrect, 6=beziers, 7=rotatedellipse, 8=polygon |
| `rep` | 0 | add N extra shapes each iteration with reduced search (mostly good for beziers) |
| `nth` | 1 | save every Nth frame (only when `%d` is in output path) |
| `r` | 256 | resize large input images to this size before processing |
| `s` | 1024 | output image size |
| `a` | 128 | color alpha (use `0` to let the algorithm choose alpha for each shape) |
| `bg` | avg | starting background color (hex) |
| `j` | 0 | number of parallel workers (default uses all cores) |
| `v` | off | verbose output |
| `vv` | off | very verbose output |

### Output Formats

Depending on the output filename extension provided, you can produce different types of output.

- `PNG`: raster output
- `JPG`: raster output
- `SVG`: vector output
- `GIF`: animated output showing shapes being added - requires ImageMagick (specifically the `convert` command)

For PNG and SVG outputs, you can also include `%d`, `%03d`, etc. in the filename. In this case, each frame will be saved separately.

You can use the `-o` flag multiple times. This way you can save both a PNG and an SVG, for example.

### Progression

This GIF demonstrates the iterative nature of the algorithm, attempting to minimize the mean squared error by adding one shape at a time. (Use a "".gif"" output file to generate one yourself!)

<img src=""https://www.michaelfogleman.com/static/primitive/examples/monalisa.3.2000.gif"" width=""440""/> <img src=""https://www.michaelfogleman.com/static/primitive/examples/monalisa-original.png"" width=""440""/>

### Static Animation

Since the algorithm has a random component to it, you can run it against the same input image multiple times to bring life to a static image.

![Pencils](https://www.michaelfogleman.com/static/primitive/examples/pencils.gif)

### Creative Constraints

If you're willing to dabble in the code, you can enforce constraints on the shapes to produce even more interesting results. Here, the rectangles are constrained to point toward the sun in this picture of a pyramid sunset.

![Pyramids](https://www.michaelfogleman.com/static/primitive/examples/pyramids.png)

### Shape and Iteration Comparison Matrix

The matrix below shows triangles, ellipses and rectangles at 50, 100 and 200 iterations each.

![Matrix](http://i.imgur.com/H5NYpL4.png)

### How it Works, Part II

Say we have a `Target Image`. This is what we're working towards recreating. We start with a blank canvas, but we fill it with a single solid color. Currently, this is the average color of the `Target Image`. We call this new blank canvas the `Current Image`. Now, we start evaluating shapes. To evaluate a shape, we draw it on top of the `Current Image`, producing a `New Image`. This `New Image` is compared to the `Target Image` to compute a score. We use the [root-mean-square error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) for the score.

    Current Image + Shape => New Image
    RMSE(New Image, Target Image) => Score

The shapes are generated randomly. We can generate a random shape and score it. Then we can mutate the shape (by tweaking a triangle vertex, tweaking an ellipse radius or center, etc.) and score it again. If the mutation improved the score, we keep it. Otherwise we rollback to the previous state. Repeating this process is known as [hill climbing](https://en.wikipedia.org/wiki/Hill_climbing). Hill climbing is prone to getting stuck in local minima, so we actually do this many different times with several different starting shapes. We can also generate N random shapes and pick the best one before we start hill climbing. [Simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing) is another good option, but in my tests I found the hill climbing technique just as good and faster, at least for this particular problem.

Once we have found a good-scoring shape, we add it to the `Current Image`, where it will remain unchanged. Then we start the process again to find the next shape to draw. This process is repeated as many times as desired.

### Primitives

The following primitives are supported:

- Triangle
- Rectangle (axis-aligned)
- Ellipse (axis-aligned)
- Circle
- Rotated Rectangle
- Combo (a mix of the above in a single image)

More shapes can be added by implementing the following interface:

```go
type Shape interface {
	Rasterize() []Scanline
	Copy() Shape
	Mutate()
	Draw(dc *gg.Context)
	SVG(attrs string) string
}
```

### Features

- [Hill Climbing](https://en.wikipedia.org/wiki/Hill_climbing) or [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing) for optimization (hill climbing multiple random shapes is nearly as good as annealing and faster)
- Scanline rasterization of shapes in pure Go (preferable for implementing the features below)
- Optimal color computation based on affected pixels for each shape (color is directly computed, not optimized for)
- Partial image difference for faster scoring (only pixels that change need be considered)
- Anti-aliased output rendering

### Inspiration

This project was originally inspired by the popular and excellent work of Roger Johansson - [Genetic Programming: Evolution of Mona Lisa](https://rogeralsing.com/2008/12/07/genetic-programming-evolution-of-mona-lisa/). Since seeing that article when it was quite new, I've tinkered with this problem here and there over the years. But only now am I satisfied with my results.

It should be noted that there are significant differences in my implementation compared to Roger's original work. Mine is not a genetic algorithm. Mine only operates on one shape at a time. Mine is much faster (AFAIK) and supports many types of shapes.

### Examples

Here are more examples from interesting photos found on Flickr.

![Example](https://www.michaelfogleman.com/static/primitive/examples/29167683201.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/26574286221.200.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/15011768709.200.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/27540729075.200.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/28896874003.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/20414282102.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/15199237095.200.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/11707819764.200.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/18270231645.200.128.4.3.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/15705764893.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/25213252889.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/15015411870.200.128.4.3.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/25766500104.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/27471731151.50.128.4.1.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/11720700033.200.128.4.3.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/18782606664.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/21374478713.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/15196426112.200.128.4.5.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/24696847962.png)
![Example](https://www.michaelfogleman.com/static/primitive/examples/18276676312.100.128.4.1.png)
",12231,12231,183,54,art,"[art, go, graphics, primitives]",0
ellisonleao,magictools,,https://github.com/ellisonleao/magictools,https://api.github.com/repos/magictools/ellisonleao,:video_game: :pencil: A list of Game Development resources to make magic happen.,"<h1 align=""center"">
    <img width=""900"" src=""https://cdn.rawgit.com/ellisonleao/magictools/7d8012bc/magicbg.jpg"" alt=""logo""/>
</h1>
<hr/>

<p align=""center"">
    <a href=""https://github.com/sindresorhus/awesome""><img src=""https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg"" alt=""Awesome""/></a>
    <a href=""#""><img src=""https://github.com/ellisonleao/magictools/actions/workflows/validate-links.yml/badge.svg"" alt=""build""/></a>
</p>

A curated list of game development resources to make **magic** happen.

### License Legends

- :free: - Free
- :tada: - Open Source
- :moneybag: - Paid
- :money_with_wings: - Partially Free

## Table of Contents

- [Graphics](#graphics)
  - [Assets/Placeholders](#assetsplaceholders)
  - [Spritesheet Tools](#spritesheet-tools)
  - [Bitmap Compression](#bitmap-compression)
  - [Texture Tools](#texture-tools)
  - [Character Generators](#character-generators)
  - [Tile/Level Editors](#tilelevel-editors)
  - [Animation](#animation)
  - [Vector/Image Editor](#vectorimage-editor)
  - [Modeling](#modeling)
  - [Terrain Generators](#terrain-generators)
  - [Voxel Editors](#voxel-editors)
- [Code](#code)
  - [Engines and Frameworks](#engines-and-frameworks)
  - [AI](#ai)
- [Audio](#audio)
  - [Collections](#collections)
  - [Music and Audio Editors](#music-and-audio-editors)
- [Board Games](#board-games)
- [Must see](#must-see)
  - [Blogs and Portals](#blogs-and-portals)
  - [Books](#books)
  - [Magazines](#magazines)
  - [Videos/Podcasts](#videospodcasts)
  - [Game Jams](#game-jams)
  - [Project Management](#project-management)
  - [Complete Game Sources](#complete-game-sources)
- [Ads](#ads)
- [Learn](#learn)
  - [General Game Development](#general-game-development)
  - [Computer Graphics](#computer-graphics)

## Graphics

_Great graphics placeholders and tools to turn that squared game into a picasso painting_

#### Assets/Placeholders

- :free: [2D Cartoon Mobile Game UI Pack](http://graphicburger.com/mobile-game-gui/) - cartoon user interface asset pack. It comes as a layered psd file.
- :free: [420 Pixel Art Icons for RPGs](http://7soul1.deviantart.com/art/420-Pixel-Art-Icons-for-RPG-129892453) - Set of 420 RPG icons, free for commercial use.
- :free: [Blender 3D models](https://www.blender-models.com/) - 3D models, particle systems/effects
- :money_with_wings: [CGTextures](http://www.textures.com) - A large collection of textures.
- :money_with_wings: [GameDev Market](https://www.gamedevmarket.net/) - a community-driven marketplace that connects indie game developers with talented asset creators.
- :free: [Games-Icons Set](http://game-icons.net/) - free icons for your games.
- :free: [Iconmonstr](http://iconmonstr.com/) - Another free icons resource for your games.
- :money_with_wings: [Kenney Assets](http://kenney.nl/assets) - Royalty free assets
- :free: [Liberated Pixel Cup assets](http://lpc.opengameart.org) - Free graphic assets of the Liberated Pixel Cup (LPC) held by the OpenGameArt forums
- :free: [Matcaps](https://github.com/nidorx/matcaps#matcaps) - A Huge library of matcap textures in PNG and ZMT, organized by color.
- :free: [OpenGameArt](http://opengameart.org/) - a media repository intended for use with free software game projects.
- :moneybag: [Oryx Design Lab](http://oryxdesignlab.com/) - Cheap high quality royalty free sprites
- :money_with_wings: [PlainTextures](http://www.plaintextures.com/) - Free high resolution textures, brushes and photos
- :free: [Pixelicious](https://www.pixelicious.xyz/) - Image-to-Pixel Art converter.
- :free: [Poly Pizza](https://poly.pizza) - 6000+ free low poly models
- :free: [Reiner's Tilesets](http://www.reinerstilesets.de/) - A blog with free 2D and 3D graphics.
- :free: [Sketchfab](https://sketchfab.com/) - Publish & embed interactive 3D models.
- :free: [SpriteLib](http://www.widgetworx.com/spritelib/) - a collection of static and animated graphic objects (also commonly known as sprites).
- :free: [StickyPNG](http://www.stickpng.com/) - Free transparent PNG images.
- :free: [TextureHaven](https://texturehaven.com/) - Free textures with additional maps like displacement and bump maps. Also HDRIs.
- :free: [TextureKing](http://www.textureking.com/) - Free material stock textures
- :money_with_wings: [Vecteezy](http://www.vecteezy.com/) - Free Vector Art.

#### Spritesheet Tools

- :tada: [Cheetah-Texture-Packer](https://github.com/scriptum/Cheetah-Texture-Packer) - High efficient and fast 2D bin packing tool
- :tada: [EzSpriteSheet](https://github.com/z64me/EzSpriteSheet) - Creates sprite sheets from animated GIFs and more
- :tada: [Libgdx Texture Packer](https://github.com/libgdx/libgdx/wiki/Texture-packer) - Texture Packer built into Libgdx
- :free: [Littera](http://kvazars.com/littera) - Bitmap font generator
- :free: [ShoeBox](http://renderhjs.net/shoebox/) - Adobe Air based app with game and ui related tools.
- :money_with_wings: [TexturePacker](https://www.codeandweb.com/texturepacker) - Great spritesheet creation editor.
- :tada: [Tilesplit](https://github.com/AlexPoulsen/tilesplit) - CLI text-based tilesheet splitter and namer. Turn a spritesheet into many separate files with names you pick, or not if you don't care. Support templates and textures that are not all the same size.

#### Bitmap Compression

- :tada: [ImageAlpha](http://pngmini.com/) — Mac OS X GUI for pngquant and other tools
- :free: [PNGGauntlet](http://pnggauntlet.com/) - Smash PNGs for faster sites
- :free: [PNGoo](https://pngquant.org/PNGoo.0.1.1.zip) - Windows GUI for batch conversion.
- :tada: [Pngyu](http://nukesaq88.github.io/Pngyu/) - simple PNG image file compression tool.
- :tada: [SuperPNG Photoshop plug-in](http://www.fnordware.com/superpng/) — Mac and Windows. Comparison with ""Save for Web""
- :money_with_wings: [TinyPNG](https://tinypng.com/) - Advanced lossy compression for PNG images that preserves full alpha transparency.

#### Texture Tools

- :moneybag: [FilterForge](https://www.filterforge.com/) - A plugin for Adobe Photoshop that allows you to build your own filters.
- :free: [Live Normal](https://tenebrislab.github.io/livenormal/) - An Android and iOS app for generating seamless materials on the go. You take a photo, and Live Normal creates a tile-able texture and generates texture maps ready for a PBR engine of your choice.
- :moneybag: [PixPlant](http://www.pixplant.com/) - PixPlant is a smart 3D texturing tool that creates high quality normal, displacement, specular maps and seamless textures from photos.

#### Character Generators

- :free: [Charas](http://charas-project.net/index.php) - Charas is a charset generator for RPG Maker.

#### Tile/Level Editors

- :moneybag: [AutoTileGen](http://pixelatto.com) - AutoTileGen is an automatic tileset generator for 2D game terrains.
- :tada: [LDtk](https://deepnight.net/tools/ldtk-2d-level-editor/) - LDtk is an open-source 2D level editor for indie devs, with a strong focus on user-friendliness.
- :tada: [Material Maker](https://github.com/RodZill4/material-maker) - procedural texture creator made in Godot
- :tada: [OGMO Editor](https://ogmo-editor-3.github.io/)- generic level editor.
- :tada: [Overlap2D](https://github.com/UnderwaterApps/overlap2d/) - a 2D level and UI editor with an engine agnostic philosophy.
- :tada: [Tiled](http://www.mapeditor.org/) - free, easy to use and flexible tile map editor.

#### Animation

- :money_with_wings: [Cascadeur](https://cascadeur.com/) - Powerful physics-based 3D character animation
- :tada: [LWF](http://gree.github.io/lwf/) - Lightweight SWF. LWF is an animation engine which can play animation data converted from FLASH contents in HTML5, Unity, Cocos2d-x, iOS UIKit, and more.
- :moneybag: [Fusion Character Animator](http://loopengo.free.fr/) - small tool for Clickteam Fusion 2.5 to facilitate the animation of 2D character sprites for developers.
- 🆓 [GraphicsDale](https://graphicsgale.com/us/) - Powerful tool for spriting and pixel art.
- :moneybag: [Mixamo](https://www.mixamo.com/#/) - tool for auto auto rigging and animation of 3D humanoid models,
- :tada: [Pixel Composer](https://github.com/Ttanasart-pt/Pixel-Composer) - Powerful node-based VFX editor for pixel art
- :moneybag: [Spine](http://esotericsoftware.com/) - Spine is dedicated to 2D animation, providing an efficient workflow both for creating amazing animation and for integrating it into your games.
- :moneybag: [Spriter Pro](https://brashmonkey.com/download-spriter-pro/) - Modern tool for sprite animation.

#### Vector/Image Editor

- :moneybag: [Affinity Designer](https://affinity.serif.com/de/designer) - Vector graphics editor with a bunch of features which also supports Adobe file formats
- :moneybag: [Affinity Photo](https://affinity.serif.com/de/photo) - Photo and raster graphics editor which works together with Adobe file formats and Affinity Designer
- :money_with_wings: [Aseprite](http://www.aseprite.org/) - animated sprite editor & pixel art tool.
- :tada: [CR8tracer](http://cr8.netfirms.com/tracer.html) - Convert bitmap images into monochrome vector formats.
- :tada: [Gimp](http://www.gimp.org/) - GNU Image Manipulation Program. It is a freely distributed piece of software for such tasks as photo retouching, image composition and image authoring.
- :tada: [Inkscape](https://inkscape.org/en/) - An open-source vector graphics editor similar to Adobe Illustrator, Corel Draw, Freehand, or Xara X.
- :tada: [Krita](https://krita.org/) - Krita is a professional FREE and open source painting program. It is made by artists that want to see affordable art tools for everyone.
- :tada: [LibreSprite](https://libresprite.github.io/) - LibreSprite is an open source fork of Aseprite.
- :free: [Multipaint](http://multipaint.kameli.net) - A cross-platform (Win, Linux, Mac) image editor/painter which covers the color limitations of 8-bit machines (like C64, ZX Spectrum etc.)
- :money_with_wings: [Paint.NET](http://www.getpaint.net/) - Paint.NET is free image and photo editing software for PCs that run Windows.
- :moneybag: [Pickle](http://www.pickleeditor.com/) - Another Pixel art Editor.
- :tada: [PiskelApp](http://www.piskelapp.com/) - Free Online Pixel Art and Animated Sprite Tool.
- :moneybag: [Pixelmator](http://www.pixelmator.com) - Full-featured image editing app for the Mac
- :moneybag: [Pixelator](http://pixelatorapp.com) - Turn any image into fancy pixel-art
- :moneybag: [Pixen](https://github.com/Pixen/Pixen) - Pixel Art Editor for OSX
- :free: [project one](http://p1.untergrund.net) - A picture converter and editor for the Commodore 64 covering different graphics mode of this computer. Windows only
- :moneybag: [PyxelEdit](http://pyxeledit.com/) - Pixel art editor designed to make it fun and easy to make tilesets, levels and animations.
- :free: [REXPaint](https://www.gridsagegames.com/rexpaint/) - a powerful and user-friendly ASCII art editor.
- :tada: [rx](https://rx.cloudhead.io/) - a modern & minimalist pixel editor
- :free: [Tilemancer](https://led.itch.io/tilemancer) - A quick procedural tile creator designed for pixel-art games.
- :free: [Timanthes](http://csdb.dk/release/?id=75871) - A pixel art editor for the Commodore 64 computer running on Windows
- :free: [Charas](http://charas-project.net/index.php) - Charas is a charset generator for RPG Maker.
- :free: [Spritemate](http://www.spritemate.com) - Online Editor for Commodore 64 Sprites
- :tada: [SVGcode](https://svgco.de/) - SVGcode is a Progressive Web App that lets you convert raster images like JPG, PNG, GIF, WebP, AVIF, etc. to vector graphics in SVG format.
- :money_with_wings: [Vector mMgic](https://vectormagic.com/) - Free Raster to Vector Graphics Converter
- :tada: [VTracer](https://www.visioncortex.org/vtracer/) - Raster to Vector Graphics Converter built on top of visioncortex

#### Modeling

- :moneybag: [3ds Max](http://www.autodesk.com/products/3ds-max/overview)
- :money_with_wings: [Besel](https://www.bezel.it/hq) - Make a 3d real-time collaboration design and prototype in your VR headset or mobile AR.
- :tada: [Blender](http://www.blender.org/) - The free software and open-source 3D grate of the wolrd
- :free: [Clara.io](https://clara.io/)
- :money_with_wings: [Daz 3D](https://www.daz3d.com/) - A 3D software allows you to easily create custom scenes and characters in seconds.
- :free: [MakeHuman](http://www.makehumancommunity.org/)
- :moneybag: [Maya](http://www.autodesk.com/products/maya/overview)
- :moneybag: [modo](https://www.foundry.com/products/modo)
- :free: [sculptris](https://sculptris.br.uptodown.com/windows) - A version by Pixologic and the original [1.01](https://www.moddb.com/downloads/sculptris)
- :money_with_wings: [Spline](https://spline.design/) - A 3d colalaborative real-time
- :free: [Womp](https://womp.com/) - A 3D intuitive and easy to use for create right in your browser
- :moneybag: [ZBrush](https://pixologic.com/)
- :free: [ZBRUSHCOREMINI](https://www.maxon.net/en/zbrushcoremini) - The new version of sculpris by MAXON

#### Terrain Generators

- :free: [Canyon Terrain Editor](https://entardev.wordpress.com/other-projects/canyon-terrain-editor/) - Create quality, realistic terrain quickly and intuitively
- :tada: [DEM Net Elevation API](https://elevationapi.com) - Live 3D textured terrain generation from real data - export height/normal maps, glTF, OBJ, STL
- :tada: [Fracplanet](https://sourceforge.net/projects/fracplanet/) - Fractal planet and terrain generator
- :moneybag: [World Creator](https://www.world-creator.com/) - Procedural terrain and landscape generation on the GPU in real time, simulation of erosion and sediment, beautiful editor. much more
- :moneybag: [World Machine](http://www.world-machine.com/) - Procedural terrain creation, simulations of nature, and interactive editing

#### Voxel Editors

- :tada: [goxel](https://github.com/guillaumechereau/goxel)
- :free: [MagicaVoxel](https://ephtracy.github.io/)
- :free: [Q-Block](http://kyucon.com/qblock/)
- :free: [Sproxel](http://sproxel.blogspot.com.br/)
- :free: [Vengi](https://mgerhardy.github.io/vengi/)

## Code

_Set of game frameworks, engines and platforms_

### Engines and Frameworks

- :tada: [6502 Unit Test executor](https://github.com/AsaiYusuke/6502_test_executor) - A cross-platform unit testing tool for MOS 6502 assembly. (i.e. NES)
- :tada: [Allegro](http://liballeg.org/) - Allegro 4 & 5 are cross-platform, open source, game programming libraries, primarily for C and C++ developers.
- :tada: [Amethyst](https://www.amethyst.rs/) - Data-driven game engine written in Rust for 2D & 3D using `gfx-rs`.
- :tada: [amulet](http://www.amulet.xyz/) - A free Lua-based audio/visual toolkit suitable for small games and experimentation. It runs on Windows, Mac, Linux, HTML5 and iOS.
- :tada: [asimov-ts](https://github.com/pedrozaalex/asimov-ts) - A type safe (as much as possible) engine for the web written in TypeScript.
- :tada: [Astera](https://github.com/tek256/astera) - 2D C99 Cross Platform Game Library / Framework
- :tada: [axys](https://github.com/axys1/axys) - A fork of Cocos2d-x-4.0, it has Full Support OpenAL for all platforms, single texture multi GPU texture handler and C++ 17.
- :tada: [Azul3D](http://azul3d.org/) - A 3D engine written in Go.
- :tada: [Babylon.js](https://www.babylonjs.com/) - Javascript 3D Library.
- :tada: [Bevy](https://bevyengine.org/) - A refreshingly simple data-driven game engine built in Rust
- :tada: [bgfx](https://github.com/bkaradzic/bgfx) - Cross-platform, graphics API agnostic, ""Bring Your Own Engine/Framework"" style rendering library.
- :tada: [bitsy](https://ledoux.itch.io/bitsy) - A little editor for little games or worlds. The goal is to make it easy to make games where you can walk around and talk to people and be somewhere.
- :tada: [Bladecoder](https://github.com/bladecoder/bladecoder-adventure-engine) - Classic point and click adventure game engine and editor.
- :money_with_wings: [Blend4Web](http://www.blend4web.com/) - A Javascript framework for creating and displaying interactive 3D computer graphics in web browsers.
- :tada: [Blitz3D](https://github.com/blitz-research/blitz3d) 3D basic-like programming language for fast 3D desktop games.
- :tada: [boardgame.io](https://github.com/boardgameio/boardgame.io) - State management and multiplayer networking for turn-based games.
- :tada: [Box2D](http://box2d.org/) - A 2D Physics Engine for Games.
- :tada: [Bullet](http://bulletphysics.org/wordpress/) - Real-time physics simulation.
- :tada: [Chipmunk C#](https://github.com/netonjm/ChipmunkSharp) - C# implementation of the Chipmunk2D lib.
- :tada: [Chipmunk2D](https://chipmunk-physics.net/) - A fast and lightweight 2D game physics library.
- :tada: [Cinder](https://libcinder.org/) - Cinder is a community-developed, free and open source library for professional-quality creative coding in C++.
- :free: [Cocos Creator](https://www.cocos.com/en/creator) - Cocos Creator, a free cross-platform game development editor supporting Cocos2d-js, helps developers build 2D and 3D game scenes, edit game UI and other game resources quickly and efficiency.
- :tada: [Cocos2D](https://github.com/los-cocos/cocos) - graphic library for games and multimedia, for python language
- :tada: [Cocos2d-x](http://cocos2d-x.org/) - a C++ OpenGL 2D and 3D game engine. Uses C++ but has JS and Lua bindings. Target all the major mobile platforms and operating systems. Additional tools CocoStudio and Cocos Code IDE.
- :moneybag: [Construct](https://www.scirra.com/) - an HTML5 game maker, meaning you are not actually writing JavaScript. Instead, you use actions, events and conditions to do the heavy lifting.
- :money_with_wings: [CopperCube](http://www.ambiera.com/coppercube/) - CopperCube is an all-in-one 3D game engine.Very easy to use.
- :tada: [Coquette](http://coquette.maryrosecook.com/) - A micro framework for JavaScript games. Handles collision detection, the game update loop, canvas rendering, and keyboard and mouse input.
- :tada: [ct.js](https://ctjs.rocks/) — this 2D game engine makes learning programming fun and game development easy by its visual tools, good docs, and flexible, modular library.
- :tada: [Dash](https://github.com/Circular-Studios/Dash) - A free and open 3D game engine written in D.
- :tada: [Dear Imgui](https://github.com/ocornut/imgui/) - A bloat-free immediate mode GUI for C++ with minimal dependencies.
- :tada: [Defold](http://www.defold.com/) - Free 2D Game Engine for Cross-Platform Publishing
- :tada: [DEM Net Elevation API C#](https://github.com/dem-net/DEM.Net) - Terrain generation from real data with textures, normal maps, glTF, OBJ, STL support
- :tada: [Diligent Engine](https://github.com/DiligentGraphics/DiligentEngine) - A modern cross-platform low-level graphics library that supports Direct3D11, Direct3D12, OpenGL/GLES, and Vulkan.
- :tada: [E.B.U.R.P](http://pents90.github.io/eburp/) - The Eight-Bit Universal Role Playing Engine
- :tada: [ENGi](https://github.com/ajhager/engi) - A multi-platform 2D game library for Go.
- :tada: [engo](https://engoengine.github.io/) - Engo is an open-source 2D game engine written in Go.
- :tada: [Ebiten](https://ebiten.org/) - A dead simple 2D game library in Go.
- :tada: [ecs-lib](https://github.com/nidorx/ecs-lib#readme) - **ecs-lib** is a tiny and easy to use ECS (Entity Component System) library for game programming. It's written in Typescript but you can use on node.js and web browser too.
- :tada: [Ejecta](http://impactjs.com/ejecta) - A Fast, Open Source JavaScript, Canvas & Audio Implementation for iOS.
- :tada: [EnTT](https://github.com/skypjack/entt) - Gaming meets modern C++, a fast and reliable entity-component system (ECS) and much more
- :tada: [FXGL](https://github.com/AlmasB/FXGL) - A JavaFX/Kotlin game engine for Win/Mac/Linux.
- :tada: [Farseer](https://github.com/VelcroPhysics/VelcroPhysics) - a collision detection system with realistic physics responses.
- :tada: [Flame](https://github.com/flame-engine/flame) - a minimalist game engine for Flutter
- :tada: [FlashPunk](http://useflashpunk.net/) - free ActionScript 3 library designed for developing 2D Flash games.
- :moneybag: [GameMaker](http://www.yoyogames.com/en/gamemaker) - GameMaker accommodates the creation of cross-platform video games using drag and drop or a scripting language known as Game Maker Language, which can be used to develop more advanced games that could not be created just by using the drag and drop features.
- :tada: [gameplay](http://gameplay3d.io/) - A free, open-source, cross-platform, 2D + 3D game framework written in C++. It is aimed towards indie game developers who are creating desktop and mobile games.
- :money_with_wings: [GameSalad](https://gamesalad.com/) - Game Creation Engine for Mac and Windows.
- :tada: [GB Studio](https://www.gbstudio.dev/) - A free and easy to use retro adventure game creator for your favourite handheld video game system.
- :tada: [GDevelop](https://gdevelop-app.com/) - An open-source, cross-platform 2D game engine designed for everyone - it's extensible, fast and easy to learn.
- :tada: [ggez](http://ggez.rs/) - A Rust library to create Good Games Easily.
- :tada: [Gideros](http://giderosmobile.com/) - A Cross-Platform framework to create Mobile Apps and games for iOS, Android using Lua programming language.
- :tada: [Glide Engine](https://github.com/cocoatoucher/Glide) - Engine for making 2d games on iOS, macOS and tvOS in Swift programming language, with practical examples and tutorials.
- :tada: [Godot](http://www.godotengine.org/) - An advanced, feature-packed, multi-platform 2D and 3D open-source game engine.
- :tada: [Gorgon](https://www.tape-worm.net/) - A 2D rendering API for .NET, written in C#.
- :tada: [Grid](https://github.com/Planimeter/game-engine-2d) - A multiplayer-first game engine for Lua.
- :tada: [HaxeFlixel](http://haxeflixel.com/) - Create cross-platform games easier and free.
- :tada: [Heaps](https://heaps.io/) - Cross platform graphics for high performance games.
- :tada: [Horde3D](http://www.horde3d.org/) - small open source 3D rendering engine.
- :tada: [iio.js](https://github.com/iioinc/iio.js) - A javascript library that speeds the creation and deployment of HTML5 Canvas applications
- :tada: [ImpactJS](http://impactjs.com/) - Impact is a JavaScript Game Engine that allows you to develop stunning HTML5 Games for desktop and mobile browsers.
- :free: [Inform7](http://inform7.com/) - A design system for interactive fiction based on natural language.
- :tada: [Ink](http://www.inklestudios.com/ink/) - Scripting language for writing interactive narrative.
- :tada: [Irrlicht](http://irrlicht.sourceforge.net/) - open source high performance realtime 3D engine written in C++.
- :tada: [Jitter](https://github.com/mattleibow/jitterphysics) - a fast and lightweight physics engine written in C#.
- :tada: [jMonkeyEngine 3](http://jmonkeyengine.org/) - a 3D open-source game engine for adventurous Java developers.
- :tada: [JNGL](https://github.com/jhasse/jngl) - a 2D open-source game engine. Develop on Linux, Windows, OS X. Deploy to Nintendo Switch, Xbox, Linux, Windows, OS X, Web, Android, iOS and more.
- :free: [JPCT](https://www.jpct.net/) - jPCT is a 3D engine for desktop Java and Google's Android.
- :tada: [Juno](https://github.com/digitsensitive/juno) - Clean and lightweight 2D game framework written in TypeScript
- :tada: [Juno](https://github.com/rxi/juno) - Framework for making 2D games with chunky pixels in Lua
- :tada: [Kivent](http://kivent.org/) - A 2D game framework for Kivy.
- :tada: [Kivy](http://kivy.org) - Cross platform Python framework for creating apps and games for Linux, Windows, OS X, Android and iOS
- :tada: [KogGE](https://korge.soywiz.com) - Modern Multiplatform Game Engine for Kotlin. Write games for the JVM, JavaScript, Android and iOS in no time using Kotlin.
- :money_with_wings: [Leadwerks](https://www.leadwerks.com/) - Easy-to-learn game engine for 3D and VR.
- :tada: [LibGDX](https://libgdx.com/) - Powerful (totally free) library for Java, code once and run the game on desktop, Android, Web, and iOS.
- :tada: [LimeJS](http://www.limejs.com/) - HTML5 game framework for building fast, native-experience games for all modern touchscreens and
- :tada: [LITIengine](http://litiengine.com/) - 2D Java Game Engine. It provides all the infrastructure to create tile based 2D games with plain java
- :free: [Lumberyard](https://aws.amazon.com/lumberyard/) - Amazon Lumberyard is a free AAA game engine deeply integrated
- :tada: [LumixEngine](https://github.com/nem0/LumixEngine) - 3D Game engine built on C++.
- :tada: [Lums](https://github.com/lums-proj/Lums) - A 2D / 3D framework written in C++11. Very efficient and modern. Still under heavy development.
- :tada: [LÖVE](http://love2d.org) - Lua 2D Game Engine.
- :tada: [MINX](https://github.com/GearChicken/MINX) - Open Source 2D game framework written in C++ (to the style of XNA)
- :tada: [macroquad](https://github.com/not-fl3/macroquad) - The cross-platform game engine in Rust.
- :tada: [Magnum](http://magnum.graphics/) - a lightweight and modular 2D/3D graphics/game engine written in C++11
- :tada: [Matter.js](http://brm.io/matter-js/) - a 2D physics engine for the web.
- :tada: [MelonJS](http://melonjs.org) - open source light-weight HTML5 game engine.
- :free: [Mini Micro](https://miniscript.org/MiniMicro/) - Mini Micro is a fantasy computer for making, playing and sharing 2D games and programs written in the modern [MiniScript](https://miniscript.org) language.
- :tada: [Monogame](http://www.monogame.net/) - Open Source implementation of the Microsoft XNA 4 Framework.
- :tada: [Nakama](https://github.com/heroiclabs/nakama) - Distributed server for social and realtime games and apps.
- :tada: [nCine](https://ncine.github.io/) - A cross-platform 2D game engine with an emphasis on performance, written in C++11 and optionally scriptable in Lua.
- :free: [NodeBox](https://www.nodebox.net/) - a family of Python tools to create generative design.
- :tada: [nuklear](https://github.com/Immediate-Mode-UI/Nuklear) - A single-header ANSI C immediate mode cross-platform GUI library.
- :tada: [ÖbEngine](https://github.com/Sygmei/ObEngine) - 2D Game Engine with Lua Scripting made on top of SFML !
- :tada: [ODE](http://www.ode.org/) - ODE is an open source, high performance library for simulating rigid body dynamics.
- :tada: [Ogre3D](http://www.ogre3d.org/) - is a scene-oriented, real-time, flexible 3D rendering engine (as opposed to a game engine) written in C++.
- :tada: [OpenFL](http://www.openfl.org/) - Open Source Haxe Engine for making multi-platform games.
- :tada: [openFrameworks](https://openframeworks.cc/) - An open source and free C++ toolkit for creative coding.
- :tada: [OpenRA](http://www.openra.net/) - OpenRA is a Libre/Free Real Time Strategy Game Engine.
- :tada: [OpenXRay](https://github.com/OpenXRay/xray-16) - a community-modified X-Ray engine used in S.T.A.L.K.E.R. game series.
- :moneybag: [PICO-8](http://www.lexaloffle.com/pico-8.php) - A fantasy console for making, sharing and playing tiny games and other computer programs.
- :tada: [p2.js](http://schteppe.github.io/p2.js/) - JavaScript 2D physics library
- :tada: [Panda3D](https://www.panda3d.org/) - a framework for 3D rendering and game development for Python and C++ programs.
- :tada: [Phaser](http://phaser.io/) - free and fast 2D game framework for making HTML5 games for desktop and mobile web browsers, supporting Canvas and WebGL rendering.
- :tada: [Piston](http://www.piston.rs/) - a modular open source game engine written in Rust.
- :tada: [Pixel Vision 8](https://github.com/PixelVision8/PixelVision8) - Pixel Vision 8's core philosophy is to teach retro game development with streamlined workflows. PV8 is also a platform that standardizes 8-bit fantasy console limitations built on top of the open-source C# game engine based on MonoGame.
- :tada: [PixiJS](http://www.pixijs.com/) - is a newcomer HTML5 game renderer - first released in early 2013. A main appeal of the engine is its use of WebGL for faster performance. If WebGL isn't supported, the engine falls back to standard canvas.
- :tada: [Planck.js](http://piqnt.com/planck.js/) - 2D JavaScript physics engine for cross-platform HTML5 game development.
- :money_with_wings: [PlayCanvas](https://playcanvas.com/) - A WebGL Game Engine.
- :tada: [Processing](https://www.processing.org/) - Processing is a programming language, development environment for artists, designers, researchers.
- :tada: [PuzzleScript](http://www.puzzlescript.net/) - open-source HTML5 puzzle game engine.
- :tada: [PyGame](http://pygame.org/hifi.html) - a 2D game engine in Python.
- :tada: [Pyxel](https://github.com/kitao/pyxel) - a retro game engine for Python.
- :moneybag: [RPGMaker](http://www.rpgmakerweb.com/) - series of programs for the development of role-playing games.
- :tada: [Rajawali](https://github.com/Rajawali/Rajawali) - Android OpenGL ES 2.0/3.0 Engine
- :tada: [raylib](https://www.raylib.com/) - a simple and easy-to-use library to enjoy videogames programming, hardware accelerated with OpenGL (1.1, 2.1, 3.3 or ES 2.0)
- :tada: [Ren'Py](http://www.renpy.org/) - An open-source visual novel engine using the Python language in simplified form. It supports Windows, Mac OS X, Linux, Android and iOS.
- :tada: [Rpgboss](http://rpgboss.com) - A 2d rpg game engine and editor based on scala and libgdx. Ease of use, with no programming knowledge.
- :free: [SceneKit](https://developer.apple.com/documentation/scenekit) - Apple proprietary 3D game engine (available on macOS, iOS, iPadOS, tvOS and watchOS).
- :tada: [Screen 13](https://github.com/attackgoat/screen-13) - An easy-to-use Vulkan rendering engine. Provides a render graph for Rust.
- :tada: [SDL](http://libsdl.org/) - SDL is a cross-platform library designed to provide low level access to audio, keyboard, mouse, joystick, and graphics hardware via OpenGL and Direct3D.
- :tada: [SFML](http://www.sfml-dev.org/) - Simple and Fast Multimedia Library.
- :tada: [Solar2D](https://solar2d.com/) - A Lua based game engine with focus on ease of iterations and usage.
- :tada: [Solarus](https://www.solarus-games.org/) - Cross-platform 2D Action/Adventure C++ game engine with Lua API and game editor.
- :tada: [Spring](http://springrts.com/) - A powerful free cross-platform RTS engine.
- :free: [SpriteKit](https://developer.apple.com/documentation/spritekit) - Apple proprietary 2D game engine (available on macOS, iOS, iPadOS, tvOS and watchOS).
- :tada: [Stage.js](http://piqnt.com/stage.js/) - Lightweight and fast 2D HTML5 rendering and layout engine for cross-platform game development.
- :tada: [Starling](http://gamua.com/starling/) - The GPU powered 2D Flash API
- :money_with_wings: [Stencyl](http://www.stencyl.com/) - a game creation platform that allows users to create 2D video games for computers, mobile devices, and the web.
- :tada: [Stride](https://stride3d.net/) - Open Source C# Game Engine.
- :tada: [Superpowers](https://sparklinlabs.itch.io/superpowers) - HTML5 Collaborative 2D/3D Game Maker
- :tada: [TIC-80](https://tic.computer/) - TIC-80 is a fantasy computer for making, playing and sharing tiny games.
- :tada: [Tiny Physics Engine](https://codeberg.org/drummyfish/tinyphysicsengine/) - TPE is a small, completely public domain fixed point physically inaccurate pure C header-only 3D physics engine built to run on tiny computers such as embedded and even bare metal.
- :tada: [Three.js](http://threejs.org/) - Javascript 3D Library.
- :tada: [Turbulenz](http://biz.turbulenz.com/developers) - Turbulenz offers the ability to build, publish, iterate and monetise high-quality games that react like no others, with immersive 3D effects and real-time physics that open up a whole new world of unprecedented and extraordinary web content.
- :tada: [Twine](http://twinery.org/) - Downloadable or browser-based game development platform that allows users to create linked story paths. Not just text-based, Twine supports music, images, and sound effects. Very little coding knowledge required for basic text adventure games.
- :money_with_wings: [Unity 3D](http://unity3d.com/) - A development engine for the creation of 2D and 3D games and interactive content.
- :money_with_wings: [Unreal Engine 4](https://www.unrealengine.com/) - the new game engine technology developed by Epic Games.
- :tada: [Urho3D](http://urho3d.github.io/) - Cross-platform rendering and game engine.
- :tada: [ursina](https://www.ursinaengine.org/) - A game engine powered by python and panda3d.
- :tada: [Vassal](http://www.vassalengine.org/) - Vassal is a game engine for building and playing online adaptations of board games and card games. Play live on the Internet or by email. Vassal runs on all platforms, and is free, open-source software.
- :tada: [voxel.js](http://voxeljs.com/) - voxel.js is a collection of projects that make it easier than ever to create 3D voxel games like Minecraft all in the browser.
- :tada: [Wave](http://waveengine.net/) - Cross-platform engine written in C#.
- :tada: [Wolf RPG Editor English](https://widderune.wixsite.com/widderune/wolf-rpg-editor-english) - open source editor for RPG Maker style gamesl
- :tada: [WhiteStorm.js](https://github.com/WhitestormJS/whitestorm.js) - 3d javacript framework for building apps and games

### AI

- :tada: [Fluent Behaviour Tree](https://github.com/codecapers/Fluent-Behaviour-Tree) - C# behaviour tree library with a fluent API released under MIT.
- :tada: [SimpleAI](https://github.com/mgerhardy/simpleai/) - C++11 behaviour tree based library with a QT5 based remote debugger (and with optional LUA bindings) released under MIT.

## Audio

_Audio editors, sounds collections and more._

### Collections

- :free: [Free Game Sounds](https://gamesounds.xyz/) - Archive of all kinds of royalty-free game sounds.
- :free: [Freesound](http://www.freesound.org/) - collaborative database of Creative Commons Licensed sounds.
- :free: [Musopen](https://musopen.org/) - Royalty free music.
- :free: [Octave](http://raisedbeaches.com/octave/index.html) - free library of UI sounds.
- :free: [PacDV](http://www.pacdv.com/sounds/index.html) - royalty free sounds collection.
- :free: [SoundBible.com](http://soundbible.com/) - Royalty-free, searchable archive of sound effects under various licenses.

### Music and Audio Editors

- :tada: [Audacity](http://sourceforge.net/projects/audacity/) - open source, cross-platform software for recording and editing sounds.
- :free: [Audiosauna](http://www.audiosauna.com/) - transforms your web browser into a fast and flexible music production studio with built in synthesizers and live effects.
- :free: [Audiotool](http://www.audiotool.com/app) - Online music producer.
- :free: [Bfxr](https://www.bfxr.net/) - A tool to make sound effects for computer games.
- :free: [Bosca Ceoil](http://boscaceoil.net/) - Online (and also desktop) music producer made by Terry Cavanagh. Simple, intuitive, has a distinctive retro-ish sound.
- :free: [ChipTone](http://sfbgames.com/chiptone/) - Online sound effect generator
- :free: [FamiTracker](http://famitracker.com/) - free windows tracker for producing music for the NES/Famicom-systems.
- :tada: [jfxr](http://jfxr.frozenfractal.com) - A JavaScript port of the Bfxr sound effect generator.
- :tada: [LMMS](https://lmms.io/) - Cross-platform music production software.
- :free: [MadTracker](http://www.madtracker.org/main.php) - a powerful and efficient approach to making music. Versatility and compatibility are guaranteed due to full VST™, ASIO™ and ReWire™ support.
- :tada: [MilkyTracker](https://github.com/milkytracker/MilkyTracker) - open source tracker for Mac/Linux/Windows platforms.
- :tada: [musagi](http://www.drpetter.se/project_musagi.html) - open source, fairly large and sophisticated music editor and synthesizer
- :moneybag: [Resemble](https://www.resemble.ai/unity) - Resemble's voice cloning engine within Unity
- :tada: [Sekaiju](http://openmidiproject.osdn.jp/Sekaiju_en.html) - Open Source MIDI sequencer.
- :free: [Soundation](https://soundation.com/) - Online Professional music studio.
- :free: [SunVox](http://www.warmplace.ru/soft/sunvox/) - a small, fast and powerful modular synthesizer with pattern-based sequencer (tracker).

## Board Games

_Tools for making board games_

- :free: [Iterary](http://www.iterary.com) - Board Game Design Tool.
- :tada: [RPTools](http://www.rptools.net/) - a brand of open-source programs designed to enhance traditional pen-and-paper role playing games.

## Must see

_Blogs, portals, magazines and more_

### Blogs and Portals

- [Amit's Game Programming](http://www-cs-students.stanford.edu/~amitp/gameprog.html)
- [Designer Notes](http://www.designer-notes.com/)
- [Emanuele Feronato's Blog](http://www.emanueleferonato.com/)
- [Gamasutra](http://www.gamasutra.com/)
- [Game Development on StackExchange](http://gamedev.stackexchange.com/)
- [GameDevs.org](http://gamedevs.org/)
- [GameJolt](http://gamejolt.com/)
- [Greenlit Gaming](http://greenlitgaming.com/)
- [HTML5 Game Devs Forum](http://www.html5gamedevs.com/)
- [HobbyGameDev](http://www.hobbygamedev.com/)
- [Html5 Game Development](http://www.html5gamedevelopment.com/)
- [IndieDB](http://www.indiedb.com/)
- [Mod DB](http://www.moddb.com/)
- [Java Gaming](http://www.java-gaming.org/)
- [Lost Garden](http://www.lostgarden.com/)
- [Polygon](http://www.polygon.com/)
- [Real-Time Rendering](http://www.realtimerendering.com/)
- [Slidedb](http://www.slidedb.com/) - On Slide DB we give developers a community they can share their ideas with and showcase the work they are doing, beyond the basic app stores and the highly contested ""top charts"".
- [Superlevel](https://superlevel.de/)
- [TIGSource](http://www.tigsource.com/)
- [WhatGamesAre](http://www.whatgamesare.com/featured-posts.html)
- [iforce2d](http://www.iforce2d.net/)
- [indiegames](http://indiegames.com/index.html)

### Books

- :free: [2D Game Development: From Zero To Hero](https://gitlab.com/Penaz/2dgd_f0th)

* [3D Math Primer for Graphics and Game Development](http://www.amazon.com/Math-Primer-Graphics-Game-Development/dp/1568817231/)
* [Artificial Intelligence for Games](http://www.amazon.com/dp/0123747317?tag=game-prog-books-20)
* [Designing Games: A Guide to Engineering Experiences](https://www.amazon.com/Designing-Games-Guide-Engineering-Experiences/dp/1449337937)
* [Essential Mathematics for Games and Interactive Applications: A Programmer's Guide](http://www.amazon.com/Essential-Mathematics-Games-Interactive-Applications/dp/0123742978/)
* [Flow](http://www.amazon.com/Flow-The-Psychology-Optimal-Experience/dp/0061339202/)
* [Game Coding Complete](http://www.amazon.com/Game-Coding-Complete-Fourth-McShaffry/dp/1133776574/)
* [Game Development Essentials: Game Level Design](http://www.goodreads.com/book/show/1633392.Game_Development_Essentials)
* [Game Engine Architecture](http://www.gameenginebook.com/)
* [Game Mechanics: Advanced Game Design](http://www.goodreads.com/book/show/13705461-game-mechanics)
* [Game Programming Gems](http://www.amazon.com/Game-Programming-Gems-CD/dp/1584500492)
* [Game Programming Patterns](http://gameprogrammingpatterns.com/)
* [Game Scripting Mastery](http://www.amazon.com/Scripting-Mastery-Premier-Press-Development/dp/1931841578)
* [Geometry for Programmers (book)](https://www.manning.com/books/geometry-for-programmers)
* [Hello Scratch: Learn to Program by Making Arcade Games](https://www.manning.com/books/hello-scratch)
* [Level Up!](http://www.amazon.com/dp/047068867X?tag=game-prog-books-20)
* [Making Games with Python & Pygame](http://inventwithpython.com/pygame/)
* [Mathematics For 3D Game Programming And Computer Graphics](http://www.amazon.com/dp/1435458869?tag=game-prog-books-20)
* [Nature of Code](http://natureofcode.com/book/)
* [Physics for Game Developers](http://www.amazon.com/Physics-Game-Developers-David-Bourg/dp/0596000065)
* [Programming Game AI by Example](http://www.amazon.com/dp/1556220782?tag=game-prog-books-20)
* [Real-Time Rendering](http://www.amazon.com/Real-Time-Rendering-Third-Edition-Akenine-Moller/dp/1568814240/)
* [Rules of Play](http://www.amazon.com/Rules-Play-Game-Design-Fundamentals/dp/0262240459/)
* [The Art of Game Design](http://www.amazon.com/The-Art-Game-Design-lenses/dp/0123694965/)
* [The Ultimate Guide to Video Game Writing and Design](http://www.goodreads.com/book/show/391752.The_Ultimate_Guide_to_Video_Game_Writing_and_Design)
* [The Visual Story](http://www.amazon.com/The-Visual-Story-Creating-Structure/dp/0240807790/)
* [Theory of Fun](http://www.amazon.com/Theory-Game-Design-Raph-Koster/dp/1449363210/)
* [Tricks of the Windows Game Programming Gurus](http://www.amazon.com/Tricks-Windows-Game-Programming-Gurus/dp/0672313618)
* [Unity in Action (book)](https://www.manning.com/books/unity-in-action-second-edition)
* [Learn OpenGL: Beginner's guide to 3D rendering and game development with OpenGL and C++](https://www.amazon.de/Learn-OpenGL-Beginners-rendering-development/dp/1789340365/ref=sr_1_1_sspa?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&keywords=OpenGl+3d+game&qid=1570646865&sr=8-1-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUExTzM3UzZDT1ZYUzdCJmVuY3J5cHRlZElkPUEwMDIzMjkxMzJENlFTWkJNQzVCNCZlbmNyeXB0ZWRBZElkPUEwMzgyNTgzMUdUOElZTUtNUjlONCZ3aWRnZXROYW1lPXNwX2F0ZiZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU=)

### Magazines

- :free: [Game Developer Magazine](http://www.gdcvault.com/gdmag)
- :free: [IndieMag](https://www.indiemag.fr/)

### Videos/Podcasts

- [awesome-gametalks](https://github.com/hzoo/awesome-gametalks) - A curated list of game talks (GDC, youtube, etc).
- [Twitch GameDev](http://www.twitch.tv/directory/game/Game%20Development) - Twitch GameDev Streams

### Game Jams

- [Game jams on itch.io](https://itch.io/jams) - Listing of itch.io game jams
- [Game Off](https://gameoff.github.com) - GitHub's game jam :octocat:
- [GMTK Game Jam](https://itch.io/jam/gmtk-jam-2022) - Popular yearly game jam
- [Indie Game Jams](http://www.indiegamejams.com/) - Listing of game jams
- [Ludum Dare](http://ludumdare.com/) - very popular game jam
- [One Hour Game Jam](http://onehourgamejam.com/) - Weekly 1 hour game jam

### Project Management

- :moneybag: [Casual](https://casual.pm/) - Visual Project Management
- :money_with_wings: [Codecks](https://www.codecks.io) - Project Management Tool inspired by Collectible Card Games
- :money_with_wings: [HacknPlan](http://hacknplan.com/) - Project management for game developers
- :money_with_wings: [Taiga](https://taiga.io/) - Project management platform for agile developers & designers
- :money_with_wings: [Trello](https://trello.com/) - Organize and prioritize projects

### Complete Game Sources

- :tada: [Canabalt iOS](https://github.com/ericjohnson/canabalt-ios)
- :tada: [Doom 3](https://github.com/id-Software/DOOM-3)
- :tada: [Doom](https://github.com/id-Software/DOOM)
- :tada: [Duke Nukem 3D: Atomic Edition](http://legacy.3drealms.com/duke3d/)
- :tada: [NetHack](https://github.com/NetHack/NetHack)
- :tada: [OpenRA](https://github.com/OpenRA/OpenRA)
- :tada: [OpenTTD](https://github.com/OpenTTD/OpenTTD)
- :tada: [Prince of Persia](https://github.com/jmechner/Prince-of-Persia-Apple-II)
- :tada: [Quake 2](https://github.com/id-Software/Quake-2)
- :tada: [Quake III Arena](https://github.com/id-Software/Quake-III-Arena)
- :tada: [Quake](https://github.com/id-Software/Quake)
- :tada: [SimCity](https://github.com/simhacker/micropolis)
- :tada: [Wolfenstein 3D](https://github.com/id-Software/wolf3d)
- :free: [VVVVVV](https://github.com/TerryCavanagh/VVVVVV)

## Ads

_We still need to make some money, right?_

- [AdMob by Google](https://www.google.com/admob/) - Google's Ads and monetization service for mobile.
- [AdColony](http://www.adcolony.com/) - Mobile video Ads service.
- [Appodeal](http://www.appodeal.com/) - A programmatic ad mediation solution for mobile apps.
- [ChartBoost](https://www.chartboost.com/) - Monetization, analytics platform.
- [Unity Ads](https://unity.com/products/unity-ads) - Unity3D Official Ads SDK.
- [Vungle](https://vungle.com/) - Video Ads service.

## Learn

_Online courses, tutorials, screencasts_

### General Game Development

- :moneybag: [Coursera: Introduction to interactive Python programming](https://www.coursera.org/course/interactivepython1)
- :free: [HandmadeHero: making 2D game from scratch](https://handmadehero.org/)
- :free: [Khan Academy: Advanced JS: Games & Visualizations](https://www.khanacademy.org/computing/cs/programming-games-visualizations)
- :free: [Simple HTML5 Canvas Game](http://www.lostdecadegames.com/how-to-make-a-simple-html5-canvas-game/)
- :free: [miloyip/game-programmer](https://github.com/miloyip/game-programmer) A Study Path for Game Programmer :octocat:
- :free: [TheChernoProject](https://www.youtube.com/user/TheChernoProject)
- :free: [Udacity: HTML5 Game Development](https://www.udacity.com/course/html5-game-development--cs255)

### Computer Graphics

- :free: [3D Game Shaders For Beginners](https://github.com/lettier/3d-game-shaders-for-beginners)
- :free: [Interactive 3D Graphics](https://www.udacity.com/course/interactive-3d-graphics--cs291)
- :moneybag: [Interactive Computer Graphics](https://www.coursera.org/learn/interactive-computer-graphics)
",12153,12153,428,6,art,"[art, awesome, awesome-list, board-games, curated, design, frameworks, game-design, game-development, game-engine, game-jam, game-programming, gamedev, games, hacktoberfest, list]",0
CodingTrain,website-archive,CodingTrain,https://github.com/CodingTrain/website-archive,https://api.github.com/repos/website-archive/CodingTrain,Archive of the Coding Train website (first version),"<p align=""center"">
  <img width=""800"" alt=""The Coding Train Logo"" src=""https://github.com/CodingTrain/website/blob/main/.github/logo.png?raw=true"">
</p>
</br>

# Current Status

This repository is no longer maintained as we have moved to <a href=""https://thecodingtrain.com"">a new website</a> and <a href=""https://github.com/CodingTrain/thecodingtrain.com"">repo</a>. Please note it is still accessable through <a href= ""https://codingtrain.github.io/website-archive/"">github.io</a> but should only be used for archive purposes.


# Repository Content
Hello and welcome to the GitHub repository for The Coding Train website! This houses all of the content at <a href=""https://thecodingtrain.com/"">thecodingtrain.com</a> as well as source code for corresponding videos. The site welcomes contributions from the community in a variety of ways! More information at <a href=""CONTRIBUTING.md"">CONTRIBUTING.md</a>.

# Other links

- [The Coding Train on YouTube](https://www.youtube.com/thecodingtrain/)
- [Become a YouTube Member](https://youtube.com/thecodingtrain/join)
- [For topic suggestions](https://github.com/CodingTrain/Rainbow-Topics/)
- [Join The Coding Train Discord](https://discord.gg/hPuGy2g)
- [Coding questions](https://discourse.processing.org)

# Live Streams

Live streams are announced as events on YouTube, [please subscribe and press the bell icon to receive notifications for events](https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw/subscribe)!

# Add your own variation

If you want to share your own variation based on a Coding Train video, visit the page corresponding to the video on our [website](http://thecodingtrain.com). Check out the [Community Contributions Guide](https://thecodingtrain.com/Guides/community-contribution-guide.html) to see how it is done. It will then be featured right under the video on the website for everyone to see!

# Help by adding pages for video tutorials

We are currently in the process of migrating videos and community contributions to our new system. If you want to help with this, have a look at the [Content Contribution Guide](https://thecodingtrain.com/Guides/content-contribution-guide.html). Thanks for helping us out!
",5696,5696,379,26,art,"[art, design, education, hacktoberfest, learning, youtube]",0
williamngan,pts,,https://github.com/williamngan/pts,https://api.github.com/repos/pts/williamngan,A library for visualization and creative-coding,"# Pts

![image](./assets/pts-gif-10.gif)   

Pts is a typescript/javascript library for visualization and creative-coding. 

**Get started at [ptsjs.org](https://ptsjs.org)**.

Please give it a try, [file issues](https://github.com/williamngan/pts/issues), and send feedbacks to [@williamngan](https://twitter.com/williamngan). Thank you!

---    

### Usage

**Option 1**   
Get the latest `pts.js` or `pts.min.js` (in [dist](https://github.com/williamngan/pts/tree/master/dist) folder). Alternatively use a CDN service like [cdnjs](https://cdnjs.com/libraries/pts) or [jsdelivr](https://cdn.jsdelivr.net/gh/williamngan/pts/dist/pts.min.js) or [unpkg](https://unpkg.com/pts/dist/pts.min.js). Then add it to your html page like this:
```html
<script type=""text/javascript"" src=""path/to/pts.js""></script>
```
Pts is pretty lightweight. Currently at ~100kb minified and 30kb gzipped.


**Option 2:**   
Install via `npm install pts`. Then you can choose to import some parts of Pts into your project as needed. 
```js
import {CanvasSpace, Pt, Group, Line} from 'pts';
```

To quickly get started, try download or clone these repos:
- [pts-starter-kit](https://github.com/williamngan/pts-starter-kit): Get started with a sample app using npm and webpack
- [pts-react-example](https://github.com/williamngan/pts-react-example): Try an example of using Pts with React.
- [react-pts-canvas](https://www.npmjs.com/package/react-pts-canvas): Use it in your React project by extending react-pts-canvas component

**Get Started**   
Read the [guides](https://ptsjs.org/guide/get-started-0100) and take a look at the [demos](https://ptsjs.org/demo/?name=circle.intersectCircle2D) and their source code.    
If you need help, please don't hesitate to [file an issue](https://github.com/williamngan/pts/issues).

---    

### For development

Pts is written in typescript. You can clone or fork this project and build it as follows:

#### Build and test

Clone this repo and install dependencies via `npm install`.

```bash
npm start
npm run build
npm test
```

#### Generate documentations
Run this to generate Pts styled documentations. (Requires python 3.6)
```bash
npm run docs 
```

If you prefer to generate default typedocs, run this:
```bash
typedoc --readme none --out typedocs src --name Pts
```

---

### Contributing

We appreciate your support and feedbacks!

Please file issues if you find bugs and have feature requests. If you are able to send small PRs to improve Pts or fix bugs, that would be awesome too. 

For larger PRs, please ping [@williamngan](https://twitter.com/williamngan) to discuss first.

---    

### License
Apache License 2.0. See LICENSE file for details.   
Copyright © 2017-today by William Ngan and contributors.

",5028,5028,67,45,art,"[art, canvas, creative-coding, design, generative, generative-art, graphic-design, graphics, linear-algebra, pts, sound, svg, typescript, vector, visualization]",0
lief-project,LIEF,lief-project,https://github.com/lief-project/LIEF,https://api.github.com/repos/LIEF/lief-project,LIEF - Library to Instrument Executable Formats,"<p align=""center"" >
<img width=""90%"" src=""https://github.com/lief-project/LIEF/blob/master/.github/images/architecture.png""/><br />
</p>

<p align=""center"">
  <a href=""https://discord.gg/7hRFGWYedu"">
    <img src=""https://img.shields.io/discord/1117013848914931762"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/linux-x86-64.yml"">
    <img alt=""Linux x86-64 CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/linux-x86-64.yml?branch=master&label=Linux%20x86-64&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/linux-aarch64.yml"">
    <img alt=""Linux AArch64 CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/linux-aarch64.yml?branch=master&label=Linux%20AArch64&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/android.yml"">
    <img alt=""Android CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/android.yml?branch=master&label=Android&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/osx.yml"">
    <img alt=""macOS CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/osx.yml?branch=master&label=macOS&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/ios.yml"">
    <img alt=""iOS CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/ios.yml?branch=master&label=iOS&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/actions/workflows/windows-all.yml"">
    <img alt=""Windows CI status"" src=""https://img.shields.io/github/actions/workflow/status/lief-project/LIEF/windows-all.yml?branch=master&label=Windows&logo=github"">
  </a>
  &nbsp;
  <a href=""https://github.com/lief-project/LIEF/releases"">
    <img src=""https://img.shields.io/github/v/release/lief-project/LIEF?style=flat-square"">
  </a>
  &nbsp;
  <a href=""https://twitter.com/LIEF_project"">
   <img alt=""Twitter Follow"" src=""https://img.shields.io/twitter/follow/lief_project"">
  </a>
</p>

<br />
<p align=""center"">
  <a href=""https://lief-project.github.io/blog/""><b>Blog</b></a> •
  <a href=""https://lief-project.github.io/doc/latest/index.html""><b>Documentation</b></a> •
  <a href=""#user-content-about-1""><b>About</b></a>
</p>
<br />

# About

The purpose of this project is to provide a cross platform library which can parse,
modify and abstract ELF, PE and MachO formats.

Main features:

  * **Parsing**: LIEF can parse ELF, PE, MachO, OAT, DEX, VDEX, ART and provides an user-friendly API to access to format internals.
  * **Modify**: LIEF enables to modify some parts of these formats
  * **Abstract**: Three formats have common features like sections, symbols, entry point... LIEF factors them.
  * **API**: LIEF can be used in C, C++ and Python

# Content

- [About](#about)
- [Download / Install](#downloads--install)
- [Getting started](#getting-started)
- [Documentation](#documentation)
  - [Sphinx](https://lief-project.github.io/doc/stable/index.html)
  - [Doxygen](https://lief-project.github.io/doc/latest/doxygen/index.html)
  - Tutorials:
    - [Parse and manipulate formats](https://lief-project.github.io/doc/latest/tutorials/01_play_with_formats.html)
    - [Create a PE from scratch](https://lief-project.github.io/doc/latest/tutorials/02_pe_from_scratch.html)
    - [Play with ELF symbols](https://lief-project.github.io/doc/latest/tutorials/03_elf_change_symbols.html)
    - [ELF Hooking](https://lief-project.github.io/doc/latest/tutorials/04_elf_hooking.html)
    - [Infecting the plt/got](https://lief-project.github.io/doc/latest/tutorials/05_elf_infect_plt_got.html)
    - [PE Hooking](https://lief-project.github.io/doc/latest/tutorials/06_pe_hooking.html)
    - [PE Resources](https://lief-project.github.io/doc/latest/tutorials/07_pe_resource.html)
    - [Transforming an ELF executable into a library](https://lief-project.github.io/doc/latest/tutorials/08_elf_bin2lib.html)
    - [How to use frida on a non-rooted device](https://lief-project.github.io/doc/latest/tutorials/09_frida_lief.html)
    - [Android formats](https://lief-project.github.io/doc/latest/tutorials/10_android_formats.html)
    - [Mach-O modification](https://lief-project.github.io/doc/latest/tutorials/11_macho_modification.html)
    - [ELF Coredump](https://lief-project.github.io/doc/latest/tutorials/12_elf_coredump.html)
    - [PE Authenticode](https://lief-project.github.io/doc/latest/tutorials/13_pe_authenticode.html)
- [Contact](#contact)
- [About](#about)
  - [Authors](#authors)
  - [License](#license)
  - [Bibtex](#bibtex)

## Downloads / Install

First, make sure to have an updated version of setuptools:

```console
pip install setuptools --upgrade
```

To install the latest **version** (release):

```console
pip install lief
```

To install nightly build:

```console
pip install [--user] --index-url https://lief.s3-website.fr-par.scw.cloud/latest lief==0.14.0.dev0
```

### Packages

- **Nightly**:
  * SDK: https://lief.s3-website.fr-par.scw.cloud/latest/sdk
  * Python Wheels: https://lief.s3-website.fr-par.scw.cloud/latest/lief
- **v0.13.2**: https://github.com/lief-project/LIEF/releases/tag/0.13.2

Here are guides to install or integrate LIEF:

  * [Python](https://lief-project.github.io/doc/latest/installation.html#python)
  * [VisualStudio](https://lief-project.github.io/doc/latest/installation.html#visual-studio-integration)
  * [XCode](https://lief-project.github.io/doc/latest/installation.html#xcode-integration)
  * [CMake](https://lief-project.github.io/doc/latest/installation.html#cmake-integration)

## Getting started

### Python

```python
import lief

# ELF
binary = lief.parse(""/usr/bin/ls"")
print(binary)

# PE
binary = lief.parse(""C:\\Windows\\explorer.exe"")
print(binary)

# Mach-O
binary = lief.parse(""/usr/bin/ls"")
print(binary)
```

### C++

```cpp
#include <LIEF/LIEF.hpp>

int main(int argc, char** argv) {
  // ELF
  if (std::unique_ptr<const LIEF::ELF::Binary> elf = LIEF::ELF::Parser::parse(""/bin/ls"")) {
    std::cout << *elf << '\n';
  }

  // PE
  if (std::unique_ptr<const LIEF::PE::Binary> pe = LIEF::PE::Parser::parse(""C:\\Windows\\explorer.exe"")) {
    std::cout << *pe << '\n';
  }

  // Mach-O
  if (std::unique_ptr<LIEF::MachO::FatBinary> macho = LIEF::MachO::Parser::parse(""/bin/ls"")) {
    std::cout << *macho << '\n';
  }

  return 0;
}

```

### C (Limited API)

```cpp
#include <LIEF/LIEF.h>

int main(int argc, char** argv) {
  Elf_Binary_t* elf = elf_parse(""/usr/bin/ls"");

  Elf_Section_t** sections = elf->sections;

  for (size_t i = 0; sections[i] != NULL; ++i) {
    printf(""%s\n"", sections[i]->name);
  }

  elf_binary_destroy(elf);
  return 0;
}
```

## Documentation

* [Main documentation](https://lief-project.github.io/doc/latest/index.html)
* [Tutorial](https://lief-project.github.io/doc/latest/tutorials/index.html)
* [API](https://lief-project.github.io/doc/latest/api/index.html)
* [Doxygen](https://lief-project.github.io/doc/latest/doxygen/index.html)

## Contact

* **Mail**: contact at lief re
* **Discord**: [LIEF](https://discord.gg/7hRFGWYedu)

## About

### Authors

Romain Thomas ([@rh0main](https://twitter.com/rh0main)) - [Quarkslab](https://www.quarkslab.com)

### License

LIEF is provided under the [Apache 2.0 license](https://github.com/lief-project/LIEF/blob/0.13.0/LICENSE).

### Bibtex

```bibtex
@MISC {LIEF,
  author       = ""Romain Thomas"",
  title        = ""LIEF - Library to Instrument Executable Formats"",
  howpublished = ""https://lief.quarkslab.com/"",
  month        = ""apr"",
  year         = ""2017""
}
```


",3861,3861,125,83,art,"[android, art, binary-analysis, dex, elf, executable-formats, lief, macho, malware-analysis, modification, oat, parser, parsing, pe, python, reverse-engineering, sdk, vdex]",0
artsy,eigen,artsy,https://github.com/artsy/eigen,https://api.github.com/repos/eigen/artsy,"The Art World in Your Pocket or Your Trendy Tech Company's Tote, Artsy's mobile app.","<a href=""http://iphone.artsy.net""><img src =""docs/screenshots/overview.png""></a>

### Meta

- **State:** Production
- **[Point People](https://www.notion.so/artsy/17c4b550458a4cb8bcbf1b68060d63e6?v=3604e2682d024b64bde705abb2facebd):** [Brian Beckerle](https://github.com/brainbicycle), [Mounir Dhahri](https://github.com/MounirDhahri), [George Kartalis](https://github.com/gkartalis)
- **CI :** [![Build Status](https://circleci.com/gh/artsy/eigen.svg?style=shield)](https://circleci.com/gh/artsy/eigen)

### Intro

Don't know what Artsy is?
Check out [this overview](https://github.com/artsy/README/blob/main/culture/what-is-artsy.md#artsy-in-a-nutshell) or read our objc.io on [team culture](https://www.objc.io/issues/22-scale/artsy).

[Artsy](https://github.com/artsy) is an Open Source project. Feel free to check the [Artsy readme](https://github.com/artsy/README) for an overview as well as [Practices](https://github.com/artsy/README/tree/main/practices) and [Playbooks](https://github.com/artsy/README/tree/main/playbooks).

Eigen is Artsy's mobile app repository.

Want to know more about Eigen? Read the [mobile](http://artsy.github.io/blog/categories/mobile/) blog posts, or [eigen's](http://artsy.github.io/blog/categories/eigen/) specifically.

Other mobile projects are [Energy](https://github.com/artsy/energy), with the retired [Eidolon](https://github.com/artsy/eidolon), [Emission](https://github.com/artsy/emission) and [Emergence](https://github.com/artsy/emergence).

### Getting Started

- Get set up [here](docs/getting_started.md).

- Read about our [best practices](docs/best_practices.md).

- Further documentation can be found in the [documentation folder](docs#readme).

### Deployment

For how we deploy, check out the dedicated documentation:

- [Deploying a beta](docs/deploy_to_beta.md)
- [Deploying to the App Store](docs/deploy_to_app_store.md)

### Thanks

Thanks to all [our contributors](/docs/thanks.md).

## License

MIT License. See [LICENSE](LICENSE).

## About Artsy

<a href=""https://www.artsy.net/"">
  <img align=""left"" src=""https://avatars2.githubusercontent.com/u/546231?s=200&v=4""/>
</a>

This project is the work of engineers at [Artsy][footer_website], the world's
leading and largest online art marketplace and platform for discovering art.
One of our core [Engineering Principles][footer_principles] is being [Open
Source by Default][footer_open] which means we strive to share as many details
of our work as possible.

You can learn more about this work from [our blog][footer_blog] and by following
[@ArtsyOpenSource][footer_twitter] or explore our public data by checking out
[our API][footer_api]. If you're interested in a career at Artsy, read through
our [job postings][footer_jobs]!

[footer_website]: https://www.artsy.net/
[footer_principles]: https://github.com/artsy/README/blob/main/culture/engineering-principles.md
[footer_open]: https://github.com/artsy/README/blob/main/culture/engineering-principles.md#open-source-by-default
[footer_blog]: https://artsy.github.io/
[footer_twitter]: https://twitter.com/ArtsyOpenSource
[footer_api]: https://developers.artsy.net/
[footer_jobs]: https://www.artsy.net/jobs
",3327,3327,123,16,art,"[android, app, app-store, art, ios, objective-c, react-native, swift]",0
inconvergent,weird,,https://github.com/inconvergent/weird,https://api.github.com/repos/weird/inconvergent,Generative art in Common Lisp,"# WEIRD-A Generative Art System

**NOTE: I will probably not update this repo anymore. See
[auxin](https://github.com/inconvergent/auxin). For a stripped version of this
repo**

**NOTE: weird reqires cl-veq. the most recent compatible version of cl-veq must
be installed locally for this system to work properly:
https://github.com/inconvergent/cl-veq/releases/tag/v4.1.0-beta **

**NOTE: An improved version of the graph data structure in the `weir` package
can be found in my new project:
[cl-grph](https://github.com/inconvergent/cl-grph). Among multiple
improvements, the graph structure in `grph` is immutable, and supports Datalog
queries.**

## About

`weird` is the next iteration of [weir](https://github.com/inconvergent/weir),
which was the next iteration of [snek](https://github.com/inconvergent/snek).

The library is written to be useful for a broad range of ways in which I create
art using generative algorithms. Almost everything I have made over the past
several years has been made using some version of this system.

![Elastic Web](img/web.png)

## Components

Here are the main components:

1. 2d/3d vector mathematics via
   [cl-veq](https://github.com/inconvergent/cl-veq).  See
   [examples](https://github.com/inconvergent/cl-veq/blob/master/examples/ex.lisp)
   in veq for more details.

2. A simple (undirected) graph data structure called `weir`. The structure can
   be manipulated directly, or via `alterations`. The latter is described in
   more detail below. Here is a simple example of how you can manipulate the
   structure directly:

   ```lisp
   (in-package :weir)
   (let ((wer (make)))
     ; add three edges
     (loop repeat 3
           do (add-edge! wer
                (2add-vert! wer
                  (rnd:2in-circ 200.0))
                (2add-vert! wer
                  (veq:f2+ (veq:2rep 500.0)
                           (rnd:2in-circ 200.0))))
     ; iterate verts
     (itr-verts (wer v)
       ; prints vert coordinates
       (veq:vpr (2get-vert wer v)))

     ; iterate edges
     (itr-edges (wer vv)
       (veq:vpr (2get-verts wer vv)))

     ; move a vert relativ to current position:
     (2move-vert! wer 0 1.0 2.0)
     ; or to an absolute position
     (2move-vert! wer 1 1.0 2.0 :rel nil)

     ; edges are represented as lists of verts, and they are always
     ; sorted with the smallest vert index first, so both of these
     ; return t:
     (edge-exists wer '(0 1))
     (edge-exists wer '(1 0))

     ; get edges incident to vert 0
     (get-incident-edges wer 0))
   ```
   See [examples/draw.lisp](examples/draw.lisp) and
   [examples/ex.lisp](examples/ex.lisp) for more.

3. Random numbers, some examples:

   ```lisp
   (in-package :rnd)
   (rnd a) ; in range [0.0, a), defaults to a=1.0.
   (rnd* a) ; in range [-a, a), defaults to a=1.0.
   (rndrng a b) ; in range [a, b)
   (rndi 10) ; random fixnum
   (rndspace n a b) ; n numbers in [a, b)
   (norm :mu 0.0 :sigma 1.0) ; normal distribution
   (2in-circ a) ; in circle of radius a
   (2in-rect w h) ; in a rectangle
   (2nin-rect n w h) ; n in rectangle.
   (2on-line ax ay bx by) ; point between points a and b

   ; do something with probability 0.1, second form is optional
   (prob 0.1 (print ""10% hi"") (print ""90% oh no""))

   ; perform either form 1 or (optionally) 2
   (either (print ""form 1"") (print ""form 2""))
   ```

   See [rnd.lisp](src/rnd/rnd.lisp), [2rnd.lisp](src/rnd/2rnd.lisp) and
   [3rnd.lisp](src/rnd/3rnd.lisp), for all available functions.

4. A tool for drawing `svg` files: `wsvg`. See [draw.lisp](/examples/draw.lisp).

In addition the library contains a number of useful tools for dealing with
(predominantly) vector graphics.

![Sun](img/sun.png)

## Weir Graphs and Alterations

In my opinion, the most interesting part of the `weir` graph structure is
`alterations`. An `alteration` is a change that will be applied to the
structure at the end of a given context, provided it is valid.

The main motivation behind this is that this makes it possible to gather up a
number of changes that will be applied to the graph at a later time. This makes
it possible to access the state in the `weir` instance while you are creating
the alterations. Without there being any changes made to the state of the
`weir` instance while the alterations are being created. Once all alterations
are created, the valid ones will be applied.

Existing alterations in `weir` are postfixed with `?`. It might look like this:

```lisp
(weir:with (wer %)
  (% (add-vert? (veq:f2 100.0 740.0))
  (% (add-edge? 1 4)))
```

`(% ...)` is used to collect alterations. They will be executed at the end of
the `with` context. If an `alteration` evaluates to `nil`, nothing will happen.

Here is an example of how the forces are calculated in my [Tangle of Webs
simulation](https://inconvergent.net/2019/a-tangle-of-webs/):

```lisp
(veq:vdef* reciprocal-edge-forces (wer &key (stp 0.1))
  (weir:with (wer %)
    ; state of wer is unaltered
    (weir:itr-edges (wer e) ; edge (v0 v1)
      ; vector from v0 to v1
      ; force is proportional to this ""oriented distance""
      (veq:f2let ((force (veq:f2-
                           (veq:f2$ (weir:2get-verts wer e)
                                    1 0))))
        (loop for i in e and s in '(-1.0 1.0)
              ; alteration is created, but nothing happens
              do (% (2move-vert? i
                      (veq:f2scale force (* s stp)))))))))
    ; alterations are applied at the end
    ; of the context
```

The important thing to note here is that for the forces to be calculated
correctly, all edge lengths must be calculated _before_ the forces are applied
to the vertices.

![Symbols](img/symbols.png)

### Futures and Dependencies

You can assign a name to the result of an alteration using
```lisp
(% (add-edge? 1 3) :res :some-name?)
```
This makes it possible to create alterations that depend on the result of other
alterations:

```lisp
(in-package :weir)
(with (wer %)
  (veq:f2let ((pt (veq:f2 1f0 3f0)))
    (% (2add-vert? pt) :res :a?) ; alteration result is named :a?
    (% (2add-vert? (veq:f2 1.0 2.0)) :res :b?) ; result named :b?
    (% (add-edge? :a? :b?)))) ; depends on :a? and :b?

; all alteration results:
(print (get-alteration-result-list wer))
; or as a `hash-map`:
(print (get-alteration-result-map wer))
```

`alteration` names must be `keywords` that end with `?`. (There is an
exception, see [Looping](#Looping) below.) And using the same name for multiple
alterations _will_ result in undefined behaviour.

As you can see, a named alteration is akin to a _future_; a reference to a
result that may or may not exist eventually. For this to work, any alteration
that depends on a future that fails (or returns `nil`) will be skipped.

You can use `(weir:with (wer % :bd t) ...)` to see how an alteration is
expanded. This might make it easier to see what is going on.

As en example. The `alteration`:
```lisp
(% (2move-vert? :vert?
     (veq:f2scale
       (veq:f2- (veq:f2$ (weir:2get-verts wer '(1 3)) 1 0))
       1f0)))
```
will be expanded to:
```lisp
(VEQ:F2LET
 ((#:OUT-F2!P53
   (VEQ:F2SCALE (VEQ:F2- (VEQ:F2$ (WEIR:2GET-VERTS WER '(1 3)) 1 0)) 1.0)))
 (LET ((#:OUT-REL54 T))
   (LAMBDA (#:WER541)
     (CASE (WEIR::-IF-ALL-RESOLVED #:ALT-RES29 (LIST :VERT?))
       (:OK
        (VALUES T
                (PROGN
                 (WHEN
                     (WEIR::-VALID-VERT #:WER541
                                        (VALUES (GETHASH :VERT? #:ALT-RES29)))
                   (PROGN
                    (WEIR:2MOVE-VERT! #:WER541
                                      (VALUES (GETHASH :VERT? #:ALT-RES29))
                                      (WEIR::VAL* #:OUT-F2!P53)
                                      :REL #:OUT-REL54)
                    (VALUES (GETHASH :VERT? #:ALT-RES29)))))))
       (:BAIL (PROGN NIL (VALUES T NIL)))
       (T (VALUES NIL NIL))))))
```
Which won't work in its own unless `:VERT?` is also defined. But you can see how
the promise resolution is handled. And how values (`#:OUT-REL54`,
`#:OUT-F2!P53`) are defined in the surrounding closure.

![Scribbles](img/scribble.png)

### Looping

It is possible to use `alterations` inside loops as well. but it requires a bit
more careful consideration. Here is an example:


```lisp
(in-package :weir)
(with (wer % :db t)
  (loop for x in (math:linspace 20 -20.0 20.0) do
    (loop for z in (list 1.0 2.0) do
      (veq:f3let ((xy (veq:f3 x y z)))
        ; create a distinct name
        (let ((g? (gensym ""g"")))
          (% (add-grp? :name (gensym ""line"")) :res g?)
          (% (2add-path?
               (veq:f$_ (list (veq:f3-
                                xy (veq:f3 1.0 8.0 (rnd:rnd)))
                              (veq:f3+
                                xy (veq:f3 1.0 2.0 (rnd:rnd)))))
               :g g?)))))))
```


## Writing

I have written about things related to this code at:

  - https://inconvergent.net/2017/snek-is-not-an-acronym/
  - https://inconvergent.net/2017/a-method-for-mistakes/
  - https://inconvergent.net/2017/arbitrary-alterations/
  - https://inconvergent.net/2017/grains-of-sand/
  - https://inconvergent.net/2017/a-propensity-for-mistakes/
  - https://inconvergent.net/2020/future-alterations/
  - https://inconvergent.net/2021/future-alterations-and-loops/

Note that these posts refer to older iterations of the code. So some of the
things will be out of date.

![Boxes](img/boxes.png)


## On Use and Contributions

This code is written for my personal use, and parts of it is rather
experimental. Also, it is likely to change at my whim. For this reason I don't
recommend depending on this library for anything.

I release it publicly in case people find it useful or interesting. It is not,
however, intended as a collaboration/Open Source project. As such I am unlikely
to accept PRs, reply to issues, or take requests.


## Installation and Dependencies

`weird` depends on
[cl-veq](https://github.com/inconvergent/cl-veq/releases/tag/v4.1.0-beta), and
it requires Quicklisp to install other dependencies (which are listed in
`weird.asd`).

To install and load `weird`, do:
```lisp
(ql:quickload :weird)
```
If this does not work, `weird` may not be in a place Quicklisp or ASDF can see
them. To fix this, either:
```lisp
(load ""weird.asd"")
```
For a long term solution, add the following to `.sbclrc`:
```lisp
#+quicklisp
(push ""/path/to/dir/containing/weird"" ql:*local-project-directories*)
```
You will have to make sure `cl-veq` is also available in the same fashion for
any of this to work.

### Versions and Compatability

Weird version 6.1.0 requires version `cl-veq` 2.2.0.


### Tests

Tests can be executed using: `(asdf:test-system :weird)`.


## Thanks

I would like to thank:

  - https://twitter.com/RainerJoswig
  - https://twitter.com/jackrusher
  - https://twitter.com/paulg
  - https://twitter.com/porglezomp
  - https://twitter.com/stylewarning
  - https://github.com/Hellseher

Who have provided me with useful hints and code feedback.

The ASDF config and test setup was kindly suggested and implemented by Robert
Smith (https://twitter.com/stylewarning). Although I have made some changes
since then.

Also, many thanks to https://twitter.com/xach for making Quicklisp.

",1562,1562,29,0,art,"[art, common-lisp, generative, generative-art, graph, graph-algorithms, lisp, plotter-art, plotters, svg, vector-graphics]",0
sepandhaghighi,samila,,https://github.com/sepandhaghighi/samila,https://api.github.com/repos/samila/sepandhaghighi,Generative Art Generator,"<div align=""center"">
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/logo.png"" width=400 height=400>
<br/>
<h1>Samila</h1>
<br/>
<a href=""https://www.python.org/""><img src=""https://img.shields.io/badge/built%20with-Python3-green.svg"" alt=""built with Python3"" /></a>
<a href=""https://codecov.io/gh/sepandhaghighi/samila"">
  <img src=""https://codecov.io/gh/sepandhaghighi/samila/branch/master/graph/badge.svg"" />
</a>
<a href=""https://badge.fury.io/py/samila""><img src=""https://badge.fury.io/py/samila.svg"" alt=""PyPI version"" height=""18""></a>
<a href=""https://anaconda.org/sepandhaghighi/samila""><img src=""https://anaconda.org/sepandhaghighi/samila/badges/version.svg""></a>
<a href=""https://colab.research.google.com/github/sepandhaghighi/samila/blob/master"">
  <img src=""https://colab.research.google.com/assets/colab-badge.svg"" alt=""Samila-Colab""/>
</a>
<a href=""https://discord.com/invite/94bz5QGZWb"">
  <img src=""https://img.shields.io/discord/900055829225562162.svg"" alt=""Discord Channel"">
</a>
</div>

----------
## Table of contents					
   * [Overview](https://github.com/sepandhaghighi/samila#overview)
   * [Installation](https://github.com/sepandhaghighi/samila#installation)
   * [Usage](https://github.com/sepandhaghighi/samila#usage)
   * [Mathematical Details](https://github.com/sepandhaghighi/samila#mathematical-details)
   * [Try Samila in Your Browser](https://github.com/sepandhaghighi/samila#try-samila-in-your-browser)
   * [Issues & Bug Reports](https://github.com/sepandhaghighi/samila#issues--bug-reports)
   * [Social Media](https://github.com/sepandhaghighi/samila#social-media)
   * [Contribution](https://github.com/sepandhaghighi/samila/blob/master/.github/CONTRIBUTING.md)
   * [References](https://github.com/sepandhaghighi/samila#references)
   * [Acknowledgments](https://github.com/sepandhaghighi/samila#acknowledgments)
   * [Authors](https://github.com/sepandhaghighi/samila/blob/master/AUTHORS.md)
   * [License](https://github.com/sepandhaghighi/samila/blob/master/LICENSE)
   * [Show Your Support](https://github.com/sepandhaghighi/samila#show-your-support)
   * [Changelog](https://github.com/sepandhaghighi/samila/blob/master/CHANGELOG.md)
   * [Code of Conduct](https://github.com/sepandhaghighi/samila/blob/master/.github/CODE_OF_CONDUCT.md)

## Overview

<p align=""justify"">	
Samila is a generative art generator written in Python, Samila lets you create images based on many thousand points. The position of every single point is calculated by a formula, which has random parameters. Because of the random numbers, every image looks different.
</p>


<table>
	<tr> 
		<td align=""center"">Open Hub</td>
		<td align=""center""><a href=""https://www.openhub.net/p/samila""><img src=""https://www.openhub.net/p/samila/widgets/project_thin_badge.gif""></a></td>	
	</tr>
	<tr>
		<td align=""center"">PyPI Counter</td>
		<td align=""center""><a href=""http://pepy.tech/project/samila""><img src=""http://pepy.tech/badge/samila""></a></td>
	</tr>
	<tr>
		<td align=""center"">Github Stars</td>
		<td align=""center""><a href=""https://github.com/sepandhaghighi/samila""><img src=""https://img.shields.io/github/stars/sepandhaghighi/samila.svg?style=social&label=Stars""></a></td>
	</tr>
</table>



<table>
	<tr> 
		<td align=""center"">Branch</td>
		<td align=""center"">master</td>	
		<td align=""center"">dev</td>	
	</tr>
    <tr>
		<td align=""center"">CI</td>
		<td align=""center""><img src=""https://github.com/sepandhaghighi/samila/workflows/CI/badge.svg?branch=master""></td>
		<td align=""center""><img src=""https://github.com/sepandhaghighi/samila/workflows/CI/badge.svg?branch=dev""></td>
	</tr>
</table>


<table>
	<tr> 
		<td align=""center"">Code Quality</td>
		<td><a href=""https://www.codacy.com/gh/sepandhaghighi/samila/dashboard?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=sepandhaghighi/samila&amp;utm_campaign=Badge_Grade""><img src=""https://app.codacy.com/project/badge/Grade/14df8ed5f8434aaea85889555b0182a9""/></a></td>
		<td><a href=""https://codebeat.co/projects/github-com-sepandhaghighi-samila-dev""><img alt=""codebeat badge"" src=""https://codebeat.co/badges/01e6aa48-4cc2-4d9c-8288-c9fb490ad371"" /></a></td>
		<td><a href=""https://www.codefactor.io/repository/github/sepandhaghighi/samila""><img src=""https://www.codefactor.io/repository/github/sepandhaghighi/samila/badge"" alt=""CodeFactor"" /></a></td>
	</tr>
</table>



## Installation		


### Source code
- Download [Version 1.1](https://github.com/sepandhaghighi/samila/archive/v1.1.zip) or [Latest Source](https://github.com/sepandhaghighi/samila/archive/dev.zip)
- Run `pip install -r requirements.txt` or `pip3 install -r requirements.txt` (Need root access)
- Run `python3 setup.py install` or `python setup.py install` (Need root access)				

### PyPI


- Check [Python Packaging User Guide](https://packaging.python.org/installing/)     
- Run `pip install samila==1.1` or `pip3 install samila==1.1` (Need root access)

### Easy install

- Run `easy_install --upgrade samila` (Need root access)

### Conda

- Check [Conda Managing Package](https://conda.io)
- `conda install -c sepandhaghighi samila` (Need root access)	


## Usage

### Magic
```pycon
>>> import matplotlib.pyplot as plt
>>> from samila import GenerativeImage
>>> g = GenerativeImage()
>>> g.generate()
>>> g.plot()
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/7.png"">	

### Basic
```pycon
>>> import random
>>> import math
>>> def f1(x, y):
    result = random.uniform(-1,1) * x**2  - math.sin(y**2) + abs(y-x)
    return result
>>> def f2(x, y):
    result = random.uniform(-1,1) * y**3 - math.cos(x**2) + 2*x
    return result
>>> g = GenerativeImage(f1, f2)
>>> g.generate()
>>> g.plot()
>>> g.seed
188781
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/1.png"">	

### Projection
```pycon
>>> from samila import Projection
>>> g = GenerativeImage(f1, f2)
>>> g.generate()
>>> g.plot(projection=Projection.POLAR)
>>> g.seed
829730
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/2.png"">	

* Supported projections : `RECTILINEAR`, `POLAR`, `AITOFF`, `HAMMER`, `LAMBERT`, `MOLLWEIDE` and `RANDOM`
* Default projection is `RECTILINEAR`

### Marker
```pycon
>>> from samila import Marker
>>> g = GenerativeImage(f1, f2)
>>> g.generate()
>>> g.plot(marker=Marker.CIRCLE, spot_size=10)
>>> g.seed
448742
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/9.png"">	

* Supported markers : `POINT`, `PIXEL`, `CIRCLE`, `TRIANGLE_DOWN`, `TRIANGLE_UP`, `TRIANGLE_LEFT`, `TRIANGLE_RIGHT`, `TRI_DOWN`, `TRI_UP`, `TRI_LEFT`, `TRI_RIGHT`, `OCTAGON`, `SQUARE`, `PENTAGON`, `PLUS`, `PLUS_FILLED`, `STAR`, `HEXAGON_VERTICAL`, `HEXAGON_HORIZONTAL`, `X`, `X_FILLED`, `DIAMOND`, `DIAMON_THIN`, `VLINE`, `HLINE` and `RANDOM`
* Default marker is `POINT`

### Rotation
You can even rotate your art by using `rotation` parameter. Enter your desired rotation for the image in degrees and you will have it.

```pycon
>>> g = GenerativeImage(f1, f2)
>>> g.generate()
>>> g.plot(rotation=45)
```

* Default rotation is 0

### Range
```pycon
>>> g = GenerativeImage(f1, f2)
>>> g.generate(start=-2*math.pi, step=0.01, stop=0)
>>> g.plot()
>>> g.seed
234752
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/3.png"">	

### Color
```pycon
>>> g = GenerativeImage(f1, f2)
>>> g.generate()
>>> g.plot(color=""yellow"", bgcolor=""black"", projection=Projection.POLAR)
>>> g.seed
1018273
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/4.png"">	

* Supported colors are available in `VALID_COLORS` list
* `color` and `bgcolor` parameters supported formats:

    1. Color name (example: `color=""yellow""`)
    2. RGB/RGBA (example: `color=(0.1,0.1,0.1)`, `color=(0.1,0.1,0.1,0.1)`)
    3. Hex (example: `color=""#eeefff""`)
    4. Random (example: `color=""random""`)
    5. Complement (example: `color=""complement"", bgcolor=""blue""`)
    6. Transparent (example: `bgcolor=""transparent""`)
    7. List (example: `color=[""black"", ""#fffeef"",...]`)

⚠️ **Transparent** mode is only available for background

⚠️ **List** mode is only available for color

⚠️ In **List** mode, the length of this list must be equal to the lengths of data1 and data2

#### Point Color
You can make your custom color map and use it in Samila

```pycon
>>> colorarray = [
...  [0.7, 0.2, 0.2, 1],
...  [0.6, 0.3, 0.2, 1],
...  ""black"",
...  [0.4, 0.4, 0.3, 1],
...  [0.3, 0.4, 0.4, 1],
...  ""#ff2561""]
>>> g.generate()
>>> g.seed
454893
>>> g.plot(cmap=colorarray, color=g.data2, projection=Projection.POLAR)
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/8.png"">	


### Regeneration
```pycon
>>> g = GenerativeImage(f1, f2)
>>> g.generate(seed=1018273)
>>> g.plot(projection=Projection.POLAR)
>>> plt.show()
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/5.png"">	

### NFT.storage
Upload generated image directly to [NFT.storage](https://NFT.storage)

```pycon
>>> g.nft_storage(api_key=""YOUR_API_KEY"", timeout=5000)
{'status': True, 'message': 'FILE_LINK'}
```

You can also upload your config/data to nft storage as follows:
```pycon
>>> g.nft_storage(api_key=""API_KEY"", upload_config=True)
{'status': {'image': True, 'config':True}, 'message': {'image':'IMAGE_FILE_LINK', 'config':'CONFIG_FILE_LINK'}
```
or
```pycon
>>> g.nft_storage(api_key=""API_KEY"", upload_data=True)
{'status': {'image': True, 'data':True}, 'message': {'image':'IMAGE_FILE_LINK', 'data':'DATA_FILE_LINK'}
```

* Default timeout is **3000** seconds

### Save image
Save generated image

```pycon
>>> g.save_image(file_adr=""test.png"")
{'status': True, 'message': 'FILE_PATH'}
```
Save generated image in higher resolutions

```pycon
>>> g.save_image(file_adr=""test.png"", depth=5)
{'status': True, 'message': 'FILE_PATH'}
```

### Save data
Save generated image data

```pycon
>>> g.save_data(file_adr=""data.json"")
{'status': True, 'message': 'FILE_PATH'}
```
So you can load it into a `GenerativeImage` instance later by

```pycon
>>> g = GenerativeImage(data=open('data.json', 'r'))
```

Data structure:
```JSON
{
  ""plot"": {
    ""projection"": ""polar"",
    ""bgcolor"": ""black"",
    ""color"": ""snow"",
    ""spot_size"": 0.01
  },
  ""matplotlib_version"": ""3.0.3"",
  ""data1"": [
    0.3886741692042526,
    22.57390286376703,
    -0.1646310981668766,
    66.23632344600155
  ],
  ""data2"": [
    -0.14588750183600108,
    20.197945942677833,
    0.5485453260942901,
    -589.3284610518896
  ]
}
```

### Save config
Save generated image config. It contains string formats of functions which is also human readable.

```pycon
>>> g.save_config(file_adr=""config.json"")
{'status': True, 'message': 'FILE_PATH'}
```
So you can load it into a `GenerativeImage` instance later by

```pycon
>>> g = GenerativeImage(config=open('config.json', 'r'))
```

Config structure:

```JSON
{
    ""matplotlib_version"": ""3.0.3"",
    ""generate"": {
        ""seed"": 379184,
        ""stop"": 3.141592653589793,
        ""step"": 0.01,
        ""start"": -3.141592653589793
    },
    ""f2"": ""random.uniform(-1,1)*math.cos(x*(y**3))+random.uniform(-1,1)*math.ceil(y-x)"",
    ""f1"": ""random.uniform(-1,1)*math.ceil(y)-random.uniform(-1,1)*y**2+random.uniform(-1,1)*abs(y-x)"",
    ""plot"": {
        ""color"": ""snow"",
        ""bgcolor"": ""black"",
        ""projection"": ""polar"",
        ""spot_size"": 0.01
    }
}
```

## Mathematical details
Samila is simply a transformation between a square-shaped space from the Cartesian coordinate system to any arbitrary coordination like [Polar coordinate system](https://en.wikipedia.org/wiki/Polar_coordinate_system).

### Example
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/mathematical_details/transformation.png"">

We have set of points in the first space (left square) which can be defined as follow:

<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/mathematical_details/S1.jpg"">

And below functions are used for transformation:

```pycon
>>> def f1(x, y):
    result = random.uniform(-1,1) * x**2 - math.sin(y**2) + abs(y-x)
    return result
>>> def f2(x, y):
    result = random.uniform(-1,1) * y**3 - math.cos(x**2) + 2*x
    return result
```

<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/mathematical_details/S2.jpg"">

here we use `Projection.POLAR` so later space will be the polar space and we have:

```pycon
>>> g = GenerativeImage(f1, f2)
>>> g.generate(seed=10)
>>> g.plot(projection=Projection.POLAR)
```
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/mathematical_details/S2_.jpg"">

<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/images/6.png"">

## Try Samila in your browser!
Samila can be used online in interactive Jupyter Notebooks via the Binder or Colab services! Try it out now! :

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/sepandhaghighi/samila/master)

[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sepandhaghighi/samila/blob/master)

* Check `examples` folder 

## Issues & bug reports			

Just fill an issue and describe it. We'll check it ASAP! or send an email to [info@samila.site](mailto:info@samila.site ""info@samila.site""). 

- Please complete the issue template
 
You can also join our discord server

<a href=""https://discord.com/invite/94bz5QGZWb"">
  <img src=""https://img.shields.io/discord/900055829225562162.svg?style=for-the-badge"" alt=""Discord Channel"">
</a>


## Social media

1. [Instagram](https://www.instagram.com/samila_arts)
2. [Telegram](https://t.me/samila_arts)
3. [Twitter](https://twitter.com/samila_arts)
4. [Discord](https://discord.com/invite/94bz5QGZWb)


## References			

<blockquote>1- Schönlieb, Carola-Bibiane, and Franz Schubert. ""Random simulations for generative art construction–some examples."" Journal of Mathematics and the Arts 7.1 (2013): 29-39.</blockquote>

<blockquote>2- <a href=""https://github.com/cutterkom/generativeart"">Create Generative Art with R</a></blockquote>

<blockquote>3- <a href=""https://nft.storage/"">NFT.storage : Free decentralized storage and bandwidth for NFTs</a></blockquote>

## Acknowledgments

This project was funded through the **Next Step Microgrant**, a program established by [Protocol Labs](https://protocol.ai/).

## Show your support
								
<h3>Star this repo</h3>					

Give a ⭐️ if this project helped you!

<h3>Donate to our project</h3>	

If you do like our project and we hope that you do, can you please support us? Our project is not and is never going to be working for profit. We need the money just so we can continue doing what we do ;-) .			

<h4>Bitcoin</h4>
1KtNLEEeUbTEK9PdN6Ya3ZAKXaqoKUuxCy
<h4>Ethereum</h4>
0xcD4Db18B6664A9662123D4307B074aE968535388
<h4>Litecoin</h4>
Ldnz5gMcEeV8BAdsyf8FstWDC6uyYR6pgZ
<h4>Doge</h4>
DDUnKpFQbBqLpFVZ9DfuVysBdr249HxVDh
<h4>Tron</h4>
TCZxzPZLcJHr2qR3uPUB1tXB6L3FDSSAx7
<h4>Ripple</h4>
rN7ZuRG7HDGHR5nof8nu5LrsbmSB61V1qq
<h4>Binance Coin</h4>
bnb1zglwcf0ac3d0s2f6ck5kgwvcru4tlctt4p5qef
<h4>Tether</h4>
0xcD4Db18B6664A9662123D4307B074aE968535388
<h4>Dash</h4>
Xd3Yn2qZJ7VE8nbKw2fS98aLxR5M6WUU3s
<h4>Stellar</h4>
GALPOLPISRHIYHLQER2TLJRGUSZH52RYDK6C3HIU4PSMNAV65Q36EGNL
<h4>Zilliqa</h4>
zil1knmz8zj88cf0exr2ry7nav9elehxfcgqu3c5e5
<h4>Coffeete</h4>
<a href=""http://www.coffeete.ir/opensource"">
<img src=""http://www.coffeete.ir/images/buttons/lemonchiffon.png"" style=""width:260px;"" />
</a>
<h4>Gitcoin</h4>
<a href=""https://gitcoin.co/grants/3915/samila-generative-art-generator"">
<img src=""https://github.com/sepandhaghighi/samila/raw/master/otherfiles/gitcoin_btn.png"" style=""width:260px;"" />
</a>


",1029,1029,11,11,art,"[art, generative, generative-art, generativeart, matplotlib, nft, nft-gallery, nft-storage, nftables, nfts, python, python3]",0
preziotte,party-mode,,https://github.com/preziotte/party-mode,https://api.github.com/repos/party-mode/preziotte,An experimental music visualizer using d3.js and the web audio api.,"<p align=""center"">
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/1-logo.gif""/>
</p>

An audio visualizer experiment for the browser.  Powered by [d3.js](https://github.com/mbostock/d3) and the [web audio api](http://www.w3.org/TR/webaudio/).  Runs best in Chrome.  Working demo @ https://preziotte.com/partymode.  Try dragging in an mp3 from your desktop!  

### *epilepsy warning*

running it locally
==================
There will be issues running this app locally without a server.  I recommend `cd`ing into the directory and running `http-server` from the command line.  If you don't have this command, install it like so: `npm install -g http-server`.

a somewhat-technical overview
===========================
Using the web audio api, I can get an array of numbers which corresponds to the waveform of the sound an html5 audio element is producing.  There's a [good tutorial](http://www.developphp.com/view.php?tid=1348) on how to do this.  Then, using `requestAnimationFrame` (with a little [frame limiting](http://codetheory.in/controlling-the-frame-rate-with-requestanimationframe/) for performance reasons) I'm updating that array as the music changes.  I then normalize the data a bit (or transform it slightly depending on the visualization) and redraw the screen based on the updated array.  I'm using [d3.js](https://github.com/mbostock/d3) to draw and redraw SVG based on this normalized data.  Each visualization uses the data a bit differently -- it was mostly trial and error to get some stuff I liked looking at.  

Since I'm using D3 -- which is just drawing SVG -- I was able to style everything in CSS (no images are used at all, including icons).  There are a handful of differently colored themes for each visualization, and I do some rudimentary CSS namespacing by updating a class applied to the `html` element.  eg. `<html class='theme_1'>`. This lets me override or substitute CSS rules pretty trivially.  I can add some additional variation to each theme by messing with pseudo selectors.  For example, I can use `:nth-of-type` to hide every nth SVG rectangle or making every odd child have a different `stroke-dasharray`, etc.

Mousetrap.js handles my keyboard shortcuts brilliantly, and jQuery made life easier.

I developed this primarily in Chrome.  Other modern browsers still have some interesting issues (see known issues).  I've found that WebKit seems to have the [most competent](https://www.mapbox.com/osmdev/2012/11/20/getting-serious-about-svg/) implementation of SVG.  And specifically Chrome seems to play the nicest with the html5 audio element.  For my purposes at least.  Running this can easily strain my four year old MacBook's CPU, but I think I'm pushing several things beyond what they were intended for with this thing.  Not complaining.

Markup lies in `index.html`, javascript is in `js/main.js` and style in `css/style.css`.  I can go into more detail if there's demand for it.

ideas
=====
- make it a chrome extension -- hijack audio from any page and overlay visualizer.  would have to sandbox it in an iframe and then pass audio data into it..
- make it a chrome app -- since performance seems to be better when files are local
- auto-detect big changes in song (amplitude deltas / allow rate limiting / average threshold over time if desired) to trigger arbitrary things
- hook up more 3rd party music service such as spotify / pandora
- auto detect all mp3s in local folder and display a playlist (chromes `webkitRequestFileSystem`?)

help & inspiration
==================
- <a target='_blank' href='d3js.org'>D3</a>, and bl.ocks <a target='_blank' href='http://bl.ocks.org/mbostock/7782500'>#7782500</a>, 
<a target='_blank' href='http://bl.ocks.org/mbostock/3795048'>#3795048</a>, 
<a target='_blank' href='http://bl.ocks.org/mbostock/4248145'>#4248145</a>, 
<a target='_blank' href='http://bl.ocks.org/mbostock/4248146'>#4248146</a>
- <a target='_blank' href='http://codetheory.in/controlling-the-frame-rate-with-requestanimationframe/'>Code Theory</a>
- <a target='_blank' href='http://www.developphp.com/view.php?tid=1348'>DevelopPHP</a>
- <a target='_blank' href='http://www.michael-gerhaeuser.de/?f=fileapi/readme.html'>Michael Gerhaeuser</a>
- <a target='_blank' href='http://lostechies.com/derickbailey/2013/09/23/getting-audio-file-information-with-htmls-file-api-and-audio-element/'>Los Techies</a>
- Codrops [<a target='_blank' href='http://tympanus.net/Development/ModalWindowEffects/'>1</a>] 
[<a target='_blank' href='http://tympanus.net/codrops/2014/01/21/dot-navigation-styles/'>2</a>] 
- ColourLovers [<a target='_blank' href='http://www.colourlovers.com/palette/3406603/Sunset_at_Bayinbuluk'>1</a>] 
[<a target='_blank' href='http://www.colourlovers.com/palette/944213/forever_lost'>2</a>] 
[<a target='_blank' href='http://www.colourlovers.com/palette/728391/Dig_My_Olive_Branch'>3</a>] 
[<a target='_blank' href='http://www.colourlovers.com/palette/3406636/Just_Breathe'>4</a>] 
[<a target='_blank' href='http://www.colourlovers.com/palette/443995/i_demand_a_pancake'>5</a>]
- <a target='_blank' href='http://codepen.io/aronwoost/pen/nlyrf'>aronwoost</a>
- <a target=""_blank"" href='https://news.ycombinator.com/item?id=2299806'>Dustin Cartwright</a>
- <a target=""_blank"" href='http://matthewlein.com/ceaser/'>Ceaser</a>
- Headphones by Kevin Hipke and Record by Juan Pablo Bravo from 
<a target='_blank' href='http://thenounproject.com'>The Noun Project</a> 
- <a target=""_blank"" href='https://stackoverflow.com/questions/13368046/how-to-normalize-a-list-of-positive-numbers-in-javascript'>Stack Overflow</a>
- <a target='_blank' href='http://craig.is/killing/mice'>Mousetrap.js</a> and <a target='_blank' href='https://jquery.com/'>jQuery</a>
- <a target='_blank' href='https://github.com/aadsm/JavaScript-ID3-Reader'>aadsm/JavaScript-ID3-Reader</a>
- <a target='_blank' href='http://www.html5rocks.com/en/tutorials/getusermedia/intro/'>Eric Bidelman</a> via HTML5 Rocks
- <a target='_blank' href='http://icomoon.io/app/'>icomoon</a> (iconmelon, fontello, and iconmonstr are all pretty rad)

examples
--------
- https://preziotte.com/partymode
- https://preziotte.com/odesza (Featured on Odesza's official [Youtube](http://www.youtube.com/watch?v=Km-0kHxa7jg) channel)

cool gifs
==========
<p align=""center"">
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/0.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/2.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/4.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/5.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/6.gif""/> 
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/7.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/8.gif""/> 
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/9.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/10.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/11.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/12.gif""/><br />
<img src=""https://raw.githubusercontent.com/preziotte/party-mode/master/img/3.gif""/>
</p>

license
=======
<a rel=""license"" href=""http://creativecommons.org/licenses/by-nc/3.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by-nc/3.0/88x31.png"" /></a><br />This work is licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by-nc/3.0/"">Creative Commons Attribution-NonCommercial 3.0 Unported License</a>.  For commercial projects, please inquire mat.preziotte@gmail.com.

",762,762,25,13,art,"[art, audio, audio-visualizer, d3, d3js, data-visualization, generative-art, html5-audio-element, javascript, visualization]",0
mfrashad,text2art,,https://github.com/mfrashad/text2art,https://api.github.com/repos/text2art/mfrashad,AI-powered Text-to-Art Generator - Text2Art.com,"<br />
<p align=""center"">
  <a href=""https://mfrashad.com"">
    <img src=""images/text2art-gallery.gif"" alt=""thumbnail"" width=""600"">
  </a>

  <h3 align=""center"">Text2Art</h3>

  <p align=""center"">
    AI Powered Text-to-Art Generator
    <br />
    <a href=""https://text2art.com""><strong>Try It Out »</strong></a>
    <br />
    <a href=""https://colab.research.google.com/github/mfrashad/text2art/blob/main/text2art.ipynb"">View Notebook</a>
    ·
    <a href=""https://towardsdatascience.com/how-i-built-an-ai-text-to-art-generator-a0c0f6d6f59f"">Read Article</a>
    ·
    <a href=""https://github.com/mfrashad/text2art/issues"">Report Bug</a>
    ·
    <a href=""https://github.com/mfrashad/text2art/issues"">Request Feature</a>
  </p>
</p>


<!-- ABOUT THE PROJECT -->
## About The Project

Text2Art is an AI art generator powered with VQGAN + CLIP and CLIPDrawer models. You can easily generate all kind of art from drawing, painting, sketch, or even a specific artist style just using a text input. You can also specify the dimensions of the image. The process can take 3-20 mins and the results will be emailed to you.

You can read the write-up on how I built this project in this [article](https://towardsdatascience.com/how-i-built-an-ai-text-to-art-generator-a0c0f6d6f59f)

<img src=""images/text2art-gradio-compressed.gif"" alt=""demo"" width=""600"">


### Built With

* Python
* VQGAN + CLIP
* CLIPDraw
* [dribnet/clipit](https://github.com/dribnet/clipit)
* Firebase



<!-- GETTING STARTED -->
## Getting Started
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mfrashad/text2art/blob/main/text2art.ipynb)


You can start with the colab notebook to generate an art manually using code. If you want to deploy a website like text2art, make sure you setup your MailGun and Firebase account and replace the API key accordingly.

<!-- LICENSE -->
## License

See `LICENSE` for more information.

<!-- CONTACT -->
## Contact

You can drop me a message on my [Website](https://www.mfrashad.com/).
",753,753,17,8,art,"[art, colab-notebook, deep-learning, gan, generative-art, machine-learning, painting, pixel-art, text-to-image]",0
badgeek,svg2shenzhen,,https://github.com/badgeek/svg2shenzhen,https://api.github.com/repos/svg2shenzhen/badgeek,Convert Inkscape SVG drawings to KiCad PCB and footprint modules,"# Svg2Shenzhen

Inkscape extension for exporting drawings into a KiCad PCB.

![showcase](https://github.com/badgeek/svg2shenzhen/blob/master/doc/resources/showcase.jpeg?raw=true)

## Features

- Draw Any kind of shapes without restriction
- Supports Drill Pad, and custom drill size
- Supports Edge Cut (PCB Shape)
- Works on OSX, Windows and Linux

## Install

Warning: starting from 0.2.18 svg2shenzhen only support Inkscape 1.0 and above

1. Download the latest version (0.2.18.7)
  - Windows https://github.com/badgeek/svg2shenzhen/releases/download/0.2.18.7/svg2shenzhen-extension-0.2.18.7.zip
  - Linux / OSX https://github.com/badgeek/svg2shenzhen/releases/download/0.2.18.7/svg2shenzhen-extension-0.2.18.7.tar.gz
  - Release notes: https://github.com/badgeek/svg2shenzhen/releases
  - Older version: https://github.com/badgeek/svg2shenzhen/releases

2. Extract and copy the files into the directory indicated in Inkscape under *Edit -> Preferences -> System: User extensions*

**Step by Step Guide with Screenshot**
  - Go to your extracted folder it should look like this
  
  ![windowsStep0](https://github.com/badgeek/svg2shenzhen/blob/master/doc/resources/windows_step_0.png?raw=true)
  
  - Copy all files *(""svg2shenzhen"" folder + svg2shenzhen_about.inx + svg2shenzhen_export.inx + svg2shenzhen_prepare.inx)*
  - Open Inkscape and go **Edit --> Preferences**
  
  ![windowsStep1](https://github.com/badgeek/svg2shenzhen/blob/master/doc/resources/windows_step_1.png?raw=true)
  
  - Under Preferences go to **System**, Now in **System info** you will see option ***User extensions:*** this is the path of extension. You can hit on ***Open*** icon and it will open up the folder.
  
  ![windowsStep2](https://github.com/badgeek/svg2shenzhen/blob/master/doc/resources/windows_step_2.png?raw=true)
  
  - Paste all the files copied
  
  ![windowsStep3](https://github.com/badgeek/svg2shenzhen/blob/master/doc/resources/windows_step_3.png?raw=true)
  
  - **Restart Inkscape** 

## How to

In Inkscape:

1. *Extension > Svg2Shenzhen > Prepare Document*
2. Choose layer (F.Cu.. etc)
3. Draw PCB
4. *Extension > Svg2Shenzhen > Export KiCad*

Download and open [Example PCB](https://raw.githubusercontent.com/badgeek/svg2shenzhen-next/master/examples/viruspcb.svg)

## Tutorials

- Custom Footprints for KiCad - <https://www.gabetaubman.com/blog/posts/kicad-custom-footprint/>
- PCBArt Badge - <http://blog.sheasilverman.com/2019/01/pcbart/>

## Layername definitions

1. After the *Prepare Document* step, only two fabrication layers are used:
   *Edge.Cuts* and *Drill*,
   and for the different PCB-layers, only the *F.Cu* layer is active.
   The others have the post-fix ""-disabled"" in their layer name;
   change this by removing this post-fix to enable more layers.
2. Special use of the solder-mask layers *F.Mask* and *B.Mask*:
   Due to the fabrication standard of PCB manufacturing,
   when enabled, this will lead to the solder-mask NOT being present
   where there are black areas in your design.
   This is kinda PCB/KiCad standard, but can be confusing.
   If you want to Get-What-You-See from Inkscape,
   meaning that you really draw the color where you want the solder-mask to be,
   change the layer name to *F.Mask-invert*
3. Super easy simple PCB with exposed copper surrounded by solder-mask,
   can be generated automatically by leaving the *F.Mask* layer empty
   and renaming it to *F.Mask-auto*.
4. Feel free to add your own layers, for testing graphics and designing stuff.
   All these other layers will be ignored.

## Tips

1. For *Edge.Cut* layers, you need to convert any polygons or objects to paths with only an outline, no fill.
   Don't use any groups on *Edge.Cut* layers,
   and if you have paths with inner cut-outs,
   break them apart into separate paths.
2. For Drill layers, place circle objects,
   and they will be converted into drill pads in KiCad with the same diameter.
   These drills will not have annular rings,
   unless you also add copper to the *F.Cu* and *B.Cu* layers.
   Don't use any groups on the *Drill* layer either.

## References

- [Svg2Shenzhen Announcement on Gosh Community Forum](https://forum.openhardware.science/t/svg2shenzhen-save-inkscape-drawing-as-kicad-pcb/989)
- [PCB Art with Inkscape - Developer log](http://wiki.8bitmixtape.cc/#/4_7.1-PCB-Art-with-Kicad-and-Inkscape) on the 8BitMixtape Wiki
- [Practical Guide to Designing PCB Art](https://medium.com/@urish/a-practical-guide-to-designing-pcb-art-b5aa22926a5c)
- [KitSprint ANORG 2018](http://wiki.sgmk-ssam.ch/wiki/KitSprint_ANORG_2018#Kicad_bitmap_import_for_Shenzhen_Ready)

## Videos
- Drawing PCBs with Inkscape (FOSSDEM) with @kasbah of kitspace - https://www.youtube.com/watch?v=xXRPw7ItMaM
- Making a PCB Badge for Hackaday Supercon! - https://www.youtube.com/watch?v=YqdBiOj8uXw
- Understanding and Making PCB Art (mrtwinkletwinkle) https://www.youtube.com/watch?v=Sbkvza8cKQE

## Support this project

This project is developed independently and without any connection to funding or big collective or organization.
Donation is highly appreciated.
Go to <https://www.patreon.com/badgeek> to become a patron and support this project

<a href=""https://www.patreon.com/badgeek"">
  <img src=""https://i.imgur.com/ys5X3ZP.png"" >
</a>

## Contributors

- Budi Prakosa [@badgeek](https://github.com/badgeek)
- Kaspar Emanuel [@kasbah](https://github.com/kasbah)

## Credits

* inkscape-export-layers - <https://github.com/jespino/inkscape-export-layers>
* bitmap2component (kicad) - <https://github.com/KiCad/kicad-source-mirror/tree/master/bitmap2component>
* csv_output - <https://github.com/tbekolay/csv_output>
* svg2mod - <https://github.com/svg2mod/svg2mod>
",723,723,34,49,art,"[art, badge, badgelife, inkscape, kicad-pcb, openhardware, pcb, pcb-art]",0
icosa-foundation,open-brush,icosa-foundation,https://github.com/icosa-foundation/open-brush,https://api.github.com/repos/open-brush/icosa-foundation,"Open Brush is the open source, community led evolution of Tilt Brush! Forked from https://github.com/googlevr/tilt-brush","# Open Brush - Tilt Brush Evolved

[![Support us on Open Collective!](https://img.shields.io/opencollective/all/icosa?logo=open-collective&label=Support%20us%20on%20Open%20Collective%21)](https://opencollective.com/icosa)
[![All GitHub releases](https://img.shields.io/github/downloads/icosa-foundation/open-brush/total?label=GitHub%20downloads)](https://github.com/icosa-foundation/open-brush/releases/latest)
[![Twitter](https://img.shields.io/badge/follow-%40openbrushapp-blue.svg?style=flat&logo=twitter)](https://twitter.com/openbrushapp)
[![Discord](https://discordapp.com/api/guilds/783806589991780412/embed.png?style=shield)](https://discord.gg/W7NCEYnEfy)
![Current Version](https://img.shields.io/github/v/release/icosa-foundation/open-brush)
![Prerelease Version](https://img.shields.io/github/v/release/icosa-foundation/open-brush?include_prereleases&label=prerelease)

[![Open Brush Banner](open-brush.png)](https://openbrush.app)

Open Brush is a free fork of Tilt Brush, a room-scale 3D-painting virtual-reality application available from Google, originally developed by Skillman & Hackett. We have made a large number of changes from the original repository, including Unity upgrades and feature additions to bring Open Brush up to modern XR development standards. You can find the notable changes on our [docs site](https://docs.openbrush.app/differences-between-open-brush-and-tilt-brush).

We hope to maintain and improve upon Tilt Brush as a community-led project, free forever!

As the original repo is archived we cannot submit PRs, so feel free to submit them here! 

[User Guide](https://docs.openbrush.app/)  
[Developer Notes](https://docs.openbrush.app/developer-notes)  
[Roadmap](https://github.com/orgs/icosa-foundation/projects/1)  
[Please join the Icosa Discord and get involved!](https://discord.com/invite/W7NCEYnEfy)  
[List of tutorials, write-ups and other things from the community](https://docs.google.com/document/d/1gjoYp4y-1qlE3a7fvXVxGR3ioj3nMfgprmTHQ-bpq0k/)  
**[Support us on Open Collective!](https://opencollective.com/icosa)**  

## Downloads
### Stores (Did we mention it's free?)
- [SideQuest](https://sidequestvr.com/app/2852/open-brush)
- [Oculus App Lab](https://www.oculus.com/experiences/quest/3600360710032222)
- [Steam](https://store.steampowered.com/app/1634870/Open_Brush)
- [Oculus Rift](https://www.oculus.com/experiences/rift/5227489953989768)
- [Viveport Desktop](https://www.viveport.com/f1f3d00b-cf8a-443f-825e-4fea2dd3b005)
- [itch.io](https://openbrush.itch.io/openbrush)
### GitHub
- [Formal GitHub Releases](https://github.com/icosa-foundation/open-brush/releases/latest)
- [Bleeding Edge GitHub Releases](#bleeding-edge-releases)


## Acknowledgements
* Thank you to the Tilt Brush developers for your amazing work and for finding a way to open source the app! 
* [SiMonk0](http://www.furjandesign.com/) for the great new logo!
* The [SideQuest](https://sidequestvr.com/) team for your support.
* [VR Rosie](https://twitter.com/vr_rosie) for promotional artwork, banners, and videos.

## Bleeding Edge Releases

Instead of waiting for a formal release, you can download a ZIP from Github containing an automatically built release for either Windows (SteamVR) or Oculus Quest / Quest 2 from the [Github releases page](https://github.com/icosa-foundation/open-brush/releases). Versions of the form ""vX.Y.0"" are official releases, whereas versions that do not end in .0 are made available for testing purposes only, with no guarantees as to their quality. Additionally, these releases are marked as ""pre-release"". However, if you'd like to test a recent change prior to the official release, you can use these either in place of or in parallel with the formal Open Brush releases.

These builds share a save location with the official Open Brush release, but can be installed alongside the formal version. The Oculus build, like all sideloaded content, will be listed in ""Unknown Sources"", and will have the word ""Github"" appended to the name (with a different package name as well) to differentiate it from the official release).

Note that the ""experimental"" builds contain experimental brushes, and sketches created using the experimental brushes may appear differently when loaded in the official build of Open Brush!

In addition, there is also a version created for  Windows Monoscopic that is listed as an ""Artifact"" of the Github Actions, however, this is intended only for developers, and should not be used by general users. You can find it by browsing to the [commit list](https://github.com/icosa-foundation/open-brush/commits/main), and then clicking on the green check mark below the title (next to the XXX committed XXX ago), and scroll to the build you want, and click on **Details**. Then, towards the upper right corner, click on **Artifacts** and click on the name of the build. Unzip the downloaded file, and either run the executable (Desktop OpenXR/Monoscopic) or install the apk (Android Oculus) using `adb install com.Icosa.OpenBrush-github.apk`. 

## Important note from the original Tilt Brush README

The Tilt Brush trademark and logo (“Tilt Brush Trademarks”) are trademarks of
Google, and are treated separately from the copyright or patent license grants
contained in the Apache-licensed Tilt Brush repositories on GitHub. Any use of
the Tilt Brush Trademarks other than those permitted in these guidelines must be
approved in advance.

For more information, read the
[Tilt Brush Brand Guidelines](TILT_BRUSH_BRAND_GUIDELINES.md).

---

# Building the application

Get the Open Brush open-source application running on your own devices.

### Prerequisites

*   [Unity 2021.3.16f1](unityhub://2021.3.16f1/4016570cf34f)
*   [Python 3](https://www.python.org/downloads/) (Optional —
    needed only if you wish to run the scripts in the `Support/bin` directory)
    Tested with Python 3.8.

### Running the application in the Unity editor

Follow these steps when running the application for the first time:

1.  Start Unity.
1.  Go to **File** > **Open Scene**. \
1.  Select `/Assets/Scenes/Main.unity`. Unity should automatically prompt you to
    import **TextMesh Pro**.
1.  Choose **Import TMP Essentials**. \
    You can also do this through **Window** > **TextMesh Pro** > **Import TMP
    Essential Resources**.
1.  Press **Play**.

These steps have been tested with Release 1.0.54.

### Building the application from the Unity editor

Although it's possible to build Open Brush using the standard Unity build tools,
we recommend using a build script to ensure the application builds with the
correct settings. To run this script, go to **Open Brush** > **Build** > **Do Build**,
or build from the Open Brush build window by navigating to **Open Brush** >
**Build** > **Build Window**.

Note: The application may take a while to build the first time.

### Building the application from the Windows command line

Use the `build` script in the `Support/bin` directory to specify the target
platform and the build options you wish to enable. Run `build —help` to see the
various build options.

### Additional features

You should be able to get the basic version of Open Brush up and running very
quickly. The following features will take a little more time.

*   [Google service API support](#google-service-api-support)
*   [Enabling native Oculus support](#enabling-native-oculus-support)
*   [Sketchfab support](#sketchfab-support)
*   [Offline rendering support](#offline-rendering-support)

## Systems that were replaced or removed when open-sourcing Tilt Brush

Some systems in Tilt Brush were removed or replaced with alternatives due to
open-source licensing issues. These are:

*   **Sonic Ether Natural Bloom**. The official Tilt Brush app uses a version
    purchased from the Asset Store; the open-source version uses
    [Sonic Ether's slightly modified open-source version](https://github.com/sonicether/SE-Natural-Bloom-Dirty-Lens).
*   **FXAA**. The official Tilt Brush app uses a modified version of the FXAA
    that Unity previously released with the standard assets on earlier versions
    of Unity - FXAA3 Console. This has been replaced with
    [FXAA by jintiao](https://github.com/jintiao/FXAA).
*   **Vignette and Chromatic Aberration**. The official Tilt Brush app uses
    modified versions of the Vignette and Chromatic Aberration effects that came
    with the standard assets in earlier versions of Unity. These have been
    replaced with a modified version of
    [KinoVignette by Keijiro](https://github.com/keijiro/KinoVignette).
*   **Tilt Shift**. The official Tilt Brush app uses modified versions of the
    Tilt Shift effect that came with the standard assets in earlier versions of
    Unity. These have been replaced with a modified version of
    [Tilt shift by ruby0x1](https://gist.github.com/ruby0x1/10324388).

## Generating Secrets file
Credentials for services such as Google and Sketchfab are stored in a `SecretsConfig` scriptable object. This has been ignored in the git config for safety. To add it back:

1.  Right click in the root `/Assets` folder in Unity's project window. 
    Select `Create`, then `Secrets Config`. This will create `Secrets.asset` in the Asset folder.
1.  In `Scenes/Main.unity` go to **App > Config** and replace `SecretsExample` 
    with the newly generated `Secrets.asset`.

## Google service API support

Set up Google API support to access Google services in the app.

### Enabling Google service APIs

Follow these steps when enabling Google service APIs:

1.  Create a new project in the
    [Google Cloud Console](https://console.developers.google.com/).
1.  Enable the following APIs and services:

    *   **YouTube Data API v3** — for uploading videos to YouTube
    *   **Google Drive API** — for backup to Google Drive
    *   **People API** — for username and profile picture

Note: The name of your application on the developer console should match the
name you've given the app in `App.kGoogleServicesAppName` in `App.cs`.

### Creating a Google API key

Follow these steps when creating a Google API key:

1.  Go to the Credentials page from the Google Cloud Console.
1.  Click **Create Credential** and select **API key** from the drop-down menu.

### Google OAuth consent screen information

The OAuth consent screen asks users for permission to access their Google
account. You should be able to configure it from the Credentials screen.

Follow these steps when configuring the OAuth consent screen:

1.  Fill in the name and logo of your app, as well as the scope of the user data
    that the app will access.
1.  Add the following paths to the list of scopes:

    *   Google Drive API `../auth/drive.appdata`
    *   Google Drive API `../auth/drive.file`

### Creating an OAuth credential

The credential identifies the application to the Google servers. Follow these
steps to create an OAuth credential:

1.  Create a new credential on the Credentials screen.
1.  Select **OAuth**, and then select **Other**. Take note of the client ID and
    client secret values that are created for you. Keep the client secret a
    secret!

### Storing the Google API Key and credential data

Follow these steps to store the Google API Key and credential data:

1.  Follow the steps to [create your secrets file](#-Generating-Secrets-file).
    Add a new item to the **Secrets** field.
1.  Select `Google` as the service. Paste in the API key, client ID, and client
    secret that were generated earlier.

## Enabling native Oculus support

Open Brush targets OpenXR instead of Oculus by default. Follow these steps to enable native Oculus support:
.
1.  In the **Standalone** and **Android** tabs of the Player settings, go to **Other Settings** > **Scripting Define Symbols**.
1. Click the + button to create a new entry.
1. Add `OCULUS_SUPPORTED` and press **Apply**.

### Building your app for Oculus Quest

Follow these steps to build your app for Oculus Quest:

1.  Set up your machine for
    [Oculus Quest Development](https://developer.oculus.com/documentation/unity/book-unity-gsg/?device=QUEST).
1.  Make sure the following are set in Unity:
    *   **Open Brush** > **Build** > **Plugin: Oculus**
    *   **Open Brush** > **Build** > **Platform: Android**
    *   **Open Brush** > **Build** > **Runtime: IL2CPP**
1.  Navigate to **Open Brush** > **Build** > **Do Build**.
1.  Find the generated executable. It will most likely be somewhere under
    `../Builds/OculusMobile_Release_OpenBrush/`.
1.  Run `adb install com.Icosa.OpenBrush.apk`.

### Publishing to Oculus stores

Note: _Tilt Brush_ is a Google trademark. If you intend to publish a cloned
version of the application, you are required to
choose a different name to distinguish it from
the official version.

Follow these steps to publish to Oculus stores:

1.  Get an application ID from Oculus. The desktop and quest versions of each
    application need separate IDs.
1.  Follow the steps to [create your secrets file](#-Generating-Secrets-file).
    Add 2 new items to the **Secrets** field.
1.  Add these IDs to the `Secrets` file. Both `Oculus` and `OculusMobile` should
    have their own entries.
1.  Put the app IDs in the `Client ID` field for each.

## Open Brush intro sketch

The Open Brush intro sketch uses some slightly modified shaders to produce the
animating-in effect while the sketch fades in. For faster loading, the intro
sketch is turned into a `*.prefab` file beforehand. Only the shaders used in the
intro sketch have been converted to work with the introduction.

*   The current intro sketches are located in `Support/Sketches/Intro`. There
    are two versions, one for PC and one for mobile.
*   The `*.prefab` files are located in `Assets/Prefabs/Intro`.
*   The materials and shaders used in the intro are located in
    `Assets/Materials/IntroMaterials`.
*   The `Assets/PlatformConfigPC` and `Assets/PlatformConfigMobile` files
    reference the `*.prefab` files that will be used in the intro.

### Creating an intro sketch

Follow these steps to replace or alter the intro sketch:

1.  Make sure the sketch of your choice is already loaded. Run Open Brush in the
    Unity Editor.
1.  Select **Open Brush** > **Convert To Intro Materials** in the main Unity menu.
    This converts the materials in the sketch to the intro versions. \
    You will get warnings in the console for any materials it could not convert,
    as well as a summary of how many materials it converted.
1.  Navigate the hierarchy. Under the **Main** scene, open `SceneParent/Main
    Canvas`. Select any of the `Batch_...` objects to check whether they have
    the intro materials set.
1.  Move any objects that do not start with `Batch_` out from under the **Main
    Canvas** node.
1.  Select the **Main Canvas** node and run the **Open Brush** > **Save Game Object As Prefab**
menu command. \
    The scene will be saved as a `*.prefab` file called `gameobject_to_prefab`.
    under the `Assets/TestData` folder.
1.  Move the game object into the `Assets/Prefabs/Intro` folder.
1.  Update the references in `Assets/PlatformConfigPC` and
    `Assets/PlatformConfigMobile` to point to your new prefab file.

### Creating an intro sketch for mobile applications

You may want to have a pared-down version of the intro sketch for the mobile
version of the app. Stroke simplification is located in the **Settings** menu
inside Open Brush.

## New Scenes

By default, your app will only build the scenes defined in the **DoBuild** method (string[] scenes = {...} ) in `BuildTiltBrush.cs` under  `Assets/Editor/`. Make sure to add your custom scenes to this array if you want to see them in app.

## Sketchfab support

Follow these steps to enable Sketchfab support:

1.  [Contact Sketchfab](https://sketchfab.com/developers/oauth) for a client ID
    and secret before you can upload to their service.
    
    -  The **Application Name** will probably need to be changed
    -  The **Grant Type** should be **Authorization Code** 
    -  The **URI** should be **http://localhost:40074/sketchfab**
1.  Follow the steps to [create your secrets file](#-Generating-Secrets-file).
    Add a new item to the **Secrets** field.
1.  Add the client ID and secret to the field.
1.  Set the service as **Sketchfab**. Leave the API key blank.

### Video support bug fix

If you add video support, you may encounter a bug where the ""Looking for audio""
and ""Play some music on your computer"" text will disappear if the controller is
angled too far. Fix this by doing the following:

1.  In Unity, find the `/Assets/TextMesh Pro/Resources/Shaders/TMP_SDF.shader`
    file.
1.  Duplicate it and rename this file `TMP_SDF-WriteDepth.shader`.
1.  Open the new file in a code or text editor and make the following changes to
    it:
    1.  Change the name from `TextMeshPro/Distance Field` to
        `TextMeshPro/Distance Field Depth`.
    1.  Change `Zwrite Off` to `Zwrite On`.
1.  In Unity, select `/Assets/Fonts/Oswald-Light SDF.asset`.
1.  Under `Atlas & Material`, double click `Oswald-Light SDF Material`.
1.  At the top, change the name for `Shader` from `TextMeshPro/Distance Field`
    to `TextMeshPro/Distance Field Depth`.

## Offline rendering support

When the user records a video from a saved sketch in Open Brush, a `.bat` file
is generated next to the `.mp4` for offline rendering support. This `.bat` file
requires the path to the executable of Open Brush. The code for writing out this
path to the file has been removed.

Follow these steps to restore the path:

1.  Open the file `Assets/Scripts/Rendering/VideoRecorderUtils.cs` in a code or
    text editor.
1.  Look for the function `CreateOfflineRenderBatchFile` near the bottom of the
    file.
1.  In the function, find the comments on how to modify the string to point to
    the executable path.
1.  Update the string to point to the correct path.

## Experimental mode

Experimental mode is where features live before they are ready to be released in
a production build. This mode enables the experimental brushes and experimental
panel while disabling the intro sequence. Experimental mode can be enabled from
the settings panel, and requires a restart.

**New features and brushes that you find in experimental mode may not work as
expected.** Sketches that use experimental features and brushes won't work on
Icosa or Sketchfab, and may break if loaded into production versions of Open
Brush.

### Making your code experimental

Code in experimental mode is usually surrounded by the following block:

```
    if (Config.IsExperimental) {
      // Experimental code goes here
    }
```

### Experimental brushes

Experimental brushes and environments are located in the `Assets/Resources/X`
folder. They are not visible in non-experimental mode.
",655,655,17,53,art,"[ar, art, mr, painting, tilt-brush, tiltbrush, unity, unity3d, virtual-reality, vr, xr]",0
blocktronics,moebius,blocktronics,https://github.com/blocktronics/moebius,https://api.github.com/repos/moebius/blocktronics,Modern ANSI & ASCII Art Editor,"
![Moebius Screenshot](docs/screenshot.png)
# Moebius

Moebius is an ANSI Editor for MacOS, Linux and Windows. The major feature that differentiates it from [PabloDraw](https://github.com/blocktronics/pablodraw) is the 'half-block' brush which allows editing in a style closer to Photoshop than a text editor, although you can still use the function and cursor keys to draw with, and you should find that most of the text editing features from PabloDraw are carried over to this editor. The editor is still a work in progress, but anyone who wants to try using it is also encouraged to [log feature requests and bugs](https://github.com/blocktronics/moebius/issues) on the project's GitHub page.

## Download packages
Packaged binaries are available through Github [Releases](https://github.com/blocktronics/moebius/releases) or from the direct links below:

* [MacOS](https://github.com/blocktronics/moebius/releases/latest/download/Moebius.dmg)
* [Windows Installer](https://github.com/blocktronics/moebius/releases/latest/download/Moebius.Setup.exe)
* [Windows Portable](https://github.com/blocktronics/moebius/releases/latest/download/Moebius.exe)
* [Debian Linux](https://github.com/blocktronics/moebius/releases/latest/download/Moebius.deb)

## Installation & building
```
git clone git@github.com:blocktronics/moebius.git
npm install
npm start
```

Moebius packages can be built easily with [electron-builder](https://github.com/electron-userland/electron-builder). Note that a build for MacOS must be made on MacOS.

```
npm run-script build-mac
npm run-script build-win
npm run-script build-linux
```

## Moebius Server
Moebius features collaboration by multiple users on the same canvas through a server instance. Users connect to a server which allows them to draw and chat. The server will also create hourly backups.

To start a server:
```
git clone git@github.com:blocktronics/moebius.git
npm install
node ./server.js
```

This will start a server with default settings. In this case a password will not be set and any value entered in the Moebius client will be accepted by the server. The server runs by default on port 8000, Moebius clients can modify the port by entering the server as hostname:port

The following parameters can be set:

* `--file=filename.ans` load an initial ANSI file after the server starts
* `--pass=password` set a server password which clients need to provide to logon to the server
* `--server_port=8000` set the server port, defaults to 8000.
* `--web` and `--web_port=80` run the webserver for external viewing (default port: 80). This enables live preview of the canvas, the preview and SAUCE information in a browser, the URL would be http://hostname.tld:web_port
* `--path=pathname` set a path for this server: users and webviewers would connect to hostname.tld/path
* `--quiet=true/false` suppress console output after the server has been started
* `--discord=url` Mirrors server joins and chat activity via a [Discord Webhook](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks)

## Acknowledgements
* Uses modified Google's Material Icons. https://material.io/icons/
* Contains ANSI art by Alpha King (Blocktronics), Filth (Blocktronics) and burps (FUEL)
* Included fonts:
  * Topaz originally appeared in Amiga Workbench, courtesy of Commodore Int.
  * P0t-NOoDLE appears courtesy of Leo 'Nudel' Davidson
  * mO'sOul appears courtesy of Desoto/Mo'Soul

## License
Copyright 2022 Andy Herbert

Licensed under the [Apache License, version 2.0](https://github.com/blocktronics/moebius/blob/master/LICENSE.txt)

## Links
* Moebius homepage: [https://blocktronics.github.io/moebius/](https://blocktronics.github.io/moebius/)
* SAUCE: [http://www.acid.org/info/sauce/sauce.htm](http://www.acid.org/info/sauce/sauce.htm)
",598,598,15,29,art,"[ansi-art, art, ascii-art, cp437, drawing, editor, moebius, textmode]",0
seenaburns,isolate,,https://github.com/seenaburns/isolate,https://api.github.com/repos/isolate/seenaburns,Lightweight image browser,"# Isolate

![isolate](https://user-images.githubusercontent.com/2801344/44303858-96caca00-a300-11e8-8402-1b5834c03eb6.png)

Isolate is a lightweight tool for viewing and organizing your art reference and inspiration with ease.

Isolate works off of your local file system: you get started by dragging and dropping a folder onto the application window. After that, you can browse, search, reorganize and view images in full res. Not having to go over the internet [keeps things much faster than other tools like Pinterest.](https://twitter.com/seenaburns/status/950054230852694016)

#### Great things about Isolate

- **Quick**: Both in workflow and snappiness, Isolate is meant for the power users
- **Manage your images how you like**: Isolate just reflects your directory structure, you get to organize things how you see fit (even with nested folders)
- **No BS**: Isolate isn't a social tool. There's no sharing, notifications, discovery. It just does its job and stays out of your way.

## Install

Download | [macOS (app)](https://github.com/seenaburns/isolate/releases/download/v2.0.2/isolate-2.0.2.dmg) | [windows (unpacked .exe)](https://github.com/seenaburns/isolate/releases/download/v2.0.2/isolate.2.0.2.exe) | [linux (.appImage)](https://github.com/seenaburns/isolate/releases/download/v2.0.2/isolate-2.0.2-x86_64.AppImage)
-------- | --------------- | --------------------------- | ---------------------------

See [build/](build/) for how to build from source.

**Note**: v3 is in development! Building from source (master) is less stable than the releases.

## Screenshots

![screenshot-browsing](https://user-images.githubusercontent.com/2801344/44303857-95999d00-a300-11e8-9b26-c368e9644c4c.png)
![screenshot-modal](https://user-images.githubusercontent.com/2801344/44303856-94687000-a300-11e8-8537-fff128412224.png)

## Usage

Isolate works off of a base folder, when you first start drag and drop a folder to browse it. You can always drag and drop another folder if you ever want to browse another folder.

#### Navigation

![navigation-drawer](https://user-images.githubusercontent.com/2801344/44303469-87df1a00-a2f6-11e8-8909-d75da4b668b8.png)

When hovering over the bottom toolbar, a drawer appears, containing subdirectories you can navigate too.

- `n` opens this drawer
- `esc` closes it
- `Enter` navigates to the first item in the list
- Typing filters the directories

#### Modal

Clicking on any image will open it, fitting to the window.

- `z` zooms in and out, between fitted and the image's original size
- `ESC` closes the window
- `Left` and `Right` arrow keys navigate between images

**Right clicking** on the image shows you

- `CmdOrCtrl + Shift + C` copies the image to your clipboard
- `CmdOrCtrl + Shift + O` opens the image in your native file manager

#### Toolbar

![popup-menu](https://user-images.githubusercontent.com/2801344/44303740-9a108680-a2fd-11e8-9912-75f247a1f8fc.jpg)

Additionally in the toolbar lets you zoom the image grid, search across directories and more options under the popup menu.

- `CmdOrCtrl +` zooms in
- `CmdOrCtrl -` zooms out
- `CmdOrCtrl n` toggles night/day mode
- Shuffle toggles the order of your images. When changing folders, they are sorted by filename, but shuffle will randomly sort them.
- Hovering over `More` shows you more options

##### Moving

![moving](https://user-images.githubusercontent.com/2801344/44303800-063fba00-a2ff-11e8-86fe-e0ed84e5bfb6.jpg)

Selecting `Move` in the popup menu under `More` lets you select images and move them to other folders. A gold tint shows the selected images.

- Select/Unselect images by clicking them
- `e` activates selection
- `m` opens the directory drawer to move images
- `ESC` exits back to normal mode

##### Searching

A search bar in the top right will search for any files with the term in their path. For example `2d` would match anything in my `inspo/2d/` folder.
",340,340,12,7,art,"[art, design, desktop-app, electron, image-viewer, productivity, react, reason-react, reasonml, tool]",0
Tw1ddle,geometrize-haxe,,https://github.com/Tw1ddle/geometrize-haxe,https://api.github.com/repos/geometrize-haxe/Tw1ddle,:triangular_ruler: Geometrize is a Haxe port of primitive that geometrizes images into geometric primitives,"[![Project logo](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/logo.png?raw=true ""Geometrize Haxe - recreating images as geometric shapes logo"")](https://www.geometrize.co.uk/)

[![License](https://img.shields.io/:license-mit-blue.svg?style=flat-square)](https://github.com/Tw1ddle/geometrize-haxe/blob/master/LICENSE)
[![Build Status Badge](https://ci.appveyor.com/api/projects/status/github/Tw1ddle/geometrize-haxe)](https://ci.appveyor.com/project/Tw1ddle/geometrize-haxe)
[![Haxelib Version](https://img.shields.io/github/tag/Tw1ddle/geometrize-haxe.svg?style=flat-square&label=haxelib)](https://lib.haxe.org/p/geometrize-haxe)

Geometrize Haxe is a Haxe library for recreating images with geometric primitives. Run the demo [in your browser](https://www.samcodes.co.uk/project/geometrize-haxe-web/).

Geometrize Haxe is part of [Geometrize](https://www.geometrize.co.uk/) and was inspired by the [primitive](https://github.com/fogleman/primitive) Go library.

[![Geometrized Cat 500 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/cat.gif?raw=true ""Geometrized Cat - 500 Geometric Primitives"")](https://www.geometrize.co.uk/)

## Features
* Recreate images as geometric primitives - rectangles, rotated rectangles, triangles, circles, ellipses, rotated ellipses, lines and beziers are supported.
* Export generated shape data to JSON.
* Export geometrized images as SVGs.
* All Haxe targets are supported.

## Shape Comparison

The matrix shows typical results for circles, triangles, rotated rectangles, rotated ellipses and all supported shapes at 50, 200 and 500 total shapes:

| -                  | 50 Shapes     | 200 Shapes    | 500 Shapes   |
| ------------------ | ------------- | ------------- | ------------ |
| Circles            | [![50 Circles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_50_circles.png?raw=true)](https://www.geometrize.co.uk/) | [![200 Circles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_200_circles.png?raw=true)](https://www.geometrize.co.uk/) | [![500 Circles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_500_circles.png?raw=true)](https://www.geometrize.co.uk/) |
| Triangles          | [![50 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_50_triangles.png?raw=true)](https://www.geometrize.co.uk/) | [![200 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_200_triangles.png?raw=true)](https://www.geometrize.co.uk/) | [![500 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_500_triangles.png?raw=true)](https://www.geometrize.co.uk/) |
| Rotated Rectangles | [![50 Rotated Rectangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_50_rotated_rectangles.png?raw=true)](https://www.geometrize.co.uk/) | [![200 Rotated Rectangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_200_rotated_rectangles.png?raw=true)](https://www.geometrize.co.uk/) | [![500 Rotated Rectangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_500_rotated_rectangles.png?raw=true)](https://www.geometrize.co.uk/) |
| Rotated Ellipses   | [![50 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_50_rotated_ellipses.png?raw=true)](https://www.geometrize.co.uk/) | [![200 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_200_rotated_ellipses.png?raw=true)](https://www.geometrize.co.uk/) | [![500 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_500_rotated_ellipses.png?raw=true)](https://www.geometrize.co.uk/) |
| All Shapes         | [![50 All Shapes](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_50_all_shapes.png?raw=true)](https://www.geometrize.co.uk/) | [![200 All Shapes](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_200_all_shapes.png?raw=true)](https://www.geometrize.co.uk/) | [![500 All Shapes](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/seagull_500_all_shapes.png?raw=true)](https://www.geometrize.co.uk/) |

## How It Works

A user provides a target image, and the algorithm finds shapes to approximate that image. To identify a good shape, the algorithm generates a large number of random candidate shapes, repeatedly improving the fit of each using a hillclimbing optimization approach, eventually choosing the best-fitting shape. The shapes are added one by one.

## JavaScript Usage

If you are working in JavaScript, check out [geometrizejs](https://www.npmjs.com/package/geometrizejs) which provides JavaScript API and types for this library, tested on browser and Node.js.

On top of it, [geometrizejs-cli](https://www.npmjs.com/package/geometrizejs-cli) tool provides command line interface and support for common image formats.

## Haxe Install

Get the [Haxe](https://haxe.org/) library from [GitHub](https://github.com/Tw1ddle/geometrize-haxe) or through [haxelib](https://lib.haxe.org/p/geometrize-haxe/):

```bash
haxelib install geometrize-haxe
```

## Haxe Usage

* Instantiate an ```ImageRunner```, passing it a ```Bitmap``` target image and a starting background ```Rgba``` color.
* Generate shapes by repeatedly calling ```runner.step(options)```, passing in your ```ImageRunnerOptions```.
* Export the results using the ```export``` methods on ```SvgExporter``` and ```ShapeJsonExporter```.

Refer to the library [documentation](https://tw1ddle.github.io/geometrize-haxe/). Also see the Geometrize Haxe [web demo](https://www.samcodes.co.uk/project/geometrize-haxe-web/) and [code](https://github.com/Tw1ddle/geometrize-haxe-web/), or this HaxeFlixel [example](https://samcodes.co.uk/project/geometrize-haxe-flixel/) and [code](https://github.com/Tw1ddle/geometrize-haxe-demo/).

## Resources

* See the Geometrize [resources](https://resources.geometrize.co.uk/) page.

## Examples And Screenshots

Geometrized public domain [artwork](https://commons.wikimedia.org/wiki/Category:Paintings_by_painter) and [photos](https://www.pexels.com/public-domain-images/):

[![Geometrized Flower 330 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/flower.png?raw=true ""Flower - 330 Rotated Ellipses"")](https://www.geometrize.co.uk/)
[![Geometrized Train 230 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/train.png?raw=true ""Train - 230 Rotated Ellipses"")](https://www.geometrize.co.uk/)
[![Geometrized Woodland Cemetery 600 Rotated Rectangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/woodland_cemetery.png?raw=true ""Woodland Cemetery - 600 Rotated Rectangles"")](https://www.geometrize.co.uk/)
[![Geometrized Pomegranate 300 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/pomegranate.png?raw=true ""Pomegranate - 300 Rotated Ellipses"")](https://www.geometrize.co.uk/)
[![Geometrized Monarch Butterfly 800 Various Shapes](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/monarch_butterfly.png?raw=true ""Monarch Butterfly - 800 Various Shapes"")](https://www.geometrize.co.uk/)
[![Geometrized Leafy Railroad 800 Rotated Rectangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/leafy_railroad.png?raw=true ""Leafy Railroad - 800 Rotated Rectangles"")](https://www.geometrize.co.uk/)
[![Geometrized Pyramid 150 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/pyramid.png?raw=true ""Pyramid - 150 Triangles"")](https://www.geometrize.co.uk/)
[![Geometrized Trees 210 Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/tree_under_clouds.png?raw=true ""Tree Under Clouds - 210 Ellipses"")](https://www.geometrize.co.uk/)
[![Geometrized Chomsky 300 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/chomsky.png?raw=true ""Noam Chomsky - 300 Triangles"")](https://www.geometrize.co.uk/)
[![Geometrized Trees 250 Rotated Ellipses](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/trees.png?raw=true ""Trees - 250 Rotated Ellipses"")](https://www.geometrize.co.uk/)
[![Geometrized Fairies 500 Triangles](https://github.com/Tw1ddle/geometrize-haxe/blob/master/screenshots/fairies.png?raw=true ""Fairies - 500 Triangles"")](https://www.geometrize.co.uk/)

For more examples, see the Geometrize [gallery](https://gallery.geometrize.co.uk/).

## Notes
* This implementation is single-threaded, and performance varies by target platform. Small target images work best.
* Got an idea or suggestion? Open an issue on GitHub, or send Sam a message on [Twitter](https://twitter.com/Sam_Twidale).
* Find more related projects and open source code [here](https://resources.geometrize.co.uk/).",337,337,14,9,art,"[art, geometrize, geometry-processing, haxe, haxelib, hill-climbing, primitives]",0
aztek,awesome-self-reference,,https://github.com/aztek/awesome-self-reference,https://api.github.com/repos/awesome-self-reference/aztek,"A curated list of examples of self-reference in art, science, and technology","# Awesome Self-Reference [![Awesome](https://awesome.re/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of examples of self-reference in art, science, and technology.

## Contents

- [Art](#art)
- [Language](#language)
- [Mathematics](#mathematics)
- [Computing](#computing)
- [Web](#web)
- [Other](#other)

## Art

- [The Treachery of Images](https://collections.lacma.org/node/239578) - A painting by René Magritte.
- [Triple Self-Portrait](http://www.nrm.org/MT/text/TripleSelf.html) - A painting by Norman Rockwell.
- [Mise en abyme](https://en.wikipedia.org/wiki/Mise_en_abyme) - A formal technique of placing a copy of an image within itself.
- [Droste effect](https://en.wikipedia.org/wiki/Droste_effect) - The effect of a picture recursively appearing within itself, in a place where a similar picture would realistically be expected to appear.

## Language

- [Autogram](https://en.wikipedia.org/wiki/Autogram) - A sentence that describes itself in the sense of providing an inventory of its own characters.
- [Fumblerule](https://en.wikipedia.org/wiki/Fumblerules) - A rule of language or linguistic style, humorously written in such a way that it breaks this rule.
- [Recursive acronym](https://en.wikipedia.org/wiki/Recursive_acronym) - An acronym that refers to itself.

## Mathematics

- [Liar's paradox](https://en.wikipedia.org/wiki/Liar_paradox) - This sentence is false.
- [Russell's paradox](https://en.wikipedia.org/wiki/Russell%27s_paradox) - Does the set of all those sets that do not contain themselves contain itself?
- [Trott's constant](https://www.johndcook.com/blog/2019/06/07/trotts-constant/) - The unique number whose digits equal its continued fraction coefficients.
- [13532385396179](http://wastlund.blogspot.com/2017/06/13532385396179-number-which-is-its-own.html?m=1) - A number that is its own prime factorization, that is 13532385396179 = 13 × 53² × 3853 × 96179.
- [Tupper's self-referential formula](https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula) - A formula that visually represents itself when graphed at a specific location in the (x, y) plane.
- [Life in Life](https://www.youtube.com/watch?v=xP5-iIeKXE8) - Conway's Game of Life running inside Conway's Game of Life using OTCA metapixels.

## Computing

- [Quine](https://en.wikipedia.org/wiki/Quine_(computing)) - A computer program that takes no input and produces a copy of its own source code as its only output.
  - [An Ouroboros Quine](https://github.com/mame/quine-relay) - A Ruby program that generates Rust program that generates Scala program that generates (through 128 languages in total) REXX program that generates the original Ruby code again.
  - [A radiation hardened quine](https://github.com/mame/radiation-hardened-quine) - A Ruby quine that remains a quine after any one of the characters in its source code is removed.
  - [quinesnake](https://github.com/taylorconor/quinesnake) - A quine that plays snake over its own source.
  - [The Qlobe](http://mamememo.blogspot.com/2010/09/qlobe.html) - A Ruby quine with an ASCII image of a globe in its source code that rotates by 45 degrees after each run, eventually coming around after eight runs.
  - [html_wysiwyg](https://secretgeek.github.io/html_wysiwyg/html.html) - A truly naked, brutalist html quine.
- [hashquine_by_retr0id.png](https://twitter.com/David3141593/status/1573218394358386688) - A PNG image of the ouroboros that displays its own MD5 hash.
- [Meta-circular evaluator](https://en.wikipedia.org/wiki/Meta-circular_evaluator) - An interpreter that defines each feature of the interpreted language using a similar facility of the interpreter's host language.
- [A Micro-Manual for LISP - Not the whole truth](https://github.com/jaseemabid/micromanual) - The LISP interpreter written in LISP.
- [Fix-point combinator](https://en.wikipedia.org/wiki/Fixed-point_combinator) - A higher-order function fix that, for any function f that has an attractive fixed point, returns a fixed point x of that function.
- [Universal Turing machine](https://en.wikipedia.org/wiki/Universal_Turing_machine) - A Turing machine that can simulate an arbitrary Turing machine on arbitrary input.
- [Bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(compilers)) - A technique for producing a self-compiling compiler - that is, compiler (or assembler) written in the source programming language that it intends to compile.
- [Man man](https://www.man7.org/linux/man-pages/man1/man.1.html) - Manual pager man page (accessed using `$ man man`).

## Web

- [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia) - An article about Wikipedia on Wikipedia.
- [Wayback Machine](https://web.archive.org/web/*/https://web.archive.org/) - Snapshots of The Internet Archive stored in The Internet Archive.
- [Quine Tweet](https://twitter.com/quinetweet/status/1309951041321013248) - A tweet that quote tweets itself.
- [Awesome Self-Reference](https://github.com/aztek/awesome-self-reference) - A curated list of examples of self-reference in art, science, and technology, which includes itself.

## Other

- [Hofstadter's law](https://en.wikipedia.org/wiki/Hofstadter%27s_law) - ""It always takes longer than you expect, even when you take into account Hofstadter's Law"".
- [Miniatur Wunderland](https://www.miniatur-wunderland.com/discover-wunderland/worlds/hamburg/speicherstadt/) - The world's largest model railway in Hamburg, Germany has a model of itself in its model of Hamburg.
- [Untitled Goose Game](https://untitledgoosegame.fandom.com/wiki/Model_Village) - The village where Untitled Goose Game takes place contains a small model version of itself, and also a tiny version of the model inside that.

",250,250,7,2,art,"[art, awesome, awesome-list, geb, language, mathematics, quine, science]",0
CuriousNikhil,k5-compose,,https://github.com/CuriousNikhil/k5-compose,https://api.github.com/repos/k5-compose/CuriousNikhil,K5-compose is a sketchy port of p5.js for Jetpack Compose Desktop,"# k5-compose

**k5-compose** is a sketchy port of [P5.js](https://p5js.org/) for Jetpack Compose Desktop.

[![](https://img.shields.io/badge/mavencentral-v1.0.1-yellowgreen?style=flat-square&logo=gradle)](https://github.com/CuriousNikhil/k5-compose/releases/tag/v1.0.1) [![aweseome kotlin](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/KotlinBy/awesome-kotlin)


This library provides you a playground to play with your sketches so you don't have to worry about maintaining/remembering states and setting up the animations etc.
You can focus on creating awesome sketches, creating generative art. This library also provides you necessary physics and math functions which are ported from p5.js. 

Say for example you can do something like this in just 20 lines of code -

| Moving Vehicle code | K5 Sketch |
|---|---|
| ![carbon](https://user-images.githubusercontent.com/16976114/138512721-c580b54e-dcff-46c4-8df6-f43ec4d081f6.png) | ![fastest_gif](https://user-images.githubusercontent.com/16976114/138569158-ac14af91-d9ed-48c4-bd51-65e48a8c71cd.gif) |


## Few examples...

| [parametric eq](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/mathematics/parametric-equation.kt) | [particles js](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/simulations/particles-js-simulation.kt)  | [gravitation](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/forces/GravitationalAttraction.kt)  | [game of life automaton](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/simulations/gameOfLife.kt) |
|---|---|---|---|
| <video width=""500"" height=""500"" style=""width: 500px; height: 500px;"" src=""https://user-images.githubusercontent.com/16976114/138592033-10030335-326d-409a-a322-ea6ce95b7b78.mov"" autoplay muted loop /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/138592054-92c68869-9e86-452a-bf8a-8bf9dffc89ad.mov"" autoplay muted loop /> | <video width=""500"" height=""500"" style=""width: 500px; height: 500px;"" src=""https://user-images.githubusercontent.com/16976114/138592061-7cc2a8ae-c4de-40f6-9801-86c28621743c.mov"" autoplay muted /> | <video width=""500"" height=""500"" style=""width: 500px; height: 500px;"" src=""https://user-images.githubusercontent.com/16976114/138592081-d8661041-4beb-4d44-a640-60753ef87a5b.mov"" autoplay muted /> | 
| Starfield | Rain drops | Fractal tree | Fireworks |
| <video width=""500"" height=""500"" style=""width: 500px; height: 500px;"" src=""https://user-images.githubusercontent.com/16976114/140640787-b3d9f780-02f4-42e3-9849-c7b18f180646.mov"" autoplay muted /> | <video width=""500"" height=""500"" style=""width: 500px; height: 500px;"" src=""https://user-images.githubusercontent.com/16976114/140640784-f588c34a-187b-4e21-8df0-dae5a4cdfb07.mov"" autoplay muted /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/142251242-00474644-4dd9-4679-b9cf-99e8226ca895.mov"" /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/142251588-a4c7b042-72d7-4122-92ac-362176547670.mov"" /> |
| Circle waves | CircleGrid | danceYarn (by [@elye_project](https://twitter.com/elye_project)) | landscapeInspection (by [@elye_project](https://twitter.com/elye_project)) |
| <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/142757121-f439527e-981c-4513-bac8-1e2eb38b8556.mov"" /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/144030859-9ed897dd-e1cf-4ad7-acb6-80337df04696.mov"" /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/144699346-1eabc21f-4084-4696-b28d-10a5b379a13c.mov"" /> | <video width=""500"" height=""500"" src=""https://user-images.githubusercontent.com/16976114/144699446-067b580f-bc95-4cf3-9fb2-d2e6fc92a75d.mov"" />  |




**Also don't forget to check awesome [examples and blog posts by few contributors](#contributors)**

Click on the link to go to the code. Code explains the things in details. Try playing with those by tweaking values and running on your own. 😄 (I have added videos instead of gifs just so you can view these without loosing any frames 😉) 



### Generative Art with K5-Compose

All the examples can be found [here](https://github.com/CuriousNikhil/k5-compose/tree/main/src/main/kotlin/examples)

| Blackhole | 10Print | Circle Loop | 
|---|---|---|
| ![image](https://user-images.githubusercontent.com/16976114/140384540-df60fac9-7ab6-4cf9-825d-ecabc7ea8626.png) | ![image](https://user-images.githubusercontent.com/16976114/140384588-b59d39ff-6aa8-4f19-96b0-63c225825765.png) | ![image](https://user-images.githubusercontent.com/16976114/140384655-1de371e4-f074-4f5d-9793-9d8577c2d5f3.png) |
| Threads with Perlin-Noise | Phyllotaxis | Mandlebrot (by [@elye_project](https://twitter.com/elye_project)) |
| ![image](https://user-images.githubusercontent.com/16976114/140385172-de1f86c5-0e99-4ef7-81ac-0fd6777e99d0.png) | ![image](https://user-images.githubusercontent.com/16976114/140390189-7ab55cb2-1b9b-479c-a47f-77862a34d1db.png) | ![image](https://user-images.githubusercontent.com/16976114/144698909-2b8a6c46-55f1-4e83-ab15-08f1a5ac8618.png) |
| Perlin noise1d (by [@elye_project](https://twitter.com/elye_project)) | Perlin noise2d (by [@elye_project](https://twitter.com/elye_project)) | Ribbon |
| ![image](https://user-images.githubusercontent.com/16976114/144699041-fcfd3bad-bbae-4b16-819a-16edb5911eba.png) | ![image](https://user-images.githubusercontent.com/16976114/144699111-08e3157c-2f46-43bf-946c-9ff240a3d169.png) | ![image](https://user-images.githubusercontent.com/16976114/145774858-b1d81999-ef24-45d8-88c8-efc6fe6831a2.png) |
| Circle Packing | | |
| <img width=""506"" alt=""Screenshot 2022-03-05 at 11 55 13 PM"" src=""https://user-images.githubusercontent.com/16976114/156895784-42cdb451-1ce7-4d00-910e-4d9934f3b328.png""> | | |







## Getting started

In order to understand using this library for creating experiments, I would recommend to go through the Nature of Code book by Daniel Shiffman - https://natureofcode.com/book/.
This will give you the overall knowledge about how a physics system works in simplest way in p5/k5 or in general computer world.  
However, you could start digging into it right away by checking examples.

1. Create your [Jetpack Compose Desktop](https://github.com/JetBrains/compose-jb) project. Add the following dependency in your `build.gradle` along with the `compose` dependencies

```kotlin
implementation(""me.nikhilchaudhari:k5-compose:{latest-version}"")
```

2. Use `k5` dsl construct to create K5 sketch

```kotlin
fun main() = k5{

  // Initialise your variables, objects

  show { drawScope ->
    // use drawScope to draw the shapes
  }  
}
```

3. Use [library apis](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/index.html) for calculations and you are good to go! :p

No need to manage/remember states, animation or anything. Just focus on your logic to design sketch rest of the things are handled by the library.


## How do I do that?

### k5

It's very easy, you have to use `k5{...}` builder in order to initialise your k5-sketch. The things you define in here will be initialised only once.

```kotlin
fun main() = k5{
  // you can define all your properties, variables, vectors here.
    val position = Vector2D(20f, 20f)
    
    // Say you want to have a control over your shape and few other parameters like, force, acceleration, mass etc. You can use classes to represent your shapes.
    val spaceShip = SpaceShip(position, size) // some data class representing spaceship
    
  //...
}
```

You can pass `size` param in `k5()` 

```kotlin
  fun main() = k5(size = Size(800f, 500f)) { ... }
```

And there are more number of configurations you can do to k5-compose playground which will be applied to the `Window{..}` composable. You can check [API docs](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/index.html).


### show

Once you have initialised your necessary stuff which is going to change while running the frame of animation, you have to draw your shape/sketch in the `show{...}` function. `show` function gives you a canvas drawscope which you can used to draw into the k5 compose playground. 

Note: Whatever you pass in `show{...}` lambda will run for every frame. So if you want to update the values you've initialised and draw the sketch every frame you can pass those things in the lambda. For example -

```kotlin
fun main() = k5{
  val vehiclePosition = Vector2D(20f, 20f)

  show{ drawScope ->
      
      //update your vehicle position, 
      vehiclePosition.add(Vector2D.randomVector() * 2f)
      
       drawScope.drawCircle(color = Color.White, radius = 30f, center = vehiclePosition.toOffSet())
  }
}
```

You can apply all the compose `Modifiers` to the playground like changing background, color and taking keyboard and mouse pointer input. 

```kotlin
    show(modifier = Modifier
        .background(Color.Yellow)
        .pointerMoveFilter(
            onMove = {
                //use mouse pointer values here
                false
            }
        )
    ) {
        // Draw your sketch
    }
```

### showWithControls

If you want to add some interactivity with controls for your sketch, you can use `showWithControls(){..}`. You can add readily available Jetpack Compose elements like Slider, Checkbox, Toggle, Button, etc. And use `State` to change, update, take the inputs to your k5 sketch.

```kotlin

fun main() = k5 {

val numbers = mutableStateOf(0.3f)

// Here Slider is pure Jetpack Compose element
showWithControls(controls = {
      Text(""Number of squares"")
      Slider(
          value = numbers.value,
          onValueChange = { numbers.value = it }
      )
  }){ drawScope ->

      // Use the numbers value here
      // Draw your sketch.
  }
```
Few examples [here](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/simulations/rotatingsquares.kt) and [here](https://github.com/CuriousNikhil/k5-compose/blob/main/src/main/kotlin/examples/particles/particles-js-simulation.kt). Which looks something like this - [video](https://user-images.githubusercontent.com/16976114/150638237-d64c0a2f-9bdc-4e14-b71b-56b3aff357f6.mov)

<img width=""732"" alt=""image"" src=""https://user-images.githubusercontent.com/16976114/150638449-5af40faf-d3fe-49bc-8407-fad695378a64.png"">


This adds 2/3rd of your specified `width` to the k5 compose playground window.

## Few handy Apis

**noLoop**

Here, the `vehiclePosition` is constantly updated by adding a random vector to it's previous position and then a new circle is drawn on the playground based on the updated position. Simple, right?

Let's say you don't want to keep your sketch in loop. Let's say you want to draw it only once. You can use `noLoop()` method in `k5{...}`.

**Playground size**

You can use `dimensInt` or `dimensFloat` properties available in `k5{...}` to get the size of the playground. You can pass the `size` in `k5()` as well but there are few density display metrics related issues in using floating point values. So to avoid any miscalculations, these `Size` values can be used to get the precise height and width of your playground.


```kotlin
fun main() = k5 {

    // Use noLoop to draw your content only once
    noLoop()

    show {
        // this will be drawn only once
    }

}
```


## How do I use math and physics functions?

To use and understand mathematics and physics I would recommend [Nature Of Code](https://natureofcode.com/book/) book and [Video series](https://www.youtube.com/watch?v=70MQ-FugwbI&list=PLRqwX-V7Uu6ZV4yEcW3uDwOgGXKUUsPOM) by Daniel Shiffman. Or you can go through the [examples](https://github.com/CuriousNikhil/k5-compose/tree/main/src/main/kotlin/examples) section in the repo.

### Vectors

`Vector2D` is data class - a vector representing any vector quantity in 2D plane. You can create a simple vector like `val acceleration = Vector2D(x = 2f, y = 3f)`, this means that the acceleration vector's x component is 2f and y component is 3f.

To perform vector operations there are extensions and operators available to give you all the necessary vector algebra APIs. You can take a look at those methods here in the [API Docs](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-vector2-d/index.html). 

Few helper methods available to create vectors from angle and also to create random vectors - 

**Random Vector**
You can create random unit vector by using static method `randomVector` of `Vector2D` class. This creates a random unit vector.

```kotlin
val position = Vector2D.randomVector()
```

**Vector from angle**
If you want to create a vector using any `angle` you can use `fromAngle` static method. For ex - the below code will create a vector with angle as PI radians and length of 2. (means x = 2 * cos(angle), y = 2 * sin(angle))

```kotlin
val position = Vector2D.fromAnAngle(angle = PI, length = 2f)
```

**toOffset**
There's another handy method to convert your vector to the `Offset` type since you need to pass Offset types while drawing in Jetpack Compose. So you can convert Vector2D into Offset. Using `toOffset` on vector value.

```kotlin
 val position = Vector2D(2f, 5f)
    position.toOffSet()
```

### Random

You can use the `Random` functions available in Kotlin by default. 
To quickly generate any random number within particular range, there are helper extensions available over `ClosedRange` for any Number data types. 

For ex - `(-12f..-8f).random()` or `(1..40).random()` or `(1.0..10.0).random()` etc

If you want ot generate `randomGaussian` or a random number with your custom set `seed` value, apis are available to set the seed for randomness etc. You can check it [here](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-random-kt/index.html). And you can use `k5Random`([api doc](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-random-kt/k5-random.html)) and `randomGaussian`([api doc](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-random-kt/random-gaussian.html)) functions to generate random values.  


### Noise

Noise is used a lot in p5 to generate a smooth randomness in numbers. This library contains Perlin noise helper methods which will generate noise values. You can check it [here](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-noise-kt/index.html). 

There are three methods available for generating noise values - `noise1D(x: Double)`, `fun noise2D(x: Double, y: Double)` and `fun noise3D(x: Double, y: Double, z: Double)` 

If you don't know what noise is please take a look [here](https://en.wikipedia.org/wiki/Perlin_noise)

### Trigonometry

You could of course use the basic kotlin.math trigonometric functions but just to keep it in handy this library has extensions functions over `Float` values. So you can just convert any float value to trigonometric function value over this float.

```kotlin
  val tan = 1f.tan()
  val cos = 0.2f.cos()
  val sin = 0.1f.sin()

  val atan = 1f.atan()
  val acos = 0.2f.acos()
  val asin = 0.1f.asin()
```

You can check few more trigonometric functions [here](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-trigonometry-kt/index.html)


**Angle**
The default angle measurement is in radians. If you want to change the angles to be measured in the degrees, then you can set the `angleMode` to degrees. And degress will be used to measure the angle and in all the functions related to angles.

```kotlin
angleMode = AngleMode.DEGREES
```

### Calculations

There are certain calculations that are related to vector, numbers etc which are required when you write physics system in a 2D environment. Those few methods are directly ported from p5.js. You can find some functions like `lerp`, `map`, `norm`, `constrain` etc. [here](https://javadoc.io/doc/me.nikhilchaudhari/k5-compose/latest/k5-compose/math/-calculations-kt/index.html)


## Contributors

* [@elye_project](https://twitter.com/elye_project) has added awesome animations using perlin noise check them out [here](https://github.com/CuriousNikhil/k5-compose/tree/main/src/main/kotlin/examples/elye)
  * He has also written a blog post- [How to write animations under 50 lines using K5 Compose in Jetpack Compose](https://medium.com/mobile-app-development-publication/jetpack-compose-animation-under-50-lines-using-k5-compose-playground-bef35060c471)


### Contribution Guide

PRs are welcomed! Please check contribution guide [here](https://github.com/CuriousNikhil/k5-compose/wiki/Contribution-Guide)

### License
Licensed under Apache License, Version 2.0 [here](https://github.com/CuriousNikhil/k5-compose/blob/main/LICENSE)
",200,200,3,0,art,"[android, art, draw, generative-art, jetpack-compose, kotlin, p5js]",0
urpflanze-org,urpflanze,urpflanze-org,https://github.com/urpflanze-org/urpflanze,https://api.github.com/repos/urpflanze/urpflanze-org,"A library for developers who want to approach to creative coding, artists who want to approach coding and for those who find it fun to play with math.","<img height=""60"" src=""./docs/assets/images/logo-for-github.svg"">

## Synopsis

This library is based on the [Urpflanze](https://github.com/urpflanze-org/urpflanze) package for generate the scene.

It deals with creating two-dimensional shapes, repeating them, manipulating them point by point and encapsulating them.

## Motivations

The creation of this library comes from the need to create simple APIs for
manage the repetition of primitive shapes and the possibility of applying transformations to each of them, applying transformations on the points avoiding the use of canvas transformations.

Another need - which then became one of the main features - was to be able to encapsulate the result of a generation and manage it as if it were a new shape.

## Donate

I am trying to create a tool for those who want to approach the world of programming
or for programmers who want to approach the world of creative coding.

I have spent a lot of time and will spend more to support this project.
I also have in mind a **[web editor](https://github.com/urpflanze-org/editor)** (open-source) where you can use the features of this library in the browser.

You can see a preview [here](https://editor.urpflanze.org)

[![](https://img.shields.io/badge/donate-paypal-003087.svg?logo=paypal)](https://www.paypal.me/genbs)
[![](https://img.shields.io/badge/donate-ko--fi-29abe0.svg?logo=ko-fi)](https://ko-fi.com/urpflanze)

[![](https://img.shields.io/badge/bitcoin-1CSQq4aMmsA71twvyZHZCjmeB2AmQGCPNq-f7931a.svg?logo=bitcoin)](https://explorer.btc.com/btc/address/1CSQq4aMmsA71twvyZHZCjmeB2AmQGCPNq)
[![](https://img.shields.io/badge/ethereum-0x9086c4bb7015c1d6dc79162d02e7e1239c982c01-ecf0f1.svg?logo=ethereum)](https://etherscan.io/address/0x9086c4bb7015c1d6dc79162d02e7e1239c982c01)

---

##

|                                                          |                                                              |                                                       |
| :------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------------------: |
|    <img src=""./docs/assets/images/readme/cadere.gif"">    | <img src=""./docs/assets/images/readme/crepuscolar-soul.gif""> |   <img src=""./docs/assets/images/readme/four.gif"">    |
| <img src=""./docs/assets/images/readme/triangleloop.gif""> |   <img src=""./docs/assets/images/readme/psychedelic.gif"">    | <img src=""./docs/assets/images/readme/particles.gif""> |

---

## Installation

The most immediate way to include Urpflanze in your project is to use an online hosted version.

### CDN

Full version

```html
<script src=""https://cdn.jsdelivr.net/npm/@urpflanze/js""></script>
```

Customizable version

```html
<script src=""https://cdn.jsdelivr.net/npm/@urpflanze/js[@version]/build/urpflanze[-light][.min].js""></script>
```

### NPM

To install it just run the command:

```sh
npm i --save @urpflanze/js
```

At the end you can include Urpflanze in your code

```javascript
import * as Urpflanze from '@urpflanze/js'

const scene = new Urpflanze.Scene()

// or

import { Scene } from '@urpflanze/js'

const scene = new Scene()
```

_use `urpflanze/dist/index-light` for light version_

## Example

### Hello Rect!

```javascript
const scene = new Urpflanze.Scene()

const rect = new Urpflanze.Rect({
	repetitions: 8,
	distance: 100,
	sideLength: 20,
})
scene.add(rect) // Add rect to scene

const drawer = new Urpflanze.DrawerCanvas(scene, document.body)
drawer.draw() // Draw scene on canvas
```

### Output

![Example output](./docs/assets/images/readme/output-1.png)

---

## [Full docs and Examples](https://docs.urpflanze.org/urpflanze/)

---

### [Core](https://github.com/urpflanze-org/core) · [DrawerCanvas](https://github.com/urpflanze-org/drawer-canvas) · [Animation](https://github.com/urpflanze-org/animation)
",191,191,7,0,art,"[2d-framework, 2d-graphics, art, creative-coding, creativecoding, generative-art, javascript, line-art, math-art, plotter]",0
wojtryb,Shortcut-Composer,,https://github.com/wojtryb/Shortcut-Composer,https://api.github.com/repos/Shortcut-Composer/wojtryb,Krita plugin for creating complex keyboard shortcuts,"# Shortcut composer **v1.4.0**

[![python](https://img.shields.io/badge/Python-3.8-3776AB.svg?style=flat&logo=python&logoColor=white)](https://www.python.org)
[![Code style: black](https://img.shields.io/badge/code%20style-autopep8-333333.svg)](https://pypi.org/project/autopep8/)
[![License: GPLv3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![wojtryb website](https://img.shields.io/badge/YouTube-wojtryb-ee0000.svg?style=flat&logo=youtube)](https://youtube.com/wojtryb)
[![wojtryb twitter](https://img.shields.io/badge/Twitter-wojtryb-00aced.svg?style=flat&logo=twitter)](https://twitter.com/wojtryb)
[![wojtryb portfolio](https://img.shields.io/badge/Art_Portfolio-wojtryb-000000.svg?style=flat&logo=)](https://cara.app/wojtryb)

---

**`Extension`** for painting application [**`Krita`**](https://krita.org/), which allows to create custom, complex **`keyboard shortcuts`**.

The plugin adds new shortcuts of the following types:
- [**`Pie menu`**](https://github.com/wojtryb/Shortcut-Composer/wiki/Plugin-actions#pie-menus) - while key is pressed, displays a pie menu, which allows to pick values by hovering a mouse.
- [**`Cursor tracker`**](https://github.com/wojtryb/Shortcut-Composer/wiki/Plugin-actions#cursor-trackers) - while key is pressed, tracks a cursor, switching values according to cursor offset.
- [**`Canvas preview`**](https://github.com/wojtryb/Shortcut-Composer/wiki/Plugin-actions#canvas-previews) - Temporarily changes canvas elements while the key is pressed.
- [**`Multiple assignment`**](https://github.com/wojtryb/Shortcut-Composer/wiki/Plugin-actions#multiple-assignments) - repeatedly pressing a key, cycles between multiple values of krita property.
- [**`Temporary key`**](https://github.com/wojtryb/Shortcut-Composer/wiki/Plugin-actions#temporary-keys) - temporarily activates a krita property with long press or toggles it on/off with short press.

## Important links
> Download the [**`latest version`**](https://github.com/wojtryb/Shortcut-Composer/archive/refs/heads/main.zip) of the plugin, or visit its [**`github page`**](https://github.com/wojtryb/Shortcut-Composer).

---

- [Watch video tutorials 📺](https://www.youtube.com/playlist?list=PLeiJahtD9hCrtKRRYjdi-JqRtqyvH3xCG)
- [Read user manual 📄](https://github.com/wojtryb/Shortcut-Composer/wiki)
- [Join community discussion 👥](https://krita-artists.org/t/shortcut-composer-v1-2-2-plugin-for-pie-menus-multiple-key-assignment-mouse-trackers-and-more/55314)
- [Report a bug 🦗](https://github.com/wojtryb/Shortcut-Composer/issues)
- [Request a new feature 💡](https://github.com/wojtryb/Shortcut-Composer/discussions)
- [What's new in latest version? ⭐](https://github.com/wojtryb/Shortcut-Composer/releases)

## Changelog videos

[![PIE MENUS - introducing Shortcut Composer](https://user-images.githubusercontent.com/51094047/244950488-83bd44ff-87f6-4b95-82c7-0f5031bb1b8e.png)](https://www.youtube.com/watch?v=eHK5LBMNiU0 ""Managing BRUSHES with Shortcut Composer 1.3"")

[![PIE MENUS - introducing Shortcut Composer](https://github-production-user-asset-6210df.s3.amazonaws.com/51094047/238015603-3143fc2d-0fa7-4da1-868d-2ec054ccaeb3.png)](https://www.youtube.com/watch?v=Tkf2-U0OyG4 ""PIE MENUS - introducing Shortcut Composer"")

[![PIE MENUS - release video](https://github-production-user-asset-6210df.s3.amazonaws.com/51094047/238179887-87c00d86-0e65-46c2-94c4-52bb02c99501.png)](https://youtu.be/hrjBycVYFZM ""PIE MENUS - introducing Shortcut Composer"")

## Requirements
- Version of krita on plugin release: **5.1.5**
- Required version of krita: **5.1.0** or later

OS support state:
- [x] Windows (10, 11)
- [x] Linux (Ubuntu 20.04, 22.04)
- [ ] MacOS (Known bug of canvas losing focus after using PieMenu)
- [ ] Android (Does not support python plugins yet)

> **Note**
> On **Linux** the only oficially supported version of Krita is **.appimage**, which ships with all required dependencies. Running the plugin on Krita installed from Snap or distribution repositories is not recommended as it may not work out of the box and may require extra dependency-related work.

## How to install or update the plugin:
Installation steps are THE SAME for installing the plugin for the first time and for updating it to the new version:

1. Download the plugin:
    - Use the direct link for [stable](https://github.com/wojtryb/Shortcut-Composer/archive/refs/heads/main.zip) or [development](https://github.com/wojtryb/Shortcut-Composer/archive/refs/heads/development.zip) release.
    - Alternatively, on [github page](https://github.com/wojtryb/Shortcut-Composer) switch from `main` to any of the unstable versions, click the green button `code` and pick the `download zip` option.
2. In krita's topbar, open **Tools > Scripts > Import Python Plugin From File** and pick the downloaded .zip file
3. Restart krita.
4. Set custom shortcuts in **Settings > Configure Krita > Keyboard Shortcuts** under **Scripts > Shortcut Composer: ...** sections. By intention, there are no default bindings.

> **Warning**
> Some keyboard buttons like **Space, R, Y, V, 1, 2, 3, 4, 5, 6** are reserved for Krita's Canvas Inputs. Assigning those keys to actions (including those from the plugin) may result in conflicts and abnormal behaviour different for each OS. Either avoid those keys, or remove their bindings in **Settings > Configure Krita > Canvas Input Settings**.


## For krita plugin programmers
Some parts of plugin code solve general problems, which can apply outside of Shortcut Composer. Those solutions were placed in separate packages that can be copy-pasted into any other plugin and reused there.

They depend only on original [Krita API](https://api.kde.org/krita/html/classKrita.html) and PyQt5 with which krita is shipped.

- [Custom keyboard shortcut interface](./shortcut_composer/input_adapter/)
- [Config system](./shortcut_composer/config_system/)
- [Alternative Krita API](./shortcut_composer/api_krita/)
",184,184,8,2,art,"[art, digital-painting, keyboard-shortcuts, krita, krita-plugin, painting, pie, plugin, python3]",0
ClementCariou,virtual-art-gallery,,https://github.com/ClementCariou/virtual-art-gallery,https://api.github.com/repos/virtual-art-gallery/ClementCariou,Explore an Art Gallery in your browser.,,166,166,4,3,art,"[3d, art, gallery, painting, procedural-generation, regl, webgl]",0
quchen,generative-art,,https://github.com/quchen/generative-art,https://api.github.com/repos/generative-art/quchen,"I wanted to make a nicer sticker for Munihac, then things got out of hand.","# Generative art using Haskell

[quchen](https://github.com/quchen) and [fmthoma](https://github.com/fmthoma)
playing around with 2-dimensional geometry and generative art using Haskell and
Cairo.

## Documentation

[Haddock of current master](https://quchen.github.io/generative-art/)

Some more documentation is also available in the [docs/](docs/README.md) folder.

## Showcases

![](showcases/circuits.svg)

![](showcases/truchet.svg)

![](showcases/truchetti.svg)

![](showcases/voronoi_3d.svg)

![](showcases/vector_fields.svg)
",144,144,6,4,art,"[art, generative-art, haskell]",0
owenmcateer,Motus-Art,,https://github.com/owenmcateer/Motus-Art,https://api.github.com/repos/Motus-Art/owenmcateer,My digital sketch book,"[![Motus Art](assets/img/website/MotusArt.jpg ""Motus Art"")](#motus-art)
[![Project Aureole](assets/img/website/Project-Aureole.jpg ""Project Aureole"")](https://github.com/owenmcateer/Project-Aureole)
[![Store](assets/img/website/Buy-prints.jpg ""Buy Motus Art Prints"")](https://motusart.redbubble.com/)


# Motus Art

**Creative Coding and Generative art.**  
https://www.instagram.com/motus_art/

You can now purchase Motus Art designs on [Canvas prints](https://www.redbubble.com/people/motusart/shop?artistUserName=motusart&asc=u&iaCode=u-print-canvas), [Posters](https://www.redbubble.com/people/motusart/shop?artistUserName=motusart&asc=u&iaCode=u-print-poster), [T-Shirts](https://cottonbureau.com/people/owen-mcateer), [Notebooks](https://www.redbubble.com/people/motusart/shop?artistUserName=motusart&asc=u&iaCode=u-notebook-spiral) and [more](https://www.redbubble.com/people/motusart/shop).
Checkout the [Motus Art store](https://www.redbubble.com/people/motusart/shop).


## Latest work
[**Genuary 2023**](./GENUARY.md)

---

[**Sinking floor**][week175] [*(code)*][week175code]  
[![Sinking floor](./assets/img/preview/week_175.png)][week175]

[**New directions**][week174] [*(code)*][week174code]  
[![New directions](./assets/img/preview/week_174.png)][week174]

[**Colourful smokey waves**][week173] [*(code)*][week173]  
[![Colourful smokey waves](./assets/img/preview/week_173.png)][week173]

[**Smokey waves**][week172] [*(code)*][week172]  
[![Smokey waves](./assets/img/preview/week_172.png)][week172]

[**Life timeline**][week171] [*(code)*][week171code]  
[![Life timeline](./assets/img/preview/week_171.png)][week171]


## Full archive
[![Sinking floor](./assets/img/preview/week_175.png)][week175]
[![New directions](./assets/img/preview/week_174.png)][week174]
[![Colourful smokey waves](./assets/img/preview/week_173.png)][week173]
[![Smokey waves](./assets/img/preview/week_172.png)][week172]
[![Life timeline](./assets/img/preview/week_171.png)][week171]
[![Dancing rays](./assets/img/preview/week_170.png)][week170]
[![Step back](./assets/img/preview/week_169.png)][week169]
[![Noisy Circles](./assets/img/preview/week_168.png)][week168]
[![Elastic circles](./assets/img/preview/week_167.png)][week167]
[![Scale &amp; rotate](./assets/img/preview/week_166.png)][week166]
[![Low poly waves](./assets/img/preview/week_165.png)][week165]
[![Flow Fields](./assets/img/preview/week_164.png)][week164]
[![Twisted audio](./assets/img/preview/week_163.png)][week163]
[![500k lines](./assets/img/preview/week_162.png)][week162]
[![Ripple angles](./assets/img/preview/week_161.png)][week161]
[![Cubed](./assets/img/preview/week_160.png)][week160]
[![Square tunnel](./assets/img/preview/week_159.png)][week159]
[![Scaling Tower](./assets/img/preview/week_158.png)][week158]
[![Rotating stack](./assets/img/preview/week_157.png)][week157]
[![Ripples](./assets/img/preview/week_156.png)][week156]
[![Pi Day 2022](./assets/img/preview/week_155.png)][week155]
[![Cyclone](./assets/img/preview/week_154.png)][week154]
[![Night ocean](./assets/img/preview/week_153.png)][week153]
[![Reactor core](./assets/img/preview/week_152.png)][week152]
[![Packed Circles](./assets/img/preview/week_150.png)][week150]
[![A loud GIF](./assets/img/preview/week_149.png)][week149]
[![Cobweb Frosting](./assets/img/preview/week_148.png)][week148]
[![Entity Globe](./assets/img/preview/week_147.png)][week147]
[![Marching planes](./assets/img/preview/week_146.png)][week146]
[![Rotating & Flipping (Audio reactive)](./assets/img/preview/week_136.png)][week145]
[![Wormhole (Audio reactive)](./assets/img/preview/week_103.png)][week144]
[![Crosswork](./assets/img/preview/week_143.png)][week143]
[![Blurry cubes](./assets/img/preview/week_142.png)][week142]
[![Inner point](./assets/img/preview/week_141.png)][week141]
[![Crossed wires](./assets/img/preview/week_140.png)][week140]
[![Pi Day 2021](./assets/img/preview/week_139.png)][week139]
[![360](./assets/img/preview/week_138.png)][week138]
[![Polygonal Chain](./assets/img/preview/week_137.png)][week137]
[![Rotating &amp; Flipping](./assets/img/preview/week_136.png)][week136]
[![Pastel Rings](./assets/img/preview/week_135.png)][week135]
[![Blips](./assets/img/preview/week_134.png)][week134]
[![Broken Heart](./assets/img/preview/week_133.png)][week133]
[![Love of Colour](./assets/img/preview/week_132.png)][week132]
[![Tides Ellipses](./assets/img/preview/week_131.png)][week131]
[![Wave Machine](./assets/img/preview/week_130.png)][week130]
[![Ripple effect](./assets/img/preview/week_129.png)][week129]
[![Cube Labyrinth](./assets/img/preview/week_128.png)][week128]
[![45° Random](./assets/img/preview/week_127.png)][week127]
[![The passage](./assets/img/preview/week_126.png)][week126]
[![The Eternal Descent](./assets/img/preview/week_125.png)][week125]
[![A way out of the Prefab World](./assets/img/preview/week_124.png)][week124]
[![Grids: Tetrahedrons](./assets/img/preview/week_123.png)][week123]
[![Infinite](./assets/img/preview/week_122.png)][week122]
[![Slates](./assets/img/preview/week_121.png)][week121]
[![Water Simulations](./assets/img/preview/WaterSimulations.png)][waterSims]
[![Tides](./assets/img/preview/week_120.png)][week120]
[![Spaced Order](./assets/img/preview/week_119.png)][week119]
[![Twisted sequence](./assets/img/preview/week_118.png)][week118]
[![Grids: Pentadecagon](./assets/img/preview/week_117.png)][week117]
[![The arista](./assets/img/preview/week_116.png)][week116]
[![Plane boxes](./assets/img/preview/week_115.png)][week115]
[![School of fish](./assets/img/preview/week_114.png)][week114]
[![The Drop](./assets/img/preview/week_113.png)][week113]
[![Pins & needless](./assets/img/preview/week_112.png)][week112]
[![Week 111](./assets/img/preview/week_111.png)][week111]
[![Week 110](./assets/img/preview/week_110.png)][week110]
[![Week 109](./assets/img/preview/week_109.png)][week109]
[![Week 108](./assets/img/preview/week_108.png)][week108]
[![Week 107](./assets/img/preview/week_107.png)][week107]
[![Week 106](./assets/img/preview/week_106.png)][week106]
[![Week 105](./assets/img/preview/week_105.png)][week105]
[![Week 104](./assets/img/preview/week_104.png)][week104]
[![Week 103](./assets/img/preview/week_103.png)][week103]
[![Week 102](./assets/img/preview/week_102.png)][week102]
[![Week 101](./assets/img/preview/week_101.png)][week101]
[![Week 100](./assets/img/preview/week_100.png)][week100]
[![Week 99](./assets/img/preview/week_99.png)][week99]
[![Week 98](./assets/img/preview/week_98.png)][week98]
[![Week 97](./assets/img/preview/week_97.png)][week97]
[![Week 96](./assets/img/preview/week_96.png)][week96]
[![Week 95](./assets/img/preview/week_95.png)][week95]
[![Week 94](./assets/img/preview/week_94.png)][week94]
[![Week 93](./assets/img/preview/week_93.png)][week93]
[![Week 92](./assets/img/preview/week_92.png)][week92]
[![Week 91](./assets/img/preview/week_91.png)][week91]
[![Week 90](./assets/img/preview/week_90.png)][week90]
[![Week 89](./assets/img/preview/week_89.png)][week89]
[![Week 88](./assets/img/preview/week_88.png)][week88]
[![Week 87](./assets/img/preview/week_87.png)][week87]
[![Week 86](./assets/img/preview/week_86.png)][week86]
[![Week 85](./assets/img/preview/week_85.png)][week85]
[![Week 84](./assets/img/preview/week_84.png)][week84]
[![Week 83](./assets/img/preview/week_83.png)][week83]
[![Week 82](./assets/img/preview/week_82.png)][week82]
[![Week 81](./assets/img/preview/week_81.png)][week81]
[![Week 80](./assets/img/preview/week_80.png)][week80]
[![Week 79](./assets/img/preview/week_79.png)][week79]
[![Week 78](./assets/img/preview/week_78.png)][week78]
[![Week 77](./assets/img/preview/week_77.png)][week77]
[![Week 76](./assets/img/preview/week_76.png)][week76]
[![Week 75](./assets/img/preview/week_75.png)][week75]
[![Week 74](./assets/img/preview/week_74.png)][week74]
[![Week 73](./assets/img/preview/week_73.png)][week73]
[![Week 72](./assets/img/preview/week_72.png)][week72]
[![Week 71](./assets/img/preview/week_71.png)][week71]
[![Week 70](./assets/img/preview/week_70.png)][week70]
[![Week 69](./assets/img/preview/week_69.png)][week69]
[![Week 68](./assets/img/preview/week_68.png)][week68]
[![Week 67](./assets/img/preview/week_67.png)][week67]
[![Week 66](./assets/img/preview/week_66.png)][week66]
[![Week 65](./assets/img/preview/week_65.png)][week65]
[![Week 64](./assets/img/preview/week_64.png)][week64]
[![Week 63](./assets/img/preview/week_63.png)][week63]
[![Week 62](./assets/img/preview/week_62.png)][week62]
[![Week 61](./assets/img/preview/week_61.png)][week61]
[![Week 60](./assets/img/preview/week_60.png)][week60]
[![Week 59](./assets/img/preview/week_59.png)][week59]
[![Week 58](./assets/img/preview/week_58.png)][week58]
[![Week 57](./assets/img/preview/week_57.png)][week57]
[![Week 56](./assets/img/preview/week_56.png)][week56]
[![Week 55](./assets/img/preview/week_55.png)][week55]
[![Week 54](./assets/img/preview/week_54.png)][week54]
[![Week 53](./assets/img/preview/week_53.png)][week53]
[![Week 52](./assets/img/preview/week_52.png)][week52]
[![Week 51](./assets/img/preview/week_51.png)][week51]
[![Week 50](./assets/img/preview/week_50.png)][week50]
[![Week 49](./assets/img/preview/week_49.png)][week49]
[![Week 48](./assets/img/preview/week_48.png)][week48]
[![Week 47](./assets/img/preview/week_47.png)][week47]
[![Week 46](./assets/img/preview/week_46.png)][week46]
[![Week 45](./assets/img/preview/week_45.png)][week45]
[![Week 44](./assets/img/preview/week_44.png)][week44]
[![Week 43](./assets/img/preview/week_43.png)][week43]
[![Week 42](./assets/img/preview/week_42.png)][week42]
[![Week 41](./assets/img/preview/week_41.png)][week41]
[![Week 40](./assets/img/preview/week_40.png)][week40]
[![Week 39](./assets/img/preview/week_39.png)][week39]
[![Week 38](./assets/img/preview/week_38.png)][week38]
[![Week 37](./assets/img/preview/week_37.png)][week37]
[![Week 36](./assets/img/preview/week_36.png)][week36]
[![Week 35](./assets/img/preview/week_35.png)][week35]
[![Week 34](./assets/img/preview/week_34.png)][week34]
[![Week 33](./assets/img/preview/week_33.png)][week33]
[![Week 32](./assets/img/preview/week_32.png)][week32]
[![Week 31](./assets/img/preview/week_31.png)][week31]
[![Week 30](./assets/img/preview/week_30.png)][week30]
[![Week 29](./assets/img/preview/week_29.png)][week29]
[![Week 28](./assets/img/preview/week_28.png)][week28]
[![Week 27](./assets/img/preview/week_27.png)][week27]
[![Week 26](./assets/img/preview/week_26.png)][week26]
[![Week 25](./assets/img/preview/week_25.png)][week25]
[![Week 24](./assets/img/preview/week_24.png)][week24]
[![Week 23](./assets/img/preview/week_23.png)][week23]
[![Week 22](./assets/img/preview/week_22.png)][week22]
[![Week 21](./assets/img/preview/week_21.png)][week21]
[![Week 20](./assets/img/preview/week_20.png)][week20]
[![Week 19](./assets/img/preview/week_19.png)][week19]
[![Week 18](./assets/img/preview/week_18.png)][week18]
[![Week 17](./assets/img/preview/week_17.png)][week17]
[![Week 16](./assets/img/preview/week_16.png)][week16]
[![Week 15](./assets/img/preview/week_15.png)][week15]
[![Week 14](./assets/img/preview/week_14.png)][week14]
[![Week 13](./assets/img/preview/week_13.png)][week13]
[![Week 12](./assets/img/preview/week_12.png)][week12]
[![Week 11](./assets/img/preview/week_11.png)][week11]
[![Week 10](./assets/img/preview/week_10.png)][week10]
[![Week 09](./assets/img/preview/week_09.png)][week09]
[![Week 08](./assets/img/preview/week_08.png)][week08]
[![Week 07](./assets/img/preview/week_07.png)][week07]
[![Week 06](./assets/img/preview/week_06.png)][week06]
[![Week 05](./assets/img/preview/week_05.png)][week05]
[![Week 04](./assets/img/preview/week_04.png)][week04]
[![Week 03](./assets/img/preview/week_03.png)][week03]
[![Week 02](./assets/img/preview/week_02.png)][week02]
[![Week 01](./assets/img/preview/week_01.png)][week01]

## About Motus Art

Motus Art is a creative coding art project of coded animation.
* [Newsletter](http://eepurl.com/dmntwP)
* [GitHub](https://github.com/owenmcateer)
* [Instagram](https://www.instagram.com/Motus_Art/)
* [Twitter](https://twitter.com/motus_art)

### Weekly newsletter

Signup to the newsletter and be informed when new pieces are added.  
[**Subscribe**](http://eepurl.com/dmntwP)

### License, share, learn

Feel free to edit, modify and learn from this [code](https://github.com/owenmcateer/Motus-Art) but you must credit a link back to this work.  
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

[week01]: https://owenmcateer.github.io/Motus-Art/projects/week_01.html
[week01code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_01/main.js
[week02]: https://owenmcateer.github.io/Motus-Art/projects/week_02.html
[week02code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_02/main.js
[week03]: https://owenmcateer.github.io/Motus-Art/projects/week_03.html
[week03code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_03/main.js
[week04]: https://owenmcateer.github.io/Motus-Art/projects/week_04.html
[week04code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_04/main.js
[week05]: https://owenmcateer.github.io/Motus-Art/projects/week_05.html
[week05code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_05/main.js
[week06]: https://owenmcateer.github.io/Motus-Art/projects/week_06.html
[week06code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_06/main.js
[week07]: https://owenmcateer.github.io/Motus-Art/projects/week_07.html
[week07code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_07/main.js
[week08]: https://owenmcateer.github.io/Motus-Art/projects/week_08.html
[week08code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_08
[week09]: https://owenmcateer.github.io/Motus-Art/projects/week_09.html
[week09code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_09/main.js
[week10]: https://owenmcateer.github.io/Motus-Art/projects/week_10.html
[week10code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_10/main.js
[week11]: https://owenmcateer.github.io/Motus-Art/projects/week_11.html
[week11code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_11/main.js
[week12]: https://owenmcateer.github.io/Motus-Art/projects/week_12.html
[week12code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_12/main.js
[week13]: https://owenmcateer.github.io/Motus-Art/projects/week_13.html
[week13code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_13/main.js
[week14]: https://owenmcateer.github.io/Motus-Art/projects/week_14.html
[week14code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_14/main.js
[week15]: https://owenmcateer.github.io/Motus-Art/projects/week_15.html
[week15code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_15/main.js
[week16]: https://owenmcateer.github.io/Motus-Art/projects/week_16.html
[week16code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_16/main.js
[week17]: https://owenmcateer.github.io/Motus-Art/projects/week_17.html
[week17code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_17/main.js
[week18]: https://owenmcateer.github.io/Motus-Art/projects/week_18.html
[week18code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_18/main.js
[week19]: https://owenmcateer.github.io/Motus-Art/projects/week_19.html
[week19code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_19/main.js
[week20]: https://owenmcateer.github.io/Motus-Art/projects/week_20.html
[week20code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_20/main.js
[week21]: https://owenmcateer.github.io/Motus-Art/projects/week_21.html
[week21code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_21/main.js
[week22]: https://owenmcateer.github.io/Motus-Art/projects/week_22.html
[week22code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_22/main.js
[week23]: https://owenmcateer.github.io/Motus-Art/projects/week_23.html
[week23code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_23/main.js
[week24]: https://owenmcateer.github.io/Motus-Art/projects/week_24.html
[week24code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_24/main.js
[week25]: https://owenmcateer.github.io/Motus-Art/projects/week_25.html
[week25code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_25/main.js
[week26]: https://owenmcateer.github.io/Motus-Art/projects/week_26.html
[week26code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_26/main.js
[week27]: https://owenmcateer.github.io/Motus-Art/projects/week_27.html
[week27code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_27/main.js
[week28]: https://owenmcateer.github.io/Motus-Art/projects/week_28.html
[week28code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_28/main.js
[week29]: https://owenmcateer.github.io/Motus-Art/projects/week_29.html
[week29code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_29/main.js
[codevember]: https://owenmcateer.github.io/Motus-Art/projects/codevember/
[week30]: https://owenmcateer.github.io/Motus-Art/projects/week_30.html
[week30code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_30/main.js
[week31]: https://owenmcateer.github.io/Motus-Art/projects/week_31.html
[week31code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_31/main.js
[week32]: https://owenmcateer.github.io/Motus-Art/projects/week_32.html
[week32code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_32/main.js
[week33]: https://owenmcateer.github.io/Motus-Art/projects/week_33.html
[week33code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_33/main.js
[week34]: https://owenmcateer.github.io/Motus-Art/projects/week_34.html
[week34code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_34/main.js
[week35]: https://owenmcateer.github.io/Motus-Art/projects/week_35.html
[week35code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_35/main.js
[week36]: https://owenmcateer.github.io/Motus-Art/projects/week_36.html
[week36code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_36/main.js
[week37]: https://owenmcateer.github.io/Motus-Art/projects/week_37.html
[week37code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_37/main.js
[week38]: https://owenmcateer.github.io/Motus-Art/projects/week_38.html
[week38code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_38/main.js
[week39]: https://owenmcateer.github.io/Motus-Art/projects/week_39.html
[week39code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_39/main.js
[week40]: https://owenmcateer.github.io/Motus-Art/projects/week_40.html
[week40code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_40/main.js
[week41]: https://owenmcateer.github.io/Motus-Art/projects/week_41.html
[week41code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_41/main.js
[week42]: https://owenmcateer.github.io/Motus-Art/projects/week_42.html
[week42code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_42/main.js
[week43]: https://owenmcateer.github.io/Motus-Art/projects/week_43.html
[week43code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_43/main.js
[week44]: https://owenmcateer.github.io/Motus-Art/projects/week_44.html
[week44code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_44/main.js
[week45]: https://owenmcateer.github.io/Motus-Art/projects/week_45.html
[week45code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_45/main.js
[week46]: https://owenmcateer.github.io/Motus-Art/projects/week_46.html
[week46code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_46/main.js
[week47]: https://owenmcateer.github.io/Motus-Art/projects/week_47.html
[week47code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_47/main.js
[week48]: https://owenmcateer.github.io/Motus-Art/projects/week_48.html
[week48code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_48/main.js
[week49]: https://owenmcateer.github.io/Motus-Art/projects/week_49.html
[week49code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_49/main.js
[week50]: https://owenmcateer.github.io/Motus-Art/projects/week_50.html
[week50code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_50/main.js
[week51]: https://owenmcateer.github.io/Motus-Art/projects/week_51.html
[week51code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_51/main.js
[week52]: https://owenmcateer.github.io/Motus-Art/projects/week_52.html
[week52code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_52/main.js
[week53]: https://owenmcateer.github.io/Motus-Art/projects/week_53.html
[week53code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_53/main.js
[week54]: https://owenmcateer.github.io/Motus-Art/projects/week_54.html
[week54code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_54/main.js
[week55]: https://owenmcateer.github.io/Motus-Art/projects/week_55.html
[week55code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_55/main.js
[week56]: https://owenmcateer.github.io/Motus-Art/projects/week_56.html
[week56code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_56/main.js
[week57]: https://owenmcateer.github.io/Motus-Art/projects/week_57.html
[week57code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_57/main.js
[week58]: https://owenmcateer.github.io/Motus-Art/projects/week_58.html
[week58code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_58/main.js
[week59]: https://owenmcateer.github.io/Motus-Art/projects/week_59.html
[week59code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_59/main.js
[week60]: https://owenmcateer.github.io/Motus-Art/projects/week_60.html
[week60code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_60/main.js
[week61]: https://owenmcateer.github.io/Motus-Art/projects/week_61.html
[week61code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_61/main.js
[week62]: https://owenmcateer.github.io/Motus-Art/projects/week_62.html
[week62code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_62/main.js
[week63]: https://owenmcateer.github.io/Motus-Art/projects/week_63.html
[week63code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_63/main.js
[week64]: https://owenmcateer.github.io/Motus-Art/projects/week_64.html
[week64code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_64/main.js
[week65]: https://owenmcateer.github.io/Motus-Art/projects/week_65.html
[week65code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_65/main.js
[week66]: https://owenmcateer.github.io/Motus-Art/projects/week_66.html
[week66code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_66/main.js
[week67]: https://owenmcateer.github.io/Motus-Art/projects/week_67.html
[week67code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_67/main.js
[week68]: https://owenmcateer.github.io/Motus-Art/projects/week_68.html
[week68code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_68/main.js
[week69]: https://owenmcateer.github.io/Motus-Art/projects/week_69.html
[week69code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_69/main.js
[week70]: https://owenmcateer.github.io/Motus-Art/projects/week_70.html
[week70code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_70/main.js
[week71]: https://owenmcateer.github.io/Motus-Art/projects/week_71.html
[week71code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_71/main.js
[week72]: https://owenmcateer.github.io/Motus-Art/projects/week_72.html
[week72code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_72/main.js
[week73]: https://owenmcateer.github.io/Motus-Art/projects/week_73.html
[week73code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_73/main.js
[week74]: https://owenmcateer.github.io/Motus-Art/projects/week_74.html
[week74code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_74/main.js
[week75]: https://owenmcateer.github.io/Motus-Art/projects/week_75.html
[week75code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_75/main.js
[week76]: https://owenmcateer.github.io/Motus-Art/projects/week_76.html
[week76code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_76/main.js
[week77]: https://owenmcateer.github.io/Motus-Art/projects/week_77.html
[week77code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_77/main.js
[week78]: https://owenmcateer.github.io/Motus-Art/projects/week_78.html
[week78code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_78/main.js
[week79]: https://owenmcateer.github.io/Motus-Art/projects/week_79.html
[week79code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_79/main.js
[week80]: https://owenmcateer.github.io/Motus-Art/projects/week_80.html
[week80code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_80/
[week81]: https://owenmcateer.github.io/Motus-Art/projects/week_81.html
[week81code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_81/main.js
[week82]: https://owenmcateer.github.io/Motus-Art/projects/week_82.html
[week82code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_82/main.js
[week83]: https://owenmcateer.github.io/Motus-Art/projects/week_83.html
[week83code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_83/main.js
[week84]: https://owenmcateer.github.io/Motus-Art/projects/week_84.html
[week84code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_84/main.js
[week85]: https://owenmcateer.github.io/Motus-Art/projects/week_85.html
[week85code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_85/
[week86]: https://owenmcateer.github.io/Motus-Art/projects/week_86.html
[week86code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_86/main.js
[week87]: https://owenmcateer.github.io/Motus-Art/projects/week_87.html
[week87code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_87/main.js
[week88]: https://owenmcateer.github.io/Motus-Art/projects/week_88.html
[week88code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_88/main.js
[week89]: https://owenmcateer.github.io/Motus-Art/projects/week_89.html
[week89code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_89/main.js
[week90]: https://owenmcateer.github.io/Motus-Art/projects/week_90.html
[week90code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_90/main.js
[week91]: https://owenmcateer.github.io/Motus-Art/projects/week_91.html
[week91code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_91/main.js
[week92]: https://owenmcateer.github.io/Motus-Art/projects/week_92.html
[week92code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_92/main.js
[week93]: https://owenmcateer.github.io/Motus-Art/projects/week_93.html
[week93code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_93/main.js
[week94]: https://owenmcateer.github.io/Motus-Art/projects/week_94.html
[week94code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_94/main.js
[week95]: https://owenmcateer.github.io/Motus-Art/projects/week_95.html
[week95code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_95/
[week96]: https://owenmcateer.github.io/Motus-Art/projects/week_96.html
[week96code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_96/main.js
[week97]: https://owenmcateer.github.io/Motus-Art/projects/week_97.html
[week97code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_97/main.js
[week98]: https://owenmcateer.github.io/Motus-Art/projects/week_98.html
[week98code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_98/main.js
[week99]: https://owenmcateer.github.io/Motus-Art/projects/week_99.html
[week99code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_99/main.js
[week100]: https://owenmcateer.github.io/Motus-Art/projects/week_100.html
[week100code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_100/main.js
[week101]: https://owenmcateer.github.io/Motus-Art/projects/week_101.html
[week101code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_101/main.js
[week102]: https://owenmcateer.github.io/Motus-Art/projects/week_102.html
[week102code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_102/main.js
[week103]: https://owenmcateer.github.io/Motus-Art/projects/week_103.html
[week103code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_103/main.js
[week104]: https://owenmcateer.github.io/Motus-Art/projects/week_104.html
[week104code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_104/main.js
[week105]: https://owenmcateer.github.io/Motus-Art/projects/week_105.html
[week105code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_105/main.js
[week106]: https://owenmcateer.github.io/Motus-Art/projects/week_106.html
[week106code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_106/main.js
[week107]: https://owenmcateer.github.io/Motus-Art/projects/week_107.html
[week107code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_107/main.js
[week108]: https://owenmcateer.github.io/Motus-Art/projects/week_108.html
[week108code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_108/main.js
[week109]: https://owenmcateer.github.io/Motus-Art/projects/week_109.html
[week109code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_109/main.js
[week110]: https://owenmcateer.github.io/Motus-Art/projects/week_110.html
[week110code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_110/main.js
[week111]: https://owenmcateer.github.io/Motus-Art/projects/week_111.html
[week111code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_111/main.js
[week112]: https://owenmcateer.github.io/Motus-Art/projects/week_112.html
[week112code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_112/main.js
[week113]: https://owenmcateer.github.io/Motus-Art/projects/week_113.html
[week113code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_113/main.js
[week114]: https://owenmcateer.github.io/Motus-Art/projects/week_114.html
[week114code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_114/main.js
[week115]: https://owenmcateer.github.io/Motus-Art/projects/week_115.html
[week115code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_115/main.js
[week116]: https://owenmcateer.github.io/Motus-Art/projects/week_116.html
[week116code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_116/main.js
[week117]: https://owenmcateer.github.io/Motus-Art/projects/week_117.html
[week117code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_117/main.js
[week118]: https://owenmcateer.github.io/Motus-Art/projects/week_118.html
[week118code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_118/main.js
[week119]: https://owenmcateer.github.io/Motus-Art/projects/week_119.html
[week119code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_119/main.js
[week120]: https://owenmcateer.github.io/Motus-Art/projects/week_120.html
[week120code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_120/main.js
[waterSims]: https://owenmcateer.github.io/Motus-Art/projects/water-simulations/1.SlideFall.html
[waterSimsCode]: https://github.com/owenmcateer/Motus-Art/blob/master//projects/water-simulations/
[week121]: https://owenmcateer.github.io/Motus-Art/projects/week_121.html
[week121code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_121/main.js
[week122]: https://owenmcateer.github.io/Motus-Art/projects/week_122.html
[week122code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_122/main.js
[week123]: https://owenmcateer.github.io/Motus-Art/projects/week_123.html
[week123code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_123/
[week124]: https://owenmcateer.github.io/Motus-Art/projects/week_124.html
[week124code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_124/
[week125]: https://owenmcateer.github.io/Motus-Art/projects/week_125.html
[week125code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_125/main.js
[week126]: https://owenmcateer.github.io/Motus-Art/projects/week_126.html
[week126code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_126/main.js
[week127]: https://owenmcateer.github.io/Motus-Art/projects/week_127.html
[week127code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_127/main.js
[week128]: https://owenmcateer.github.io/Motus-Art/projects/week_128.html
[week128code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_128/main.js
[week129]: https://owenmcateer.github.io/Motus-Art/projects/week_129.html
[week129code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_129/main.js
[week130]: https://owenmcateer.github.io/Motus-Art/projects/week_130.html
[week130code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_130/main.js
[week131]: https://owenmcateer.github.io/Motus-Art/projects/week_131.html
[week131code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_131/main.js
[week132]: https://owenmcateer.github.io/Motus-Art/projects/week_132.html
[week132code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_132/main.js
[week133]: https://owenmcateer.github.io/Motus-Art/projects/week_133.html
[week133code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_133/main.js
[week134]: https://owenmcateer.github.io/Motus-Art/projects/week_134.html
[week134code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_134/main.js
[week135]: https://owenmcateer.github.io/Motus-Art/projects/week_135.html
[week135code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_135/main.js
[week136]: https://owenmcateer.github.io/Motus-Art/projects/week_136.html
[week136code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_136/main.js
[week137]: https://owenmcateer.github.io/Motus-Art/projects/week_137.html
[week137code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_137
[week138]: https://owenmcateer.github.io/Motus-Art/projects/week_138.html
[week138code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_138/main.js
[week139]: https://owenmcateer.github.io/Motus-Art/projects/week_139.html
[week139code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_139/main.js
[week140]: https://owenmcateer.github.io/Motus-Art/projects/week_140.html
[week140code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_140/main.js
[week141]: https://owenmcateer.github.io/Motus-Art/projects/week_141.html
[week141code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_141/main.js
[week142]: https://owenmcateer.github.io/Motus-Art/projects/week_142.html
[week142code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_142/main.js
[week143]: https://owenmcateer.github.io/Motus-Art/projects/week_143.html
[week143code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_143/main.js
[week144]: https://owenmcateer.github.io/Motus-Art/projects/week_144.html
[week144code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_144/main.js
[week145]: https://owenmcateer.github.io/Motus-Art/projects/week_145.html
[week145code]: https://github.com/owenmcateer/Motus-Art/blob/master/src/week_145/main.js
[week146]: https://owenmcateer.github.io/Motus-Art/projects/week_146.html
[week146code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_146
[your10print]: https://owenmcateer.github.io/Motus-Art/projects/your10print.html
[week147]: https://owenmcateer.github.io/Motus-Art/projects/week_147.html
[week147code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_147/main.js
[week148]: https://owenmcateer.github.io/Motus-Art/projects/week_148.html
[week148code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_148/main.js
[week149]: https://owenmcateer.github.io/Motus-Art/projects/week_149.html
[week149code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_149/main.js
[week150]: https://owenmcateer.github.io/Motus-Art/projects/week_150.html
[week150code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_150/
[week152]: https://owenmcateer.github.io/Motus-Art/projects/week_152.html
[week152code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_152/main.js
[week153]: https://owenmcateer.github.io/Motus-Art/projects/week_153.html
[week153code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_153/main.js
[week154]: https://owenmcateer.github.io/Motus-Art/projects/week_154.html
[week154code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_154/main.js
[week155]: https://owenmcateer.github.io/Motus-Art/projects/week_155.html
[week155code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_155/main.js
[week156]: https://owenmcateer.github.io/Motus-Art/projects/week_156.html
[week156code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_156/main.js
[week157]: https://owenmcateer.github.io/Motus-Art/projects/week_157.html
[week157code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_157/main.js
[week158]: https://owenmcateer.github.io/Motus-Art/projects/week_158.html
[week158code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_158/main.js
[week159]: https://owenmcateer.github.io/Motus-Art/projects/week_159.html
[week159code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_159/main.js
[week160]: https://owenmcateer.github.io/Motus-Art/projects/week_160.html
[week160code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_160/main.js
[week161]: https://owenmcateer.github.io/Motus-Art/projects/week_161.html
[week161code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_161/main.js
[week162]: https://owenmcateer.github.io/Motus-Art/projects/week_162.html
[week162code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_162/main.js
[week163]: https://owenmcateer.github.io/Motus-Art/projects/week_163.html
[week163code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_163/main.js
[week164]: https://twitter.com/motus_art/status/1573326499918249984
[week164code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_164/
[week165]: https://owenmcateer.github.io/Motus-Art/projects/week_165.html
[week165code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_165/
[week166]: https://owenmcateer.github.io/Motus-Art/projects/week_166.html
[week166code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_166/main.js
[week167]: https://owenmcateer.github.io/Motus-Art/projects/week_167.html
[week167code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_167/main.js
[week168]: https://www.shadertoy.com/view/DtVSDm
[week169]: https://owenmcateer.github.io/Motus-Art/projects/week_169.html
[week169code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_169/main.js
[week170]: https://owenmcateer.github.io/Motus-Art/projects/week_170.html
[week170code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_170/main.js
[week171]: https://owenmcateer.github.io/Motus-Art/projects/week_171.html
[week171code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_171/main.js
[week172]: https://www.shadertoy.com/view/DtBcRD
[week173]: https://www.shadertoy.com/view/DtsyWl
[week174]: https://owenmcateer.github.io/Motus-Art/projects/week_174.html
[week174code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_174/main.js
[week175]: https://owenmcateer.github.io/Motus-Art/projects/week_175.html
[week175code]: https://github.com/owenmcateer/Motus-Art/tree/master/src/week_175/main.js",137,137,9,0,art,"[animation, art, colors, creative-coding, javascript, moving-arts, p5js]",0
all-iver,shapes2d,,https://github.com/all-iver/shapes2d,https://api.github.com/repos/shapes2d/all-iver,Shapes2D for Unity3D - Make simple art assets quickly in Unity,"<img src=""http://sub-c.org/Shapes2D/documentation/_images/logo.png"" width=""506"" height=""140"" alt=""Shapes2D logo"" />

**Shapes2D** is a Unity asset for easily creating art assets in the Unity editor. You can use Shapes2D for creating PNG sprites, prototyping, game jams, UI, effects and more.

You can get Shapes2D [on the asset store](https://assetstore.unity.com/packages/tools/sprite-management/shapes2d-make-art-fast-62586), or clone this repository and copy Assets/Shapes2D into your project's Assets folder.

Documentation is online at [http://sub-c.org/Shapes2D/documentation/](http://sub-c.org/Shapes2D/documentation/).

Twitter at [https://twitter.com/all_iver](@all_iver).

Discord at [https://discord.gg/U7x8Yum](https://discord.gg/U7x8Yum).
",134,134,14,19,art,"[2d, art, asset, assets, procedural, shapes, unity, unity3d]",0
korymath,talk-generator,,https://github.com/korymath/talk-generator,https://api.github.com/repos/talk-generator/korymath,talk-generator is capable of generating coherent slide decks based on a single topic suggestion.,"# Talk Powerpoint Generator

[![CircleCI](https://circleci.com/gh/korymath/talk-generator.svg?style=svg&circle-token=dcba7d5a9ff7953cff0526e201990c0b811b3aae)](https://circleci.com/gh/korymath/talk-generator)
[![codecov](https://codecov.io/gh/korymath/talk-generator/branch/master/graph/badge.svg?token=gqkCyuXop0)](https://codecov.io/gh/korymath/talk-generator)
[![License](https://img.shields.io/github/license/mashape/apistatus.svg)](https://github.com/korymath/britbot/blob/master/LICENSE.md)

This program automatically generates PowerPoints about any topic.
These presentation slide decks can be used by improvisers for the improvisational comedy format *""Improvised TED talk""* or *""Powerpoint Karaoke""*.
In such games, the actors have to present an unseen presentation slide deck, but pretend to be an expert and explain *""their""* slide show choices.

## Demo

Ty out this generator on our online platform: [talkgenerator.com](http://talkgenerator.com/).

### Example

![Automatically Generated](https://media.giphy.com/media/MXXe522nIAA9JZjExI/giphy.gif)

## Easy Install and Run

Our program relies on certain APIs that require authentication in order to use it.
Create a file named `.env` (don't forget the period) in your project directory, and fill this with the correct API keys as described on our [wiki page about this](https://github.com/korymath/talk-generator/wiki/Setting-Up-API-Keys).

```sh
# Make a new Python 3 virtual environment
python3 -m venv venv;

# Activate the virtual environment
source venv/bin/activate;

# Upgrade pip and install  requirements
pip install --upgrade pip setuptools;
python3 -m pip install -r requirements.txt;

# Download NLTK dependencies
python run_nltk_download.py;

# Install the Talk Generator
pip install -e .;

# Generate a 10 slide talk with topic peanuts
talkgenerator --topic ""peanuts"" --num_slides 10
```

### Run arguments

| Argument               | Description               |
| ---------------------- | ------------------------- |
| `topic` | The topic of the generator. This works best if it is a common, well-known noun. Use comma-separated words to generate a slide deck about multiple topics |
| `slides` | The number of slides in the generated presentation (*default: 10*) |
| `schema` | The presentation schema to use when generating the presentation. Currently, only two modes are implemented, being `default` and `test` (for testing during development) |
| `title` | Title of the presentation. Either `topic` or this one should to be set in order to generate a slide deck (just setting `topic` is usually more fun though)  |
| `presenter` | The name that will be present on the first slide. Leave blank for an automatically generated name |
| `output_folder` | The folder to output the generated presentations (*default: `./output/`*) |
| `save_ppt` | If this flag is true(*default*), the generated powerpoint will be saved on the computer in the `output_folder`|
| `open_ppt` | If this flag is true (*default*), the generated powerpoint will automatically open after generating|
| `parallel` | If this flag is true (*default*), the generator will generate all slides in parallel |

## Program structure

See the [wiki](https://github.com/korymath/talk-generator/wiki/Program-structure) to know more about the inner implementation.

## Tests

Test files are `tests/*.py`, prefixed with `test_`. Test files use the `unittest` module.
They can easily be run all together when using PyCharm by right clicking on `talk-generator` and pressing *Run 'Unittests in talk-generator'*

```sh
coverage run -m pytest; coverage html
```

Test coverage is automatically handled by `codecov`. Tests are automatically run with CircleCI based on the `.yml` file in the `.circleci` directory.

## Credits

This generator is made by
[Thomas Winters](https://github.com/TWinters)
and [Kory Mathewson](https://github.com/korymath),
with contributions from
[Shaun Farrugia](https://github.com/h0h0h0)
and [Julian Faid](https://github.com/jfaid).

If you would like to refer to this project in academic work, please cite the following paper:

Winters T., Mathewson K.W. (2019) **Automatically Generating Engaging Presentation Slide Decks**. In: Ekárt A., Liapis A., Castro Pena M. (eds) Computational Intelligence in Music, Sound, Art and Design. EvoMUSART 2019. Lecture Notes in Computer Science, vol 11453. Springer, Cham

```sh
@InProceedings{winters2019tedric,
    author=""Winters, Thomas
    and Mathewson, Kory W."",
    editor=""Ek{\'a}rt, Anik{\'o}
    and Liapis, Antonios
    and Castro Pena, Mar{\'i}a Luz"",
    title=""Automatically Generating Engaging Presentation Slide Decks"",
    booktitle=""Computational Intelligence in Music, Sound, Art and Design"",
    year=""2019"",
    publisher=""Springer International Publishing"",
    address=""Cham"",
    pages=""127--141"",
    isbn=""978-3-030-16667-0""
}
```

## License

MIT License. Copyright (c) 2018-2020 [Kory Mathewson](https://github.com/korymath) and [Thomas Winters](https://github.com/TWinters)
",120,120,8,4,art,"[art, evolutionary-computation, funny-experiments, python, python3]",0
BrendanParmer,NodeToPython,,https://github.com/BrendanParmer/NodeToPython,https://api.github.com/repos/NodeToPython/BrendanParmer,Convert Blender node groups to a Python add-on,,118,118,5,11,art,"[add-on, art, blender, blender-addon, blender-python, blender-script, geometry-nodes, geonodes, material, node-editor, node-to-python, procedural, procedural-art, python]",0
cmang,durdraw,,https://github.com/cmang/durdraw,https://api.github.com/repos/durdraw/cmang,"Versatile Unicode, ANSI & ASCII Art editor for the Linux/Unix/macOS terminal, with animation, 256 color support and custom themes","Durdraw
=======

                  __                __
                _|  |__ __ _____ __|  |_____ _____ __ __ __
               / _  |  |  |   __|  _  |   __|  _  |  |  |  |\
              /_____|_____|__|__|_____|__|___\____|________| | 
              \_____________________________________________\|  v 0.21.1


![Durdraw-0 20-demo](https://github.com/cmang/durdraw/assets/261501/ce539865-2e84-4423-92af-cd9ddeeb02ce)

## OVERVIEW

Durdraw is an ASCII, ANSI and Unicode art editor for UNIX-like systems (Linux, 
macOS, etc). It runs in the terminal and supports frame-based animation,
custom themes, 256 and 16 color modes, terminal mouse input, IRC color export,
Unicode and Code Page 437 block characters, HTML output, and other interesting
features.

Durdraw is heavily inspired by classic ANSI editing software for MS-DOS and
Windows, such as TheDraw, Aciddraw and Pablodraw, but with a modern Unix twist.

Files can be saved in DUR animation format, or exported in ASCII (.asc, .txt),
ANSI (.ans), JSON, GIF, mIRC color, HTML, and PNG formats.

## REQUIREMENTS

* Python 3
* Linux, macOS, or other Unix-like System

## INSTALLATION

1: Download and extract, or use git to download:

```
   git clone https://github.com/cmang/durdraw.git  
   cd durdraw 
```

2: Install or upgrade using pip:

```
    pip install --upgrade .
```

Or run the installer:

```
   python3 setup.py install
```

3: Optionally, install some themes and a sample configuration file for your local user into ~/.durdraw/:

```
    ./installconf.sh
```


You should now be able to run `durdraw`

## RUNNING WITHOUT INSTALLING

You may need to install the ""PIL"" or ""pillow"" python module first:

```
    pip3 install pillow
```

Then you can run Durdraw with:

```
    ./start-durdraw
```

To look at some included example animations:

```
    ./start-durdraw -p examples/*.dur
```

## SCREENSHOTS AND EXAMPLES

[![Watch the video](https://durdraw.org/durdraw-youtube-thumbnail-with-play-button.png)](https://youtu.be/7Icf08bkJxg)

![dopetrans3](https://user-images.githubusercontent.com/261501/210064369-4c416e85-12d0-47aa-b182-db5435ae0c78.gif)
![durdraw-screenshot](https://user-images.githubusercontent.com/261501/142838691-9eaf58b0-8a1f-4636-a41a-fe8617937d1d.gif)
![durdraw-linux-unicode-ansi](https://user-images.githubusercontent.com/261501/161380487-ac6e2b5f-d44a-493a-ba78-9903a6a9f1ca.png)
![eye](https://user-images.githubusercontent.com/261501/210064343-6e68f88d-9e3e-415a-9792-a38684231ba0.gif)
![cm-doge](https://user-images.githubusercontent.com/261501/210064365-e9303bee-7842-4068-b356-cd314341098b.gif)
![bsd-color-new](https://user-images.githubusercontent.com/261501/210064354-5c1c2adc-06a3-43c5-8e21-30b1a81db315.gif)

## COMMAND LINE USAGE

You can play a .dur file or series of .dur files with:

```
    $ durdraw -p filename.dur
    $ durdraw -p file1.dur file2.dur file3.dur ...
```

Other command-line options:

<pre>

usage: start-durdraw [-h] [-p PLAY [PLAY ...]] [-q | -w | -x TIMES] [--256color | --16color] [-b]
                     [-W WIDTH] [-H HEIGHT] [-m] [--nomouse] [-A] [-u UNDOSIZE] [-V] [--debug]
                     [filename]

positional arguments:
  filename              .dur or ascii file to load

optional arguments:
  -h, --help            show this help message and exit
  -p PLAY [PLAY ...], --play PLAY [PLAY ...]
                        Just play .dur file or files, then exit
  -q, --quick           Skip startup screen
  -w, --wait            Pause at startup screen
  -x TIMES, --times TIMES
                        Play X number of times (requires -p)
  --256color            Try 256 color mode
  --16color             Try 16 color mode
  -b, --blackbg         Use a black background color instead of terminal default
  -W WIDTH, --width WIDTH
                        Set canvas width
  -H HEIGHT, --height HEIGHT
                        Set canvas height
  -m, --max             Maximum canvas size for terminal (overrides -W and -H)
  --nomouse             Disable mouse support
  --notheme             Disable theme support
  --theme THEME         Load a custom theme file
  -A, --ibmpc           IBM-PC ANSI Art Mode - Use F1-F10 keys for Code Page 437 extended ASCII (IBM-
                        PC) block characters
  -u UNDOSIZE, --undosize UNDOSIZE
                        Set the number of undo history states - default is 100. More requires more
                        RAM, less saves RAM.
  -V, --version         Show version number and exit

</pre>

## INTERACTIVE USAGE/EDITING

Use the arrow keys (or mouse) and other keys to edit, much like a text editor.
You can use the ""Esc"" (or ""Meta"") key to access commands:

```
   .. Art Editing ....................  .. Animation .......................
   : F1-F10 - insert character       :  : esc-k - next frame               :
   : esc-up - next fg color          :  : esc-j - previous frame           :
   : esc-dow1 - prev fg color        :  : esc-p - start/stop payback       :
   : esc-right - next bg color       :  : esc-n - clone frame              :
   : esc-left - prev bg color        :  : esc-N - append empty frame       :
   : esc-/ - insert line             :  : esc-d - delete frame             :
   : esc-' - delete line             :  : esc-D - set frame delay          :
   : esc-. - insert column           :  : esc-+/esc-- - faster/slower      :
   : esc-, - delete column           :  : esc-R - set playback/edit range  :
   : esc-] - next character set      :  : esc-g - go to frame #            :
   : esc-[ - previous character set  :  : esc-M - move frame               :
   : esc-y - eyedrop (pick up color) :  :..................................:
   : esc-c - color picker (256 mode) :  .. File Operations .................
   : shift-arrows - select for copy  :  : esc-C - new/clear canvas         :
   : esc-v - paste                   :  : esc-o - open                     :
   :.................................:  : esc-s - save                     :
   .. UI/Misc ......................... :..................................:
   : esc-m - main menu                : .. Canvas Size .....................
   : esc-t - mouse tools              : : esc-"" - insert line              :
   : esc-z - undo                     : : esc-: - delete line              :
   : esc-r - redo                     : : esc-> - insert column            :
   : esc-h - help                     : : esc-< - delete column            :
   : esc-q - quit                     : :..................................:
   :..................................:
                                                            Prev   Next
                                                            Frame  Frame
                                                            |      |
Main   Frame     Speed     Frame   Play/Edit  Mouse   First | Play |  Last
Menu   Number      |       Delay   Range      Tools   Frame | Pause|  Frame
 |     |           |        |       |          |         |  |  |   |  |
[Menu] F: 1/8    <FPS>: 8   D: 0.00 R: 1/8   [Move]      |< << |> >> >|  
```

## CONFIGURATION

You can create a custom startup file where you can set a theme.


If you did not already do so during installation, you can install a sample configuration and some themes into ~/.durdraw/ with the command:

```
    ./installconf.sh
```

This will place durdraw.ini into ~/.durdraw/ and the themes into ~/.durdraw/themes/.

Here is an example durdraw.ini file:

<pre>
; Durdraw 0.20 Configuration File
[Theme]
theme-16: ~/.durdraw/themes/purpledrank-16.dtheme.ini
theme-256: ~/.durdraw/themes/mutedform-256.dtheme.ini
</pre>

The option 'theme-16' sets the path to the theme file used in 16-color mode, and 'theme-256' sets the theme file used for 256-color mode. 

Note that you can also load a custom theme file using the --theme command-line argument and passing it the path to a theme file, or disable themes entirely with the --notheme command line option.

Here is an example 16-color theme:

<pre>
[Theme-16]
name: 'Purple Drank'
mainColor: 6
clickColor: 3
borderColor: 6
clickHighlightColor: 5
notificationColor: 4
promptColor: 4
</pre>

and a 256-color theme:

<pre>
[Theme-256]
name: 'Muted Form'
mainColor: 104
clickColor: 37
borderColor: 236
clickHighlightColor: 15
notificationColor: 87
promptColor: 189
menuItemColor: 189
menuTitleColor: 159
menuBorderColor: 24
</pre>

The colors and theme options are as follows:

colors for 16-color mode:
1 black
2 blue
3 green
4 cyan
5 red
6 magenta
7 yellow
8 white

color codes numbers for 256-color mode can be found in Durdraw's 256-color selector.

```
mainColor: the color of most text
clickColor: the color of buttons (clickable items)
clickHighlightColor: the color the button changes to for a moment when clicked
borderColor: the color of the border around a drawing
notificationColor: the color of notification messages
promptColor: the color of user prompt messages
menuItemColor: the color of menu items
menuTitleColor: the color of menu titles
menuBorderColor: the color of the border around menus
```


## OTHER TIPS

    * To use themes, copy durdraw.ini to ~/.durdraw/ and edit it. Durdraw
      will also check in the current directory for durdraw.ini.

    * The mouse can be used for moving the cursor (even over SSH) and
      clicking buttons, if your terminal supports Xterm mouse reporting.
      In iTerm2 this is under Profiles, Terminal and Terminal Emulation.

    * If IBM-PC characters (-A) are not working in gnu screen, try running the
      following screen command (by pressing ctrl-a and typing):
        :utf8 off off
      then type ""ctrl-a l"" to redraw the window.
      Also see ""OPTIONAL INSTALLATION"" notes below

## OPTIONAL INSTALLATION

For PNG and animated GIF export, install Ansilove (https://ansilove.org/) and make sure it is is in your path. PNG and GIF export only work in 16-color mode for now.

If you want to try making animated IBM-PC/MS-DOS ANSI art with durdraw, you
need a terminal and font that supports ASCII encoding and IBM's Code Page 437.
You can find fonts in the ""extras"" directory for this purpose. Once this is done,
start Durdraw with the -A or --ibmpc command-line argument.

Note that ANSI art character support is experimental (see FAQ).

In Linux/X11, here is one possible way to set up a terminal for IBM-PC ANSI art:

* Install mrxvt
* Install vga.pcf by copying it to /usr/share/fonts/X11/misc and then running
  these commands. This may be different on your OS:
    $ mkfontdir /usr/share/fonts/X11/misc/
    $ xset fp rehash
* Give mrxvt IBM-PC colors by copying the contents of Xdefaults into your own
  ~/.Xdefaults file. You can create ~/.Xdefaults if it does not exist.
* Launch mrxvt with: mrxvt -fn vga -bg black -fg grey

If you are using macOS or MacOS X and want IBM-PC ANSI art support in
Terminal.app:

1. Install dos437.ttf font (included) by double-clicking it.
2. Create a profile in Terminal Preferences/Settings with the following
   settings (similar settings can be applied in iTerm):
    * In Text tab, Font set to dos437 (I like 9pt) and ""Display ANSI colors""    
      and ""Use bright colors for bold text"" are checked
    * In Keyboard tab, ""Use option as meta key"" selected
    * In ""Advanced"" tab, Character encoding set to ""Western (ISO Latin 1)""
    * Set background color to black (low or no transprency) and foreground
      color to white

Once this is setup, pass ""-A"" to durdraw's command-line to allow you to use
F1-F12 to input ANSI block characters. 

## FAQ

#### Q: Don't TheDraw and some other programs already do ANSI animation?
A: Yes, but traditional ANSI animation does not provide any control over timing, instead relying on terminal baud rate to control the speed. This does not work well on modern systems without baud rate emulation. Durdraw gives the artist fine control over frame rate, and delays per frame. Traditional ANSI animation also updates the animation one character at a time, while Durdraw updates the animation a full frame at a time. This makes it less vulnerable to visual corruption from things like errant terminal characters, resized windows, line noise, etc. Finally, unlike TheDraw, which requires MS-DOS, Durdraw runs in modern Unicode terminals.

#### Q: Can I run Durdraw in Windows?
A: Short answer: It's not supported, but it seems to work fine in the Windows Subsystem for Linux (WSL). Long answer: Some versions run fine in Windows Command Prompt, Windows Terminal, etc, without WSL, but it's not tested or supported. If you want to help make Durdraw work better in Windows, please help by testing, submitting bug reports and submitting patches.

#### Q: Can I run Durdraw on Amiga, MS-DOS, Classic MacOS, iOS, Android, etc?
A: Probably not easily. Durdraw requires Python 3 and Ncurses. If your platform can support these, it will probably run. However, the file format for Durdraw movies is a plain text JSON format. It should be possible to support this format in different operating systems and in different applications.

#### Q: Does Durdraw support IBM-PC ANSI art?
A: Yes - Kind of. Durdraw can support IBM-PC (Code Page 437) extended ASCII characters using the -A command-line option, and can export ANSI files. However, ANSI importing is not currently supported. Please see the ""OPTIONAL INSTALLATION"" section above for more details. If you do not pass the -A command-line option, then Unicode block characters similar to IBM-PC block characters are enabled by default.

### CREDITS

Developer: Sam Foster

Home page: http://durdraw.org

Development: https://github.com/cmang/durdraw

### LEGAL

Durdraw is Copyright (c) 2009-2023 Sam Foster <samfoster@gmail.com>. All rights reserved.

Permission to use, copy, modify, and distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

License for dos437.ttf font:
Copyright (c) 2011 joshua stein <jcs@jcs.org>

Permission to use, copy, modify, and distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

The vga.pcf font was taken from the Dosemu project and appears to be in
the public domain. Further discussion on its copyright status can be found
at http://www.dosemu.org/docs/misc/COPYING.html

",117,117,3,1,art,"[animation, ansi, ansi-art, art, ascii, ascii-art, ascii-graphics, cp437, drawing, editor, gif, linux, ncurses, terminal, text-editor, textmode, tui, unicode, unicode-art, xterm-256color]",0
lostjared,Acid.Cam.v2.OSX,,https://github.com/lostjared/Acid.Cam.v2.OSX,https://api.github.com/repos/Acid.Cam.v2.OSX/lostjared,Acid Cam v2 for macOS distorts video to create art.,"# Acid.Cam.v2.OSX

![ScreenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/acid.cam.img1.jpg?raw=true ""screenshot1"")

[VERSION: 2.84.0 (macOS)]

Join us on Discord: https://discord.gg/kSxTe6M8

Acid Cam is an Open Source project I initially began working on back in 2011. The first version of the program was written in Objective-C and worked with webcams only. The version of Acid Cam this document describes in the 2.0 series, which was rewritten from scratch in C++ with the macOS user interface being Objective-C++.
Acid Cam distorts video to create art. It is designed to be used with other software (Syphon) or on its own. There are multiple versions of the program for macOS, Linux, and Windows, as well as a command-line version of the program. The program also has a live webcam feature. If you wish to use this feature, you should use a lower resolution and not stack up to many filters. The majority of the time, this program is more useful in video mode, where it can process multiple filters in up to 2160p 4K resolution.

Some important Notes:

To be able to use all the filters in this app, your system should have at least 8 GB of Ram for 1080p video. For 4K higher Ram is recommended, but you can set the Max Stored Frames based on the resolution you are doing and when it is reached it will release the frames. On my system for 2160p video when using something like a Random filter I set it to 400 frames for my system with 32 GB ram. You can set it lower based on your system ram level It is in the preferences window. Some filters require more than the default amount of allocated frames. Usually these have the name 640 or 720 in the title. If you are running with enough Ram, please set the require frame limit before starting your session!

The video Acid Cam outputs is saved at a very high bitrate. Sometimes you will need to lower the bitrate to view the video with a video player. I usually import the video into Final Cut Pro X then lower the bitrate by exporting it as H.264. Another program you could use would be Handbrake. The following image is of MediaInfo on a 4K video created with Acid Cam. The overall bitrate is very high.

![mediainfo](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/mediainfo4k.png?raw=true ""mediainfo_ss"")

or use FFMPEG like this:

    $ ffmpeg -i ""input.file.mp4"" -c:v libx265 -tag:v hvc1 -crf 22 output.file.mp4

This version shares some code with libacidcam, so sometimes, when I update the parts that are shared show up in both projects. libacidcam uses C++/OpenCV and Autotools, and this macOS program uses Objective-C++/Cocoa/OpenCV and Xcode
This project was created in hopes of providing some entertainment, or for the Glitch artist to give you an image/video to use with other tools.
I call the art that I create with Acid Cam ""Acid Glitch,"" but you can call it whatever you want. It is just meant to be a tool to use with other programs to help aid in the creation of artistic images/videos.
Acid Cam's effects are created by using Acid Cam 'filters', or pieces of code that distort an image and can be combined to produce some exciting effects. The project currently has over 2,000 filters to mix and match and supports output as MPEG-4 or H.264.
5.20.19: I upgraded the program's OpenCV library files to version 3.4.6, and some of it has changed. The OpenCV header files included now have a warning from possible misuse of a comma. Also, I am on Mojave, and the GUI scales windows up and down automatically while still having a resolution of 5K. The problem is OpenCV has code that resizes the window, and it is not sized correctly. I will work on fixing these issues, but the version of OpenCV I compiled contains OpenCL support. Just on my computer with the new libraries, it moves much faster.
I can confirm Acid Cam works with Elgato Camlink 4K. With this device, you can use any HDMI device as a Webcam source for Acid Cam. Combined with OBS, you can live stream your self filtering video games/yourself on your camcorder in real-time with audio.

The Start Session 

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/session.png?raw=true ""screenshot1"")

The start session window is where you choose if you want to use a Webcam or a video file. You also can select the desired output format or if you want to record it. Checking repeat causes the video to loop. You can resize the output frame and stretch it if required. If stretch is not checked, the video will retain its original aspect ratio.

The Activity Log:

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/log.png?raw=true ""screenshot1"")


The Activity Log shows information about the video and allows you to select a single filter, You can check fade, and it will fade from filter to filter when you change it. Negate returns the opposite or negative of the video. The RGB sliders offset the colors RGB values. The RGB order lets you rearrange the order of the component RGB values. The color map is using only a specific set of colors. Near the bottom of the window displays how many stored frames are allocated. The program caches frames to for a lot of the filters, and when it reaches a certain number, they are automatically released. You can see how many frames you want to go before each release. You can also release manually through the programs menu.

The preferences window:

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/pref.png?raw=true ""screenshot1"")


The preferences window: contains a series of options you can set to change how some of the filters operate. Process mode is how the index variable is incremented and decremented for some of the older filters. Movement speed is for most animated filters movements speed changes how fast it moves in and out. Custom cycle delay is for filters that have the word delay in the name and how many frames it should wait before changing. BlendWithSource is how much percentage of the image do you wish to restore. Threads are how many threads to use for the filters that are multithreaded. Key tolerance is for the Image windows Chroma Key features. Pixel difference is for the ones that detect a change in the image, how much of a difference for it to trigger that it has changed. Max stored frames is how many frames to store before resetting the cache. FFMPEG Path is if you optionally want to install FFMPEG, you can point it to the path for the program to find it. Syphon output is for using a Syphon server what resolution you want to use. Frame wait is for how long to wait for ones that have wait in the name. Stretch Line is for StretchLineRowInc and StretchLineColInc how much distortion you want. The higher the value, the more distorted it gets.

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/image.png?raw=true ""screenshot1"")


The image window you select a series of images, and they appear in the dropdown list. You can then select one and set it as one of the image types like Blend Image. You can also set a chroma key, and you can set a second video file. The Cycle option is how many frames do you want to wait before it changes the currently selected image from the dropdown list you selected. You can see to shuffle the images, move at random or in order.

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/keys.png?raw=true ""screenshot1"")


The Chroma key window you select a series of color ranges. You can set the component colors then set whether you want a range of tolerance. When you have your keys in the list, click set colors to activate it. Then select a filter that uses a chroma key.

![creenShot1](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/custom.png?raw=true ""screenshot1"")


The custom filter window, this is probably the most important window in the application. You can select multiple filters and have them executed one after the other, with ones output being the input to the next in a chain. You can toggle a filter on or off while in a custom. You can save and load a custom. User-defined is when you select a list of filters and assign it a new name so you can use it. You can save/load these user-defined lists, and you should first set the output directory by pressing the dir button to a location you have read/write access.
Subfilter: A subfilter is when you pass a specific filter to another filter that has the word SubFilter in its name. It magnifies the amount of possible outputs.

Download old versions of Acid Cam for macOS: http://lostsidedead.biz/osx

NOTE: Some of the filters that contain either a 720 or 1080 at the end require a lot of ram if you do not have enough the program will exit.

View Facebook page for Information and  sample videos: http://facebook.com/AcidCam

OpenCV3_4_1 (Newest)  Version is on the master branch  now, to use the old 2.4  version switch to oldmacosx branch
or for OpenCV 3 go to OpenCV3.

Newest version of the program now requires macOS High Sierra to run. 

To compile first clone then open with Xcode and build.

![ScreenShot](https://github.com/lostjared/Acid.Cam.v2.OSX/blob/master/screens/AcidCam2_ScreenShot.png?raw=true ""screenshot"")

Project home page: http://lostsidedead.com

Information about the static build of OpenCV in this project:

General configuration for OpenCV 3.4.6 =====================================

Version control:               unknown



Platform:

Timestamp:                   2019-05-20T20:32:42Z

Host:                        Darwin 17.7.0 x86_64

CMake:                       3.14.1

CMake generator:             Unix Makefiles

CMake build tool:            /usr/bin/make

Configuration:               Release



CPU/HW features:

Baseline:

Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2 AVX512_SKX

requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX

SSE4_1 (12 files):         + SSE SSE2 SSE3 SSSE3 SSE4_1

SSE4_2 (1 files):          + SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2

FP16 (0 files):            + SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX

AVX (5 files):             + SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2 AVX

AVX2 (26 files):           + SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2

AVX512_SKX (2 files):      + SSE SSE2 SSE3 SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2 AVX_512F AVX512_SKX



C/C++:

Built as dynamic libs?:      NO

C++ Compiler:                /Library/Developer/CommandLineTools/usr/bin/c++  (ver 10.0.0.10001044)

C++ flags (Release):         -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Wno-long-long -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG

C++ flags (Debug):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Wno-long-long -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG

C Compiler:                  /Library/Developer/CommandLineTools/usr/bin/cc

C flags (Release):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Wno-long-long -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG

C flags (Debug):             -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-unnamed-type-template-args -Wno-comment -fdiagnostics-show-option -Wno-long-long -Qunused-arguments -Wno-semicolon-before-method-body -ffunction-sections -fdata-sections  -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG

Linker flags (Release):      -Wl,-dead_strip  

Linker flags (Debug):        -Wl,-dead_strip  

ccache:                      NO

Precompiled headers:         NO

Extra dependencies:          avformat m z avcodec avresample swscale avutil -framework VideoDecodeAcceleration bz2 -framework Accelerate -framework AVFoundation -framework CoreGraphics -framework CoreMedia -framework CoreVideo -framework QuartzCore -framework Cocoa -framework OpenCL /System/Library/Frameworks/Accelerate.framework

3rdparty dependencies:       libprotobuf libjpeg-turbo libwebp libpng libtiff IlmImf zlib ittnotify quirc ippiw ippicv



OpenCV modules:

To be built:                 calib3d core dnn features2d flann highgui imgcodecs imgproc ml objdetect shape stitching superres ts video videoio world

Disabled:                    java_bindings_generator photo python2 python_bindings_generator

Disabled by dependency:      videostab

Unavailable:                 cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev java js python3 python3 viz

Applications:                -

Documentation:               NO

Non-free algorithms:         NO



GUI: 

Cocoa:                       YES

VTK support:                 NO



Media I/O: 

ZLib:                        build (ver 1.2.11)

JPEG:                        build-libjpeg-turbo (ver 2.0.2-62)

WEBP:                        build (ver encoder: 0x020e)

PNG:                         build (ver 1.6.36)

TIFF:                        build (ver 42 - 4.0.10)

OpenEXR:                     build (ver 1.7.1)

HDR:                         YES

SUNRASTER:                   YES

PXM:                         YES



Video I/O:

DC1394:                      NO

FFMPEG:                      YES

avcodec:                   YES (ver 57.25.0)

avformat:                  YES (ver 57.7.2)

avutil:                    YES (ver 55.20.0)

swscale:                   YES (ver 4.0.0)

avresample:                YES (ver 3.0.0)

AVFoundation:                YES



Parallel framework:            GCD



Trace:                         YES (with Intel ITT)



Other third-party libraries:

Intel IPP:                   2019.0.0 Gold [2019.0.0]

at:                   /Volumes/LostSideDrive-2/Downloads/opencv3/3rdparty/ippicv/ippicv_mac/icv

Intel IPP IW:                sources (2019.0.0)

at:                /Volumes/LostSideDrive-2/Downloads/opencv3/3rdparty/ippicv/ippicv_mac/iw

Lapack:                      YES (/System/Library/Frameworks/Accelerate.framework)

Eigen:                       YES (ver 3.3.1)

Custom HAL:                  NO

Protobuf:                    build (3.5.1)

OpenCL:                        YES (no extra features)

Include path:                NO

Link libraries:              -framework OpenCL

Python (for build):            /usr/bin/python2.7

Install to:                    /usr/local/opencv_3.4.6

- Jared Bruni
",101,101,7,0,art,"[art, augmented-reality, glitch-art, opencv, video-processing]",0
oelin,midjourney-reborn,,https://github.com/oelin/midjourney-reborn,https://api.github.com/repos/midjourney-reborn/oelin,A Discord bot for all your Midjourney needs 🔥.,"# Midjourney Reborn 🔥

A Discord bot for all your Midjourney needs! Use this bot to convert text prompts into beautiful artwork via Midjourney V4.

<div align=left>
<img src='art.png'>
</div>


## Usage

To run this demo, clone the repository and then create a `config.json` file containing your bot's token.

```sh
git clone https://github.com/oelin/midjourney-reborn/

cd midjourney-reborn
```

```sh
echo {""token"": ""YOUR TOKEN""} > ./config.json
```

Then run the following commands to install start the bot.

```sh
npm i

npm run deploy

npm start
```


## Commands

This project is in active development so expect lots of changes to this section. Currenlty the primary command supported is `/imagine [prompt]`, which can be used to generate images with Midjourney. For instance, `/imagine an astronaut riding a horse on mars artstation` might produce the following image:

<img src='https://replicate.delivery/pbxt/f4nlztv3uz1iFC4AEf2wBYQGTezdVeysvtZUtwfsvZOJDN6AC/out-0.png' width=50%>

In the near future we hope to add support for features such as upscailing, variant generation and additional generation parameters. 


## Technologies

This bot utilizes [discord.js](https://discord.js.org/#/) and [Midjourney Client](https://github.com/oelin/midjourney-client) to enable Midjourney V4 access from within Discord. The underlying images are generated on fast GPUs provided by [Replicate](https://replicate.com).


## Resources

* [Midjourney Website](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F)
* [Midjourney/Openjourney on Replicate](https://replicate.com/prompthero/openjourney)
",95,95,6,1,art,"[ai, art, discord-bot, midjourney, openjourney]",0
Rohith04MVK,AI-Art-Generator,,https://github.com/Rohith04MVK/AI-Art-Generator,https://api.github.com/repos/AI-Art-Generator/Rohith04MVK,A program that can add an artistic touch to any image.,"<h1 align=""center"">AI-Art-Generator</h1>

[![made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18nLCUAQZJ-vuOIn04IrBMubqsV6VO_9j?usp=sharing)[![Made with Tensorflow](https://aleen42.github.io/badges/src/tensorflow.svg)](https://www.tensorflow.org/)

<h2 align=""center"">Overview</h2>

## Simple Art style transferer
You give a style image and the model learns the features and transfers it to the content image
Best recommended to run with a GPU for the fastest result

## How it works?

Neural style transfer is an optimization technique that involves creating a new image that merges the content of one image with the style of another. Here's a high-level overview of how the AI-Art-Generator works:

    - Load the content image and the style image.
    - Preprocess the images by resizing and normalizing them.
    - Create a model that combines a pre-trained convolutional neural network (CNN) with the VGG19 architecture.
    - Define loss functions that measure the content loss and style loss between the generated image and the target image.
    - Set up the optimization process using gradient descent to minimize the total loss.
    - Iterate the optimization process to update the generated image and minimize the loss.
    - Generate the final stylized image.

By minimizing the content loss, the generated image retains the content of the original content image. By minimizing the style loss, the generated image captures the artistic style of the style image. The balance between the content and style losses can be adjusted to control the final result.

## Further reading

[Gatys’ paper](https://arxiv.org/abs/1508.06576)\
[Gradient descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)

## Credits
[Tensorflow article](https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398)
(It was for version TensorFlow V1)


## Some examples of the project

#### Content and style images

![image](https://cdn.discordapp.com/attachments/748848099891347498/794168270831353856/tRe7lwtniHiKzxOK0pl2g5HA6HwFwXCRc6dDhcDgcDofjIuESLYfD4XA4HI6LhEu0HA6HwFwOC4SLtFyOBwOh8PhuEi4RMvhcDgc.png)

### Output

![image](https://cdn.discordapp.com/attachments/748848099891347498/794168176110731264/uNsabtFDjw5F7SPtB5ZrBdeNPfbuXaH96JOWTIkCF3KLtdQhkyZMiQIffDA18yJAhQ5QhgYZMiQIXcoQwMfMmTIkDuUoYEPGTJky.png)

## How to run locally?

#### Clone the repo.
``` sh
git clone https://github.com/Rohith04MVK/AI-Art-Generator
```

#### Setup conda.
```sh
conda create -n AI-Art-Generator python=3.8.5
```
```sh
conda activate AI-Art-Generator
```


#### Install dependencies.

```sh
pip install -r requirement.txt
```
#### OR
```sh
conda install --file requirement.txt
```

#### Replace the pictures.
Replace line 10  `content_path` with the image you want to transform
Replace line 11 `style_path` with the style picture you want to transfer

#### Run the file!
```sh
python aiart.py
```

## Starchart
[![Star History Chart](https://api.star-history.com/svg?repos=Rohith04MVK/AI-Art-Generator&type=Date)](https://star-history.com/#Rohith04MVK/AI-Art-Generator&Date)
",93,93,4,0,art,"[ai, art, deep-learning, machine-learning, style-transfer, tensorflow2, vgg19]",0
MaxHalford,procedural-art,,https://github.com/MaxHalford/procedural-art,https://api.github.com/repos/procedural-art/MaxHalford,:milky_way: Procedural art with vanilla JavaScript,"# Procedural art with JavaScript

> Time you enjoy wasting isn't wasted time.

This repository contains some procedural art algorithms I like devising during my spare time. I don't use any external libraries and I rely on the HTML `<canvas>` element for rendering. Every time you open of the `html` files it will generate a random image. Each art work has a write up which you can access by clicking on the section names.

## [1 - Recursive polygons](https://maxhalford.github.io/blog/recursive-polygons/)

<div align=""center"">
    <img width=""60%"" src=""screenshots/1_recursive_polygons.png"" alt=""recursive_polygons"">
</div>

## [2 - Mondrian](https://maxhalford.github.io/blog/mondrian/)

<div align=""center"">
    <img width=""60%"" src=""screenshots/2_mondrian.png"" alt=""mondrian"">
</div>

## [3 - Unknown pleasures](https://maxhalford.github.io/blog/unknown-pleasures/)

<div align=""center"">
    <img width=""60%"" src=""screenshots/3_unknown_pleasures.png"" alt=""unknown_pleasures"">
</div>

## [4 - Stella triangles](https://maxhalford.github.io/blog/stella-triangles/)

<div align=""center"">
    <img width=""60%"" src=""screenshots/4_stella_triangles.png"" alt=""4_stella_triangles"">
</div>

## [5 - Morellet crosses](https://maxhalford.github.io/blog/morellet/)

<div align=""center"">
    <img width=""60%"" src=""screenshots/5_morellet_crosses.png"" alt=""5_morellet_crosses"">
</div>



## License

The MIT License (MIT). Please see the [license file](LICENSE) for more information.
",89,89,8,0,art,"[art, javascript, procedural-generation]",0
raphamorim,react-motions,,https://github.com/raphamorim/react-motions,https://api.github.com/repos/react-motions/raphamorim,Compose React Animations using High-Order Functions or Components,"# React Motions

[![CircleCI](https://circleci.com/gh/raphamorim/react-motions/tree/master.svg?style=svg)](https://circleci.com/gh/raphamorim/react-motions/tree/master)

> Compose React Animations using High-Order Functions or Components

React-Motions is a mix of ideas from [Recompose](https://github.com/acdlite/recompose) and [Animate.css](https://github.com/daneden/animate.css). In fact, `react-motions` is a set of pure functions entirely based on animation purpose.

```bash
yarn add react-motions --dev 
```

# Usage

Using HOF

```jsx
import { withBounce, withShake, withInfinite, withSequence } from 'react-motions'

const Component = <div>How can I look beautiful</div>

const ComponentWithShake = withShake(Component)
const ComponentWithShakeAndBounce = withShake(withBounce(Component))
const ComponentWithInfiniteBounce = withInfinite(withBounce(Component))
const ComponentWithShakeThenBounce = withSequence(withShake(withBounce(Component)))
```

HOF - Based on Compositions

You can add compose animations (even custom animations) based on functions. Here is an example:

```jsx
import { withShake, withFadeOut, withInfine } from 'react-motions'

const Component = () => (
  withInfinite(
    withFadeOut(
      withInfinite(
        withShake(
          <h2>Bouncing and Fading Out infinitely!!</h2>
        )
      )
    )
  )
)
```

Using Components

```jsx
import { Bounce, Shake } from 'react-motions'

const ComponentWithShake = () => (
  <Shake duration={4}>
    <div>How can I look beautiful</div>
  </Shake>
)

const ComponentWithBounce = () => (
  <Bounce infinite>
    <div>How can I look beautiful</div>
  </Bounce>
)
```

React-Motions was created to be agnostic to the renderer:

| React Renderer | Available for use  | Version |
| :--- | :--- | :--- |
| [React-DOM](github.com/facebook/react) | ✔️ | `^16` |
| [React-Native](https://github.com/facebook/react-native) | ✖️ | ✖️ |
| [React-TV](https://github.com/raphamorim/react-tv) | ✔️ | `^0.3`

# API

## withInfinite

Set last animation with `infinity` property.

```jsx
import { withInfinite, withBounce } from 'react-motions'

const DoNotStopBouncing = withInfinite(withBounce(<div>Let's bounce without stop!</div>))
```

## withSequence

Execute next animation only after previous animation be finished. 

```jsx
import { withSequence, withShake, withJello } from 'react-motions'

const SequencialAnimations = withSequence(
  withShake,
  withJello,
  <div>First shake it then jello! </div>
)
```

## compose

Execute all animations in the same time.

```jsx
import { compose, withFlash, withPulse } from 'react-motions'

const VividAnimation = compose(
  withFlash,
  withPulse,
  <div>Flash and Pulse!</div>
)
```

## Bounce
### Component

Render a React Component with Bounce animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Bounce } from 'react-motions'

const ComponentBounce = (
  <Bounce duration={2} infinite>
    Let's bounce here
  </Bounce>
)
```

### Function

Return a React Component with Bounce animation (`1s` duration)

```jsx
import { withBounce } from 'react-motions'

const ComponentWithBounce = withBounce(<div>Let's bounce here</div>)
```

## FadeIn
### Component

Render a React Component with FadeIn animation (`2s` duration and iterationCount `infinite`)

```jsx
import { FadeIn } from 'react-motions'

const ComponentFadeIn = (
  <FadeIn duration={2} infinite>
    Let's fadeIn here
  </FadeIn>
)
```
### Function

Return a React Component with FadeIn animation (`1s` duration)

```jsx
import { withFadeIn } from 'react-motions'

const ComponentWithFadeIn = withFadeIn(<div>Let's fadeIn here</div>)
```

## FadeOut
### Component

Render a React Component with FadeOut animation (`2s` duration and iterationCount `infinite`)

```jsx
import { FadeOut } from 'react-motions'

const ComponentFadeOut = (
  <FadeOut duration={2} infinite>
    Let's fadeOut here
  </FadeOut>
)
```
### Function

Return a React Component with FadeOut animation (`1s` duration)

```jsx
import { withFadeOut } from 'react-motions'

const ComponentWithFadeOut = withFadeOut(<div>fadeOut here</div>)
```

## Flash
### Component

Render a React Component with Flash animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Flash } from 'react-motions'

const ComponentFlash = (
  <Flash duration={2} infinite>
    Let's flash here
  </Flash>
)
```
### Function

Return a React Component with Flash animation (`1s` duration)

```jsx
import { withFlash } from 'react-motions'

const ComponentWithFlash = withFlash(<div>Flash! Flash!</div>)
```

## Jello
### Component

Render a React Component with Jello animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Jello } from 'react-motions'

const ComponentJello = (
  <Jello duration={2} infinite>
    Let's jello here
  </Jello>
)
```
### Function

Return a React Component with Jello animation (`1s` duration)

```jsx
import { withJello } from 'react-motions'

const ComponentWithJello = withJello(<div>Jelloooool</div>)
```

## Pulse
### Component

Render a React Component with Pulse animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Pulse } from 'react-motions'

const ComponentPulse = (
  <Pulse duration={2} infinite>
    Let's pulse here
  </Pulse>
)
```
### Function

Return a React Component with Pulse animation (`1s` duration)

```jsx
import { withPulse } from 'react-motions'

const ComponentWithPulse = withPulse(<div>Let's pulse here</div>)
```

## RubberBand
### Component

Render a React Component with RubberBand animation (`2s` duration and iterationCount `infinite`)

```jsx
import { RubberBand } from 'react-motions'

const ComponentRubberBand = (
  <RubberBand duration={2} infinite>
    Let's rubberBand here
  </RubberBand>
)
```
### Function

Return a React Component with rubberBand animation (`1s` duration)

```jsx
import { withRubberBand } from 'react-motions'

const ComponentWithRubberBand = withRubberBand(<div>rubberBand!</div>)
```

## Shake
### Component

Render a React Component with Shake animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Shake } from 'react-motions'

const ComponentShake = (
  <Shake duration={2} infinite>
    Let's shake here
  </Shake>
)
```
### Function

Return a React Component with Shake animation (`1s` duration)

```jsx
import { withShake } from 'react-motions'

const ComponentWithShake = withShake(<div>Let's shake here</div>)
```
## Swing
### Component

Render a React Component with Swing animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Swing } from 'react-motions'

const ComponentSwing = (
  <Swing duration={2} infinite>
    Let's swing here
  </Swing>
)
```
### Function

Return a React Component with Swing animation (`1s` duration)

```jsx
import { withSwing } from 'react-motions'

const ComponentWithSwing = withSwing(<div>Swing!</div>)
```
## Tada
### Component

Render a React Component with Tada animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Tada } from 'react-motions'

const ComponentTada = (
  <Tada duration={2} infinite>
    Let's tada here
  </Tada>
)
```

### Function

Return a React Component with Tada animation (`1s` duration)

```jsx
import { withTada } from 'react-motions'

const ComponentWithTada = withTada(<div>Tadaaaan!</div>)
```
## Wobble
### Component

Render a React Component with Wobble animation (`2s` duration and iterationCount `infinite`)

```jsx
import { Wobble } from 'react-motions'

const ComponentWobble = (
  <Wobble duration={2} infinite>
    Let's wobble here
  </Wobble>
)
```
### Function

Return a React Component with Wobble animation (`1s` duration)

```jsx
import { withWobble } from 'react-motions'

const ComponentWithWobble = withWobble(<div>Wobble!</div>)
```

# Roadmap

- [ ] `withSequence`
- [ ] `compose`
- [ ] Create handler props on Components for bind Animation Hooks
- [ ] Allows to configure animation property on HOC

# Credits

A thanks to [Animate.css](https://github.com/daneden/animate.css) for all animations.

Created by [Raphael Amorim](https://twitter.com/raphamorims).
",88,88,5,3,art,"[animate, animation, art, css, css3, motions, react, recompose]",0
microsoft,art,microsoft,https://github.com/microsoft/art,https://api.github.com/repos/art/microsoft,"Exploring the connections between artworks with deep ""Visual Analogies""","<p align=""center"">
<a href=""https://aka.ms/mosaic"" target=""_blank"">
  <img src=""./media/header-image.jpg"" width=""80%""/>
  </a>
</p>

## [Live Demo at aka.ms/mosaic](https://aka.ms/mosaic)

To access the search functionality, [apply to access the mosaic beta](https://forms.microsoft.com/Pages/DesignPage.aspx#FormId=v4j5cvGGr0GRqy180BHbR3nswihwe8JLvwovyYerymVUQlUzOE9VVDUyQjlJUzRFQ1pQUEJDN001Wi4u)

## About

Art is one of the few languages which transcends barriers of country, culture, and time. We aim to create an algorithm that can help discover the common semantic elements of art even between **any** culture, media, artist, or collection within the combined artworks of [The Metropolitan Museum of Art](https://www.metmuseum.org/) and [The Rijksmusem](https://www.rijksmuseum.nl/en). 

### Conditional Image Retrieval

<p align=""center"">
  <img src=""./media/teaser_img.gif"" />
</p>

Image retrieval systems allow individuals to find images that are semantically similar to a query image. This serves as the backbone of reverse image search engines and many product recommendation engines. 
We present a novel method for specializing image retrieval systems called conditional image retrieval. When applied over large art datasets, conditional image retrieval provides visual analogies that bring to light hidden connections among different artists, cultures, and media. Conditional image retrieval systems can efficiently find shared semantics between works of vastly different media and cultural origin. [Our paper](https://arxiv.org/abs/2007.07177) introduces new variants of K-Nearest Neighbor algorithms that support specializing to particular subsets of image collections on the fly. 

### Deep Semantic Similarity

To find artworks with similar semantic structure we leverage ""features"" from deep vision networks trained on ImageNet. These networks map images into a high-dimensional space where distance is semantically meaningful. Here, nearest neighbor queries tend to act as ""reverse image search engines"" and similar objects often share common structure.

<p align=""center"">
  <img src=""./media/e2e.gif"" />
</p>

### Architecture

<p align=""center"">
  <img src=""./media/architecture.png"" width=70%/>
</p>

## Webinar
To learn more about this project please join our [live webinar](https://note.microsoft.com/MSR-Webinar-Visual-Analogies-Registration-Live.html) on 10AM PST 7/30/2020.

<p align=""center"">
<a href=""https://note.microsoft.com/MSR-Webinar-Visual-Analogies-Registration-Live.html"" target=""_blank"">
  <img src=""./media/webinar.jpg"" width=""50%""/>
</a>
</p>

## Paper

- Hamilton, M., Fu, S., Freeman, W. T., & Lu, M. (2020). Conditional Image Retrieval. arXiv preprint [arXiv:2007.07177](https://arxiv.org/abs/2007.07177).

To cite this work please use the following:
```
@article{hamilton2020conditional,
  title={Conditional Image Retrieval},
  author={Hamilton, Mark and Fu, Stephanie and Freeman, William T and Lu, Mindren},
  journal={arXiv preprint arXiv:2007.07177},
  year={2020}
}
```

## Developer Guide

Please see our [developer guide](./developer_guide.md) to build the project for yourself.

## Some Favorite Matches

Shared portrayals of reverence over 3000 years:

<p align=""center"">
  <img src=""./media/match1.jpg"" width=70%/>
</p>

How to match your watch to your outfit and your dinnerware:

<p align=""center"">
  <img src=""./media/match2.jpg"" width=70%/>
</p>

## Contributors

Special thanks to all of the contributors who helped make this project a reality!

#### Project Leads
- [Mark Hamilton](https://mhamilton.net)
- Chris Hoder

#### Collaborators
- [Professor William T Freeman](https://billf.mit.edu/)
- [Lei Zhang](https://www.microsoft.com/en-us/research/people/leizhang/)
- Anand Raman
- Al Bracuti
- Ryan Gaspar
- Christina Lee
- Lily Li

#### MIT x MSFT Garage 2020 Externship Team:

<p align=""center"">
<img src=""./media/mit_externs.jpg"" width=""40%""/>
</p>

 The MIT x MSFT externs were pivotal in turning this research project into a functioning website. In only one month, the team built and designed the mosaic website. Stephanie Fu and Mindren Lu also contributed to the ""Conditional Image Retrieval"" publication through their evaluation of the affect of different pre-trained networks on nonparametric style transfer.
- Stephanie Fu
- Mindren Lu 
- Zhenbang (Ben) Chen
- Felix Tran 
- Darius Bopp 
- Margaret (Maggie) Wang
- Marina Rogers 
- Johnny Bui 

#### MSFT Garage Staff and Mentors
This project owes a heavy thanks to the MSFT Garage team. They are passionate creators who seek to incubate new projects and inspire new generations of engineers. Their support and mentorship on this project are sincerely appreciated.
- Chris Templeman
- Linda Thackery 
- Jean-Yves Ntamwemezi
- Dalitso Banda
- Anunaya Pandey

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.
",83,83,13,31,art,"[ai, art, deep-learning, image-retrieval, k-nearest-neighbours, machine-learning, nuerips, react, resnet-50, search]",0
karafra,ai-art,,https://github.com/karafra/ai-art,https://api.github.com/repos/ai-art/karafra,Discord bot generating images from given query,"<div id=""top""></div>
<!--
*** Thanks for checking out the Best-README-Template. If you have a suggestion
*** that would make this better, please fork the repo and create a pull request
*** or simply open an issue with the tag ""enhancement"".
*** Don't forget to give the project a star!
*** Thanks again! Now go create something AMAZING! :D
-->

<!-- PROJECT SHIELDS -->
<!--
*** I'm using markdown ""reference style"" links for readability.
*** Reference links are enclosed in brackets [ ] instead of parentheses ( ).
*** See the bottom of this document for the declaration of the reference variables
*** for contributors-url, forks-url, etc. This is an optional, concise syntax you may use.
*** https://www.markdownguide.org/basic-syntax/#reference-style-links
-->

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![Codecov][codecov-shield]][codecov-url]
[![MIT License][license-shield]][license-url]
[![Discord][discord-shield]][discord-invite]
[![TOP.GG][top-gg-shield]][top-gg-link]
[![Buy me a coffee][buy-me-a-coffee-badge]][buy-me-a-coffee-url]


<!-- PROJECT LOGO -->
<br />
<div align=""center"">
  <a href=""https://github.com/karafra/ai-art"">
    <img src=""https://raw.githubusercontent.com/karafra/ai-art/main/.github/images/logo.png"" alt=""Logo"" width=""80"" height=""80"">
  </a>

<h3 align=""center"">AI Art</h3>

  <p align=""center"">
    Discord bot generating AI art collages
    <br />
    <a href=""https://karafra.github.io/ai-art/""><strong>Explore the docs »</strong></a>
    <br />
    <br />
    <a href=""https://discord.gg/VDKhbrc73Z"">View Demo</a>
    ·
    <a href=""https://github.com/karafra/ai-art/issues"">Report Bug</a>
    ·
    <a href=""https://github.com/karafra/ai-art/issues"">Request Feature</a>
  </p>
</div>

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href=""#about-the-project"">About The Project</a>
      <ul>
        <li><a href=""#built-with"">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href=""#getting-started"">Getting Started</a>
      <ul>
        <li><a href=""#prerequisites"">Prerequisites</a></li>
        <li><a href=""#installation"">Installation</a></li>
      </ul>
    </li>
    <li><a href=""#deployment"">Deployment</a></li>
    <li><a href=""#usage"">Usage</a></li>
    <li><a href=""#contributing"">Contributing</a></li>
    <li><a href=""#license"">License</a></li>
    <li><a href=""#contact"">Contact</a></li>
    <li><a href=""#acknowledgments"">Acknowledgments</a></li>
  </ol>
</details>

<!-- ABOUT THE PROJECT -->

## About The Project

<div align=""center"">

  [![Product Name Screen Shot][product-screenshot]][discord-invite]

</div>

Simple discord bot which generates collages based on any query you give it (most of the time). This bot uses model which you can find [here](https://huggingface.co/spaces/dalle-mini/dalle-mini)

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

### Built With

-   [Typescript](https://www.typescriptlang.org/)
-   [Discord.js](https://discord.js.org/)
-   [Collage](https://www.npmjs.com/package/@settlin/collage)
-   [Canvas](https://www.npmjs.com/package/canvas)
-   [amqp-client.js](https://github.com/cloudamqp/amqp-client.js/)
-   [Sentry.io](https://sentry.io)
-   [Jest](https://jestjs.io)
-   [Codecov](https://codecov.io)
-   [Docker](https://docker.com)
-   [NestJs](https://nestjs.com)
-   [Compodoc](https://compodoc.app)
-   [Mongo](https://www.mongodb.com/)
-   [TypeORM](https://typeorm.io/)
-   [GraphQl](https://graphql.org/)

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- GETTING STARTED -->

## Getting Started
### Prerequisites

This is an example of how to list things you need to use the software and how to install them.

-   npm
    ```sh
    npm install npm@latest -g
    ```

### Installation

1. Create Discord application on a free API Key at [https://discord.com/developers/](https://discord.com/developers/)

2. Click on *Bot* tab and save your token.

3. Clone the repo
    ```sh
    git clone https://github.com/karafra/ai-art.git
    ```
4. Install NPM packages
    ```sh
    npm install
    ```
5. Enter your API key and bot id into [config.yml](./config.yml). 
    ```yaml
    sentry:
      dsn: ""{SENTRY_DSN}""
    # This one is optional ... only if you want to use ai-story command
    openAi:
      token: ...
    amqp:
      url: ""{AMQP_URL}""
    discord:
        token: ""{DISCORD_TOKEN}""
    deploy:
      port: ""{PORT}""
    ```

    Configuration file supports simple environment variable substitution in format __""{VARIABLE_NAME}""__, where parentheses are __required__. 

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- DEPLOYMENT -->

## Deployment

### Method 1: Deployment to Heroku

Recommended method of deploying this bot is deployment on [Heroku](https://www.heroku.com/). To deploy to Heroku please click on button bellow.

<p align=""center"">
<a href=""https://heroku.com/deploy?template=https://github.com/karafra/ai-art.git"">
  <img src=""https://img.shields.io/badge/%E2%86%91_Deploy_to-Heroku-7056bf.svg?style=for-the-badge"" alt=""Deploy"">
</a>
</p>

##### IMPORTANT


After successful deployment you will have to switch dyno from `web` to `worker`. If you do not do this, app will not bind to port and fail. 

<p align=""center"">
  <img src=""https://raw.githubusercontent.com/karafra/ai-art/main/.github/images/heroku-dynos.png"" />
</p>

After successful deployment you can invite bot to your server by clicking on this link `https://discord.com/api/oauth2/authorize?client_id={CLIENT_ID}&permissions=34816&scope=applications.commands%20bot`, where `CLIENT_ID` is your bots client id. Link already contains minimal scopes (_bot_, _application.commands_) and minimal bot permissions (_send messages_, _attach files_)

### Method 2: Containerized deployment:
Another even easier method of deployment is deployment via docker container.

1. Verify docker-compose installation

    A] Type `docker-compose -v` into terminal. if output looks similar to `docker-compose version 1.29.2, build 5becea4c` then you can continue to the next step.

    B] If this command throws an error, you have to follow [docker-compose installation guide](https://docs.docker.com/compose/install/)

2. Set required variables
    - Only required variables is `TOKEN`, this can be set as environment variables using `export ENV_NAME=VALUE` on linux based OS or `$env:VARIABLE_NAME=VALUE` on Windows based OS

3. Building Docker containers
  - Type `docker-compose -f ""docker/deploy/docker-compose.yml"" build` into terminal, this will automatically build all required docker images.

4. Start container
    - Type `docker-compose -f ""docker/deploy/docker-compose.yml"" up` into terminal. This will start all services needed. RabbitMQ management console will be accessible [here](http://localhost:15673/) with login credentials being:
      - username:   
        - `guest`
      - password:
        - `guest`
    
    - MongoDb management console will be accessible [here](https://localhost:8081/) without any login credentials

__This network is not external, so it will not be accessible from outside.__

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- USAGE EXAMPLES -->

## Usage

Commands are separated into 2 command groups

- `help` - Help command 
- `/ai-art`
  - `cog-view-2` - Generates collage of 9 images using CogView2 model
  - `dalle-mini` - Generates collage of 9 images using Dall-e mini model
  - `wombo-dream` - Generartes one image based on WomboDream model  
- `/ai-story`
  - `story` - Generates story from given headline (Requires OpenAi API) token

- React with :envelope: to any collage and bot will dm it to you.

Discord offers autocompletion so all you need is to start typing name of the command or group in which command is, discord will then guide you through all the required parameters using its autocompletion.

<p align=""center"">
  <img src=""https://raw.githubusercontent.com/karafra/ai-art/main/.github/images/command-selection.png"" />
</p>

_For more examples, please refer to the [Documentation](https://karafra.github.io/ai-art/additional-documentation/commands.html)_

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- CONTRIBUTING -->

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag ""enhancement"".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- LICENSE -->

## License

Distributed under the Apache2.0 License. See [LICENSE](./LICENSE) for more information.

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- CONTACT -->

## Contact

Your Name - [@Karafro](https://twitter.com/Karafro) - dariusKralovic@protonmail.com

Project Link: [https://github.com/karafra/ai-art](https://github.com/karafra/ai-art)

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- ACKNOWLEDGMENTS -->

## Acknowledgments

- [DALL·E Mini](https://github.com/borisdayma/dalle-mini)
  - Image generation model for `/ai-art dalle-mini`
- [CogView2](https://github.com/THUDM/CogView2)
  - Image generation model for `/ai-art cog-view-2`
- [Open Ai](https://beta.openai.com/playground)
  - Story generation model for `/ai-story story`
- [WomboDream](https://www.wombo.art/)
  - Art generation model for `ai-art wombo-art`

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->

[contributors-shield]: https://img.shields.io/github/contributors/karafra/ai-art.svg?style=for-the-badge
[contributors-url]: https://github.com/karafra/ai-art/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/karafra/ai-art.svg?style=for-the-badge
[forks-url]: https://github.com/karafra/ai-art/network/members
[stars-shield]: https://img.shields.io/github/stars/karafra/ai-art.svg?style=for-the-badge
[stars-url]: https://github.com/karafra/ai-art/stargazers
[issues-shield]: https://img.shields.io/github/issues/karafra/ai-art.svg?style=for-the-badge
[issues-url]: https://github.com/karafra/ai-art/issues
[license-shield]: https://img.shields.io/github/license/karafra/ai-art.svg?style=for-the-badge
[license-url]: https://github.com/karafra/ai-art/blob/master/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555
[linkedin-url]: https://linkedin.com/in/linkedin_username
[product-screenshot]: https://raw.githubusercontent.com/karafra/ai-art/main/.github/images/showcase.gif
[discord-shield]: https://img.shields.io/discord/984823638333210715?color=purple&label=DEMO%20SERVER&logo=discord&logoColor=white&style=for-the-badge
[discord-invite]:https://discord.gg/VDKhbrc73Z
[top-gg-shield]: https://img.shields.io/static/v1?label=TOP.GG&message=LISTED&color=purple&style=for-the-badge&logo=google-chrome&logoColor=white
[top-gg-link]: https://top.gg/bot/984821826096091206
[codecov-shield]: https://img.shields.io/codecov/c/github/karafra/ai-art?style=for-the-badge&token=zeGtflSZ48
[codecov-url]: https://app.codecov.io/gh/karafra/ai-art
[buy-me-a-coffee-badge]: https://img.shields.io/badge/-buy_me_a%C2%A0coffee-gray?logo=buy-me-a-coffee&style=for-the-badge
[buy-me-a-coffee-url]: https://www.buymeacoffee.com/karafra
",75,75,5,15,art,"[ai, art, artificial-intelligence, bot, dalle-mini, discord, discord-bot, discord-js, generator, heroku, heroku-deployment, integration]",0
billythegoat356,Pandore,,https://github.com/billythegoat356/Pandore,https://api.github.com/repos/Pandore/billythegoat356,The fastest way to convert an image to ASCII art.,"-----

<p align=""center"">
<img src=""https://repository-images.githubusercontent.com/405202771/4d2005fd-b5f3-4a19-8fce-fad952163d70"", width=""500"", height=""500"">
</p>

-----

### <p align=""center"">🐉 Pandore 🐉</p>

<br><br>
<p align=""center"">
<strong>
This program, written in Python3 allows you to convert
<br>
images to ASCII art in a few clicks!
</strong>
</p>
<br>

-----

### <p align=""center"">📋 Examples 📋</p>

<br><br><br>
<p align=""center"">
<img src=""https://cdn.discordapp.com/attachments/892840615732195340/909217885870784512/image.jpg"" width=""500"", height=""500"">
<br><br>
to
<br><br>
<img src=""https://cdn.discordapp.com/attachments/892840615732195340/909218422980751421/unknown.png"" width=""500"", height=""500"">
</p>
<br><br><br>

-----

### <p align=""center"">⭐ Features ⭐</p>

<br><br>
<strong>+ Fast</strong>
<br>
<strong>+ Easy to use</strong>
<br>
<strong>+ Customizable scale</strong>
<br>

<p align=""right"">
<img src=""https://repository-images.githubusercontent.com/405202771/4d2005fd-b5f3-4a19-8fce-fad952163d70"" width=""250"", height=""250"">
</p>

<br>
<strong>- You can only convert images with a white font otherwise it will be kind of buggy</strong>
<br><br>

-----

### <p align=""center"">🎯 Levels 🎯</p>

<p align=""center""><strong><i>This section shows the ""levels"" of this project, from 0/5 ⚪ to 5/5 ⚫!</i></strong</p>
<p align=""center""><strong><i>⚪🟢🔵🔴🟣⚫</i></strong</p>

<br><br>
* Time: 🟢
* Complexity: 🟣
* Service: 🔴
<br><br>

-----

### <p align=""center"">💡 Ideas 💡</p>

<p align=""center""><strong><i>Feel free to make a pull request on this repository to submit any idea!</i></strong</p>

<br><br>
* Replace the font with the white color so the ASCII art will have a ""transparent font""
<br><br>

-----

### <p align=""center"">📌 Disclaimer 📌</p>

<br><br>
* ***Please use this program only for educational purposes.***
* ***It is not meant to be used in any malicious way, and I decline any responsibility for what you do with it.***
<br><br>

-----

### <p align=""center"">billythegoat356</p>
",73,73,2,1,art,"[art, ascii, ascii-art, image, pil, python, python3]",0
ItsCEED,Imaginepy,,https://github.com/ItsCEED/Imaginepy,https://api.github.com/repos/Imaginepy/ItsCEED,"ImaginePy, opensource (reversed) API like Stable Diffusion, Midjourney. Everything at 0 Cost.","<div align=""center"">
<img src=""https://github.com/ItsCEED/ImaginePy-Midjourney-Free-Alternative/blob/main/docs/imagine_logo.gif"" width=""10%"">

**ImaginePy**
<br>
<a href=""https://discord.gg/axfkjqWR5E"" target=""_blank"">
  <img src=""https://discordapp.com/api/guilds/1110314971012808774/widget.png?style=banner4"" alt=""Discord Banner 4"">
</a>
<br>
<img src=""https://img.shields.io/badge/python-3.7+-informational?style=plastic"" alt=""Python version"">
<img src=""https://img.shields.io/github/release-date/ItsCEED/ImaginePy-Midjourney-Free-Alternative?style=plastic"" alt=""Release"">
<img src=""https://img.shields.io/github/release/ItsCEED/ImaginePy-Midjourney-Free-Alternative?style=plastic"" alt=""Version"">

</div>

## Features

- 🎨 Turn words into art
- 👓 Choose from an array of art styles
- 🔧 Adjust your masterpiece with creative controls!
- 📦 Stay ahead of the game with the ever-growing art library!
- 🌇 Generate wallpapers
- 🔎 Discover and explore similar artistic designs
- This is refactored and improved version of the original from [hyugogirubato]

## Installation

_Note: Requires [Python] 3.7.0 or newer with PIP installed._

```shell
$ python setup.py install
```

You now have the `imaginepy` package installed.

### PyPi Installation

```
pip install imaginepy
```

[Python]: https://python.org
[Venv's]: https://docs.python.org/3/tutorial/venv.html
[Venv's Docs]: https://docs.python.org/3/library/venv.html
[hyugogirubato]: https://github.com/hyugogirubato/pyImagine

### From Source Code

The following steps are instructions on download, preparing, and running the code under a Venv environment.
You can skip steps 3-5 with a simple `python setup.py install` call instead, but you miss out on a wide array of benefits.

1. `git clone https://github.com/ItsCEED/Imaginepy`
2. `cd Imaginepy`
3. `python -m venv env`
4. `source env/bin/activate`
5. `python setup.py install`

As seen in Step 5, running the `imaginepy` executable is somewhat different to a normal PIP installation.
See [Venv's Docs] on various ways of making calls under the virtual-environment.

[Python]: https://python.org
[Venv's]: https://docs.python.org/3/tutorial/venv.html
[Venv's Docs]: https://docs.python.org/3/library/venv.html
[hyugogirubato]: https://github.com/hyugogirubato/pyImagine

## Usage

The following is a minimal example of using ImaginePy in a script. It gets the generated image
from the text and increases the quality.

```python
from imaginepy import Imagine
from imaginepy.constants import *


def main():
    imagine = Imagine()

    img_data = imagine.sdprem(
        prompt=""Woman sitting on a table, looking at the sky, seen from behind"",
        style=Style.NO_STYLE,
        ratio=Ratio.RATIO_16X9,
        negative="""",
        seed=1000,
        cfg=16,
        model=Model.REALISTIC,
        asbase64=False  # default is false, putting it here as presentation.
    )

    if img_data is None:
        print(""An error occurred while generating the image."")
        return

    img_data = imagine.upscale(img_data)

    if img_data is None:
        print(""An error occurred while upscaling the image."")
        return

    try:
        with open(""example.jpeg"", mode=""wb"") as img_file:
            img_file.write(img_data)
    except Exception as e:
        print(f""An error occurred while writing the image to file: {e}"")


if __name__ == ""__main__"":
    main()
```

Async version

```python
import asyncio
from imaginepy import AsyncImagine
from imaginepy.constants import *


async def main():
    imagine = AsyncImagine()
    img_data = imagine.sdprem(
        prompt=""Woman sitting on a table, looking at the sky, seen from behind"",
        style=Style.NO_STYLE,
        ratio=Ratio.RATIO_16X9,
        negative="""",
        seed=1000,
        cfg=16,
        model=Model.REALISTIC,
        asbase64=False  # default is false, putting it here as presentation.
    )

    if img_data is None:
        print(""An error occurred while generating the image."")
        return

    img_data = await imagine.upscale(image=img_data)

    if img_data is None:
        print(""An error occurred while upscaling the image."")
        return

    try:
        with open(""example.png"", mode=""wb"") as img_file:
            img_file.write(img_data)
    except Exception as e:
        print(f""An error occurred while writing the image to file: {e}"")

    await imagine.close()


if __name__ == ""__main__"":
    asyncio.run(main())

```

## Credit

- Imagine Icon &copy; Vyro AI & API
- Original reverse and version by: [hyugogirubato]

## License

[GNU General Public License, Version 3.0](LICENSE)
",72,72,8,8,art,"[ai, aiart, api, art, generative-art, midjourney, midjourney-app, reverse, stable-diffusion, stablediffusion]",0
zv,tree,,https://github.com/zv/tree,https://api.github.com/repos/tree/zv,Procedural trees,,71,71,7,2,art,"[art, javascript, procedural]",0
adamfuhrer,glitch-image,,https://github.com/adamfuhrer/glitch-image,https://api.github.com/repos/glitch-image/adamfuhrer,glitch image generator,"# Glitch Image Generator

A generative tool which allows you to create and save unique glitchy images

[glitchyimage.com](https://glitchyimage.com/)

![glitch art](https://glitchyimage.com/glitch-vintage.jpeg)
",70,70,5,0,art,"[art, generative, generative-art, glitch-art]",0
nordlicht,nordlicht,nordlicht,https://github.com/nordlicht/nordlicht,https://api.github.com/repos/nordlicht/nordlicht,Creates colorful timebars from video and audio files,"# nordlicht

**nordlicht** is a C library that creates colorful timebars from video and audio files. For a general introduction, installation and usage instructions, please visit <http://nordlicht.github.io/>.

## Building from source

Get CMake, FFmpeg/libav, [popt](http://freecode.com/projects/popt), and [help2man](https://www.gnu.org/software/help2man/), and issue the following commands to create the `nordlicht` binary:

    $ mkdir build
    $ cd build
    $ cmake ..
    $ make

To run the test suite, run `make check`. Note that the test suite will download a ~20 MB test video from Wikimedia Commons.

## Contributing

Development of *nordlicht* happens on GitHub. Please report any bugs or ideas to the [issue tracker](https://github.com/nordlicht/nordlicht/issues). To contribute code, fork the repository and submit a pull request.

You can also help by packaging the software for your favorite operating system, or writing an integration for your favorite video player. Even rough prototypes are highly appreciated!

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.

## License: GPLv2+

See [LICENSE.md](LICENSE.md) for details.
",64,64,6,18,art,"[art, audio, c, navigation, user-interface, video, visualization]",0
oussamabonnor1,Catcheep,,https://github.com/oussamabonnor1/Catcheep,https://api.github.com/repos/Catcheep/oussamabonnor1,"Catcheep is an android game where you play as someone helping aliens to go back to their planet, the way to do so is by catching sheep that are concidered as their energy source, Made with Unity3D!","# Catcheep 

![GitHub license](https://img.shields.io/github/license/oussamabonnor1/Catcheep.svg)
![Jetlight studio](https://img.shields.io/badge/Made%20by-Jetlight%20studio-blue.svg?color=082544)

Catcheep is an android game where you play as someone helping aliens to go back to their planet, the way to do so is by catching sheep that are concidered as their energy source, Made with Unity3D!

## Aliens came to visit our planet but guess what? They ran out of fuel and you've got to help them out! 
Here's the kicker though: Sheep are the fuel aliens need for their spaceships engines to start!

<img src=""https://user-images.githubusercontent.com/17766221/33531668-9eea2b6c-d890-11e7-989c-b1c363817e6c.png"" width=""250"" /> &nbsp;&nbsp;

## Wolfy is their savior, Fortunately!
he proposed a deal and they agreed to pay for the amount of sheep needed. But Wolfy can't do it on his own. Your mission, then, is to help Wolfy catch the right number of sheep! But beware of the sick sheepies; the aliens are very picky when it comes to quality! 

<img src=""https://user-images.githubusercontent.com/17766221/33531680-b5c650f4-d890-11e7-96d8-94987c4291b2.png"" width=""250"" /> &nbsp;&nbsp;
<img src=""https://user-images.githubusercontent.com/17766221/33531681-b5ebdd56-d890-11e7-9c21-7ad3d8daa74b.png"" width=""250"" /> &nbsp;&nbsp;
<img src=""https://user-images.githubusercontent.com/17766221/33531682-b6137438-d890-11e7-8a47-56df292bcac4.png"" width=""250"" /> &nbsp;&nbsp;

Follow Wolfy's instructions in order to properly catch the requested sheep amounts in each mission and then exchange them with cash. 

## You can also purchase the sheepy help tools in the shop to make it easier to catch them ! 

<img src=""https://user-images.githubusercontent.com/17766221/33531713-2b263d78-d891-11e7-9082-8df2098b928a.png"" width=""250"" /> &nbsp;&nbsp;

Ranking up the mission levels isn't all what we've got in store for ya! Catch the max amount of sheep to challenge your friends and conquer the leaderboards! Show them all you are the best!

To get even more help, search for the sheepy tips we gave you to have an even better, enjoyable playing experience! Get yourself ready and your fingers prepped, and enjoy the ride!!

<img src=""https://user-images.githubusercontent.com/17766221/33531677-b51e3202-d890-11e7-91d6-7ed6bc2ce323.png"" width=""250"" /> &nbsp;&nbsp;
<img src=""https://user-images.githubusercontent.com/17766221/33531683-b6395522-d890-11e7-9ce4-e70c7aaf0b4b.png"" width=""250"" /> &nbsp;&nbsp;
<img src=""https://user-images.githubusercontent.com/17766221/33531684-b65ea872-d890-11e7-981e-41f9b9becf69.png"" width=""250"" /> &nbsp;&nbsp;

## Team:
[Jetlighters](https://github.com/JetLightStudio) having fun.

### special thanks to: 
 [Khadidja Boukridmi](https://github.com/BK-Star)
",64,64,5,0,art,"[android, android-game, art, csharp, game, game-development, gimp, unity, unity2d, visual-studio]",0
jeffThompson,CreativeProgramming1,,https://github.com/jeffThompson/CreativeProgramming1,https://api.github.com/repos/CreativeProgramming1/jeffThompson,An introductory course exploring code as a tool for creative making,"> ""The process of preparing programs for a digital computer is especially attractive, not only because it can be economically and scientifically rewarding, but also because it can be an aesthetic experience much like composing poetry or music.""  
> – Donald Knuth

> ""This may sound paradoxical, but the machine, which is thought to be cold and inhuman, can help to realize what is most subjective, unattainable, and profound in a human being.""  
> – Vera Molnar


# CREATIVE PROGRAMMING 1

**[:arrow_down: Jump right to the Course Calendar :arrow_down:](https://github.com/jeffThompson/CreativeProgramming1#course-calendar)**  
 
| Instructor     | Prof. Jeff Thompson (please call me Jeff) |  
| :---           | :--- |  
| Email          | jeff.thompson@stevens.edu |  
| Time/location  | Mondays 9am–12.50pm, Morton 201 |  
| Student hours  | Tuesdays 10am–noon (Morton 208) and by appointment (Zoom) |  

In this class, we will explore the computer as a tool capable of powerful creative possibility, not via pre-built software, but instead by writing code ourselves. We will look at the basic structures and affordances of code as inspiration for making artworks, as a tool capable of creating things that would be impossible by hand, and as a fallible system that encapsulates our cultural and personal biases.

During the course of the semester, you’ll learn how to write code for a variety of visual projects, including images, animations, and interactive work. We’ll primarily be using [`p5.js`](https://p5js.org) that was originally developed by [Lauren McCarthy](https://lauren-mccarthy.com) and is an offshoot of [Processing](https://processing.org) (which turns twenty years old this year!). `p5.js` is a toolkit created specifically for artists and designers build on the Javascript programming language and features a really [easy-to-use online code editor](https://editor.p5js.org).

Along the way, we’ll also look at historical and contemporary figures in the arts and computer science who have shaped how we use computers as creative tools, and we’ll explore code from a critical, humanistic perspective.

See the [syllabus PDF](https://github.com/jeffThompson/CreativeProgramming1/blob/master/Syllabus.pdf) for course policies, grading, etc.

***

### FORMAT  
This semester we're finally back together in person! Our class time will be spent together critiquing your homework projects, covering technical material, introducing new assignments, looking at examples, group ideation and feedback exercises, and work time. Attendance will be taken at the start of class every week.

Because we will cover a lot of material this semester and because this course will be both rigorous and thorough, it’s really important that you stay on top of your coursework. 

:warning: **Don’t hesitate to reach out if you have any questions at all! Better to ask a question than be unsure of something.**  

***
 
### COURSE CALENDAR  
Please note this is subject to change. Be sure to check Canvas, this page, and your email regularly. Homework and readings are listed for the days they are assigned.

| AUG 30     | [BOOTING UP](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week00_BootingUp) |
| :---       | :--- |
| In class   | Hello, introductions and syllabus, how to access course materials, instruction drawings |
| Reading    | *Computer Graphics* (Mohr)|
| Homework   | `Instruction Drawings`|

| SEPT 6     | LABOR DAY, NO CLASS! |
| :---       | :--- |
| Homework   | Finish `Instruction Drawings`|  

| SEPT 13    | [DRAWING && COORDINATE SYSTEMS](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week01_DrawingBasics) |
| :---       | :--- |
| In class   | Creating sketches in the `p5.js` editor, ""Hello World,"" RGB color, drawing shapes, fill and stroke, saving images, getting help |
| Homework   | `Robot Drawings` |

| SEPT 20    | [ITERATION && LOOPS 1](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week02_IterationAndLoops) |
| :---       | :--- |
| In class   | Variables, for loops, nested loops, driving parameters with loops, historical quilt research |
| Homework   | Create a quilt block for your `Algorithmic Quilt` |
 
| SEPT 27    | [ITERATION && LOOPS 2](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week02_IterationAndLoops) |
| :---       | :--- |
| In class   | Matrix transformations, creating functions to re-use code |
| Homework   | Finish your `Algorithmic Quilt` |

| OCT 4      | [RANDOMNESS 1](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week04_Randomness) |
| :---       | :--- |
| In class   | Psuedo-random numbers, `random()`, Brownian motion, random choices |
| Readings   | *Open Source as Open Culture/Culture as Open Source* by Siva Vaidhyanathan and *Motives for Writing Free Software* by the Free Software Foundation |
| Homework   | `Randomness` code sketches |

| OCT 11     | INDIGENOUS PEOPLES' DAY, CLASS MEETS ON TUESDAY! |
| :---       | :--- |
| Homework   | (See above) |

| OCT 12     | [RANDOMNESS 2 (and ⊨ Open Source)](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week04_Randomness) |
| :---       | :--- |
| In class   | Discuss readings, contributing to open source projects, Perlin noise  |
| Homework   | Finish `Randomness` project |

| OCT 18     | [COLLAGE](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week06_Collage) |
| :---       | :--- |
| **Note!**  | **Jeff out of town, class will meet online** |  
| In class   | Loading images, resizing, accessing pixel values with `get()` |
| Homework   | `Collaged Photographs` |

| OCT 25     | [INTERACTIVITY 1](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week07_Interactivity) |
| :---       | :--- |
| **Note!**  | **Jeff out of town, class will meet online** |
| In class   | Mouse and keyboard input, using an external editor |  
| Homework   | `Interactivity` in-progress sketches |

| NOV 1      | [INTERACTIVITY 2](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week07_Interactivity) |
| :---       | :--- |
| In class   | More interactivity demos, work time |  
| Homework   | Finish `Interactivity` project |

| NOV 8      | [ANIMATION 1](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week09_Animation) |
| :---       | :--- |
| In class   | Change over time, `frameCount` and timing, flags, sprites |
| Homework   | `Animation`: rough version of first two scenes |

| NOV 15     | [ANIMATION 2](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week09_Animation) |
| :---       | :--- |
| In class   | Easing, sound |
| Homework   | Finish `Animation` |

| NOV 22     | [FINAL PROJECT 1](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week11_FinalProject) |
| :---       | :--- |
| In class   | Object-oriented programming |
| Homework   | Write `Final Project` proposal |

| NOV 29     | [FINAL PROJECT 2](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week11_FinalProject) |
| :---       | :--- |
| In class   | Project feedback |
| Homework   | Rough version of `Final Project` |

| DEC 6      | [FINAL PROJECT 3](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week11_FinalProject) |
| :---       | :--- |
| In class   | Project feedback, work day |
| Homework   | Finish `Final Project` and documentation |

| DEC 13, 9AM | [FINAL CRITIQUE](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week11_FinalProject) |
| :---       | :--- |
| Crit       | Final critique of projects |

| DEC 15, 5PM | [DOCUMENTATION DUE](https://github.com/jeffThompson/CreativeProgramming1/tree/master/Week11_FinalProject) |
 :---       | :--- |
| Online    | Project documentation due by 5pm on Canvas |

*Topics noted with [⊨ symbol](https://en.wikipedia.org/wiki/Double_turnstile) are short explorations of topics that jump off from or surround programming in a creative context; the symbol ⊨ is used in the field of logic to mean that an idea semantically entails another*

",63,63,10,0,art,"[art, course, design, javascript, p5js, processing]",0
ekzhang,dispict,,https://github.com/ekzhang/dispict,https://api.github.com/repos/dispict/ekzhang,"Design a growing artistic exhibit of your own making, with semantic search powered by OpenAI CLIP","# Dispict: a creative aesthetics tool

Design a growing artistic exhibit of your own making, with semantic search
powered by OpenAI CLIP. Bring your own labels and context.

[![dispict cover image](./public/assets/social-image.jpg)](https://dispict.com)

**[dispict.com](https://dispict.com)** greets you with a blank canvas. You begin
typing. Your writing becomes a _label_, and related artworks appear spatially
around the text you wrote. As you pan and zoom around the gallery, you can try
other labels to see how the artwork shifts in aesthetic quality.

Focus on a single work to see its context: artist, setting, history, and
narrative descriptions. This crucially allows you to learn about the story of
the art being presented.

## Motivation

There's currently a lot of excitement about computers helping creatives find
inspiration by generating original art pieces from text prompts
([1](https://openai.com/dall-e-2/), [2](https://www.midjourney.com/),
[3](https://stability.ai/blog/stable-diffusion-public-release)). But these lose
the unique, genuine part of walking through an art museum where every work has
been lovingly created by humans, and the viewer is surrounded by _insight_ and
_intention_. What if computers could connect us with masterpieces made by
artists of the past?

The Harvard Art Museums' online collection is huge, containing over 200,000
digitized works. This is far more than can be easily taken in by a single
person. So instead, we apply computation to what it's good at: finding patterns
and connections.

**Creativity and curiosity require associative thinking.** Just like the
technological innovations of centuries past have changed the aesthetic character
of fine art from literal portraiture to more flexible modes of self-expression,
_Dispict_ hopes to be technology that explores the honest, intimate relationship
of the creative process with artistic discovery.

## Technical Details

_Dispict_ uses real-time machine learning. It's built on contrastive
language-image pretraining (CLIP) and nearest-neighbor search, served from
Python (on a [Modal](https://modal.com/) endpoint) with a handcrafted
[Svelte](https://svelte.dev/) frontend.

### Development

If you want to hack on dispict yourself, you can run the frontend development
server locally using [Node v16](https://nodejs.org/) or higher:

```shell
npm install
npm run dev
```

This will automatically connect to the serverless backend recommendation system
hosted on Modal. To additionally change this part of the code, you need to
create a Modal account, then install [Python 3.10+](https://www.python.org/) and
follow these steps:

1. Run the Jupyter notebooks `notebooks/load_data.ipynb` and
   `notebooks/data_cleaning.ipynb` to download data from the Harvard Art
   Museums. This will produce two files named `data/artmuseums[-clean].json`.
2. Run `SKIP_WEB=1 modal run main.py` to spawn a parallel Modal job that
   downloads and embeds all images in the dataset using
   [CLIP](https://openai.com/blog/clip/), saving the results to
   `data/embeddings.hdf5`.
3. Run `modal deploy main.py` to create the web endpoint, which then gives you a
   public URL such as `https://ekzhang-dispict-suggestions.modal.run`.

You can start sending requests to the URL to get recommendations. For example,
`GET /?text=apple` will find artwork related to apples, such as the image shown
below.

<p align=""center"">
<a href=""https://harvardartmuseums.org/collections/object/230725"">
<img src=""https://nrs.harvard.edu/urn-3:HUAM:756527"" alt=""'West Indian Girl' by Childe Hassam"" width=""600"">
</a>
</p>

To point the web application at your new backend URL, you can set an environment
variable to override the default backend.

```shell
VITE_APP_API_URL=https://[your-app-endpoint].modal.run npm run dev
```

## Acknowledgements

Created by Eric Zhang ([@ekzhang1](https://twitter.com/ekzhang1)) for
[Neuroaesthetics](https://mbb.harvard.edu/) at Harvard. All code is licensed
under [MIT](LICENSE), and data is generously provided by the
[Harvard Art Museums](https://www.harvardartmuseums.org/) public access
collection.

I learned a lot from Jono Brandel's [_Curaturae_](https://curaturae.com/) when
designing this.
",59,59,4,0,art,"[aesthetics, art, clip, computer-vision, creative, graphic-design, machine-learning, modal, museum, python]",0
melloskitten,pixelino,,https://github.com/melloskitten/pixelino,https://api.github.com/repos/pixelino/melloskitten,Pixel-drawing app for iOS ✍️,"# pixelinoo
## Create awesome pixel art! 🎨👾🖌️


__pixelinoo__ is an art drawing app that lets you create your own pixel art!
![App images](docs/appImages.png)


Draw, color and create everything pixel-y! pixelinoo lets you draw whatever comes to your mind on a pixel-based canvas, where you can fill and modify your drawings according to your wishes. You can save your drawings inside the app, export them to your personal Photos gallery, or even share it with your friends over your favorite instant messenger. Let's get creative!

## App Store Download

You can get pixelinoo __for free__ on the App store 🎨

[![App store download](https://www.designpieces.com/wp-content/uploads/2016/02/download-on-the-app-store.png)](https://itunes.apple.com/de/app/pixelinoo/id1459038137?l=en&mt=8)


## Contribution

Feel free to file new issues or feature requests. Contributions are always welcome! Enjoy and let's get creative 🎨

",54,54,5,5,art,"[app, art, artwork, creative, creativity, drawing, drawing-app, game, ios, iphone, mobile, mobile-app, pixel, pixel-art, pixel-art-maker, pixel-editor, pixelart, swift]",0
scriptkittie,GlitchKernel,,https://github.com/scriptkittie/GlitchKernel,https://api.github.com/repos/GlitchKernel/scriptkittie,"A Glitch art tool for data bending, glitching, and distorting static images.",,51,51,7,0,art,"[algorithms, art, corruption, databending, datamoshing, glitch, glitchart, java, jpeg]",0
LapisDev,qr-art,,https://github.com/LapisDev/qr-art,https://api.github.com/repos/qr-art/LapisDev, A QR code generator for creating QR codes combined with images or GIF animation.,"# QR Art
A QR code generator for creating QR codes combined with images or GIF animation. It is based on .NET Core. Code for QR code encoding and GIF encoding is borrowed from [Kazuhiko Arasel's QR code generator implementation](https://github.com/kazuhikoarase/qrcode-generator) in JavaScript and Typescript.

## Usage and Examples
QR Art provides a command line interface:
```
Usage: qr-art [arguments] [options]

Arguments:
  content  Text to encode.
  image    An image to be used as background.
  format   Output image format. [png|gif|svg]
  outpath  Output path.

Options:
  -?|-h|--help             Show help information
  -v|--version             Show version information
  -t|--type <type>         Type number of QR code. [1-39]
  -e|--errcor <level>      Error correct level. [L|M|Q|H]
  -f|--foreground <color>  Foreground color.
  -b|--background <color>  Background color.
  -c|--cell <size>         Cell size.
  -m|--margin <margin>     Margin.
  -a|--animation           Generate animated QR code.
```

```
qr-art ""A panda"" samples/panda.jpg gif
```
<img src=""src/qr-art/samples/panda.jpg"" width=""214""> ![](src/qr-art/samples/panda_output.gif)

```
qr-art ""A tree on the grass"" samples/tree.jpg gif -f #657981 -b #B8D5F2
```
<img src=""src/qr-art/samples/tree.jpg"" width=""214""> ![](src/qr-art/samples/tree_output.gif)

```
qr-art  ""A dog combing hair"" samples/hair.gif gif -a
```
<img src=""src/qr-art/samples/hair.gif"" width=""214""> ![](src/qr-art/samples/hair_output.gif)
",50,50,0,1,art,"[animation, art, csharp, dotnet, image, netcore, qr-code]",0
thoppe,streamlit-CLIP-Unsplash-explorer,,https://github.com/thoppe/streamlit-CLIP-Unsplash-explorer,https://api.github.com/repos/streamlit-CLIP-Unsplash-explorer/thoppe,Explore the image embeddings of Unsplash using CLIP's image similarity,"# Unsplash+CLIP image similarity
_Small project to explore the image embeddings of [CLIP](https://github.com/openai/CLIP) image similarity using [Unsplash](https://unsplash.com/) and [Streamlit](streamlit.io)_

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/thoppe/streamlit-clip-unsplash-explorer)

https://share.streamlit.io/thoppe/streamlit-clip-unsplash-explorer

or `pip install -r requirements.txt` and run

    streamlit run streamlit_app.py

All photo credits can be found by clicking on the image.
Any missing photos or 404s existed at the time of creation.",44,44,5,1,art,"[ai, art, clip, openai, python, streamlit, unsplash]",0
yuhonas,zsh-ansimotd,,https://github.com/yuhonas/zsh-ansimotd,https://api.github.com/repos/zsh-ansimotd/yuhonas,a zsh-plugin to display old skool ansi & ascii bbs art on logon,"# zsh ansi motd (message of the day) [![Lint for errors](https://github.com/yuhonas/zsh-ansimotd/actions/workflows/ci.yml/badge.svg)](https://github.com/yuhonas/zsh-ansimotd/actions/workflows/ci.yml) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)



This zsh plugin adds an old skool ansi art based motd when the login shell is executed

![Example MOTD](./example.png)

## Why

I grew up in the day's of [ BBS's ](https://en.wikipedia.org/wiki/Bulletin_board_system) and [ ansi art ](https://en.wikipedia.org/wiki/ANSI_art) so I wanted something
to replicate the experience of jumping onto a new [ BBS ](https://en.wikipedia.org/wiki/Bulletin_board_system) everytime I started my login shell

## Installation

### Dependencies

* [zsh](https://www.zsh.org/)
* [shuf]( https://en.wikipedia.org/wiki/Shuf) which is part of gnu [coreutils](https://formulae.brew.sh/formula/coreutils)

For Mac/Linux using [ Homebrew ](https://brew.sh/) you can install coreutils using

```
brew install coreutils
```

#### Optional
* [fd](https://github.com/sharkdp/fd) a modern `find` replacement, it will use this preferentially if it's installed otherwise fallback to `find`
* [pv](https://www.ivarch.com/programs/pv.shtml) a pipe viewer which can limit the art rendering speed to [emulate the feel of an old skool BBS](https://github.com/yuhonas/zsh-ansimotd#the-real-bbs-experience)

### Install using your favourite plugin manager or not

```
# for znap
znap source yuhonas/zsh-ansimotd

# for antigen
antigen bundle yuhonas/zsh-ansimotd

# for zplug
zplug ""yuhonas/zsh-ansimotd""

# manually
# Clone the repository and source it in your shell's rc file
```

### Getting some awesome ansi art to display

After installation you'll need to download some ansi art for it to randomly display, I suggest a few places

#### 16colo.rs

Head over to [16colo.rs](https://16colo.rs/) and if you find a year(s) you like you can download everything from that year using their rsync mirror

eg. to download everything from [1996](https://16colo.rs/year/1996/) to the `ANSI_MOTD_ART_DIR`
```
rsync -azvhP --include '*/' --include '*.ANS' --exclude '*' rsync://16colo.rs/pack/1996 ""$ANSI_MOTD_ART_DIR""
```

#### artscene.textfiles.com

Find a pack you like at [artscene](http://artscene.textfiles.com/artpacks/) and unpack it into the ansi motd config directory

You can do this by

##### Using the plugins helper function
Use [ansi_art_download](https://github.com/yuhonas/zsh-ansimotd/blob/main/zsh-ansimotd.plugin.zsh#L15) to download all zip files of ansi art from a url and unpack them into the ansi motd config directory (this can take a while depending on the amount of ansi art contained in that year)

eg. to download all ansi art from `1996` from the url http://artscene.textfiles.com/artpacks/1996/ run the following in your shell

```
ansi_art_download http://artscene.textfiles.com/artpacks/1996/
```

#### Manually

Copy any `.ans`, `.img` or `.asc` files containg ansi art into your `ANSI_MOTD_ART_DIR` directory which is derived from `${XDG_CONFIG_HOME:-$HOME/.config}/ansimotd` (the plugin performs a recursive search for art so any directory nesting is fine)

### Configuration / Settings

The plugin exports the following useful variables to the session

* `ANSI_MOTD_ART_DIR`  - the full path to the config directory where the plugin will search for ansi art
* `ANSI_MOTD_FILENAME` - the full file path to the last shown peice of ansi art, if you want to do something with it, laud over it, delete it etc

There's also a handful of ENV variables you can use to configure the plugin (these will need to be set prior to plugin instantiation)

#### The real BBS experience

To buffer the ansi art output at a fixed speed you can set the `ANSI_MOTD_RATE_LIMIT_OUTPUT` ENV variable

eg. to limit the ansi art rendering rate to a data rate of 8k
```
export ANSI_MOTD_RATE_LIMIT_OUTPUT=""8k""
```

See also [Pull Request #10](https://github.com/yuhonas/zsh-ansimotd/pull/10#pullrequestreview-1407110513) to see it in action

#### Small screens
If you happen to be running on a small fixed screen perhaps on something like [termux](https://termux.dev/en/) you can set the following ENV variable to truncate the art to screen width

```
export ANSI_MOTD_DISABLE_LINE_WRAPPING=1
```

See also [Pull Request #6](https://github.com/yuhonas/zsh-ansimotd/pull/6)


### Note
Art to be displayed is assumed to use the [Code Page 437]( https://en.wikipedia.org/wiki/Code_page_437 ) character set


### License

This project is licensed under the [ MIT ](./LICENSE) license

### Contributors

<a href=""https://github.com/yuhonas/zsh-ansimotd/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=yuhonas/zsh-ansimotd"" />
</a>

Made with [contrib.rocks](https://contrib.rocks).

### Special Thanks 🙇

* To [romkatv](https://www.reddit.com/r/zsh/comments/12ueb6b/comment/jhmlgez/?utm_source=share&utm_medium=web2x&context=3) for posting a fix for the word wrapping issue on narrow terminals
* To [mainsm](https://github.com/yuhonas/zsh-ansimotd/issues/5#issue-1683181011) for posting 👆 as an issue in the repo
",42,42,1,0,art,"[art, ascii-art, bbs, oldschool, ricing, shell, zsh, zsh-plugin]",0
jogboms,rijksbook,,https://github.com/jogboms/rijksbook,https://api.github.com/repos/rijksbook/jogboms,🖼 A basic Flutter app built for educational purposes,"# rijksbook

![Format, Analyze and Test](https://github.com/jogboms/rijksbook/workflows/Format,%20Analyze%20and%20Test/badge.svg?branch=master) [![codecov](https://codecov.io/gh/jogboms/rijksbook/branch/master/graph/badge.svg)](https://codecov.io/gh/jogboms/rijksbook)

A new Flutter project.

## Getting Started

After cloning, 

```bash
flutter pub get 
flutter packages pub run build_runner build --delete-conflicting-outputs
```

To run in demo mode,

```bash
flutter run --dart-define=demo-mode=true
```

## UI Shots

<div style=""text-align: center"">
  <table>
    <tr>
      <td style=""text-align: center"">
        <img src=""./screenshots/01.png"" width=""200"" />
      </td>
      <td style=""text-align: center"">
        <img src=""./screenshots/02.png"" width=""200"" />
      </td>
      <td style=""text-align: center"">
        <img src=""./screenshots/03.png"" width=""200"" />
      </td>
      <td style=""text-align: center"">
        <img src=""./screenshots/04.png"" width=""200"" />
      </td>
      <td style=""text-align: center"">
        <img src=""./screenshots/05.png"" width=""200"" />
      </td>
    </tr>
  </table>
</div>

This project is a starting point for a Flutter application.

A few resources to get you started if this is your first Flutter project:

- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)
- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)

For help getting started with Flutter, view our
[online documentation](https://flutter.dev/docs), which offers tutorials,
samples, guidance on mobile development, and a full API reference.
",39,39,4,0,art,"[art, dart, dartlang, flutter, flutter-apps, flutter-demo, flutter-examples, museum]",0
monitoringartist,grafana-monitoring-art,monitoringartist,https://github.com/monitoringartist/grafana-monitoring-art,https://api.github.com/repos/grafana-monitoring-art/monitoringartist,Grafana Monitoring Art datasource,"[<img src=""https://monitoringartist.github.io/managed-by-monitoringartist.png"" alt=""Managed by Monitoring Artist: DevOps / Docker / Kubernetes / AWS ECS / Zabbix / Zenoss / Terraform / Monitoring"" align=""right""/>](http://www.monitoringartist.com 'DevOps / Docker / Kubernetes / AWS ECS / Zabbix / Zenoss / Terraform / Monitoring')

# Grafana Monitoring Art Datasource

[![Public snapshot live](https://img.shields.io/badge/Public%20snapshot-ready-brightgreen.svg)](https://snapshot.raintank.io/dashboard/snapshot/Taz80xbYsIawWOsYqzOs7IJI24OOruec) Please add your GitHub star ★, it will encourage us to publish more Monitoring Art dashboards.

Add some art into your Grafana. Real metrics. No dependency, no waiting for data
collection. Just install, import dashboard(s) and enjoy it immediately. Visit
plugin presentation microsite [www.monitoringart.com](http://www.monitoringart.com).

## Dashboards

[![Monitoring Art - Monitoring Artist Logo](https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/src/img/doc/grafana-monitoring-art-monitoring-artist-logo.png)](https://github.com/monitoringartist/grafana-monitoring-art/tree/master/dashboards)

[![Monitoring Art - Grafana Logo](https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/src/img/doc/grafana-monitoring-art-grafana-logo.png)](https://github.com/monitoringartist/grafana-monitoring-art/tree/master/dashboards)

[![Monitoring Art - Zabbix Logo](https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/src/img/doc/grafana-monitoring-art-zabbix-logo.png)](https://github.com/monitoringartist/grafana-monitoring-art/tree/master/dashboards)

[![Monitoring Art - World](https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/src/img/doc/grafana-monitoring-art-world.png)](https://github.com/monitoringartist/grafana-monitoring-art/tree/master/dashboards)

## Installation

Use the grafana-cli tool to install Monitoring Art from the commandline:

```
grafana-cli plugins install grafana-monitoring-art
```

The plugin will be installed into your grafana plugins directory; the default is
`/var/lib/grafana/plugins`.

Note: Grafana 3.0 or greater is required to install and use plugins.

## Configuration

No configuration. Just add the datasource and then import dashboard(s).

![Monitoring Art - datasource configuration](https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/datasource-configuration.png)

## How is it possible

Get right metric values. Build stacked graph, tweak colors and metric order/lines
filling. For example how to visualize the square:

<img src=""https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/howto1.png"" align=""left"" height=""125""/>
<img src=""https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/howto2.png"" align=""left"" height=""125""/>
<img src=""https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/howto3.png"" align=""left"" height=""125""/>
<img src=""https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/howto4.png"" align=""left"" height=""125""/>
<img src=""https://raw.githubusercontent.com/monitoringartist/grafana-monitoring-art/master/doc/howto5.png"" height=""125""/>

Do you want Monitoring Art with your logo? Not a problem. Contact author and buy
your customized Monitoring Art.

# Contribution

Feel free to create pull request to improve datasource/datasets quality.

## Author

[Devops Monitoring Expert](http://www.jangaraj.com 'DevOps / Docker / Kubernetes / AWS ECS / Google GCP / Zabbix / Zenoss / Terraform / Monitoring'),
who loves monitoring systems and cutting/bleeding edge technologies: Docker,
Kubernetes, ECS, AWS, Google GCP, Terraform, Lambda, Zabbix, Grafana, Elasticsearch,
Kibana, Prometheus, Sysdig, ...

Summary:
* 1000+ [GitHub](https://github.com/monitoringartist/) stars
* 6000+ [Grafana dashboard](https://grafana.net/monitoringartist) downloads
* 800 000+ [Docker image](https://hub.docker.com/u/monitoringartist/) pulls

Professional devops / monitoring / consulting services:

[![Monitoring Artist](http://monitoringartist.com/img/github-monitoring-artist-logo.jpg)](http://www.monitoringartist.com 'DevOps / Docker / Kubernetes / AWS ECS / Google GCP / Zabbix / Zenoss / Terraform / Monitoring')
",38,38,7,2,art,"[art, dashboard, devops, grafana, monitoring]",0
nowaythisworks,Infinite-Art-Gallery,,https://github.com/nowaythisworks/Infinite-Art-Gallery,https://api.github.com/repos/Infinite-Art-Gallery/nowaythisworks,3D Infinite Art Gallery! This pulls from Reddit's r/Art and creates a procedural infinite art gallery from random (sfw-only) posts.,"# Infinite-Art-Gallery
### [Click for Demo!](https://infinite-art-gallery.brazil-0034.repl.co/)
3D Infinite Procedurally-Generated Art Gallery! This pulls from Reddit's r/Art and creates a procedural infinite art gallery from random (sfw-only) posts.

Rendered entirely with THREE.JS in the browser. (May) require a server couterpart to host and filter posts from the Reddit, Harvard Art Museum, and Met APIs.

## How It Works
- First, a world is created (using a ceiling and a floor tile) using a Minecraft-style chunk system. This way, the world will traverse (mostly) infinitely no matter what direction you move in.
- Then, we use a middleman server to send random images from Reddit's art-related subreddits to the client. This can be intensive and the server is prone to crashing when there are too many people, so if there's any better solutions please contribute or post in the issues tab :))
- We generate the images randomly 30 meters in front of the player. There is a 10% chance every second for an image to generate, and once it is generated, there is a mandated cooldown of ~~10~~ 5 seconds.

## TODO
- ~~Proper Crediting - right now, the server will etch the artist's name onto the image file. This is both hard to read and computationally intensive (and possibly a licensing violation in some cases?), so maybe a plaque with the author and title could be better. Unfortunately, Reddit's API is prone to many (many) issues and we can't just direct-link the image without the middleman server.~~ Done!
- VR Support. Some nice people online told me this would work really well in VR. Lucky I have a rift lying around to test the idea with!
- ~~Walls. Add some excitement to walking! Place art in frames on walls, above plaques with information about them.~~ Done!
- ~~Server rewrite. Currently it's very slow and running on a machine less powerful than a raspberry pi, haha.~~ Done!
- 3D Art: Sculptures section! Single-colored 3d models in their own exhibits.
- Art Submissions. Maybe people could manually submit their own art?
- Classical Art. The Harvard Art Museum and The Met offer open-sourced APIs for serving classical images. This kind of goes against the point of the project though, which is to showcase art made by people like you and me - not classical artists. This one needs some discussion!
- ~~Mobile Phone Support!!!!!!! (figure out how to do controls on a phone)~~ **Done! This one was really hard. Thanks to [@mese79's repo](https://github.com/mese79/TouchControls) for help.**
- ~~Firefox Support~~ Done!
- ~~Mouse Direction Reversal~~ Done!

![front board and tutorial](https://user-images.githubusercontent.com/66288732/185100953-3f2e287d-b06c-4140-a500-f01a32982888.png)
![walls and art](https://user-images.githubusercontent.com/66288732/187042850-a3ef3008-098c-4543-9894-c5d45ed2a533.png)

",38,38,2,1,art,"[art, procedural-generation, three-js]",0
elementh,random_color,,https://github.com/elementh/random_color,https://api.github.com/repos/random_color/elementh,⚙️🎨 Rust crate for generating random attractive colors ,"# random_color

[![crate badge](https://img.shields.io/crates/v/random_color.svg)](https://crates.io/crates/random_color)

Rust crate for generating random attractive colors. Check it out on [crates.io](https://crates.io/crates/random_color).

Inspired by [RandomColor](https://github.com/davidmerfield/randomColor) by [davidmerfield](https://github.com/davidmerfield).

## Example projects

Amazing rust projects using `random_color`:

> [cargo-trend](https://github.com/dalance/cargo-trend) —
> cargo subcommand to generate trend graph of dependent crates

> [light_phylogeny](https://github.com/simonpenel/light_phylogeny) —
> rust library dedicated to phylogeny

> [Voronoi](https://github.com/HactarCE/Voronoi) —
> simple program that draws Voronoi cells for a set of points

> [conways-game-of-life](https://github.com/eval-exec/conways-game-of-life) —
> conways' game of life in rust and with shiny colors

> [graph-sketchpad](https://github.com/dcheatha/graph-sketchpad) —
> program which allows one to visually create nodes and edges, simply using sdl2

> [CDCS](https://github.com/salmmanfred/CDCS) —
> helper program for creating Symphony of Empires mods



## Using the library

Check the online [documentation](https://docs.rs/random_color/latest/random_color/).

```rust
use random_color::{Color, Luminosity, RandomColor};

let color = RandomColor::new()
  .hue(Color::Blue) // Optional
  .luminosity(Luminosity::Light) // Optional
  .seed(42) // Optional
  .alpha(1.0) // Optional
  .to_hsl_string(); // 

// color => ""hsl(179, 99%, 10%)""
```

### Hue values

+ `Color::Monochrome`
+ `Color::Red`
+ `Color::Orange`
+ `Color::Yellow`
+ `Color::Green`
+ `Color::Blue`
+ `Color::Purple`
+ `Color::Pink`

### Luminosity values

+ `Luminosity::Random`
+ `Luminosity::Bright`
+ `Luminosity::Light`
+ `Luminosity::Dark`

### Alpha values

+ You can specify a value between 0 and 1 with `.alpha()`
+ You can specify a random value with `.random_alpha()`
  
### Outputs

```rust
  // As HSV Array
  let color = RandomColor::new().to_hsv_array(); // color => [179, 20, 100]

  // As RGB String
  let color = RandomColor::new().to_rgb_string(); // color => ""rgb(204, 255, 254)""

  // As RGBA String
  let color = RandomColor::new().to_rgba_string(); // color => ""rgba(204, 255, 254, 1)""

  // As RGB Array
  let color = RandomColor::new().to_rgb_array(); // color => [204, 255, 254]

  // As HSL String
  let color = RandomColor::new().to_hsl_string(); // color => ""hsl(179, 99%, 10%)""

  // As HSLA String
  let color = RandomColor::new().to_hsla_string(); // color => ""hsl(179, 99%, 10%, 1)""

  // As HSL Array
  let color = RandomColor::new().to_hsl_array(); // color => [179, 99, 10]
  
  // As Hex String
  let color = RandomColor::new().to_hex(); // color => ""#b31464""
```

## Roadmap

+ Iteartor
+ Documentation

## License

The MIT License (MIT)

Copyright (c) 2017 [Lucas Maximiliano Marino](https://lucasmarino.me)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
",37,37,3,2,art,"[art, colors, random, rgb, rust, rust-crate]",0
brangerbriz,messages-from-the-mines,brangerbriz,https://github.com/brangerbriz/messages-from-the-mines,https://api.github.com/repos/messages-from-the-mines/brangerbriz,An interactive art installation that excavates messages embedded in the Bitcoin blockchain,"# Messages from the Mines

![Messages from the Mines Screenshot](.images/screenshot.png)

*Messages from the Mines* is an interactive art installation that excavates and interprets custom messages embedded in the Bitcoin blockchain. The distributed ledger contains hidden love messages, cryptic poems, ASCII art, signatures, eulogies and more. These messages are a creative misuse of the Bitcoin transaction protocol, a form of digital graffiti, unique—though overlooked—cultural artifacts forever embedded in one of the most contemporary digital technologies. 

Our project looks at the Bitcoin blockchain not from the traditional perspective of investors or programmers, but rather from a cultural perspective. We've built a system for extracting, archiving, researching, interpreting and annotating the messages left behind and document the evolution of this creative re-purposing of the blockchain. We approach this task not only as artists but also as anthropologists conducting contemporary media archeology; we seek an anthropological understanding of this phenomenon. Who are leaving these messages? What are their motivations and sentiments? What forms of anonymous communication occur on the ledger?

For more information about about the project, see [this large poster](.images/banner.png). 

## Docker Install

The web version of this project can be installed via Docker using the `web-docker` branch by following the instructions below.

```bash
git clone https://github.com/brangerbriz/messages-from-the-mines
cd messages-from-the-mines
git checkout web-docker
git submodule update --init --recursive

# open .env in a text editor and create and add a password for
# BASIC_AUTH_PASSWORD and MYSQL_ROOT_PASSWORD
nano .env

# launch the nginx http proxy running on port 80. We'll need this to get
# an HTTPS certificate.
docker-compose up -d http-proxy

# create an HTTPS/SSL/TLS certificate with Let's Encrypt
DOMAIN=example.org EMAIL=email@example.org ./scripts/create_cert.sh

# if this errors with ""ERROR: No containers to restart"", that's fine
DOMAIN=example.org DOCKER_USER=$USER ./scripts/reload_cert.sh

docker-compose up -d

# enter the password value you just created for MYSQL_ROOT_PASSWORD in .env when prompted
docker-compose exec db sh -c ""mysql -u root -p < /latest-web.sql && rm /latest-web.sql""
```

```bash
# add a root cronjob
sudo crontab -e 

# past these contents (and replace the placeholder vars). 
# Each day at 7PM attempt to renew the HTTPS certificate and reboot the node server
0 19 * * * ./scripts/renew_cert.sh && DOMAIN=example.org DOCKER_USER=example-user ./scripts/reload_cert.sh
```

## Manual Install

This repository is comprised entirely of git submodules of other repositories. 

- `mftm-backend`: The Node.js backend server that hosts our frontend, REST API, and our internal message review tool.
- `mftm-frontend` (located in `mftm-backend/www/mftm-frontend`): The UI for exploring the blockchain messages (pictured above).
- `mftm-database`: Python code for extracting messages from the blockchain (using `bitcoind`'s `.dat` files) and constructing the MySQL database used by `mftm-backend`. 

```bash
# clone this repo
git clone https://github.com/brangerbriz/messages-from-the-mines
cd messages-from-the-mines

# if you are on this branch we assume you want to install the web version
# of the project (not the physical installation version).
git checkout -b web
git pull origin web

# recursively init and download the submodules
git submodule update --init --recursive --remote

# you will notice that there are 4 submodules, two in the parent
# repo, each that contains one additional submodule.
git submodule status --recursive
```

These install instructions are for Ubuntu 16.04. Other OSes may work but are not officially supported: here be dragons.

### Setting up the MySQL Database

```bash
# install mysql and optional GUI helpers
sudo apt update
sudo apt install mysql-server mysql-workbench
```

Now download the latest `messages_from_the_mines` database backup from [here (direct download)](https://github.com/brangerbriz/mftm-database/releases/download/data/latest.sql.gz). Unzip that file and you should get an `.sql` file like `2018-04-18.sql`.

```bash
# download the latest version of the database
curl -L https://github.com/brangerbriz/mftm-database/releases/download/data/latest.sql.gz > latest.sql.gz

# unzip it
gunzip latest.sql.gz

# import the database backup (be sure to use the correct path to your database file)
# this will create a new Database schema called messages_from_the_mines
mysql -u root -p < latest.sql
```

You may optionally create a new MySQL user to interface with the `messages_from_the_mines` database only. This is probably a good idea, as you have to save your database username/password in plaintext in `mftm-backend/config.json` and `mftm-database/config.json` (if actually want to parse the blockchain from this computer). This process is trivial using MySQL Workbench. Just be sure that your new user has full access permissions to the `messages_from_the_mines` database schema.

### Setting up the `mftm-backend` Node.js server

Once you've configured the MySQL database, detailed instructions to setup the backend server can be found in the [`mftm-backend/README.md`](https://github.com/brangerbriz/mftm-backend) file. You should now follow those instructions before returning here.

## Run

### The backend

In one terminal, run:

```
# start the bitcoin daemon
cd mftm-backend
./start_bitcoind.sh
```

In another terminal run:

```
# still inside mftm-backend
node server
```

### The Frontend/UI

So, this really isn't the most elegant solution... but it's the one we are supporting as of right now. Because of an HTTP (not HTTPS) call that we have to make to use the ipstack geo-ip API, browsers throw a ""Mixed Content"" error if loaded over HTTPS. We built the whole thing to run on HTTPS (w/ basic auth and everyting) and to run it via HTTP would cause some security concerns, as people could read the contents of our `mftm-backend/www/auth.js` file. For now, our solution is to open `mftm-backend/www/mftm-frontend/index.html` in Firefox using `file://` and NOT serve the UI.

```
# from inside this repo's root

# copy the auth.js file to where Nick originally expected it to
# be while he was dev'n
cp mftm-backend/www/auth.js mftm-backend/www/mftm-frontend/js/auth.js

firefox mftm-backend/www/mftm-frontend/index.html
```

Sorry folks, that's just the way it goes sometimes.

## More Info

![Messages from the Mines Banner/Poster](.images/banner.png)
",36,36,9,2,art,"[archaeology, archive, art, bitcoin, interactive-art]",0
2KAbhishek,polyquine,,https://github.com/2KAbhishek/polyquine,https://api.github.com/repos/polyquine/2KAbhishek,"source = output, in five languages 🎨🃏","<div align = ""center"">

<h1><a href=""https://2kabhishek.github.io/polyquine"">polyquine</a></h1>

<a href=""https://github.com/2KAbhishek/polyquine/blob/main/LICENSE"">
<img alt=""License"" src=""https://img.shields.io/github/license/2kabhishek/polyquine?style=flat&color=eee&label=""> </a>

<a href=""https://github.com/2KAbhishek/polyquine/graphs/contributors"">
<img alt=""People"" src=""https://img.shields.io/github/contributors/2kabhishek/polyquine?style=flat&color=ffaaf2&label=People""> </a>

<a href=""https://github.com/2KAbhishek/polyquine/stargazers"">
<img alt=""Stars"" src=""https://img.shields.io/github/stars/2kabhishek/polyquine?style=flat&color=98c379&label=Stars""></a>

<a href=""https://github.com/2KAbhishek/polyquine/network/members"">
<img alt=""Forks"" src=""https://img.shields.io/github/forks/2kabhishek/polyquine?style=flat&color=66a8e0&label=Forks""> </a>

<a href=""https://github.com/2KAbhishek/polyquine/watchers"">
<img alt=""Watches"" src=""https://img.shields.io/github/watchers/2kabhishek/polyquine?style=flat&color=f5d08b&label=Watches""> </a>

<a href=""https://github.com/2KAbhishek/polyquine/pulse"">
<img alt=""Last Updated"" src=""https://img.shields.io/github/last-commit/2kabhishek/polyquine?style=flat&color=e06c75&label=""> </a>

</div>

A quine is a computer programming that prints its own source code when executed.

A polyquine does the same thing for multiple programming languages.

This repo contains such a polyquine written in `C`, `Perl`, `PHP`, `Python` and `Ruby`.

## Prerequisites

Before you begin, ensure you have met the following requirements:

- You have installed the latest version of `gcc`, `perl`, `php`, `python` and `ruby`.

## Getting polyquine

To get polyquine, follow these steps:

```bash
git clone https://github.com/2kabhishek/polyquine
cd polyquine
```

## Running polyquine

```bash
# For C
gcc polyquine.c
./a.out

# For perl
perl polyquine.pl

# For PHP
php polyquine.php

# For Python
python polyquine.py

# For Ruby
ruby polyquine.rb

```

Hit the :star: button if you found this useful.

### More Info
",36,36,2,0,art,"[art, c, javascript, languages, perl, php, polyquine, programming-language, programming-languages, python, quine, ruby]",0
undertherain,pycontextfree,,https://github.com/undertherain/pycontextfree,https://api.github.com/repos/pycontextfree/undertherain,Pythonic generative art tool,,35,35,3,2,art,"[art, fractal, generative-art]",0
soliblue,songGPT,,https://github.com/soliblue/songGPT,https://api.github.com/repos/songGPT/soliblue,"songGPT is an experimental open-source project that explores the potential of Language Models, specifically ChatGPT, in generating original and customizable musical compositions. Using Python, the output is automatically converted to MIDI and audio files, enabling users to create unique and diverse music pieces.",,34,34,2,0,art,"[aimusic, art, artificial-intelligence, chatgpt, chatgpt-api, large-language-models, llms, machine-learning, music, open-source, openai]",0
knupel,ROMANESCO-Processing,,https://github.com/knupel/ROMANESCO-Processing,https://api.github.com/repos/ROMANESCO-Processing/knupel,Generative Live Art Application - built with Processing,"## Romanesco dui 
v 2.2.0.34 – 2011-2021

Generative Live Art Application – Build with Processing 4 

## What is it ?
Romanesco is a Free and Open Source Software coded with Processing | FOSS.
I lead and code this project from many years on my freetime. Ths app have for purpose to make a realtime performance.
It makes it possible to select algorithmic shapes - items - in the library and modify them with different controllers – user interface, Midi controller, sound – and move them in a three dimensional world with the help of different kinds of devices – mouse, leapmotion and pen.

## Where Romanesco from...
The main source of this project is my desire to make live motion picture like the musician play music in band and play with them too!!! The second source of inspiration is my passion to the science and the nature and the various things that constitute it. And the third my love for the creative coding.

![romanesco dui](https://github.com/StanLepunK/ROMANESCO-Processing/blob/master/import_github_pic/Romaneco_soft_32_18_11_5.jpg)

### Download build version
To download the last built version, go to [app 2.0.1.32](http://romanescoproject.wordpress.com/download/)

## Build and code Romanesco
read the developement guide [here](https://github.com/StanLepunK/ROMANESCO-Processing/wiki)

## rope library
to use the set rope method you need to downlow Rope library
[download](https://github.com/StanLepunK/Rope/blob/master/build_rope/Rope.zip)

## LICENSE
ROMANESCO is under the licence [CeCILL](http://www.cecill.info/licences/Licence_CeCILL_V2.1-en.html).

Romanesco is a FOSS / Free and Open Source Software

For commercial use, [making a donation can be good](http://romanescoproject.wordpress.com/download/) to support the project !

ROMANESCO 2011-2021
",30,30,3,18,art,"[3d-engine, app, art, live, performance, processing, visual, vjing]",0
JiQiYiShu,Guohua,JiQiYiShu,https://github.com/JiQiYiShu/Guohua,https://api.github.com/repos/Guohua/JiQiYiShu,"Guohua: Traditional Chinese painting,  Landscape painting flower & bird painting","# Guohua 国画
Guohua: Traditional Chinese painting,  Landscape painting flower &amp; bird painting

首期：国画（山水画 & 花鸟画）

<a href='https://www.JiQiYiShu.com'>机器艺术</a>出品

### 1.定位: 
机器艺术：探索人工智能艺术与设计，展现中国元素

### 2.为什么做这个：
随着人工智能的发展，艺术结合的领域效果越来越好，应用场景丰富；但缺乏结合中国元素的应用

### 3.怎么做的：
原理：使用对抗生成网络，结合最新的技术，采用少量样本训练得到国画-山水画。

基于强大的高清人脸预训练模型，在16G GPU单卡上训练，使用自适应数据增强的StyleGan2-ada网络, 在1700张山水画上训练12个小时、3000张花鸟画训练30个小时得到。

### 4. 现在有什么？
一期国画，已经覆盖国画中的重点题材：山水画、花鸟画。

### 5.效果图
##### 5.1 生成的山水画效果图(多图、单图)

##### 多图效果：

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-ss-duotu-001-watered1.jpg""  width=""65%"" height=""65%"" />


##### 单图：

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-ss-73.jpg""  width=""65%"" height=""65%"" />

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-ss-16.jpg""  width=""65%"" height=""65%"" />


##### 5.2 生成的花鸟画效果图(多图、单图)

##### 多图：

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-fb-duotu-0011.jpg""  width=""65%"" height=""65%"" />

##### 单图：

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-fb-45.jpg""  width=""65%"" height=""65%"" />

<img src=""https://github.com/JiQiYiShu/Guohua/blob/main/resources/images/jqys-fb-56.jpg""  width=""65%"" height=""65%"" />


### 5.团队：机器艺术社区(JiQiYiShu)  |  About Team
机器艺术社是开源协助组织，由国内外AI产业界和学术界同仁共同发起，探索人工智能艺术与设计，并展现中国元素。


### 6.目前还有什么问题或课题  | Current Question and Research Topic
国画中的中文，目前生成的比较抽象，并不是具体的中文；
生成国画过程中，不仅生成高清晰艺术画，而且结合图像意境、带书法图字描述，是一个研究课题。


### 7.社区 | Community 
机器艺术社区，目前处于创始阶段，现招募创始会员。
有意探索机器艺术或对此项目感兴趣的朋友，请发送邮件联系: contact@JiQiYiShu.com

### 8.后续 | Release Plan
机器艺术社区，在2021年10月1号之前，将推出5-10个带有中国元素并结合最新AI技术的高质量的应用案例或场景，以及一些相关研究课题和发布相关论文。

### 9.网址 | Website
www.JiQiYiShu.com

### 10.机器艺术.国画数据集下载  | Downloads Images from JiQiYiShu
各约100幅

<a href='https://storage.googleapis.com/jiqiyishu/datasets/JiQiYiShu-HuaNiao100.zip'>机器艺术-山水画 下载</a>

<a href='https://storage.googleapis.com/jiqiyishu/datasets/JiQiYiShu-HuaNiao100.zip'>机器艺术-花鸟画下载</a> 


###  参考 Reference 
1.模型，StyleGan2：https://github.com/NVlabs/stylegan2

2.高清人脸数据集，Flickr-Faces-HQ Dataset (FFHQ), https://github.com/NVlabs/ffhq-dataset


",30,30,4,1,art,"[ai, art, bird, flower, landscape, painting, style-generation, stylegan, stylegan2, stylegan2-ada, traditional-chinese-painting]",0
birdneststream,asciibird,,https://github.com/birdneststream/asciibird,https://api.github.com/repos/asciibird/birdneststream,ASCII Creation,"# ASCIIBIRD - The Worlds Best IRC ASCII Art Editor

ASCIIBIRD is an IRC ascii art editor to create or edit mIRC art, it is most times worked on during live stream. It's 100% client side and created in vue2 and may be migrated to vue3 in the future.

A most latest production build to use is available at https://asciibird.birdnest.live/ - create cool and fun IRC ascii arts for your ircd MOTD or to share with your chat friends and have a good time!

Support ASCIIBIRD and birdnest streaming by [jumping on our patreon](https://www.patreon.com/birdnestshow)!

To view in detailed help and documentation please see [Help and Documentation](HELP.md)

- [ASCIIBIRD - The Worlds Best IRC ASCII Art Editor](#asciibird---the-worlds-best-irc-ascii-art-editor)
- [Big Shout outs to Patrons](#big-shout-outs-to-patrons)
- [Feature Overview](#feature-overview)
- [Roadmap and Known Bugs](#roadmap-and-known-bugs)
  - [To Be Developed](#to-be-developed)
  - [Known Bugs](#known-bugs)
  - [Mobile / Touch Screen support](#mobile--touch-screen-support)
- [What Chatters are saying about ASCIIBIRD](#what-chatters-are-saying-about-asciibird)
- [ASCII art created with ASCIIBIRD](#ascii-art-created-with-asciibird)
- [References](#references)
- [ASCII Resources](#ascii-resources)
  - [Hello to friends on the IRC](#hello-to-friends-on-the-irc)
- [Project setup](#project-setup)
  - [Compiles and hot-reloads for development](#compiles-and-hot-reloads-for-development)
  - [Compiles and minifies for production](#compiles-and-minifies-for-production)
  - [Lints and fixes files](#lints-and-fixes-files)
  - [Customize configuration](#customize-configuration)


# Big Shout outs to Patrons

> xartet, OfMonsters&Crime, mouse, funkpower, Charles, PP4L, octopus, slime, dingopride, skg, eraser, chzz, L0j1k, deakin

> special thanks to slime aka botmaster slime for the wonderful bot integration with asciibird

# Feature Overview

* Tabbed ASCII editing
* Layers support
  * Show and hide layers
  * Change layer order
  * Double click to rename layer
  * Context menu for layers
* Copy and paste ASCII blocks between tabs with the select tool
* Remembers state on refresh and when the browser loads, can also export the state to a file and load elsewhere.
  * So you never lose your ascii art!
  * Saves layers, brushes data also to same file
* Can import from clipboard, load from irc or the web, load from file
* Can export mirc ascii to clipboard, file or HTTP POST
* 99 Colour support
* Swap fg and bg colours with button click or Alt + r
* Mirror X and Y
* Grid mode with Alt + g
* Undo and redo with Ctrl + z and Ctrl + y, can specify undo limit in options.
* Fg, Bg and Char boxes to filter when using certain tools
  * For example filling with Char unchecked will ignore characters when filling
  * If you want to remove the background but keep the text, uncheck FG and Char and eraser the bg only.
* Image overlay to trace images
  * Accepts URLs only at the moment
  * Can adjust the size and properties
* Toolbar containing
  * Select, to copy, paste and save blocks as brushes
  * Text mode, with arrow key support
  * Fill background blocks
  * Brush mode, can be controlled with keyboard and mouse
  * Block picker (grab fg, bg and char of a block)
  * Eraser - remove blocks, can be controlled with keyboard and mouse
  * Fill Eraser - Fill remove blocks by bg, fg or char
* Brush Library and History
  * Make circle, square, cross and other brushes by sizes
  * Brush history, can save or re-use old brushes
  * Library - Save most used brushes to library
  * Brush history is set to a limit of 50, can be changed in options.
* Brush Preview
  * Editable brush preview
  * Can use the brush tool inside the brush preview
  * Can use the eraser tool inside the brush preview
  * Hovering outside brush area will save brush to history
* Context menu available on all brushes preview areas
  * Export any brush to PNG, mIRC clipboard or file by right clicking the brush preview
* Half block editing mode
  * Supports brush only, experimental feature

# Roadmap and Known Bugs

In no particular order, future development goals and bug fixes.

## To Be Developed

* History of colour changes
* Easier to cycle through brush history
* Half block editing mode, make own half block brush
* SVG export
* Export options for colour codes. C,00 or C0,00
* SHADING mode, draw shading chars with brush (pressure.js maybe)
* Resize canvas undo
* Unit testing (hahaha)
* More tooltips on other parts, at the moment only Toolbar has tooltips, option to disable tooltips
* Review encodings check on file import - UTF8 vs Latin something
* More fill tool options? (search / replace, new check boxes to replace what contents)
* Dark / light modes, different themes
* Expand the brush manager, brush categories, download brushes, import/export brushes
* ASCIIBIRD API ?! - Web api to extend features of asciibird

## Known Bugs

* If you hide layers it wont select the next best visible layer
* Importing a half block with continued background will persist the background
* Clear the URL after GET file import
* Bug with hotkey brush switching, if make a new ascii hotkeys are broke - something to do with the hotkey function
* If you drag a panel, then right click you can't drag it anymore
 * Sometimes panels can get stuck
* FLOOD FILL - For now the older recursive function is there, but will hit the recursion limit on larger ASCIIs.
* Editing ascii does not update title
* Fix brush tool for seamless lines when drawing fast
* Context menus inside the panels can be way off sometimes
* The context menu for the background doesn't work when scrolled down
* Brush blocks larger than 1x1 can leave undoable blocks in mirror mode
  
## Mobile / Touch Screen support

Doesn't exist at the moment. While the underlying functions and code is compatible with mobile browsers from *babel*, the touch canvas events and text will need to be reviewed to work better with touch screens. For example while you can brush once, you cannot move the brush around.

# What Chatters are saying about ASCIIBIRD

```
<ralph> ascii bird is so easy a drunk LQ chatter like myself can use, and does use it
<ralph> asciibird is to chatters what the ak-47 is to kids in Sierra Leone
<ralph> POWERFUL STUF
```

```
<kayos> man asciibird is legit revolutionary shit
<kayos> shouts birds 
```

```
<chunky> asciibird is the best get high all the time
```

```
<totally_real_nick> asciibird made me quit my job leave my wife an kids and realize my true calling as a groupie furry lot lizard at vocaloid hologram anime concerts. now i go on tour and my life has never been more full of yiffing. thanks asciibird!
```

```
<mr-spambot> fuck slime lion
<mr-spambot> i had no owldea howl good dat editor was
<mr-spambot> like u can drowl on two fuckin sides at once
<mr-spambot> it is the vim of head art
<sansGato> its cool dat asciibird u can just do like half the picture because u have that mirror thing
<sansGato> its fuckin owlsome
<sansGato> It was like I was using nanowl the whole time, i find asciibird then I am deep in the head of neowlvim
<sansGato> its like i was using boring i3, and THEN i find asciibird and I am deep in the dwm with st and dmenu !!
<sansGato> dw1 make jbird lion head admin
<sansGato> there i said it
<sansGato> !op slime lion as head admin
```

```
<chzz> asciibird is the therac-25 of ascii editors
```

```
<rebird> <g> im a changed man since ive been using asciibird
<rebird> <g> i hope you are too!
```

```
<higgs> asciibird changed my life.
```

# ASCII art created with ASCIIBIRD

Already there have been hundreds of new mIRC ascii arts created with asciibird! Here are just a few from our pal *chzz*.

![fraidnobully.png](https://asciibird.birdnest.live/docs/fraidnobully.png)
![hoodie.png](https://asciibird.birdnest.live/docs/hoodie.png)
![mediation.png](https://asciibird.birdnest.live/docs/mediation.png)
![bullyfreechat.png](https://asciibird.birdnest.live/docs/bullyfreechat.png)
![midiweekend.png](https://asciibird.birdnest.live/docs/midiweekend.png)
![chzz-dimension-noose.png](https://asciibird.birdnest.live/docs/chzz-dimension-noose.png)

# References

* http://anti.teamidiot.de/static/nei/*/extended_mirc_color_proposal.html - Good for 99 colours info
* https://modern.ircdocs.horse/formatting.html#color - Also really good
* https://www.mirc.com/colors.html - defacto standard for mIRC colours and art
* https://www.oocities.org/spunk1111/history.htm - The history of ASCII art by Joan Stark (jgs) aka spunk

# ASCII Resources

* https://mircart.org/ - IRC ASCII art
* https://asdf.us/asciiblaster/ - Asciiblaster ASCII editor, ASCIIBIRD is loosely based on this
* https://acid.vegas/asciimaker - HTML/JS based ASCII Creator from acidvegas
* https://github.com/ircart/resources - More resources on ASCII and configuring terminals/clients to display ASCII art correctly
* http://wepump.in/ascii/ - Classic IRC ASCII art
* https://irc.watch/ascii/ - IRC ASCIIs you can load into ASCIIBIRD

## Hello to friends on the IRC

> darkmage, l0de, bex, blarf, sludg, shart, chode, corn, ralph, jrra, kuntz, moony, sniff, scd, aztec, astro, anji, b-rex, bengt, butth0le, canada420, clamkin, deakin, dumbguy, ElBurro, interdome, syn, darkness, vae, gowce, moneytree, Retarded, spoon, sylar, zen, bj0rn, stovepipe, morthrane, chrono, acidvegas, again, hgc, durendal, knio, mavericks, pyrex, sh, irie, seirdy, sq, stratum, WeEatnKid, dieforirc, tater, buttvomit, luldangs, MichealK, AnalMan, poccri, vap0r, kakama, fregyXin, kayos, stovepipe, higgs, Audasity, PsyMaster, perplexa, alyosha, Darn, efsenable, EchoShun, dumbguy, HorseCrusherKristian, phobos, COMPUTERS, dave, nance, sthors

# Project setup
```
yarn
```

## Compiles and hot-reloads for development
```
yarn serve
```

## Compiles and minifies for production
```
yarn build
```

## Lints and fixes files
```
yarn lint
```

## Customize configuration
See [Configuration Reference](https://cli.vuejs.org/config/).
",29,29,3,0,art,"[art, ascii, canvas, editor, irc, javascript, mirc]",0
ahil15,Xlicon-v2,,https://github.com/ahil15/Xlicon-v2,https://api.github.com/repos/Xlicon-v2/ahil15,"XLICON-MD, A whatsapp userbot bot recode By Slasher To Build Something amazing with A17","<p align=""center"">
<a href=""https://github.com/ahil15""><img title=""Author"" src=""https://img.shields.io/badge/CREATOR-Nᴏᴛ Sʟᴀꜱʜᴇʀ-black.svg?style=for-the-badge&logo=github""></a>

<p align=""center"">  
  <a href=""https://xliconmd2.vercel.app/"">
    <img alt=""X-2.0"" height=""300"" src=""https://i.ibb.co/gR09dLk/20231002-160957.jpg"">
    <h1 align=""center"">XLICON-BOT 2.O</h1>
  </a>
</p>
<p align=""center"">
<a href=""https://github.com/ahil15""><img title=""Author"" src=""https://img.shields.io/badge/XLICON-BOT-black?style=for-the-badge&logo=twitter""></a>
<p/>
<p align=""center"">
<a href=""https://github.com/ahil15?tab=followers""><img title=""Followers"" src=""https://img.shields.io/github/followers/ahil15?label=Followers&style=social""></a>
<a href=""https://github.com/ahil15/Xlicon-v2/stargazers/""><img title=""Stars"" src=""https://img.shields.io/github/stars/ahil15/Xlicon-v2?&style=social""></a>
<a href=""https://github.com/ahil15/Xlicon-v2/network/members""><img title=""Fork"" src=""https://img.shields.io/github/forks/ahil15/Xlicon-v2?style=social""></a>
<a href=""https://github.com/ahil15/Xlicon-v2/watchers""><img title=""Watching"" src=""https://img.shields.io/github/watchers/ahil15/Xlicon-v2?label=Watching&style=social""></a>
</p>

#### 
If you re-upload  anything from my ***REPOSITORY*** give me ***Credit*** Else I can Take Legal Action On You!⚠

***

#### SETUP

1. Fork the repo
    <br>
<a href=""https://github.com/ahil15/Xlicon-v2/fork""><img title=""XLICON-2.0"" src=""https://img.shields.io/badge/FORK XLICON-2.0-h?color=black&style=for-the-badge&logo=stackshare""></a>

2. Scan the QR and upload the `creds.json` to ***XLICON-SESSION*** Folder
    <br>
<a href='https://replit.com/@ahil15/XLICON-Multi-qr?v=1' target=""_blank""><img alt='SCAN QR-1' src='https://img.shields.io/badge/Scan_qr-1-100000?style=for-the-badge&logo=scan&logoColor=white&labelColor=black&color=blue'/></a>

#### DEPLOY STEPS

1. Fork This Repository 
2. Update [`config.js`]
```js
global.Owner = [""8801853262586""]; 
global.OwnerNumber = [""8801853262586""];
global.ownertag = [""8801853262586""];
global.OwnerName = ""Slasher"";
global.BotName = ""X-2.0"";
```

#### DEPLOY TO HEROKU 

1. If You don't have a account in Heroku. Create a account.
    <br>
<a href='https://signup.heroku.com/' target=""_blank""><img alt='Heroku' src='https://img.shields.io/badge/-Create-black?style=for-the-badge&logo=heroku&logoColor=white'/></a>

2. Now Deploy
    <br>
<a href='https://xlicheroku.vercel.app/deploy.html' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/-DEPLOY-black?style=for-the-badge&logo=heroku&logoColor=white'/></a>

#### DEPLOY TO CODESPACE

3. If You don't have a account in Codespace. Create a account.
    <br>
<a href='https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fcodespaces' target=""_blank""><img alt='Codespaces' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=visualstudiocode' width=""96.35"" height=""28""/></a></p>

4. Now Deploy
    <br>
<a href='https://github.com/codespaces/new' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=visualstudiocode' width=""96.35"" height=""28""/></a></p>

#### DEPLOY TO OKTETO

5. If You don't have a account in Okteto. Create a account.
    <br>
<a href='https://www.okteto.com/pricing/?plan=SaaS' target=""_blank""><img alt='Okteto' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=opera' width=""96.35"" height=""28""/></a></p>

6. Now Deploy
    <br>
<a href='https://xlicheroku.vercel.app/deploy-okt.html' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=opera' width=""96.35"" height=""28""/></a></p>

#### DEPLOY TO RAILWAY

7. If You don't have a account in Railway. Create a account.
    <br>
<a href='https://railway.app/login' target=""_blank""><img alt='Railway' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=railway' width=""96.35"" height=""28""/></a></p>

8. Now Deploy
    <br>
<a href='https://railway.app/new' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=railway' width=""96.35"" height=""28""/></a></p>

#### DEPLOY TO MONGENIUS

9. If You don't have a account in Mongenius. Create a account.
    <br>
<a href='https://studio.mogenius.com/user/registration' target=""_blank""><img alt='Mongenius' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=genius' width=""96.35"" height=""28""/></a></p>

10. Now Deploy
    <br>
<a href='https://railway.app/new' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=genius' width=""96.35"" height=""28""/></a></p>

#### DEPLOY TO COOLIFY

11. If You don't have a account in Coolify. Create a account.
    <br>
<a href='https://app.coolify.io/register' target=""_blank""><img alt='Coolify' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=C' width=""96.35"" height=""28""/></a></p>

12. Now Deploy
    <br>
<a href='https://coolify.io/' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=C' width=""96.35"" height=""28""/></a></p>

#### DEPLOY TO RENDER

13. If You don't have a account in Render. Create a account.
    <br>
<a href='https://dashboard.render.com/register' target=""_blank""><img alt='Render' src='https://img.shields.io/badge/CREATE-h?color=black&style=for-the-badge&logo=render' width=""96.35"" height=""28""/></a></p>

14. Now Deploy
    <br>
<a href='https://dashboard.render.com' target=""_blank""><img alt='DEPLOY' src='https://img.shields.io/badge/DEPLOY -h?color=black&style=for-the-badge&logo=render' width=""96.35"" height=""28""/></a></p>

---
# `Guide`📕

- [Full Deploy Explanation & Termux Deploy & Vps Deploy](https://github.com/ahil15/Xlicon-v2/blob/main/guide.md)
---

## ```Support Me```
<a href='https://www.instagram.com/sla.sher_' target=""_blank""><img alt='Instagram' src='https://img.shields.io/badge/CONTACT-h?color=black&style=for-the-badge&logo=instagram' width=""96.35"" height=""28""/></a></p>
<a href='wa.me/8801975492880' target=""_blank""><img alt='Whatsapp' src='https://img.shields.io/badge/CONTACT-h?color=black&style=for-the-badge&logo=whatsapp' width=""96.35"" height=""28""/></a></p>
<a href='https://chat.whatsapp.com/C4ivwZKuh5bLJkqfYNPQsk' target=""_blank""><img alt='Whatsapp' src='https://img.shields.io/badge/OFFICIAL-GC-h?color=black&style=for-the-badge&logo=whatsapp' width=""96.35"" height=""28""/></a></p>
<a href='https://www.youtube.com/@infinite9452' target=""_blank""><img alt='Youtube' src='https://img.shields.io/badge/SUBSCRIBE-h?color=black&style=for-the-badge&logo=youtube' width=""96.35"" height=""28""/></a></p>
</p>

1. **Buy Me a Coffee**: Your support will help me stay motivated and continue working on exciting projects like this one.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=""https://www.buymeacoffee.com/slashernolongerlive"">
  <img src=""https://i.ibb.co/KNnhcvX/bmc-button.png"" alt=""Buy Me Coffee"" height=""40"" width=""150"" style=""margin-left: 60px;"">
</a>

<h2 align=""center""> Star the repo if u like it🌟
</h2>


 
 ## 🎯 Author 🎯
  <div align=""center"">
  
| [![SlasherOfficial](https://github.com/ahil15.png?size=150)](https://github.com/ahil15) |
|----|
| [ N ᴏ ᴛ   S ʟ ᴀ ꜱ ʜ ᴇ ʀ ](https://github.com/ahil15) |
|  Developer, Bug Fixes, Modules, updates |

  </div>
  
   
  </br> 

<h2 align=""center"">  Reminder
</h2>
   
- This bot is not made by `WhatsApp Inc.` So misusing the bot might `ban` your `WhatsApp account!`(Though your WhatsApp account can be unbanned only once.)
- I am not responsible for banning your account.
- Use at your own risk by keeping this warning in mind.
 
  
  
   ## `Special Thanks To`
- 1. ✨ Kai ( Bot Base )
- 2. ✨ Abhishek ( External Modifications and upgrades )
- 3. ✨ Guru ( Web modification and ideas )
- 4. ✨ Diegoson ( Web Qr design and modification )
- 5. ✨ HYNO ( web bug fixes and maintain )
- 6. ✨ SamPandey ( web Base )
- 7. ✨SuhailTechInfo (menu design idea )
---------


<h1 align=""center"">
</h1>

</p>
<h1 align=""center""> ✧ Thanks To Kai!!!✧
</h1>

---

  
",29,29,1,9,art,"[art, artificial-intelligence, baileys, baileys-md, bot, chatbot, deploy, javascript, md, mongodb, python3, termux-tool, virtualbox, wabot, wabot-md, whatsapp, whatsapp-bot, whatsapp-md-bot, whatsapp-web]",0
kylestew,100DaysOfGenerativeArt,,https://github.com/kylestew/100DaysOfGenerativeArt,https://api.github.com/repos/100DaysOfGenerativeArt/kylestew,My #100DaysOfGenerativeArt personal challenge,"#100DaysOfGenerativeArt
=======================

[OCT 31st 2015 -- APR 18th 2016]
---------------------------

Sparked by the [#The100DayProject](http://thegreatdiscontent.com/100days) post on The Great Discontent, I aim to create 100 pieces of generative art in 100 days. What is generative art? In my case it's the use of code to describe and execute procedural systems out of which complex works of art are generated. This will primarily be done on the [Processing](http://processing.org) platform with some hopeful exploration in Cinema 4D and the integration of various [data sets](https://data.nasa.gov/developer) available on the internet.  

Follow Along
------------
Instagram: [kylestew](https://instagram.com/kylestew/)  
Tumblr: [kyleRstewart](http://kylerstewart.tumblr.com/)
",28,28,4,0,art,"[art, creative-coding, processing]",0
benrutter,house-of-left,,https://github.com/benrutter/house-of-left,https://api.github.com/repos/house-of-left/benrutter,"Generative scripts built using Python Shades, Java Processing, and Sonic Pi","# house of left

## What's this repo?

Heya 👋 I make mostly visual artworks with code.

I'm interested in generative art systems, where based on an input (usually random) the output can vary.

In this repo, you'll find works in progress under ""sketches"" (stuff in here might work, might have errors, and might produce some kind of crazy half finished output) and more complete stuff under ""pieces"".

## Generative readme gallery

This readme is also a self-generating gallery of outputs from everything in the pieces folder. The pieces here will be different each time the readme file is generated.



### the bay
![auto-generated image for below title](gallery/the_bay.png)



### swimming pools
![auto-generated image for below title](gallery/swimming_pools.png)



### riley
![auto-generated image for below title](gallery/riley.png)



### take the a train
![auto-generated image for below title](gallery/take_the_a_train.png)

",28,28,2,0,art,"[art, generative-art, music]",0
qiray,MathArtist,,https://github.com/qiray/MathArtist,https://api.github.com/repos/MathArtist/qiray,Tool for generating pictures using mathematical formulas.,"# MathArtist

Tool for generating pictures using mathematical formulas.

<img src=""images/example7.png"" alt=""drawing"" width=""200px""/>

## Algorithm

To create new image we perform these steps:

* Generate name using data folder with mulltiple nouns, adjectives, prepositions and pronouns and [names_generator](names_generator.py) module to convert single words into fun looking image name.
* Select operators from predefined sets and coordinates conversion transformations. All coordinates are converted to range [-1, 1] because this range nicely fits to many mathematical operations. See [coords](coords.py) module for more information.
* Generate expression tree using operators from previous step that convert each (x, y) point to color. There are multiple operators from simplest VariableX (which converts coordinate to (x, x, x) color) to difficult Mix and Closest (you can see their code in [operators](operators.pyx) module). Tree size is dynamic so there can be something simple like Mix(x, y, Well(x)) or long multiline formula which computing can take some minutes.
* We also use [checker](checker.py) to check if generated formula is bad and recreate it. Checker is very simple - it thinks formula is good when it has different functions, has few well and tent functions (because they produce boring looking lines) and generates multicolor image (because the ""Black square"" by Malevich already exists). By the way sometimes checker decides that even bad formula should get a chance. It's not a bug, it's a feature.
* And now we convert each point of image to color using coordinates transform from step 2 and expression tree from step 3. After all points have their colors we can draw comleted image. That's all.

## Releases

You can download the last release here: 

https://github.com/qiray/MathArtist/releases

## Requirements

This program uses Python 3 so you need to have Python 3 and pip for build and run it. To install them use instructions for your OS.

It also needs some extra libraries and applications such as argparse, PIL, numpy, PyQt5, pyinstaller and Cython. This program has script [build.sh](build.sh) for preparing and building binaries. So for installing requirements run:

```bash
bash build.sh prebuild
```

Of course you should have bash for running this script.

Some packages such as PyQt5 require additional packages on some OS. For example on deb-based systems you should also install python3-pyqt5:

``` bash
apt install python3-pyqt5 pyqt5-dev-tools
```

This tool also need C/C++ compiler because of using Cython. You can install it following instructions for your OS.

## Building

For making Cython modules you should run:

```bash
bash build.sh cython
```

Or for installing requirements and building Cython modules in one step you can run:

```bash
bash build.sh
```

### Pyinstaller

I prefer to use pyinstaller for building release versions. To build release run:

```bash
bash build.sh install
```

The release will be in dist folder.

## Usage

To run app from sources folder type:

```bash
python main.py
#or this if your python 3 has name python3:
python3 main.py
```

To run app from release build run double click on mathartist executable or run:

```bash
./mathartist
```

There are 2 work modes: console and GUI.

### Console

In console mode app generates one image, saves it and exits.

There are some extra modes:

```
usage: MathArtist [-h] [--console] [--name NAME] [--about] [--file FILE]
                  [--generate_list]

Tool for generating pictures using mathematical formulas.

optional arguments:
  -h, --help       show this help message and exit
  --console        Run in console mode (no window)
  --name           Set image name
  --about          Show about info
  --file FILE      Load file
  --generate_list  Generate operators' list (developer option)
```

### GUI

GUI in this app is pretty simple. There are 4 buttons: 

- ""Random image"" which generates new random name and image.

- ""Generate image"" which generates new image based on it's name in text field (same names produce same images).

- ""Save image"" which saves image in output folder.

- ""Load image"" which shows open file dialog to load text file with formula.

And 1 text field for image name.

![](images/gui.png)

#### Shortcuts

There are some hotkeys:

| Shortcut         | Command      |
| :--------------- | :----------- |
| <kbd>n</kbd>, <kbd>r</kbd>     | Generate new random image |
| <kbd>g</kbd>     | Generate new image based on it's name in text field |
| <kbd>o</kbd>     | Open text file with formula |
| <kbd>s</kbd> | Save image in output folder |
| <kbd>a</kbd> | Show about info |
| <kbd>Esc</kbd>     | Close app |
| <kbd>F1</kbd>     | Show online help (this readme) |

### Samples

<p float=""left"">
  <img src=""images/example1.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example2.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example3.png"" alt=""drawing"" width=""200px""/>
</p>
<p float=""left"">
  <img src=""images/example4.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example5.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example6.png"" alt=""drawing"" width=""200px""/>
</p>
<p float=""left"">
  <img src=""images/example7.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example8.png"" alt=""drawing"" width=""200px""/>
  <img src=""images/example9.png"" alt=""drawing"" width=""200px""/>
</p>

There is samples folder with some nice images in text format. You can use app's read file option (""Load image"" button in GUI) to convert these texts into images.

## Online content

Math Artist also has it's own Twitter (https://twitter.com/math_artist) and Instagram (https://www.instagram.com/qarmath/) accounts. You are welcome to follow, like, repost and comment.

## License

In short the MathArtist uses GNU GPL3. For more information see the LICENSE file.

But there is one nuance. This program uses some code from Andrej Bauer's randomart project. Original randomart project is licensed with BSD 2-clause license. You can download it here - http://math.andrej.com/2010/04/21/random-art-in-python/

Andrej Bauer's code in this project is licensed with both BSD 2-clause and GNU GPL3 licenses. The combined project uses only GNU GPL3. You shouldn't use any part of MathArtist with BSD license. Please use GNU GPL3 only.

## Thanks

I'd like to thank:

Andrej Bauer for wonderful online random art project (http://www.random-art.org/online/), original Python randomart code (http://math.andrej.com/2010/04/21/random-art-in-python/) and great ideas which lead to this project.

Matt DesLauriers for cool color-wander project (http://color-wander.surge.sh/ and https://github.com/mattdesl/color-wander) and nice palettes used in this project.

Volodymyr Shymanskyy for his JS randomart project (https://github.com/vshymanskyy/randomart) that gave me some ideas such as mindepth and some operators.

Halvor Kjærås for random art generator - (http://ironigardinen.net/generatorer/art2/index.html). It gave me some ideas and data for MathArtist art name generator.
",27,27,3,0,art,"[art, art-generator, artwork, cython, expression-tree, formula, generative-art, generator, gnu-gplv3, gplv3, gui, math, mathematical-expressions, mathematical-formulas, mathematical-functions, mathematics, pyinstaller, pyqt5, python, python3]",0
ibara,sprite,,https://github.com/ibara/sprite,https://api.github.com/repos/sprite/ibara,ncurses-based sprite editor,"sprite
======
Sprite is an ncurses-based sprite editor.
You can use it to create and share pixel art.

By default, sprite sets up a 16x16 pixel canvas.
If you'd like a larger 32x32 pixel canvas, start sprite with the -e
flag.
If your terminal is not large enough to fit a 32x32 canvas, it will
use a 16x16 canvas instead.
If you'd like a smaller 8x8 pixel canvas, start sprite with the -s
flag.

Most terminals do not have 1:1 square character cells.
This may cause the canvas to have a different aspect ratio than
expectations.
PNG export does create standard 1:1 square pixels; exported images
will look correct.

Save file format
----------------
Images are saved as a flat text file, one pixel per line, in the form
```
y,x,color
```
Color is an index number from 0-255 that matches XTerm color.
Only pixels with color are saved; transparent pixels are left out.
The .spr and .txt file extensions are used by convention but any file
extension can be used for save files.

Images can be exported to PNG, but sprite is not able to open PNGs,
so please save images rather than export if you want to work on them
over multiple sessions. The .png file extension is recommended for
export; sprite does not add the file extension automatically when
exporting.

Requirements
------------
You need ncurses with 256 color support.
While it will work with fewer than 256 colors it will not be as good.

You also need libpng for PNG export support.

Building
--------
Just run `make`.

Remove `-DHAVE_STRTONUM` if your system needs the strtonum(3) function.

Remove `-DHAVE_GETPROGNAME` if your system needs the getprogname(3)
function.

License
-------
ISC License.
See `LICENSE` for details.
",26,26,3,0,art,"[art, artwork, bsd, console, game, game-art, game-dev, game-development, gameart, linux, ncurses, openbsd, pixel, pixel-art, pixelart, pixels, sprite, unix]",0
MaxAlyokhin,audio-motion-interface,,https://github.com/MaxAlyokhin/audio-motion-interface,https://api.github.com/repos/audio-motion-interface/MaxAlyokhin,Web synthesizer that generates sound using smartphone gestures in the space,"# Audio-motion interface (AMI)

*Sonification interface for motion and orientation*

[![Uptime Robot status](https://img.shields.io/uptimerobot/status/m793083121-0b0a0d608a9491e5a58871a4)](https://ami.stranno.su) [![Uptime Robot status](https://img.shields.io/uptimerobot/ratio/m793083121-0b0a0d608a9491e5a58871a4)](https://ami.stranno.su)

**Demo**: https://ami.stranno.su

**Video**: https://youtu.be/H1ryDYgeoOs

> **Note**: [Bug](https://bugzilla.mozilla.org/show_bug.cgi?id=1435625) in Firefox — on default settings there are problems with sound. It is recommended to put the attack value at least 0.1 to fix. Also, Firefox is not recommended because of the slower refresh rate of motion parameters.

![](https://store.stranno.su/ami/design-en.webp)

*<a href=""README_RU.md"">Эта страница есть также на русском</a>*

The system synthesizes sound based on data from smartphone motion sensors: speed determines the volume, position determines the frequency. In other words, it is a musical instrument (synthesizer) that uses hand gestures instead of keys or strings.

There are so-called local mode, when the sound is generated by the smartphone and distributed mode, when the smartphone transmits data about the movement to the computer and the computer generates sound.

The algorithm has a minimal number of internal settings, leaving it up to you to process the sound (it can be both pedals/effects and a variety of DAWs like Ableton, Cubase, FL Studio, etc.).

## Briefly how to use

The easiest option is to open from your smartphone at https://ami.stranno.su. The smartphone will ask for access to the sensors — it must be allowed. After that it will immediately start generating sound from the built-in speaker with a slight shake. Here it is better to either connect headphones, or connect to a bluetooth speaker, or use a mini-jack to mini-jack cable (or with a jack adapter) to connect to the speakers/amplifier/combo. There are the following disadvantages with this option:

- you are constrained by a cable
- your smartphone has a noticeable delay
- you cannot see what you are playing (the note/frequency being generated)
- it is not very convenient to change the settings

All these disadvantages are solved by a *distributed mode*. To do so:

- switch the synthesis strategy on the smartphone to the distributed mode
- enter additionally from the computer to https://ami.stranno.su. The computer will automatically turn on the special data receiver mode. This will display the line ""Connected (1)"" (the number may be higher if someone else has visited the site with you)
- The smartphone now transmits the motion data to the computer. This is where both the smartphone and the computer start synthesizing sound. The smartphone does this with more delay, so you can hear something like an echo when the sound is on in both devices. Here you can turn down the volume on the smartphone to zero, and connect the computer to your audio system.

From the computer, therefore, the sound can be transferred to the DAW via Virtual Audio Cabel (VAC) and processed there, letting the input VAC operating system sounds (as the browser gives sound there), and the output VAC connect to the DAW. Then the sound can be taken either from the mini-jack of the computer, or from an external audio-interface, and from there process further.

Some possible schemes of work:
- smartphone → built-in speaker
- smartphone → headphones
- smartphone → bluetooth-speaker
- smartphone → padals/effects → speakers/combo
- smartphone → computer → DAW on computer → padals/effects → speakers/combo

You can also load presets into the system (you need to download as a file and use the Import button in the system):
- [electronica.json](https://store.stranno.su/ami/electronica.json)
- [ambient.json](https://store.stranno.su/ami/ambient.json)
- [noise.json](https://store.stranno.su/ami/noise.json)

> **Note**: Using https://ami.stranno.su is demo. Its main disadvantage is the synchronization between all users; your sound and your settings can be interrupted by random users. Plus, since the traffic information goes over the internet (at least to Frankfurt, where the server is located, and back), there can be a delay (about 20-100ms, depending on the quality of the connection). To solve all these disadvantages it is recommended to deploy the system locally (see section **[Recommended use (running on a local computer)](#recommended)**).

## Contents

- [Run](#run)
  - [Simple usage (running the web version at ami.stranno.su)](#simple)
  - [Recommended usage (running on a local computer)](#recommended)
  - [Advanced usage (running on local computer + sound processing)](#pro)
  - [Running the development version](#dev)
- [Theory and terms](#theory)
  - [""Interface"" instead of ""synthesizer""](#interface)
  - [Synthesis strategy](#strategy)
  - [Synthesis point](#point)
  - [Local mode](#local)
  - [Distributed mode](#destributed)
  - [Batch](#batch)
  - [Motion event](#event)
  - [Cutoff](#threshold-theory)
  - [Gesture](#gesture)
  - [Audio-graph](#graph)
  - [Used semisphere](#semisphere)
  - [AMI instance](#instance)
  - [State](#state)
- [User guide](#user)
  - [System control](#user)
    - [Generated frequency](#generated)
    - [Note](#note)
    - [Cutoff](#threshold)
    - [Speed influences the volume](#influence)
    - [Release](#release)
    - [Oscillator amount](#count)
    - [Latency](#latency)
    - [Used semisphere](#semisphere-guide)
    - [Frequency range](#freqs)
    - [Notes range](#notes-range)
    - [Frequency generation mode](#generation)
    - [Tempered mode](#tempered)
    - [Motion by α/β/γ axes](#motion)
    - [Smartphone position on the γ axis](#gamma)
    - [Motion status](#is-motion)
    - [Maximum value](#max)
    - [Data receiver mode enabled](#receiver)
    - [Data source mode enabled](#source)
    - [Connecting to server](#websocket)
    - [Connection with server is ready](#websoket-on)
    - [Connection with server is failed](#websoket-off)
    - [Connected (х)](#connected)
    - [Waiting for connections](#waiting)
    - [Performance saving mode](#lite)
    - [Cutoff type](#type)
    - [Sensor timeout](#timeout)
    - [Attack](#attack)
    - [Volume](#volume)
    - [Attenuation to value](#release-value)
    - [Filter](#filter)
    - [LFO](#lfo)
    - [Compressor](#compressor)
    - [Reset oscillators](#reset)
    - [Errors](#errors)
    - [Fullscreen-mode](#fullscreen)
    - [Audio generation](#audio-generate)
  - [MIDI](#midi)
  - [Storing the interface state (settings) (Import / Export)](#state-storing)
- [Tech guide](#tech)
- [Secure context](#secure)

## Run
<a id=""run""></a>

### Simple usage (running the web version at ami.stranno.su)
<a id=""simple""></a>

In local mode:
1. Go to https://ami.stranno.su from your smartphone

> **Note**: in local mode, the delay in sound synthesis can be quite noticeable due to the fact that the computing resource of a smartphone is quite limited compared to even the most average laptop

In distributed mode:
1. Go to https://ami.stranno.su from your computer
2. Go to https://ami.stranno.su from your smartphone

(in any order)

> **Note**: in distributed mode, sound synthesis becomes shared by all who are currently logged into the site, and the settings are synchronized between all users. That is, if several people came to the site at the same time and someone changed the synthesis settings, they will be changed **at all participants**; sounds generated by one participant will be played **at all devices of all visitors**

### Recommended usage (running on a local computer)
<a id=""recommended""></a>

The recommended use is to run your own instance of AMI on your computer and work in distributed mode.

> **Note**: smartphone and computer must be connected to the same wifi network. Or you can run a virtual router on your laptop (using a third-party service a la Connectify) and connect your smartphone to your laptop. The most ideally you would run the hotspot on a laptop to even out the latency of the router. **On Windows you can use the ""Mobile Hotspot"" function**.

> **Note**: the latency with this startup option is the shortest possible

The purpose of both installations is this: Node.js is already in the folders. You need to use it to open the index.js file. This is convenient to do with a script. In MacOS you need to additionally make the script executable with `chmod -R 755 app`.

Perhaps there are easier ways to install. I would be glad to hear your suggestions.

Windows:
1. [Download archive](https://store.stranno.su/ami/windows/audio-motion-interface.zip)
2. Unpack
3. Click on `run.bat`

MacOS:
1. [Download archive](https://store.stranno.su/ami/macos/audio-motion-interface.zip)
2. Unpack
3. Move the folder to Documents*
4. `cmd` + `Space`
5. Enter ""terminal.app"", start the Terminal
6. In the terminal enter `cd` and *drag the folder* ""audio-motion-interface"" from Finder to the terminal. The terminal will automatically insert the path to the folder. You will get something like:
`cd /User/User Name/Documents/audio-motion-interface`
Press `Enter`
7. Input `chmod -R 755 app` and press `Enter`
8. Right-click the run.command file, then ""open with Terminal"".
9. Give permission to execute the file. **In the future you can run AMI simply by clicking on run.command**

*In general you can move it to any folder, but then you need to edit the run.command file with any text editor and fix the paths to Node.js and to index.js

On Linux the installation will be similar to MacOS, only you will need to download Node.js binaries for Linux and put them in the /app/node folder. If Node.js is already installed globally, you just need to run the index.js file with it.

> **Node:** because a self-signed certificate is used to encrypt the traffic the API requires, the browsers will show a warning about an invalid (untrusted) certificate. This is normal for working within local network. Read more in the [Secure context](#secure) section

### Advanced usage (running on local computer + sound processing)
<a id=""pro""></a>

It must be said that the most effective use case is the distributed mode on the local computer. In fact, the smartphone here is used solely as an interface to transmit data from the sensors, and the computer is used as an interface to manage this data.

After getting to the computer, this data can be processed in any convenient way. For example, you can send the sound to a DAW (Ableton, Cubase, FL Studio) via [Virtual Audio Cabel](https://vac.muzychenko.net/en/) (VAC) and process it there, letting the operating system sounds *in* of the VAC (since the browser gives the sound there), and *out* of the VAC connect to the DAW. Then the sound can be taken either from the computer's mini-jack or from an external audiointerface, and processed further from there.

If you do not have an external audiointerface (sound card), you will see a delay in sound processing (at least on Windows). To avoid this, it is recommended to use [ASIO](https://www.asio4all.org/).

It is also possible to make your local AMI instance available from the Internet without having to deploy it to a remote server. To do this, you need to share your local AMI instance to the Internet using *tunneling*, for example with [ngrok](https://ngrok.com/) (it's free):

`ngrok http https://localhost`

On the computer, open https://localhost

On your smartphone, open the link to the tunnel that ngrok generated.

### Running the development version
<a id=""dev""></a>

If you want to refine or rework the code, you must run the required development environment.

First run:

1. `git clone https://github.com/MaxAlyokhin/audio-motion-interface.git`
2. Open folder in terminal
3. `npm i`
4. `nodemon index` (or just `node index`)
5. Open second terminal
6. `cd client`
7. `npm i`
8. `gulp`

Further launches:
1. In the first terminal: `nodemon index` (or just `node index`)
2. In the second terminal: `cd client`.
3. `gulp`.

The first terminal is the backend, the second terminal is the frontend.

It is also necessary to remove the automatic launch of the browser on server restart. To do this, you need to comment out this line in the index.js:
``` javascript
server.listen(443, '0.0.0.0', function () {
  console.log(`${getDate()} Audio-motion interface is up and running`)
  lookup(hostname, options, function (err, ips, fam) {
    ips.forEach(ip => {
      if (ip.address.indexOf('192.168') === 0) {
        address = ip.address
        console.log(`${getDate()} Opening https://${address} in default browser`)
        // open(`https://${address}`) <-- This line
        console.log(`${getDate()} Close terminal for exit from AMI`)
      } else {
        address = 'ami.stranno.su'
      }
    })
  })
})
```

> **Note**: For development purposes, it is better to globally install Nodemon. That way, it will be responsible for restarting code changes in the backend, and Gulp will be responsible for frontend code changes.

The repository already contains the private and public keys to run the https server. See the [Secure context](#secure) section below for details.

## Theory and terms
<a id=""theory""></a>

### ""Interface"" instead of ""synthesizer""
<a id=""interface""></a>

The word ""synthesizer"" refers to an electronic musical instrument, often with a keyboard, which generates sound by means of electrical conversions by circuitry (analog) or by means of mathematical calculations by a microprocessor (digital). An important feature here is that such instruments are not acoustic (unlike classical guitars, violins, or woodwinds), but rather provide a *control system for the electric current* supplied to the acoustic system (an acoustic system here means any sound-producing device: speakers, combos, headphones, built-in speakers). Moreover, this is also true for devices that have a sensor as part of them. The electric guitar, for example, is also not an acoustic instrument: its central element is the pickup, and the strings are just a way of forming the signal. Also, any microphone is a sensor, and voice is also simply a way of forming a signal for the microphone to be converted into electricity and to be controlled by it. All such devices are signal (data) shaping tools, and acoustic systems are sonification tools, that is, the translation of non-sound processes (like voltage changes) into sound. Any sound recording process is the reverse of sonification. The keys on a synthesizer or the strings on an electric guitar are simply a part of the control system for the electric current that has migrated into these instruments in its familiar format for musicians.

An interface is a translator from language to language (in the broad sense of the word). All modern music is a set of ways of *translating* an acoustic signal into an electrical signal and back, or creating an electrical signal from nothing and then manipulating that.

An interface is a method of access. Any musical instrument, even an acoustic one, is an interface for accessing a particular set of sounds produced by that instrument.

Any sensor is an interface. A smartphone nowadays almost always has an accelerometer and a gyroscope, a motion and orientation sensor, respectively. We can build a sound synthesis and control system based on them, *translating* data from sensors into signals, processing and *translating* into sound. That is, here the system not only and not so much synthesizes sound as it does the translation and interpretation of motion and orientation change processes, so here the word ""synthesizer"" would reflect only part of the system.

This repository represents a specific implementation of such a system.

### Synthesis strategy
<a id=""strategy""></a>

A way of getting data from sensors and determining *where* it will be translated into sound.

### Synthesis point
<a id=""point""></a>

A device that acquires motion data and synthesizes sound based on it.

### Local mode
<a id=""local""></a>

The *data source* and *synthesis point* are on the smartphone (combined).

### Distributed mode
<a id=""destributed""></a>

The *data source* is on the smartphone, and the *synthesis point* is on a remote machine (separated). This mode generally allows any number of complex combinations with multiple data sources (smartphones) and multiple synthesis points that are as far apart as you want (when streaming data over the internet) and connected to different audio systems.

### Batch
<a id=""batch""></a>

A set of virtual devices [oscillator](https://en.wikipedia.org/wiki/Electronic_oscillator) → [filter](https://en.wikipedia.org/wiki/Low-pass_filter) → [LFO](https://en.wikipedia.org/wiki/Low-frequency_oscillation) → [envelope](https://en.wikipedia.org/wiki/Envelope_(music)).

### Motion event
<a id=""event""></a>

[JS-event](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Building_blocks/Events), generated approximately every 16ms (on Chrome and Chromium-based browsers, on the Firefox every 100ms) by the smartphone, containing motion parameters. Events occur even when the device is motionless, in which case the motion parameters are zero.

### Cutoff
<a id=""threshold-theory""></a>

The minimum movement speed at which the system is started.

### Gesture
<a id=""gesture""></a>

A set of motion events from above the cutoff to below the cutoff. Each gesture corresponds to its own batch. It is important to note that the word ""gesture"" here has nothing to do with touchscreen gestures or mouse gestures, as it does in other more familiar interfaces; here ""gesture"" is more of a hand gesture in space, or, in a general sense, the process of moving a smartphone in space, *generating* a set of motion events from above the cutoff to below the cutoff.

### Audio-graph
<a id=""graph""></a>

A graph is an abstraction that connects *nodes* with *links*. For example, a graph for an electric guitar might be something like this:

guitar → pedal 1 → pedal 2 → pedal 3 → combo

The AMI consists of virtual devices (nodes) that are connected in a certain way. The overall graph looks something like this:

[oscillator → filter → LFO → envelope] → compressor

The devices in square brackets (batch) are generated *at each gesture* and connected to the compressor. When the batch is finished, it is removed and disconnected from the compressor.

### Used semisphere
<a id=""semisphere""></a>

The human hand has understandable limitations when rotating the hand: the left hand comfortably rotates from the palm up position to the palm down position clockwise, and the right hand comfortably rotates from the palm up position to the palm down position counterclockwise.

The smartphone can be rotated along its axis 360 degrees. But in this system, 360 degrees is divided in half: when the smartphone is on the table with the screen up, it is 180 degrees (palm up), and when on the screen (palm down) it is 0. From 0 to 180 you can go two ways: rotating the smartphone counterclockwise and clockwise. To make the system ergonomic, we can divide the 360 degrees into two semispheres, where the right semisphere is convenient for left-handed people and the left semisphere is convenient for right-handed people.

![](https://store.stranno.su/ami/semi-sphere.jpg)
**The picture in the center conventionally shows the smartphone with the screen down. ""Правша"" in russian means right-handed people and ""Левша"" in russian means left-handed people*

### AMI instance
<a id=""instance""></a>

An AMI instance is one server and clients (computer and smartphone browsers) connected to it. For example, https://ami.stranno.su is one instance of AMI; all clients connecting to it become part of the instance.

### State
<a id=""state""></a>

State refers to the entire set of system settings **directly affecting the character of the sound** (that is, apart from user interface settings such as language or dark/light theme).

Gestures, passing through the state, turn into sound. Therefore, the state determines the sound.

At the instance level, state is the same for all clients and is synchronized between all clients. Clients have equal access to state changes.

All instance-level gestures data is sent to all clients.

Thus an instance is a single entity. The server acts as a commutator between clients, sharing gestures and state between all of them.

Read more about state work in the [Storing state (settings) of the interface (Import / Export)](#state-storing)

## User guide
<a id=""user""></a>

### System control
<a id=""user""></a>

Sound synthesis is affected by two parameters — position and speed.


<a id=""generated""></a>

<a id=""note""></a>

Position (angle of tilt along the semisphere) determines the frequency displayed in the **Generated frequency** field, as well as below in the **Note** field the hit of this frequency in the nearest note.


<a id=""threshold""></a>

<a id=""influence""></a>

The speed of movement affects two factors:
- turns on the system when the speed exceeds the **Cutoff** defined in the corresponding field
- affects the volume when **Speed influences the volume** is enabled

If the cutoff is set to 0, one oscillator will run the whole time.


<a id=""release""></a>

Accordingly, the system turns on when the cutoff is exceeded, creates a batch, and generates sound. When decelerating to a value below the cutoff, the system plans to decay the sound (if the **Release** field is not 0).


<a id=""count""></a>

The **Oscillator amount** field displays all the batches sounding at the moment.

For example, if you shake your hand chaotically for some time, the cutoff will be exceeded several times at random, which means that several batches will be generated, which will fade smoothly and their sound will overlap each other. It is better not to bring the number of oscillators, according to current observations, to values higher than 120 pieces, as almost certainly the computing power of the device will end there and the sound will start to stutter, or will disappear at all.

According to subjective observations, the optimal cutoff can be between 3 and 7 (the default is 1), then random movements can be eliminated.


<a id=""latency""></a>

The **Latency** field displays the latency from the motion event to the sound synthesis. On a smartphone, it is equal to the software latency (<a href=""https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/outputLatency"">`AudioContext.outputLatency`</a>). On the desktop, it is equal to the software latency + the transfer time of the motion object from the smartphone to the desktop. In the interface is displayed in the format `device latency + network latency`.

According to current observations, the lowest latency is observed on Apple devices (this applies to both IPhone and desktop devices, about 8ms). For example, on the smartphone Huawei Honor 10 device latency is 80ms, on the laptop Huawei Matebook device latency is 40ms; at the same time when starting the system locally via wi-fi router the network latency comes out 4-5ms. So, specifically for these devices, total smartphone latency = 80ms, total laptop latency 40 + 5 = 45ms. That is, comes out a paradoxical situation that on the laptop sound occurs earlier than on the smartphone.

The most efficient option is to use an Apple laptop and install the system locally, then the latency will be about 5 + 8 = 13ms.


<a id=""semisphere-guide""></a>

Since the frequencies are distributed over a semisphere, there is a field **Used semisphere** that allows you to switch the system for left- or right-handed people.


<a id=""freqs""></a>

The semisphere contains 1800 divisions (180 degrees * tenths), on which the values specified in the field **Frequency range** are distributed. The values are distributed continuously and exponentially, i.e. there are more hertz for each degree at higher values, which allows to take into account the peculiarities of our hearing and make the frequency distribution across the semisphere even.


<a id=""generation""></a>

<a id=""tempered""></a>

<a id=""notes-range""></a>

You can redistribute notes within a 12-step evenly tempered scale by using the **Frequency generation mode** field by selecting **Tempered mode**. Then the frequency range field will automatically change to **Range of Notes**. By selecting a small range, you can hit the notes you want quite accurately and confidently.


<a id=""motion""></a>

The **Motion by α/β/γ axes** field shows the speeds of movement by the three coordinates in space.


<a id=""gamma""></a>

The **Smartphone position on the γ axis** field shows the tilt angle in the semisphere. This tilt angle determines the frequency of the synthesized sound.


<a id=""is-motion""></a>

The **Motion status** field shows `true` when the cutoff is exceeded and the system is generating sounds in the current batch. In the `false` position, the system is in standby mode when the cutoff is exceeded and generates no sound.


<a id=""max""></a>

The field **Maximum value** shows the maximum speed of movement for the whole session (i.e. from the moment of opening the tab, to the current moment).


<a id=""receiver""></a>

**Data receiver mode enabled** means the computer is ready to receive data from external smartphones.


<a id=""source""></a>

**Data source mode enabled** means that the smartphone broadcasts its motion data to the remote computer.


<a id=""websocket""></a>

**Connecting to server** — in this status, the system tries to establish a websocket connection with the server through which the data will be broadcast between the smartphone and the computer.


<a id=""websoket-on""></a>

**Connection with server is ready** — it is possible to transmit data between devices.


<a id=""websoket-off""></a>

**Connection with server is failed** — something happened on the server and it is no longer responding, or the device has disconnected from the Internet and lost communication.


<a id=""connected""></a>

**Connected (x)** — number of connected devices, *other than this computer* (this field is displayed only from the desktop).


<a id=""waiting""></a>

**Waiting for connections** — no device is connected apart from this computer (this field is only displayed from the desktop).


<a id=""lite""></a>

**Performance saving mode** — motion events, as well as recalculation of the synthesized sound output values, trigger a very fast update of the data in the interface. This update is quite a costly operation. To save device resources, especially if you hear clicks or sound artifacts at some point, you can enable this mode, but it will turn off all data updates in the interface and you will only have to navigate by ear.


<a id=""type""></a>

**Cutoff type** — with ""full"" type, sound is generated from the point above the cutoff to the point below the cutoff. In the ""Peak"" type, sound is generated only on the point of highest movement speed. Explanation: each gesture slows down at the end of its movement. This leads to, firstly, a difficult system to control, and secondly, in the ""speed influences the volume"" mode, the middle of the sound can be loud and the end very quiet. We can catch the slowdown and interpret it as the end of the gesture. The oscillator will then cut off at the speed peak. In practice, this allows for clearer individual controlled sounds.

<picture align=""center"">
  <img src=""https://store.stranno.su/ami/full-peak.jpg"">
</picture>


<a id=""timeout""></a>

**Sensor timeout** — like the sensor cutoff, this setting allows you to better control your movement and get rid of accidental sounds. It sets a pause after the end of the previous gesture, leveling out the accidental excesses of the cut-off when slowing down the speed of movement.


<a id=""attack""></a>

**Attack** — the time of smooth growth of the volume to the value in the volume field.


<a id=""volume""></a>

**Volume** — the target volume value to which the attack grows and from which the attenuation begins.


<a id=""release-value""></a>

**Attenuation to value** — the volume value to which the sound is attenuated. The default value is `0.0001`, the minimum value (zero cannot be set for mathematical reasons, as the attenuation is exponential). If you set this value higher than the volume, the sound will grow and cut off abruptly, which will create a kind of inside-out effect.


<a id=""filter""></a>

**Filter** — lowpass filter, cuts the upper frequencies starting from the frequency specified in the corresponding field. The **Q-factor** determines the ""power"" of frequency suppression, the breadth of influence on frequencies (of all possible filters lowpass was chosen, because it softens ringing high frequencies, which is very appropriate for such a system. If there is a need for a more sophisticated filtering or a full-fledged equalizer in general, it is necessary to use external solutions, whether DAW or some separate devices).


<a id=""lfo""></a>

**LFO** is the oscillator that controls the main oscillator volume knob. The amplitude is ahead of the depth of volume change, and the frequency is ahead of the volume change rate.


<a id=""compressor""></a>

**Compressor** — by default its influence is minimized. If you want to play a lot of oscillators at once, but do not want to descend into rough noise, you can set, for example, the **Release** field to `0.25`, and the **Threshold** field to `-50`.


<a id=""reset""></a>

**Reset oscillators** — turns off and deletes all the batches that are working. It helps if the abundance of oscillators makes the sound produce artifacts, as well as if you set very high attenuation values and do not want to wait for the sound to fade out.


<a id=""errors""></a>

**Errors** — this field will be removed after the end of testing. Here will be inserted all the errors that occur during the work, which will help to debug the system.


<a id=""fullscreen""></a>

**Fullscreen-mode** — on your smartphone, opposite the text ""Audio-motion interface"", there will be an icon to switch to full-screen mode (Apple devices do not support it). This mode is recommended because it disables the standard browser gestures ""Back"" (when swiping from the left edge to the right) and ""Refresh"" (when swiping from the top edge down), which will give you more confidence in holding the smartphone in your hand without fear of pressing something.


<a id=""audio-generate""></a>

**Audio generation** — indicator showing whether sound is currently being generated.

### MIDI
<a id=""midi""></a>

AMI allows you to generate MIDI messages. To enable MIDI, the MIDI regime must be enabled. Automatically selects the first available port and its first channel. When the cutoff is exceeded, a noteOn signal is sent, then in Peak mode the noteOff signal is sent after the time specified in the Duration field; in Full mode, noteOff is sent only when the movement is over + after the time in the Duration field; during the movement, the pressure on the channel changes when speed affects the volume (that is, speed during the movement is equal to the change in the force of the key press). In Peak mode, speed increases Velocity. The MIDI Reset button sends an allSoundOff signal.

MIDI messages can be sent:
- to neighboring tabs and browser windows if they listen to MIDI (e.g., Web analog [DX7](http://mmontag.github.io/dx7-synth-js))
- to DAWs and other applications that have virtual synthesizers (that is, AMI can control, for example, a synthesizer in Ableton)
- to external MIDI-enabled devices connected to your computer

> **Note**: After any manipulations with MIDI ports (connecting/disconnecting/ reconnecting) you must restart the browser completely, closing all browser windows if there are several

> **Note**: MIDI messages are generated only on the desktop. The smartphone in this mode only sends movement and orientation data

### Saving the state (settings) of the interface
<a id=""state-storing""></a>

At the first start of the application, the default settings are set.

Thereafter, any changes to the settings are immediately written to the computer, so your work is automatically restored when you restart.

But you may have a situation where you need to keep multiple copies of your settings at once. Also, when you clear the browser completely, when you change browsers, or when you start the application from a different domain (e.g. a new address `192.168.X.X`), the settings will be lost. As a solution, the application provides buttons **Import / Export** to save and load settings from an external file in `.json` format.

## Tech guide
<a id=""tech""></a>

Stack: HTML, Sass, JS, Web Audio API, Device Motion API, Device Orientation API, Socket.io, Express, Gulp.

AMI is essentially a small ""fullstack"" web application with https server on Express and websocket server on Socket.io, handing out a simple frontend in native JS using Web Audio API (WAAPI), Device Motion API (DMAPI) and Device Orientation API (DOAPI). We collect data from DMAPI/DOAPI, tidy it up, and send it directly to WAAPI in local mode and to websocket in distributed mode (and on the remote machine this data is received via websocket and sent there to WAAPI).

<picture align=""center"">
  <source media=""(prefers-color-scheme: dark)"" srcset=""https://store.stranno.su/ami/api-dark.png"">
  <img src=""https://store.stranno.su/ami/api-en.png"">
</picture>

index.js is the entry point into the application. Runs Express and Socket.io, distributes the frontend from /client/dist. Frontend builds Gulp in /client folder from /client/src and puts the finished thing in /client/dist. JS is built by Webpack, Sass is compiled to CSS, HTML is built from templates, and the built JS and CSS is injected into `<head>`. BrowserSync starts development server on a separate port, but it will not work backend (but it works live-reload), so it's better to open the address without port (`https://localhost`).

The application code is commented in many places, so you can learn the nuances directly in the code.

A rough scheme of data flow through the functions after initialization:

<picture align=""center"">
  <source media=""(prefers-color-scheme: dark)"" srcset=""https://store.stranno.su/ami/functions-dark.png"">
  <img src=""https://store.stranno.su/ami/functions-new.png"">
</picture>

The [current-device](https://github.com/matthewhudson/current-device) library is used to define the device type - mobile or desktop, which initializes the corresponding mode. On the mobile device each motion event is checked for speed (maximum of three coordinates) and compared to the cutoff, if exceeded, then we create a batch. *If after that* are below the cutoff, then we plan to remove the batch. All elements of a batch are fluffed into arrays, and then deleted from them.

The application uses an MVC-like architecture (meaning MVC on the client), where the model uses a mutable state instead of the database, and the View will refer not only to the GUI, but also the data from the gyroscope and accelerometer, as well as the synthesized sound. The most important parts of the business logic are in `audio.js`, `motion.js`, and `orientation.js`. The state and almost all of its control is in `settings.js`. The `settings` object contains the entire state of the application. Changes to this object are made through methods of the `mutations` object. The connection between the view (its UI part) and the state is made in the `settingsInit()` function. This object is written to `localStorage`. Each mutation of it causes an update of `localStorage`. The `settings` object, with the exception of the `settings.ui` property, completely defines the sound of the system. The Import / Export buttons allow you to manipulate the state as an external JSON file.

It is quite possible to build a system with many states and control them through a kind of ""master device"" that mixes ""tracks"" from different devices, but in this case it was decided that each instance of AMI is a separate musical instrument with its own characteristic sound at the moment.

<picture align=""center"">
  <img src=""https://store.stranno.su/ami/mvc.jpg"">
</picture>

### Secure context
<a id=""secure""></a>

Due to the fact that the Motion/Orientation API requires secure context (i.e. encryption of traffic), we have to raise the http**s** server. For this purpose, with the help of [OpenSSL](https://en.wikipedia.org/wiki/OpenSSL) were generated public and private keys, with which the traffic between the computer and the smartphone is encrypted ([self-signed certificate](https://en.wikipedia.org/wiki/Self-signed_certificate)). There's not much practical benefit from such encryption, since the data moves within your local network (and if leaked to the Internet, the data about the rotation of your smartphone won't do much harm), but secure context is required by all browsers to transmit data about the movement and position to external devices.

If necessary, you can generate your own self-signed certificate (see [here](https://stackoverflow.com/questions/21397809/create-a-trusted-self-signed-ssl-cert-for-localhost-for-use-with-express-node) for details).

When you publish code on the web, you will most likely have some other infrastructure (nginx + server control panel, etc.) before the Express server, so the need for https-server will most likely disappear and you can change the index.js this way:

``` javascript
const fs = require('fs')
const os = require('os')
const http = require('http') // <-- Changed the package from https to http
const express = require('express')
const { Server } = require('socket.io')
const { lookup } = require('dns')
const open = require('open')

const hostname = os.hostname()
const app = express()
const server = http.createServer(app) // <-- Removed certificate download
```
",26,26,3,0,art,"[art, midi, music, sonification, synthesizer, web, webaudio, websocket]",0
beetrandahiya,ChelseaJS,,https://github.com/beetrandahiya/ChelseaJS,https://api.github.com/repos/ChelseaJS/beetrandahiya,"ChelseaJS is a Javascript library for creative, generative Coding.","![home-banner](home-banner.svg)
           
ChelseaJS is a Javascript library for creative, generative Coding.

It's simple and intuitive syntax makes it easy for everyone (including non-coders) to get fimiliar with the library and start creating beautiful illustrations and learn in the process.

ChelseaJS is completely free and <a href=""https://github.com/beetrandahiya/ChelseaJS"">open source</a>.

ChelseaJS provides you with a wide functionality for drawing and composition.

ChelseaJS is ever evolving and we are always looking for new features and improvements.         

#  ChelseaJS comes with the Power of SVG

Everything you make in ChelseaJS is a SVG.


+ Can be scaled up or down to any extent without losing quality and clarity.
+ Better Performance
+ Can be modified with CSS
+ SVG produces multiple graphical elements which inturn become the part of DOM tree.
                   
# Why ChelseaJS?
+ Intuitive syntax
+ Easy to learn
+ Ultra Lightweight ( less than 22KB )
+ Amazingly Fast
+ No dependencies
+ Well documented
 
## What are you still waiting for? <a href=""https://beetrandahiya.github.io/ChelseaJS-docs/"">Get Started</a> now. 



# Know the Creator
<div align='center'> 

### Prakrisht Dahiya </a>
<div padding=""8px"">
<a href=""https://www.instagram.com/prakrishtdahiya/"">
<img src='assets/icons8-instagram-48.png' width=""48px"" hspace=""8"" >
</a>    
<a href=""mailto:beetrandahiya@gmail.com"">
<img src=""assets/icons8-gmail-48.png"" width=""48px"" hspace=""8"">
</a> 
<a href=""https://codepen.io/beetran"">
<img src='assets/Codepen.png' width=""48px"" hspace=""8"" >
</a> 
<a href=""https://www.github.com/beetrandahiya"">
<img src='assets/github_logo.png' width=""48px"" hspace=""8"" >
</a>
</div>
</div>
  

# Issues and Suggestions
[You can suggest features and point out bugs here](https://github.com/beetrandahiya/ChelseaJS/issues)

## License
This project is licensed under the [MIT License](../blob/master/LICENSE)


",25,25,1,0,art,"[animation, art, education, generative-art, graphics, html, illustration, indiedev, javascript, learning, svg]",0
doriclaudino,p5.recorder,,https://github.com/doriclaudino/p5.recorder,https://api.github.com/repos/p5.recorder/doriclaudino,"record and export p5js canvas as webm, mp4, gif","# p5.recorder

[![NPM](https://nodei.co/npm/p5.recorder.png?downloads=true&downloadRank=true&stars=true)](https://nodei.co/npm/p5.recorder/)

[![](https://data.jsdelivr.com/v1/package/npm/p5.recorder/badge?style=rounded)](https://www.jsdelivr.com/package/npm/p5.recorder)
[![npm version](https://badge.fury.io/js/p5.recorder.svg)](https://badge.fury.io/js/p5.recorder)

[![styled with prettier](https://img.shields.io/badge/styled_with-prettier-ff69b4.svg)](https://github.com/prettier/prettier)
[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/doriclaudino/p5.recorder/issues)

### Install (CDN)

```html
<!--jsdelivr-->
<script src=""https://cdn.jsdelivr.net/npm/p5.recorder@0.0.7/dist/p5.recorder.js""></script>
```

### Install (NPM)

```bash
npm install p5.drawer
or
yarn install p5.drawer
```

Example `using default options`:
```javascript
let rec = new p5.Recorder();
rec.start();

//stop after some time
rec.stop();
```


Example `using custom options`:
```javascript
let autoDownloadFile = false

//set to no download at the end
let rec = new p5.Recorder(autoDownloadFile);

let options = {
  filename: ""my_custom_name_output.webm"",
  recordAudio: true,
  audioBitRate: 128000,
  videoBitRate: ‭100000000‬ , //10 megabits
  fps: 45,
}

//passing custom configs
rec.start(options);

//stop after some time
rec.stop();

/**
 * contains current status
 * status: {
 *   frames: 0,
 *   progress: 0,
 *   state: undefined,
 *   time: undefined,
 * }
 */
rec.status;


//download the file after stop
rec.download();
```


</br> 

## default options start() method:

| **name** | **value**  |
| --- | --- |
| filename | ""p5.recorder.canvas.webm"" |
| recordAudio | true |
| audioBitRate | 128000 |
| videoBitRate | 120000000 |
| fps | 60 |


## enable audio
Don't forget to __CHECK__ enable audio (we are trying a better approach to capture audio-context on p5js-sound):

![Image description](https://i.imgur.com/LVgEuzA.png)




## commands
- yarn dev
- yarn build



## still in development

only support .webm for now

## for future reference

https://editor.p5js.org/doriclaudino/sketches/LgLw5UaBr
",25,25,5,20,art,"[art, export-video, ffmpeg, javascript, mp4, p5, p5js, sketch]",0
Spacial,awesome-arts,,https://github.com/Spacial/awesome-arts,https://api.github.com/repos/awesome-arts/Spacial,Awesome Arts is a collection of arts links and stuff.,"# Awesome Arts [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

 “The true artist is not proud… Though he may be admired by others, he is sad not to have reached that point to which his better genius only appears as a distant, guiding sun.”

- [Who gave you the best advice on being an artist, and what was it?](https://www.vulture.com/2018/11/27-artists-on-the-best-and-worst-advice-they-ever-got.html)

---

## Music

- [Music Map](https://musicmap.info/)
- [Center for Computer Research in Music and Acoustics](https://ccrma.stanford.edu)
- [Convolution Processing With Impulse Responses](https://www.soundonsound.com/techniques/convolution-processing-impulse-responses)
- [How to Listen to Music](http://www.openculture.com/2017/08/how-to-listen-to-music-a-free-course-from-yale-university.html): A Free Course from Yale University
- [Interactive Music Course Notes and Materials](https://github.com/tambien/InteractiveMusic) and the [site](https://tambien.github.io/InteractiveMusic/)
- [Coltrane Pitch Diagrams](https://medium.com/@lucas_gonze/coltrane-pitch-diagrams-e25b7d9f5093)
- [AutoEq](https://github.com/jaakkopasanen/AutoEq): Automatic headphone equalization from frequency responses
- [Get started making music](https://learningmusic.ableton.com/)
- [Rhythm and Transforms](http://sethares.engr.wisc.edu/RT.html) ([What is Rhythm?](http://sethares.engr.wisc.edu/htmlRT/whatisrhythm.html) and [Illusions of Sound Perception](http://sethares.engr.wisc.edu/htmlRT/4%20sound_illusions.html))
- [WolframTones](http://tones.wolfram.com/generate/G16aF5KBayLGZqrbyXodKZNu6fmG6ANllrjanSNAPM): An Experiment in a New Kind of Music — made possible by the Wolfram Language and A New Kind of Science
- [BASIC MUSIC THEORY FOR BEGINNERS – THE COMPLETE GUIDE](https://iconcollective.edu/basic-music-theory/)
- [Six things I sort of believe about making music](https://www.johnwhiles.com/posts/music-production-lessons.html)

### Resources

- [SoundBible.com](http://soundbible.com) offers thousands of free sound effects, sound clips, and straight up sounds.
- [Musical Chord Progression Arpeggiator](https://codepen.io/jakealbaugh/full/qNrZyw)
- [Matrix Calculator](https://www.musictheory.net/calculators/matrix)
- [coltrane](https://github.com/pedrozath/coltrane): 🎹🎸A music theory library with a command-line interface
- [The Infinite Drum Machine](https://experiments.withgoogle.com/ai/drum-machine/view/)
- [Guitar Dashboard](http://guitardashboard.com/)
- ELECTRONIC ORGY: [PIERRE HENRY](http://electronicorgy.blogspot.com/2017/07/pierre-henry-mix-pierre-henry-030-4xcd.html): MIX PIERRE HENRY 03.0 (4xCD BOX SET COMPILATION - PHILIPS - 2001) (FLAC)
- (es) [Carlos Reynoso](http://carlosreynoso.com.ar/) Homepage.
- [turtle.audio](http://turtle.audio): s a music sequencer inspired by turtle graphics programming. I have been working on this for 2 years (!!) and it's terrifying to finally show you. Please enjoy! 🔊 and [slang](http://slang.kylestetz.com) - [github](https://github.com/kylestetz/slang): a simple audio programming language implemented in JS
- [Bach Organ Works](http://www.blockmrecords.org/bach/download.htm): Complete works organized into 13 groups for download.
- [Moroccan Tape Stash](http://moroccantapestash.blogspot.com/?m=1)
- [Chords and Scales Reference](http://chords.jpglomot.com/#)
- [piano genie](https://piano-genie.glitch.me/): Have some fun pretending you're a piano virtuoso using machine learning!
- [TEST HEADPHONES](https://www.youtube.com/watch?v=X5Ck0iePWTQ&feature=youtu.be): Headphone Test Music with Test Tones
- [Zupiter](https://pointersgonewild.com/2019/10/06/zupiter-a-web-based-modular-synthesizer/): a Web-Based Modular Synthesizer
- [Yellowstone National Park’s Sound & Video Libraries Are Free for Anyone to Use](https://kottke.org/19/10/yellowstone-national-parks-sound-video-libraries-are-free-for-anyone-to-use)
- [Configure Fedora to practice and compose music](https://fedoramagazine.org/configure-fedora-to-practise-and-compose-music/)
- [SOUNDS OF THE FOREST](https://timberfestival.org.uk/soundsoftheforest-soundmap/): We are collecting the sounds of woodlands and forests from all around the world, creating a growing soundmap bringing together aural tones and textures from the world’s woodlands.
- [The sound of Venus (Venera 14) Звук Венеры (Венера-14)](https://www.youtube.com/watch?v=8jZDW53U8qQ&feature=emb_logo)
- [Lots of us learned classical music from watching old cartoons](https://twitter.com/NonsenseIsland/status/1366449816042102787), so I’m going to identify the pieces that frequently popped up.
- [Músicas da Venezuela - Com Maria Betania Hernandez e Lucas Casacio](https://www.youtube.com/watch?v=mgu2Bqk3iQA)
- [Freesound](https://freesound.org/) aims to create a huge collaborative database of audio snippets, samples, recordings, and all sorts of bleeps, ... released under Creative Commons licenses that allow their reuse.
- [Get started making sounds](https://learningsynths.ableton.com/): Drag in the box below to play a synthesizer.

### Articles

- [Groove is in the Heart: Matching Beats Per Minute to Heart Rate](https://medium.com/@Spotify/groove-is-in-the-heart-matching-beats-per-minute-to-heart-rate-271a79b7f96a)
- [Weekly Billboard Theory — Finesse](https://medium.com/that-good-you-need/weekly-billboard-theory-finesse-4b986e8096f2)
- [Speaker Wire](http://www.roger-russell.com/wire/wire.htm)
- [Colors of noise](https://www.johndcook.com/blog/2015/12/07/colors-of-noise/)
- [Tune up your sound with PulseEffects: Microphones](https://fedoramagazine.org/tune-up-your-sound-with-pulseeffects-microphones/)

### Platforms and applications

- [Music Transformer](https://magenta.tensorflow.org/music-transformer): Generating Music with Long-Term Structure. arxiv [paper](https://arxiv.org/abs/1809.04281)
- [Resonance Audio: Multi-platform spatial audio at scale](https://www.blog.google/products/google-vr/resonance-audio-multi-platform-spatial-audio-scale/)
- [VCVRACK](https://vcvrack.com/): Open-source virtual modular synthesizer. [repo](https://github.com/VCVRack/Rack)
- [Sonic Visualiser](http://www.sonicvisualiser.org/download.html) is an application for viewing and analysing the contents of music audio files.
- [Sndio](http://www.sndio.org/) is a small audio and MIDI framework part of the OpenBSD project and ported to FreeBSD, Linux and NetBSD
- [KXStudio](http://kxstudio.linuxaudio.org/index.php) is a collection of applications and plugins for professional audio production.
- [Fedora JAM](https://labs.fedoraproject.org/en/jam/) is for audio enthusiasts and musicians who want to create, edit and produce audio and music on Linux.
- [Sonic Pi](https://sonic-pi.net/) The Live Coding Music Synth for Everyone.
  - [sonic-pi/INSTALL-FEDORA.md at master · samaaron/sonic-pi](https://github.com/samaaron/sonic-pi/blob/master/app/gui/qt/INSTALL-FEDORA.md)
- [Audio Mastering Suite](http://www.hotto.de/software/audiomasteringsuite.html)
- [keithwhor/audiosynth: JS Dynamic Audio Synth](https://github.com/keithwhor/audiosynth)
- [Hacklily](https://www.hacklily.org/): Online Music Sheet Editor
- [JGuitar](https://jguitar.com/chordsearch): chord search.
- [Magenta](https://magenta.tensorflow.org/): An open source research project exploring the role of machine learning as a tool in the creative process.
- [AIVA](https://www.aiva.ai/): The Artificial Intelligence composing emotional soundtrack music.
- [eternal](https://kousun12.github.io/eternal/): This project was created for gratuitous reasons; it’s an attempt to serve an aesthetic that I appreciate, over a medium which I feel is appropriate for its expression.
- [SinGAN: Learning a Generative Model from a Single Natural Image](https://arxiv.org/abs/1905.01164)
- [Klio](https://github.com/spotify/klio): smarter data pipelines for audio. Klio is an ecosystem for processing audio files – or any binary files – easily and at scale. [Using Klio to Scale and Share Your Research - Pre-Work](https://github.com/fallonchen/ismir-klio): Code supporting the ISMIR 2020 Klio Tutorial.
- [blue](https://github.com/kunstmusik/blue): [An Integrated Music Environment](https://blue.kunstmusik.com/)
- [csound-live-code](https://live.csound.com/): [Library and web application for live coding with Csound](https://github.com/kunstmusik/csound-live-code)
- [Learn Synthesis](https://github.com/kunstmusik/learn-synthesis): Website for learning synthesis methods 
- [ChucK](https://github.com/ccrma/chuck): ChucK Music Programming Language
- [Traces](https://flaviogaete.info/traces) rests on neither extreme, yet brings a glimpse of both: the vibrating, pulsating rhythm of fragmented audio.

#### Supercollider

Exemplos básicos pra iniciar o uso do Supercollider (SC).

- [SuperCollider](https://supercollider.github.io/)
- [Supercollider stuff](supercollider/README.md): directory with supercollider examples.
- [Compiling SuperCollider](https://github.com/overtone/overtone/wiki/Compiling-SuperCollider)
- [Installing SuperCollider on Fedora](https://github.com/supercollider/supercollider/wiki/Installing-SuperCollider-on-Fedora)
- [examples/demonstrations](https://github.com/supercollider/supercollider/tree/develop/examples/demonstrations)
- [sc3ctrl](https://github.com/rfwatson/sc3ctrl): Control SuperCollider app from command line
- [supercollider-tmbundle](https://github.com/rfwatson/supercollider-tmbundle): TextMate bundle for supercollider.app
- [SuperCollider Workshop @ NIME2020](https://github.com/muellmusik/SC-NIME2020)
- [Lick the toad](https://github.com/KonVas/lick-the-toad): Sonification project using neural net and SuperCollider.

#### Sonic-Pi

- [Sonic Pi - The Live Coding Music Synth for Everyone](http://sonic-pi.net/)
- [sonic-pi/INSTALL-FEDORA.md at master · samaaron/sonic-pi](https://github.com/samaaron/sonic-pi/blob/master/app/gui/qt/INSTALL-FEDORA.md)

### PureData

- [The Pure Programming Language](https://agraef.github.io/pure-lang/)

### Programming

- [The Mystery and Music of Kaprekar Constant- 6174](http://arabale.com/blog/2014/4/29/the-mystery-and-music-of-kaprekar-constant-6174)
- [An interactive, explorable explanation about the peculiar magic of sound waves](https://github.com/joshwcomeau/waveforms)
- [“IN C”](https://codepen.io/jakealbaugh/pen/NAjdLY)
- [Granular Audio Synthesis](https://blog.demofox.org/2018/03/05/granular-audio-synthesis/)
- [Palestras](https://blog.lfzawacki.com/palestras-github/) do [Lucas Zawacki](https://twitter.com/lfzawacki), [floss music](https://lfzawacki.github.io/floss-music/) e [Processamento de Áudio com Arduino Due](https://github.com/lfzawacki/arduino-due-dsp-slides), his [soundcloud](https://soundcloud.com/lfzawacki/)
- [Machine Learning for Drummers](http://blog.petersobot.com/machine-learning-for-drummers)
- [Algorithms and Interactive Tools for Exploring Music Composition, Analysis, and Interdisciplinary Learning.](http://musicalgorithms.org/4.1/app/)
- [pytheory](https://github.com/kennethreitz/pytheory): Music Theory for Humans.
- [camp](https://github.com/mpdehaan/camp): Computer Aided Music Production
- [Python program to sequence MIDI music using a CSV spreadsheet](https://gist.github.com/maximecb/f440c1db489177c1037ec4f158cf5e4f)
- A [spectral visualizer](https://github.com/Bauxitedev/spectral-visualizer) that analyzes the frequencies of music and sound, written in Godot 3.1.
- [Green noise and Barks](https://www.johndcook.com/blog/2016/04/27/green-noise-and-barks/) [Python script](https://www.johndcook.com/blog/2016/04/27/how-to-create-green-noise-in-python/)
- [Piano Phase](http://www.pianophase.com/): This site is based on the first section from Steve Reich's 1967 piece Piano Phase. Two pianists repeat the same twelve note sequence, but one gradually speeds up. Here, the musical patterns are visualized by drawing two lines, one following each pianist.
- [mucoder tonespace](http://www.mucoder.net/en/tonespace/): chord generator and visualizer
- [soundZoom](http://www.dodeka.info/microtonal-isomorphic-keyboard-app/): SoundZoom is a digital and isomorphic keyboard that makes you explore the sound universe in a new way. The app allows you to discover new tonalities and sounds that are far beyond the traditional 12-semitone temperament. With soundZoom you can basically zoom in a semitone and divide it by either 2, 3, 4 or 12.
- [Play_The_Orchestra](https://www.hackster.io/137840/play-the-orchestra-2e32f4): Allows a user to play the orchestra via IoT technology.
- [SoundShape](https://p-rocha.github.io/SoundShape/): Crossing the bridge between Bioacoustics and Geometric Morphometrics - [github](https://github.com/p-rocha/SoundShape)
- [A Physical Intelligent Instrument using Recurrent Neural Networks](https://github.com/edrukar/intelligent_instrument)
- [My T460s running Arch Linux at the heart of my music setup.](https://www.reddit.com/r/thinkpad/comments/czhteh/my_t460s_running_arch_linux_at_the_heart_of_my/)
- [Falsehoods programmers believe about music](https://literateprogrammer.blogspot.com/2016/07/falsehoods-programmers-believe-about.html)
- [livecoding-ai-drums](https://github.com/sneha-belkhale/livecoding-ai-drums): Generate livecoding drum patterns with magenta.js
- [Making New Proteins From Music](https://www.forbes.com/sites/evaamsen/2020/03/28/making-new-proteins-from-music/)
- [alda](https://alda.io/): a music programming language for musicians. [Alda is a text-based programming language for music composition. It allows you to write and play back music using nothing but a text editor](https://github.com/alda-lang/alda).
- [html-midi-player](https://github.com/cifkao/html-midi-player):  MIDI file player and visualizer web components.
- [nnAudio](https://github.com/KinWaiCheuk/nnAudio): Audio processing by using pytorch 1D convolution network
- [Audio Scheduler VM](https://github.com/oramics/ash-vm): [An audio scheduler virtual machine](https://oramics.github.io/ash-vm/)
- [mimium](https://github.com/mimium-org/mimium): mimium (MInimal Musical medIUM) a programming language as an infrastructure for sound and music.
- [dsp](https://github.com/bmc0/dsp): An audio processing program with an interactive mode.
- [GRUV](https://github.com/MattVitelli/GRUV): is a Python project for algorithmic music generation using recurrent neural networks.
- [Audio-Effects](https://github.com/juandagilc/Audio-Effects): Collection of audio effects plugins implemented from the explanations in the book ""Audio Effects: Theory, Implementation and Application"" by Joshua D. Reiss and Andrew P. McPherson.
- [Klang](https://github.com/atheler/klang): Block based synthesis and music library for Python.
- [Playing with modular synthesizers and VCV Rack](https://fedoramagazine.org/vcv-rack-modular-synthesizers/)
- [Polyhedrus](https://github.com/ValdemarOrn/Polyhedrus) - Digital Synthesizer: Real-time Audio Synthesizer written in C++.
- [Awesome Rust Audio](https://github.com/kfrncs/awesome-rust-audio): An Awesome List for Audio Programming in Rust.
- [WASM SYNTH, or, how music taught me the beauty of math](https://timdaub.github.io/2020/02/19/wasm-synth/#f1) [repo](https://github.com/TimDaub/wasm-synth)
- [Hum Synthesizer](https://github.com/crbulakites/hum): A music notation language and synthesizer written in Rust.
- [Ceephax Acid Crew](http://www.ceephax.co.uk/index.htm): CEEPAX IS AN INTERPRETER FOR MUSIC CREATED BY CRUSTACEANS.
- [AV Linux MX Edition](http://www.bandshed.net/avlinux/)

### Local Directories

- Repositório dos exercícios das aulas de Teoria Musical da Unila, Março de 2016

      Todas as músicas serão feitas no MuseScore, Latex, Python, SuperCollider, etc..

#### License

Lembrando que os arquivos de código são GPL v3 ou superior, arquivos de música são CC By-Sa-Nc:

- *GPL v3 ou Superior*: veja [LICENSE](LICENSE).
- *Creative Commons By-Sa-NC*: veja [CC 2016](CCby-nc-sa).

### MuseScore (mscore)

Lista de arquivos do MuseScore (versão mínima: 2) de anotações de aula e exercícios.

Obs: pacote no fedora: mscore;

#### Python and Music

Códigos em geral com python e música (variados).

#### Latex

Alguns exemplos de arquivos .tex para notação musical (e alguns scripts para auxílio).

### Music News

- [The Legend of the Music Tree](https://www.smithsonianmag.com/arts-culture/the-legend-of-the-music-tree-180979792/): Exotic lumber salvaged from a remote forest in Belize is the world’s most coveted tonewood.
- [Gizmotron 2.0](http://daily.redbullmusicacademy.com/2015/06/gizmotron-feature): The Comeback of a ’70s Guitar Gadget
- [The Master Recycler](https://www.nybooks.com/articles/2018/12/20/bach-master-recycler/): Around 1730 Johann Sebastian Bach began to recycle his earlier works in a major way.
- [SACRIFICIO, RESPLANDOR Y PLEGARIA](https://m.facebook.com/story.php?story_fbid=1788207394589184&id=472559692820634&refsrc=https%3A%2F%2Fm.facebook.com%2FORQUESTAdeINSTRUMENTOSAUTOCTONOS%2Fvideos%2F1788207394589184%2F&_rdr) de Daniel Judkovski dirigida por Alejandro Iglesias Rossi en el Teatro Municipal Alberto Saavedra Perez. Grabado en la Isla del Sol del Lago Titicaca y en La Paz, Bolivia, 2005.
- [Jimi Hendrix Unplugged: Two Great Recordings of Hendrix Playing Acoustic Guitar | Open Culture](http://www.openculture.com/2014/04/jimi-hendrix-unplugged-two-rare-recordings-of-hendrix-playing-acoustic-guitar.html)
- [Listen by numbers: music and maths](https://www.theguardian.com/music/2011/jun/27/music-mathematics-fibonacci)| Music | The Guardian
- [Inside the booming business of background music](https://www.theguardian.com/news/2018/nov/06/inside-the-booming-business-of-background-music)
- [How would user-centric licensing affect music-streaming payouts?](https://musically.com/2018/03/02/user-centric-licensing-really-affect-streaming-payouts/)
- [Old Digital Cameras](http://old-digitalcameras.com/): Here is my collection of 600+ ""old"" digital cameras.
- [Twenty Instruments Reconstructed to Play Through the Keys of a Vintage Piano](https://www.thisiscolossal.com/2019/01/twenty-instruments-play-through-a-vintage-piano/)
- [The Day the Music Burned](https://www.nytimes.com/2019/06/11/magazine/universal-fire-master-recordings.html): It was the biggest disaster in the history of the music business — and almost nobody knew. This is the story of the 2008 Universal fire.
- [Leonardo da Vinci's forgotten musical invention has been created for the first time](https://www.classicfm.com/music-news/leonardo-da-vinci-viola-organista/)
- [MINIDISCS [HACKED]](https://radiohead.bandcamp.com/album/minidiscs-hacked) ([raw link](https://bandcamp.com/EmbeddedPlayer/album=540938686/size=large/bgcol=ffffff/linkcol=0687f5/transparent=true/)) by Radiohead
- [Music Inspired by Astronomy](https://www.skyandtelescope.com/astronomy-news/people-places-and-events/music-astronomy-catalog/): A Catalog
- [Storing data in music](https://www.sciencedaily.com/releases/2019/07/190709122014.htm)
- [Researchers' AI aligns sheet music with MIDI audio](https://venturebeat.com/2020/07/22/researchers-ai-aligns-sheet-music-with-midi-audio/)
- [Deciphering Chopin’s shorthand in the posthumous Mazurka in F minor](https://www.claviercompanion.com/article-details/deciphering-chopin-s-shorthand-in-the-posthumous-mazurka-in-f-minor)
- [The Pudding](https://pudding.cool/2018/06/music-map/): #1 Songs in 3,000 Cities
- [How many artists overshadow their band after going solo?](https://pudding.cool/2021/04/solo/)
- [45 Lost Albums We Want To Hear](https://www.stereogum.com/2004872/lost-shelved-unreleased-albums/lists/album-list/)
- [Keith Richards Demonstrates His Famous 5-String Technique (Used on Classic Stones Songs Like “Start Me Up,” “Honky Tonk Women” & More)](https://www.openculture.com/2021/05/keith-richards-demonstrates-his-famous-5-string-technique.html)
- [Jazz and music theory](https://twitter.com/vcmusictheory/status/1387121552878149633)
- [‘That was the day I knew I had died … ’ José Mauro, Brazilian music’s reborn genius](https://www.theguardian.com/music/2021/jun/02/that-was-the-day-i-knew-i-had-died-jose-mauro-the-reborn-genius-of-bossa-nova?CMP=twt_a-culture_b-gdnculture)
- [Universal's Audible Watermark](https://www.mattmontag.com/music/universals-audible-watermark)

---

## Circus

- [Siteswap FAQ](http://www.juggling.org/help/siteswap/faq.html)
- [That time Steve Jobs hired a career juggler to teach programming to developers](https://www.cake.co/conversations/w3j7jDp/that-time-steve-jobs-hired-a-career-juggler-to-teach-programming-to-developers)
- [The Big-Tent Family](https://medium.com/vantage/life-on-the-road-with-the-circus-4bc911a3cae4): Photographer Norma I. Quintana spent 10 summers following a one-ring circus. [book to order](https://normaiquintana.squarespace.com/circus-listing/circus-a-traveling-life)
- [Fanfare Ciocarlia - Moliendo Cafe](https://www.youtube.com/watch?v=QiHmiZQNgL4): good music for circus.

---

## Literature

- [The Best Books of 2019 (So Far)](https://kottke.org/19/06/the-best-books-of-2019-so-far)
- [What Germans Are Reading](https://www.the-american-interest.com/2019/08/03/what-germans-are-reading/)

### Poetry

- The poetry and brief life of a Foxconn worker: [Xu Lizhi](https://libcom.org/blog/xulizhi-foxconn-suicide-poetry)(1990-2014)
- [HTTP/2 204](https://ja.cob.land/http2-204-a-poem) (a poem)

## Writing

- [Who Pays Writers?](http://whopayswriters.com/#/results) is an anonymous, crowd-sourced list of which publications pay freelance writers—and how much. This list is primarily concerned with journalistic writing for publications; we do NOT collect information about copywriting, advertising, corporate, tech-startup blogs, or sponsored-content assignments.
- [Words that do Handstands](http://hardmath123.github.io/ambigrams.html)
- [One Neat Trick to Writing Great Mystery Plots](https://www.vulture.com/2019/10/charles-finch-on-how-he-writes-charles-lenox-mysteries.html)
- [Kurt Vonnegut](https://www.youtube.com/watch?v=GOGru_4z1Vc), Shape of Stories

### Spirituality

- [No Self Nirvana](https://noselfnirvana.com) Quotes, practices, poetry about mindfulness, concentration, insight, impermanence, emptiness, aimlessness, signlessness, nirvana.

---

## Painting

- [Nusay Gallery - Official website](https://nusaygallery.com/)
- [Seventy-Five Ways to Draw a Circle](https://sighack.com/post/seventy-five-ways-to-draw-a-circle) · Sighack
- [THE COLLECTION](https://www.artic.edu/collection?is_public_domain=1) - Art Institute of Chicago
- [How Banksy Authenticates His Work](https://reprage.com/post/how-banksy-authenticates-his-work)

---

## Photography

- [Introducing Elodie:](https://medium.com/@jmathai/introducing-elodie-your-personal-exif-based-photo-and-video-assistant-d92868f302ec) Your Personal EXIF-based Photo and Video Assistant. [github](https://github.com/jmathai/elodie)
- [LIGHT PAINTING ANIMATIONS DIRECTLY FROM BLENDER](https://hackaday.com/2018/07/30/light-painting-animations-directly-from-blender/)
- [canon_cr3](https://github.com/lclevy/canon_cr3): Describing the Canon CR3 fileformat from Canon M50 / EOSR
- [Sagittarius Rising](https://jpcvanheijst.com/blogs/2018/09/711348-sagittarius-rising-n-long-exposure-photography-from-the-stratosphere-7-minute-read)– Long exposure photography from the stratosphere.
- [O realismo mágico da fotografia de Izan Petterle](https://brasil.elpais.com/brasil/2018/08/31/album/1535728846_339466.html)
- [World’s fastest camera freezes time at 10 trillion frames per second](http://www.inrs.ca/english/actualites/worlds-fastest-camera-freezes-time-10-trillion-frames-second)
- [The Color Photography of Vivian Maier](https://petapixel.com/2018/11/16/the-color-photography-of-vivian-maier/)
- (pt-br) [News by Lucas Landau](http://www.lucaslandau.com/news)
- [Remove Image Background](https://www.remove.bg)
- [For What It's Worth](http://www.dillonmarsh.com/fwiw.html) by DILLON MARSH
- [Over 6,000 Ottoman-Era Photographs Now Available Online](https://hyperallergic.com/478505/getty-research-institute-ottoman-photography/)
- [WHAT MAKES A PICTURE GOOD?](https://phillipreeve.net/blog/what-makes-a-picture-good/)
- [12 Classic Mistakes We’ve All Made Trying To Make Better Prints](https://www.johnpaulcaponigro.com/blog/39066/11-classic-mistakes-weve-all-made-trying-to-make-better-prints/)
- [igua∞u](https://margenscosturas.wordpress.com/livro/): paisagem humana na tríplice fronteira / Marcelo Marinho, Henrique Gazzola.
- [Astronomy Photographer of the Year shortlist](https://www.rmg.co.uk/national-maritime-museum/astronomy-photographer-year-2021-shortlist-images)
- [Four Seasons in the Life of a Finnish Island](https://kottke.org/18/04/four-seasons-in-the-life-of-a-finnish-island)
- [How to Develop Black & White Film at Home With Coffee](https://www.fieldmag.com/articles/how-to-develop-film-with-coffee-caffenol-guide)

### Photo Tech

- [Scientists Use Camera with Human-Like Vision to Capture 5,400 fps Video](https://petapixel.com/2019/07/09/scientists-use-camera-with-human-like-vision-to-capture-5400-fps-video/)

---

## Cinema

- [Akira Kurosawa Names His 21 Favorite Art Films in the Criterion Collection | Open Culture](http://www.openculture.com/2017/06/akira-kurosawas-names-his-21-favorite-art-films-in-the-criterion-collection.html)
- [The cult of Stanley Kubrick](https://www.economist.com/prospero/2018/12/10/the-cult-of-stanley-kubrick)
- [‘Suspiria’](https://theflipflopreviews.wordpress.com/2019/01/23/luca-guadagnino-suspiria-review/): Luca Guadagnino’s ‘Suspiria’ Simulates The Act Of Fucking An Otherworldly Being
- [‘Apollo 11’ Trailer](https://www.slashfilm.com/apollo-11-trailer-never-before-seen-nasa-footage-becomes-a-stunning-documentary/): Never-Before-Seen NASA Footage Becomes a Stunning Documentary
- [Buster Keaton](http://www.lapsuslima.com/buster-keaton-anarchitect/): Anarchitect
- In Search of Our Better Selves: The Rebirth, Redemption and Road Warriors of [George Miller’s ‘Mad Max: Fury Road’](https://cinephiliabeyond.org/mad-max-fury-road/)
- [TONY SCOTT explains](https://twitter.com/vashikoo/status/1154919540142116866?s=20) how he used 4 cameras to film the kidnap scene in MAN ON FIRE and how he visually tried to show the confusion and disorientation experienced by Denzel Washington's character. Creating emotion through technical means was one of his great strengths.#filmmaking
- [The Very Slow Movie Player](https://kottke.org/18/12/the-very-slow-movie-player) is [here](https://medium.com/s/story/very-slow-movie-player-499f76c48b62)
- [Python For Feature Film](https://www.gfx.dev/python-for-feature-film)
- [Why Do Wes Anderson Movies Look Like That?](https://www.youtube.com/watch?v=ba3c9KEuQ4A) [THE GRAND BUDAPEST HOTEL: Wes Anderson takes the 4:3 challenge](http://www.davidbordwell.net/blog/2014/03/26/the-grand-budapest-hotel-wes-anderson-takes-the-43-challenge/)
- [Stanley Kubrick Interview (27th November 1966)](https://www.youtube.com/watch?v=xa-KBqOFgDQ)
- [Kubrick’s Lenses – The Ultimate Guide to the Lenses Used by Stanley Kubrick](https://indiefilmhustle.com/stanley-kubrick-lenses/)
- [A desconhecida vida de Anthony Hopkins, o vencedor do Oscar 2021 que aprendeu a ser feliz aos 75](https://brasil.elpais.com/cultura/2021-04-25/a-desconhecida-vida-de-anthony-hopkins-o-ator-indicado-ao-oscar-2021-que-aprendeu-a-ser-feliz-apos-os-75.html)
- [A Supercut of Supercuts: Aesthetics, Histories, Databases](https://openscreensjournal.com/articles/10.16995/os.45/)
- [""Dune"" (the movie), annotated](https://maxread.substack.com/p/dune-annotated)
- [Heaven and Earth Magic](https://www.youtube.com/watch?v=zbjSSyAo9WA): some Terry Gilliam's references.

### Videos

- [C O N T A C T](https://vimeo.com/320306886)
- [APAGANDÔ](https://homeostasislab.org/visualizar/obra/2072)
- [A Decade of Sun](https://kottke.org/20/06/a-decade-of-sun) and [Gorgeous Time Lapse of the Sun](https://kottke.org/14/11/gorgeous-time-lapse-of-the-sun) 
- [Incredible time-lapse shows a single cell transforming into a salamander](https://www.nationalgeographic.com/animals/article/time-lapse-film-shows-salamander-development)
- [Starlings making the shape of a bird](https://www.youtube.com/watch?v=L_u4IcRy2dw)
- [Hong Kong BLOCKS / Experimental short film](https://www.youtube.com/watch?v=EJD77Ckbqxg&t=163s)
- [Time Lapse of the Changing Seasons of Denmark](https://kottke.org/21/08/time-lapse-of-the-changing-seasons-of-denmark)
- [Tara The Android - I Feel Fantastic](https://www.youtube.com/watch?v=QaY48Yz1U08)

### Tools

- [Introducing Olive, new non-linear video editor | Libre Graphics World](http://libregraphicsworld.org/blog/entry/introducing-olive-new-non-linear-video-editor), github: [olive](https://github.com/olive-editor/olive/): Professional open-source NLE video editor

---

## Theatre

- [THE BOOKS THAT MADE DRACULA](http://www.londonlibrary.co.uk/dracula)
- [The mystery of what makes a joke funny](https://theconversation.com/the-mystery-of-what-makes-a-joke-funny-but-only-to-some-people-125769) – but only to some people

---

## Visual

- [CREATIVE CODING MANIFESTO 2021](https://brm1sxuu.myraidbox.de/creative-coding-manifesto-2021/)
- [one visual idea a day](https://villares.github.io/sketch-a-day/)
- [Video Music](https://codepen.io/jakealbaugh/full/ZxLKvG/) and [Sonic Pixels](https://github.com/jakealbaugh/sonicpx) (encodes audio in images by storing audio samples inside of pixels. The images it creates can be decoded and played back as audio.) - both by [Jake Albaugh](https://codepen.io/jakealbaugh/)
- [Video Hub App](https://videohubapp.com/)
- [Spiral Test](https://gist.github.com/Bleuje/5cfe3bf5d83b63805389bbaf45ae73fb) (in processing)
- [The Pioneer of Generative Art: Georg Nees](https://www.mitpressjournals.org/doi/abs/10.1162/leon_a_01325)
- [My journey into fractals](https://medium.com/@bananaft/my-journey-into-fractals-d25ebc6c4dc2)
- [Mindstamp](https://mindstamp.io/): Create Engaging Interactive Videos in Seconds
- [Manolo Gamboa Naon on Behance](https://www.behance.net/manoloide)
- [Quantum Garden](http://quantum.garden/) is a citizen science project where everyone can contribute to solve a quantum physics research problem of crucial importance for the outbreak of quantum technologies.
- [processing-video](https://github.com/gohai/processing-video): Experimental video library using GStreamer 1.0
- [The Inferno](https://www.alpacaprojects.com/inferno/en/): The illustrated and interactive Dante's Inferno, an alternative learning tool for the Divine Comedy first Cantica, made for aiding visual memory.
- [Logarithmic spiral - Wikipedia](https://en.wikipedia.org/wiki/Logarithmic_spiral)
- [Boris Labbé](https://www.borislabbe.com/): Graphic artist from his beginning, Boris Labbé has been developing, over the last eight years, an approach in animated video. Experiment after experiment, the film he develops tend to leave the spatio-temporal pattern imposed by the classical cinema, evolving towards video installation devices that include major technological revolutions of the past century, crossed with the latest digital technology generations. All his videos, like a part of the experimental film heritage have the emblem of the palingenesis, concept making both appeal to the loop and regeneration : cyclical return of the same events ; regular reappearance of ancestral characters ; perpetual return to life.
- [A Beautifully-Designed Edition of Euclid’s Elements from 1847 Gets Digitized](http://www.openculture.com/2018/12/a-beautifully-designed-edition-of-euclids-elements.html): Explore the New Online, Interactive Reproduction
- [alcFreeliner](https://github.com/maxdee/alc_freeliner): [live geometric animation tool powerhouse](https://freeliner.xyz)
- [tilde.town](https://tilde.t) is a computer meant for sharing.
- [p5.js](https://p5js.org/community/)
  - [Carlos de Oliveira Junior's Waves](https://observablehq.com/@vamoss/py5js)
- [q5xjs](https://github.com/LingDong-/q5xjs): A small and fast alternative (experimental) implementation of p5.js 
- [g9.js](http://omrelli.ug/g9/gallery/) - [Automatically Interactive Graphics](https://github.com/bijection/g9)
- [arcologies](https://tyleretters.github.io/arcologies-docs/): [an interactive environment](https://github.com/tyleretters/arcologies) for [designing 2d sound arcologies with norns and grid](https://github.com/tyleretters/arcologies-m4l)
- Some works by [Daniel Buzzo](https://github.com/danbz/):
  - [art-and-code](https://github.com/danbz/art-and-code): demo code from youtube video tutorials and how-tos.
  - [volume-camera](https://github.com/danbz/volume-camera): multisensory depth-camera experiment
  - [Generative Systems for Art and Design](https://github.com/uwe-creative-technology/generative_systems) course materials
  - [Workshop](https://github.com/generative-drawing/generative-drawing.github.io): Introduction to Generative Drawing with pencils, paper, C++ and openFrameworks
- NOITE DE PROCESSING: [Redes Neurais Gerativas](https://www.youtube.com/watch?v=hgGTCe1AEDU) - Sergio Venancio
- [Shoebot](http://shoebot.github.io/shoebot/): [Easy vector graphics with Python](https://github.com/shoebot/shoebot)
- [Casual Creators: Defining a Genre of Autotelic Creativity Support Systems](https://escholarship.org/uc/item/4kg8g9gd#article_main): Artists, musicians, writers and designers use tools to be creative, whether they are designing a personal opus or producing work for hire. There are many more people who are neither paid professionals nor historic geniuses, but who also enjoy being creative in a casual way. Can we design systems to help these casual users engage with their creative sides?
- [aRt](https://github.com/gkaramanis/aRt): Making art with R
- [Saskia Freeke](https://blog.adafruit.com/2020/11/03/digitalfruit-saskia-freeke/)
- [Iterative Partial Match (IPM) vs Wave Function Collapse (WFC) for procedural content generation.](https://stalcup.github.io/static-files/posts/wfc-vs-ipm/)
- Clemens Wenger: [Physics of Beauty](https://physicsofbeauty.art/)
- [these start from a single line, then a random line (edge) is cloned, rotated around the middle, then intersected with the its twin. some new sub-edges are discarded. repeat.](https://twitter.com/inconvergent/status/1308094415328731136?s=19)
- [studio sketchpad](http://studio.sketchpad.cc/sp/account/sign-in?cont=http%3a%2f%2fstudio.sketchpad.cc%2f)
- [gridder](https://github.com/jsbueno/gridder): Python snippets for grid-drawing, game-of-life-like toys and simulators.
- [Shoebot](https://shoebot.github.io/shoebot/): Generate vector graphics with Python
- [The Color of Water](https://algorithmicsea.com/): Algorithmic Sea.
- [An Atlas of Emotions](https://artsexperiments.withgoogle.com/art-emotions-map/) by Google
- [Noise in Creative Coding](https://varun.ca/noise/)
- [Homeostasis lab](https://opencall.homeostasislab.org/bem-vindo)
- [Creative coding algorithms & techniques](https://www.notion.so/Creative-coding-algorithms-techniques-c5550ef2f7574126bdc77b09ed76651b)
- [Programação Criativa](https://github.com/arteprog/programacao-criativa): Material do curso introdutório Programação Criativa de Monica Rizzolli e Alexandre Villares, em construção. [Programação Criativa: Arte Feita em Código](https://hackmd.io/@RQBGVE5GQnK7StPX6B6H8g/SJV81ay2u)
- [Frost Science Museum](https://superuber.com/frost-science-museum/)
- [The Color of Water](https://algorithmicsea.com/): Algorithmic Sea
- [GRAFICA Obscura](http://graficaobscura.com/): This is a compilation of technical notes, pictures and essays that I've accumulated over the years.
- [Abstraction from Valeris](https://valeris-media.tumblr.com/): [Moving GIF Abstraction from Valeris #ArtTuesday](https://blog.adafruit.com/2021/11/02/moving-gif-abstraction-from-valeris-arttuesday/)
- [The Weird and Wonderful World of AI Art](https://jxmo.notion.site/The-Weird-and-Wonderful-World-of-AI-Art-b9615a2e7278435b98380ff81ae1cf09)

### Processing

- [All my sketches of Processing](https://github.com/manoloide/AllSketchs) by [manoloide](https://github.com/manoloide)
- [Research essay: The History of Processing](https://maxoffsky.com/research/research-essay-the-history-of-processing/)
- [Alexandre B A Villares](http://abav.lugaralgum.com/sketch-a-day/)
- [sketches](https://github.com/berinhard/sketches/): my sketches created with [processing](https://berinhard.github.io/sketches/)
- [Berin's sketches](https://berinhard.github.io/sketches/): This is a list of sketches I'm creating while learning and exploring Processing.
- [ProcessingTeachingSketches](https://github.com/jeffThompson/ProcessingTeachingSketches): Teaching sketches created in Processing (and Java)
- [command](https://github.com/davidbouchard/command): A tiny library for Processing to run external programs and commands from a sketch (and capture their output if needed).
- [haxademic](https://github.com/cacheflowe/haxademic): A personal toolkit for Java/Processing projects in Eclipse
- [ppython](https://github.com/Abdur-rahmaanJ/ppython): Implementation of processing.org's processing in pure python. No dependency, no import and no run().
- [Processing](http://www.dainf.ct.utfpr.edu.br/~merkle/processing/reference/ptBR/index.html): Linguagem (Interface para programação de Aplicações, Application Programming Interface - API).
- [Resources for teaching programming](https://github.com/villares/Resources-for-teaching-programming)
- [A-na5 - 2020/10/03](https://a-na5.tumblr.com/post/630946505418817536/20200209-code-i-could-tweet)
- [100 formas de contar de 1 a 100 utilizando programação](https://1-100.github.io/)
- [Dancing Sphere](https://twitter.com/yuruyurau/status/1226297447460163584)
- [PCD-Brasil-2021-FiltroVideo](https://github.com/Processing-Brasil/PCD-Brasil-2021-FiltroVideo)
- [Open Call for 2021 Fellowships](https://medium.com/processing-foundation/open-call-for-2021-fellowships-44c777cc335)

### Visual Python

- [creativecodinginpython](https://github.com/sheena1010/creativecodinginpython)
- [pyp5js](https://berinhard.github.io/pyp5js/): [Python to P5.js Transcriptor](https://github.com/berinhard/pyp5js)

## Noise

- [Randomness and Perlin Noise](http://makeyourownalgorithmicart.blogspot.com.br/2018/02/randomness-and-perlin-noise.html)

## Colors

- [Perceptually uniform color spaces](https://programmingdesignsystems.com/color/perceptually-uniform-color-spaces/)
- [#c0ffee is the color](http://c0ffee.surge.sh)
- [Colour Science for Python](https://github.com/colour-science/colour)
- [color-thief](https://github.com/lokesh/color-thief): Grabs the dominant color or a representative color palette from an image. Uses javascript and canvas.
- [colorgram.py](https://github.com/obskyr/colorgram.py): is a Python library that lets you extract colors from images. Compared to other libraries, the colorgram algorithm's results are more intense.
- [UI design for software developers. Part 1, Colors](http://amortizedcost.net/ui-desing-for-software-developer-part-1/)
- [Your browser and my browser see different colors](https://mux.com/blog/your-browser-and-my-browser-see-different-colors/)
- [why we're blind to the color blue](https://calebkruse.com/10-projects/seeing-blue/): we'll explore why our eyes are unable to focus on the color blue, and how we see with our brain as much as with our eyes.

## Threads

- [ThreadTone](http://www.thevelop.nl/blog/2016-12-25/ThreadTone/)
- [String art - Wikipedia](https://en.wikipedia.org/wiki/String_art)

## Illustrations

- [Humaaans](https://www.humaaans.com/)
- [Syndicate Studio](https://syndicatestudio.co/):  Creative Studio based in Semarang, Indonesia. 

## Painting

- [How To Get Better at Painting](http://www.learning-to-see.co.uk/how-to-get-better-at-painting-without-painting-anything): Without Painting Anything.
- [Night Watch, Militia Company of District II under the Command of Captain Frans Banninck Cocq, Rembrandt van Rijn, 1642](https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-photo): This is the largest and most detailed photo ever taken of a work of art. It is 717 gigapixels, or 717,000,000 pixels, in size.

---
## Curation and Presentation

- [A Manual for the Display of Interactive New Media Art](https://inmamanual.wordpress.com/)

## Games

- [GPU Performance for Game Artists](http://www.fragmentbuffer.com/gpu-performance-for-game-artists/)
- [8bit games in browser emulator](https://floooh.github.io/tiny8bit/). [github](https://github.com/floooh/chips-test)
- [SWAGGINZZZ](https://pellsson.github.io/): In what was her first game of NetHack ever, SWAGGINZZZ struggled. She constantly bumped into walls, and oftentimes found herself with critically low HP. The setbacks would not deter her however, and after 7 minutes and 15 seconds she ended up ascending – having taken 2087 in-game turns to do so.
- [Color Emulation](https://byuu.net/video/color-emulation): In this article, I'll walk through the importance of color emulation, and provide some example code and screenshots.
- [wick editor](https://www.wickeditor.com/): [The Wick Editor is a free](https://github.com/Wicklets/wick-editor), open-source tool for creating games, animations, and everything in-between!
- [game-programming-patterns](https://github.com/munificent/game-programming-patterns): Source repo for the book

## Software

- [A gallery of 130+ Gimp filters/effects examples](https://alvinalexander.com/design/gimp-catalog-filters-effects-examples-cheat-sheet)
- [Rexpaint](https://www.gridsagegames.com/rexpaint/): is a powerful and user-friendly ASCII art editor. Use a wide variety of tools to create ANSI block/line art, roguelike mockups and maps, UI layouts, and for other game development needs.
- [Jeff Thompson](http://www.jeffreythompson.org/index.php)
- [Awesome-Design-Tools](https://github.com/LisaDziuba/Awesome-Design-Tools): The best design tools for everything.
- [BIRDFONT](https://birdfont.org): is a free font editor which lets you create vector graphics and export TTF, OTF, EOT and SVG fonts. The editor has good support for both monochrome and color font formats.
- [inspect-open-images](https://github.com/gecid-aia/inspect-open-images): Python utilitary to help to download, crop and derivate new images from Open Image V6 dataset
- [NaNoWriMo](https://www.omnicalculator.com/other/nanowrimo): National Novel Writing Month, or NaNoWriMo for short, is a writing challenge. Every November, thousands of writers from all around the world commit to writing 50,000 words of their own prose in a month.
- [VUO](https://vuo.org/what-is-vuo): is an application to help people develop interactive experiences, live performances, digital media, and more.

## Fonts

- [CSS SANS](https://yusugomori.com/projects/css-sans/)
- [Fonts and UFO Masters of Inria Serif and Inria Sans Typeface](https://github.com/BlackFoundry/InriaFonts) [more](https://black-foundry.com/fonts/)
- [Reforma](https://pampatype.com/blog/reforma): A new voice for an institution with deep roots
- [Sans Forgetica](http://sansforgetica.rmit/): Sans Forgetica is a downloadable font that is scientifically designed to help you remember your study notes.
- [Typedia](http://typedia.com/): A Shared Encyclopedia of Typefaces
- [WALL-e](https://typesetinthefuture.com/2018/12/04/walle/): From a trash-filled Earth to the futuristic Axiom and back again, WALL·E is a finely crafted balance between consumerist dystopia and sixties space-race optimism.
- [Comic Neue](http://comicneue.com)
- [LIBERTINE FONTS](http://libertine-fonts.org/): Libre multilingual font family
- [inter](https://github.com/rsms/inter): Inter is a typeface specially designed for user interfaces with focus on high legibility of small-to-medium sized text on computer screens.
- [Optima](https://github.com/wsshin/website/tree/master/fonts)
- [macFonts](https://github.com/potyt/fonts)
- [Guide to Only the Best Open-Source Typefaces](https://beautifulwebtype.com/)
- [Cascadia Code](https://github.com/microsoft/cascadia-code)
- [hellveticafont](https://hellveticafont.com/)
- [Neon Genesis Evangelion](https://fontsinuse.com/uses/28760/neon-genesis-evangelion)
- [APL386 Unicode](https://abrudz.github.io/APL386/) ([source](https://github.com/abrudz/APL386))
- [wavefont](https://github.com/audio-lab/wavefont): Typeface for rendering data
- [BitmapFonts](https://github.com/ianhan/BitmapFonts): My collection of bitmap fonts pulled from various demoscene archives over the years
- [font of web](https://fontofweb.com/): Type a Website and Find Its Fonts
- [Relief SingleLine typeface](https://github.com/isdat-type/Relief-SingleLine)
- [First Batch of Color Fonts Arrives on Google Fonts](https://material.io/blog/color-fonts-are-here)

## Fun

- [VINTAGE CASSETTES: 1963-2010](http://vintagecassettes.com)
- [At the Internet Archive, this is how we digitize #78 rpm records.](https://canaltech.com.br/musica/conheca-o-processo-de-digitalizacao-de-discos-de-vinil-do-internet-archive-183805/)
- [HEXEN 2.0](http://www.suzannetreister.net/HEXEN2/TAROT_COL/HEXEN_2_TAROT.html) (tarot)
- [U.S.A. Song Map](https://www.wearedorothy.com/collections/world-maps/products/u-s-a-song-map-open-edition)
- [Rain Simulator](http://rainbowhunt.me/)
- [Generating Beatles’ Lyrics with Machine Learning](https://towardsdatascience.com/generating-beatles-lyrics-with-machine-learning-1355635d5c4e)
- [Gujarati Type Foundry Type Book](http://oa.letterformarchive.org/item?workID=lfa_type_0401&targPic=LFA_Type_0401_032.jpg)
- [Studio Ghibli Makes 1,178 Images Free to Download from My Neighbor Totoro, Spirited Away & Other Beloved Animated Films](https://www.openculture.com/2020/12/studio-ghibli-makes-1178-images-free-to-download.html): [新しく、スタジオジブリ5作品の場面写真を追加提供致します](https://www.ghibli.jp/info/013409/)
- [Healing Grid Optical Illusion](https://kottke.org/21/04/healing-grid-optical-illusion), by [Ryota Kanai](http://illusionoftheyear.com/2005/08/healing-grid/)
- [Animals Laugh Too: UCLA Study Finds Laughter in 65 Species, from Rats to Cows](https://www.openculture.com/2022/01/animals-laugh-too-ucla-study-finds-laughter-in-65-species-from-rats-to-cows.html)
- [Awesome Self-Reference](https://github.com/aztek/awesome-self-reference): A curated list of examples of self-reference in art, science, and technology.

## Drivers

- [Scream](https://github.com/duncanthrax/scream) - Virtual network sound card for Microsoft Windows

## Hardware

- Beautiful Tech: [Roland RE 201 Space Echo](http://www.musicofsound.co.nz/blog/beautiful-tech-roland-re-201-space-echo) | Music of Sound

## Slides

Some tips to make beautiful slides:

- [Code highlighting for Keynote presentations](https://gist.github.com/jimbojsb/1630790)
- [highlight Theme-Samples](http://www.andre-simon.de/doku/highlight/en/theme-samples.php)
- [listings - How can I automatically highlight SuperCollider symbols and environment variables? - TeX - LaTeX Stack Exchange](https://tex.stackexchange.com/questions/159245/how-can-i-automatically-highlight-supercollider-symbols-and-environment-variable)

## Inspiration

- [Beethoven’s Advice on Being an Artist](https://www.brainpickings.org/2017/05/18/beethoven-emilie-letter/): His Touching Letter to a Little Girl Who Sent Him Fan Mail
- [web-tweeps](https://github.com/iRaul/web-tweeps): A curated list of developers / designers / artists on twitter. ⚡️
- [THE WORLD’S WRITING SYSTEMS](http://worldswritingsystems.org/)
- [Talking AI, Art, and Entangled Realities with HeK Basel’s Director Sabine Himmelsbach](https://medium.com/digital-art-weekly-by-danae-hi/talking-ai-art-and-exhibition-entangled-realities-with-hek-basels-director-sabine-himmelsbach-654b7077c0a0)
- [24h Sunrise/Sunset](https://driesdepoorter.be/24h-sunrise-sunset/): is an installation that displays a realtime sunset and sunrise somewhere happening in the world with the use of CCTV. by Dries Depoorter.
- [How foundation works.](https://foundation.app/how-it-works)
- [In Praise of Idleness](https://harpers.org/archive/1932/10/in-praise-of-idleness/), by Bertrand Russell
- [XXXX Swatchbook](http://www.evelinkasikov.com/XXXX-Swatchbook)
- [TERRA INCOGNITA 1 : KAMILYA JUBRAN, FLOY KROUCHI, YOUMNA SABA](https://www.banlieuesbleues.org/plateforme/evenement/3352/2021-04-09-2000-festival-plateforme-terra-incognita-1-kamilya-jubran-floy-krouchi-youmna-saba/)
- [Símbolos Indígenas](https://symbolismofthings.com/significado-simbolos-indigenas-simbolismo/), [Marajoara](https://www.dicionariotupiguarani.com.br/dicionario/marajoara/), [Ancient Protection Symbols](https://givemehistory.com/symbols-of-protection)
- [Kunza](http://www.memoriachilena.gob.cl/archivos2/pdfs/mc0038216.pdf): diccionario kunza-español, lengua del pueblo lickan antai (atacameño).
- [The 10 Paradoxical Traits of Creative People, According to Psychologist Mihaly Csikszentmihalyi](https://www.openculture.com/2021/11/the-10-paradoxical-traits-of-creative-people-according-to-psychologist-mihaly-csikszentmihalyi-rip.html)

### People

- [LUISA PEREIRA](http://www.luisapereira.net/)
- [Guilherme Ranoya](https://www.ranoya.com/public/profile/?nonew=true)
- [noite do bprocessing](https://garoa.net.br/wiki/Noite_de_Processing) no garoa hacker clube
- [Manuel Corman](https://manueljosephcorman.wixsite.com/manu/)
- [JACQUES PERCONTE](https://www.jacquesperconte.com/). [Tempestaire :: E3:NJAINF_017_20200125_2011](https://vimeo.com/504338055)

## Art+Tech Universities

- [Poéticas Interdisciplinares](https://www.ppgav.eba.ufrj.br/programa/linhas-de-pesquisa/poeticas-interdisciplinares/)/UFRJ
- [PPGIS](http://www.ppgis.ufscar.br/)/UFSCAR
- [Programa de Pós-Graduação em Artes Visuais](http://www3.eca.usp.br/pos/ppgav)/USP
- [Programa de Pós-Graduação em Design da FAUUSP](https://www.fau.usp.br/ensino/pos-graduacao/design/)
- [Future Sketches group](https://www.media.mit.edu/groups/future-sketches/overview/)

## NFT

- [hic et nunc](https://www.hicetnunc.xyz/): The present decentralized application allows its users to manage decentralized digital assets, serving as a public smart contract infrastructure on Tezos Blockchain.
- [Arrangement created by Mario Klingemann / @Quasimondo](https://here-or-there.glitch.me/index.html)
- [bulk-upload-to-opensea](https://github.com/infotrex/bulk-upload-to-opensea): BULK UPLOAD NFTs to OPENSEA.

---

## News

### 2018

- [Generative Art Finds Its Prodigy — Artnome](https://www.artnome.com/news/2018/8/8/generative-art-finds-its-prodigy)
- [What We Know About Art and the Mind](https://www.newyorker.com/culture/cultural-comment/what-we-know-about-art-and-the-mind)
- [CAN](https://arxiv.org/abs/1706.07068): Creative Adversarial Networks, Generating ""Art"" by Learning About Styles and Deviating from Style Norms
- [The Sound of Pixels](http://sound-of-pixels.csail.mit.edu/)
- [The Great Chinese Art Heist](https://www.gq.com/story/the-great-chinese-art-heist)
- [How the Brain Experiences Time](https://neurosciencenews.com/time-perception-9771/)
- [BienalWebApp](http://app33.bienal.org.br/#/audioguia/audioguia-detalhe/5426)
- [The Other Secret Twist: On the Political Philosophy of The Good Place - Los Angeles Review of Books](https://lareviewofbooks.org/article/secret-twist-political-philosophy-good-place/#!)
- [Excerpt: Eric Idle’s Always Look on the Bright Side of Life](http://www.vulture.com/2018/10/eric-idle-book-monty-python-always-look-on-the-bright-side-of-life.html)
- [The Art Institute of Chicago Has Put 50,000 High-Res Images from Their Collection Online](https://kottke.org/18/11/the-art-institute-of-chicago-has-put-50000-high-res-images-from-their-collection-online)
- [The Graphic Art of Incredibles 2](http://joshholtsclaw.com/blog/2018/3/5/the-graphic-art-of-incredibles-2)
- [Monty Python and the Holy Grail Censorship Letter: We Want to Retain ""Fart in Your General Direction"" | Open Culture](http://www.openculture.com/2014/09/monty-python-and-the-holy-grail-censorship-letter.html)
- [WHY ARE SO MANY DUDES LOSING THEIR SHIT OVER 8D AUDIO?](https://melmagazine.com/en-us/story/why-are-so-many-dudes-losing-their-shit-over-8d-audio)
- (pt-br) [Cantores Indígenas](http://amazonia.org.br/2015/05/14-músicas-de-diferentes-cantores-ind%C3%ADgenas-brasileiros-para-conhecer/)
- (pt-br) [CRISTIAN WARIU TSEREMEY’WA, JOVEM INDÍGENA XAVANTE, CRIA CANAL NO YOUTUBE PARA DESCONSTRUIR PRECONCEITOS](https://www.inclusao360.org/indigenas/cristian-wariu-tseremeywa-jovem-indigena-xavante-cria-canal-no-youtube-para-desconstruir-preconceitos/)
- (pt-br) [Quem são os youtubers indígenas do Brasil](https://www.vice.com/pt_br/article/qvqjw7/quem-sao-os-youtubers-indigenas-do-brasil)
- [PsyBry - Binge (2016)](http://www.psybry.net/index-flatiron/#/binge-2016/)
- [Banksy Loses Copyright To His Work After Refusing To Disclose Identity In Court](https://designtaxi.com/news/411567/Banksy-Loses-Copyright-To-His-Work-After-Refusing-To-Disclose-Identity-In-Court/)

## 2019

- [Public Domain Day Is Finally Here!: Copyrighted Works Have Entered the Public Domain Today for the First Time in 21 Years | Open Culture](http://www.openculture.com/2019/01/public-domain-day-is-coming.html)
- [Mixing art and artificial intelligence](https://www.aalto.fi/news/mixing-art-and-artificial-intelligence)
- [Hermann Hesse on Solitude, the Value of Hardship, the Courage to Be Yourself, and How to Find Your Destiny](https://www.brainpickings.org/2019/01/15/hermann-hesse-solitude-suffering-destiny/)
- [A obra completa de Machado de Assis para download gratuito](https://www.revistabula.com/679-a-obra-completa-de-machado-de-assis-para-download/). [obras](http://machado.mec.gov.br/)
- [Watch: Machine Learning Music Composed From Re-Synthesized Fragments From 100s Of Terabytes Of LA Phil Recordings](https://nwn.blogs.com/nwn/2019/01/wdch-dreams-robert-thomas-la-phil.html)
- [A Novel Concept: Silent Book Clubs Offer Introverts A Space To Socialize](https://www.npr.org/2019/08/12/740897970/a-novel-concept-silent-book-clubs-offer-introverts-a-space-to-socialize)

# 2021

- [OS OITO UNIVERSITÁRIOS. VÍDEO HISTÓRICO DO MOVIMENTO ESTUDANTIL DA DÉCADA DE 60](https://documentosrevelados.com.br/os-oito-universitarios-video-historico-do-movimento-estudantil-da-decada-de-60/)
- [](https://here-or-there.glitch.me/index.html)

## Technology

- [LOLWUT](http://antirez.com/news/123): a piece of art inside a database command - antirez
- [nuclear](https://nuclear.gumblert.tech/): There's no need to use services that limit your freedom and seek to exploit you just to listen to your favourite artists. Nuclear empowers you to listen to what you want, where you want, and how you want, for free.

## Travel

- [20 Abandoned Cities from Around the World](http://web.archive.org/web/20180221100932/www.dailycognition.com/index.php/2008/08/30/20-abandoned-cities-from-around-the-world.html)
- [Visa List](https://visalist.io/) - Find visa requirements for 238 countries

## Mythology

- [Hyōsube](https://en.wikipedia.org/wiki/Hy%C5%8Dsube): Hyōsube (ひょうすべ) is a Japanese yōkai. There are legends about them in many areas starting with the Saga Prefecture and the Miyazaki Prefecture.
- [Ghosts in Ancient Japan](https://www.worldhistory.org/article/1059/ghosts-in-ancient-japan/): [Ushi-Oni](https://en.wikipedia.org/wiki/Ushi-oni)

## Crazy stuff

- [Back when it was normal to advertise cocaine gadgets in magazines, 1970-1980](https://rarehistoricalphotos.com/cocaine-paraphernalia-ads-1970s/)
",25,25,5,1,art,"[art, arts, audio, awesome, awesome-list, cinema, music, paiting, photography, poetry, supercollider]",0
NaserElziadna,fluid_simulation,,https://github.com/NaserElziadna/fluid_simulation,https://api.github.com/repos/fluid_simulation/NaserElziadna,Feel bored or anxious? This app can solve your problem! Play with fluids with a touch of your fingers. Play and experiment with these swirling substances. Gorgeous visuals will take your breath away and help you to relieve stress. ,"
<img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/logo.png"" alt=""drawing"" style=""width: 10%;max-width: 30%;border-radius: 17px;display: block;""/>
<a href=""https://www.buymeacoffee.com/NaserElziadna"" target=""_blank""><img src=""https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png"" alt=""Buy Me A Coffee"" style=""height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;"" ></a>

![visitors](https://visitor-badge.laobi.icu/badge?page_id=NaserElziadna.fluid_simulation)
# fluid_simulation
<a href=""https://play.google.com/store/apps/details?id=com.nmmsoft.fluid_simulation"">
    <img alt=""Get it on Google Play""
        height=""80""
        src=""https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png"" />
</a> 

Feel bored or anxious? This app can solve your problem! Play with fluids with a touch of your fingers. Play and experiment with these swirling substances. Gorgeous visuals will take your breath away and help you to relieve stress. 😍

This beautiful creation can help you to chill, relieve this pesky stress from your mind and enjoy your moment of life, right now. When you first launch it you're gonna be frozen by a beauty, that magnificence, that you have never ever seen before. Believe it or not you will become happy playing it, squeezing every second from it, to experience love and connection to our big universe.

# Source Code - Proposal

i have put alot of hard work on this project , so after getting <b>500 </b>⭐ starts on the repository, the true source code will be reveled automaticlly

# app Gallery
## ScreenShot
<table style=""width:75%;height:75%;"">
  <tr>
    <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_1.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
    <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_2.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
     <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_3.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
     <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_4.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
  </tr>
  <tr> 
    <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_5.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
     <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_6.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
     <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_7.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
     <td>
      <img src=""https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/screen_shoot_8.webp"" alt=""drawing"" style=""width:100%;""/>    
    </td>
  </tr>
</table>  

## video
[![Watch the video](https://github.com/NaserElziadna/fluid_simulation/blob/main/screen_shoots/00.jpg)](https://www.youtube.com/watch?v=r7fo1Aa2B4M)
",24,24,2,0,art,"[apk, art, fluid, fluid-simulation, flutter, game, naser-elziadna]",0
DominikBoenisch,Training-the-Archive,,https://github.com/DominikBoenisch/Training-the-Archive,https://api.github.com/repos/Training-the-Archive/DominikBoenisch,Research project combining artificial intelligence and museum collection data through machine learning and object recognition.,"## Training the Archive
A research project based at the German [Ludwig Forum for International Art Aachen](http://ludwigforum.de/) and the [Hartware MedienKunstVerein (HMKV)](https://hmkv.de/) in Dortmund, Germany that combines artificial intelligence and museum collection data through machine learning and object recognition. The project is funded by the Digital Culture Programme of the [German Federal Cultural Foundation](https://www.kulturstiftung-des-bundes.de/de) (Kulturstiftung des Bundes).

Over the next four years (2020-2023), the research project ""Training the Archive"" will explore the possibilities and risks of AI in relation to the automated structuring of data to support curatorial practice and artistic production. Connected to this is the research question of whether AI can learn research processes so that patterns, connections and associations become recognizable that are not apparent to humans in this form. Together with international artists and curators, a procedure is to be developed that will help to make digital archives - such as the collection of the Ludwig Forum Aachen - accessible in a new way.

Blog: https://trainingthearchive.ludwigforum.de/

<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/logo_partners.jpg"" alt=""Logos"" width=""240"" height=""75"">  <img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/logo_funding.jpg"" alt=""Logos"" width=""193"" height=""75"">

### Prototype: 
Clustering of images from a museum collection to identify interesting links.  Subsequently, 
the human being is to be brought back into the loop, in which networks for image recognition are 
retrained with the knowledge of curators, for example, in order to make the clusters more dynamic and personalized.

### Step by step guide:
1. Scraping of data from the [Open Source Library](https://www.smk.dk/en/article/smk-open/) of the National Gallery of Denmark (SMK).
    * [Notebook](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/1_Scraper)
2. Extracting feature vectors from [Keras Applications](https://keras.io/api/applications/) or [Tensorflow Hub](https://tfhub.dev/s?q=bit)
    * [Notebooks](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/2_Feature_Extractor)
3. Generating a dataset for the training using [triplet loss](https://omoindrot.github.io/triplet-loss)
   * [Notebook](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/3_Training_Dataset)
4. Training of a network with our annotations, which artworks are related and which are not
   * [Notebooks](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/4_Training)
5. Clustering of artworks using different neural networks and visualization of the results
   * [Notebook](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/5_Clustering_Plot)
6. Nearest (or even farthest) neighbors and walk through the latent space
   * [Notebook](https://github.com/DominikBoenisch/Training-the-Archive/tree/master/Prototype/6_Feature_Neighbors)

### Results of the visualization:
All Images © Dominik Bönisch, Ludwig Forum Aachen using data from the [Open Source Library](https://www.smk.dk/en/article/smk-open/) of the National Gallery of Denmark (SMK).

#### Scatterplot
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Cluster_Example3.png"" alt=""Cluster Example"" width="""" height=""500"">

#### Gridplot
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Grid_Example.png"" alt=""Cluster Example"" width=""1000"" height="""">

#### Nearest/Farthest neighbors
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Neighbors_Example.jpg"" alt=""Cluster Example"" width=""1000"" height="""">

#### Walkthrough the latent space
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Walkthrough_start.jpg"" alt=""Walkthrough Example"" width="""" height=""110"">
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Walkthrough.png"" alt=""Walkthrough Example"" width=""1000"" height="""">

#### Walkthrough the latent space using a *tube-shaped* scatterplot with an arrowed path
<img src=""https://github.com/DominikBoenisch/Training-the-Archive/blob/master/Images/Walkthrough_TubeScatter_Example.png"" alt=""Walkthrough Tube Example"" width=""1000"" height="""">

### Contribute: 
You have suggestions or feedback? We are very happy about that. Feel free to [write us a line](https://trainingthearchive.ludwigforum.de/en/kontakt/).

### Acknowledgment:
The first prototype was developed within the context of the so-called [*AI school*](https://www.link-niedersachsen.de/ki_schule) in the [LINK](https://www.link-niedersachsen.de/) programme of the Lower Saxony Foundation in cooperation with the tutors [Dr. rer. nat. Jan Sölter](https://de.linkedin.com/in/jansoelter) and [Dr. rer. nat. Thomas Rost](https://github.com/thalro).

### License:
This prototype is licensed under the GPL-3.0 License. See the [license](https://github.com/DominikBoenisch/Training-the-Archive/blob/master/LICENSE) file for detail.
",23,23,4,0,art,"[art, artificial-intelligence, big-data, machine-learning, machine-learning-algorithms, museum-collections, museums]",0
kneitinger,nightgraph,,https://github.com/kneitinger/nightgraph,https://api.github.com/repos/nightgraph/kneitinger,"An interactive, low-boilerplate creative coding platform","# nightgraph
A creative coding platform in Rust. Provides drawing APIs, a CLI, Native and WASM GUIs, and low-boilerplate artwork creation. Designed initially for [@night_generator](https://www.instagram.com/night_generator/) pen-plotter works, but steadily expanding into a general purpose platform.
![Artwork of human sitting, stylized similarly to contour lines or CP-1919/""Unknown Pleasures""](./assets/img/sitting.png)

### Status
This project is in **very early** active development, and probably shouldn't be used by anyone until it's first release in the near future 💜

With that said, there are a lot of exciting features on the roadmap:
- Scripting language and/or node editor for user created sketches at runtime.
- Keyframes/animations in `nightgraph-ui`, as well as rendering to various video formats
- Higher order geometric operations: clustering, fracturing, tiling, canvas-iterating operations.
- Forward-porting [@night_generator](https://www.instagram.com/night_generator/) works written in a previous version of this platform (such as Kinect scans).

and many more in this project's [issues](https://github.com/kneitinger/nightgraph/issues).

### Crates

#### [nightgraphics](./graphics)
A 2D drawing API, with a collection of shapes primitives as well as standard
operations on them, and between other shapes, and a canvas to place them on
and render from.

#### [nightsketch](./sketch)
An internal crate used by `nightgraph-ui` and `nightgraph-cli` to store, expose, and modify sketches (self contained works of art written in `nightgraphics`).

#### [nightgraph-ui](./ui)
A GUI written in [`egui`](https://github.com/emilk/egui) that displays `nightsketch` sketches, as well as auto-generated controls from their parameters. Runs natively on all Linux/MacOS/Windows, or in any modern web browser via `wasm`.

#### [nightgraph-cli](./cli)
A CLI for `nightsketch` sketches that lists sketches, their parameters, descriptions for both, and allows rendering sketches to SVGs with modified values.

#### [nightsketch_derive](./sketch_derive)
An internal crate that greatly simplifies the act of adding new sketches to `nightsketch`.  Through doc comments, attributes, and object naming, CLI/GUI controls are auto-generated for selection of sketches, setting of parameters, etc.

### Credit & Licenses

This project and its contained crates are licensed under the [MIT license](../LICENSE-MIT). Any artwork generated by _an existing_ sketch, such as `sketch/src/blossom.rs`, is licensed [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Artwork can be attributed to Kyle Kneitinger (kyle@kneit.in), or [@night_generator](https://www.instagram.com/night_generator/) on Instagram.

`Jost-500-Medium.otf` and `Jost-400-Book.otf` by [indestructible type\*](https://indestructibletype.com/Jost.html), [SIL Open Font License](https://github.com/indestructible-type/Jost/blob/master/OFL.txt)

`Monofur_Regular.ttf` by Tobias Köhler, [Custom ""Freeware"" License](./ui/assets/Monofur_Regular_License.txt)

[`nightgraph-ui`](./ui) derived from [emilk/eframe_template](https://github.com/emilk/eframe_template)
",22,22,5,11,art,"[2d-graphics, art, creative-coding, plotter-art]",0
DomDom3333,Wallpaper-Maker,,https://github.com/DomDom3333/Wallpaper-Maker,https://api.github.com/repos/Wallpaper-Maker/DomDom3333,"WinForms based, Programmatically generated Wallpaper maker which makes Minimalist style wallpapers.","# Wallpaper-Maker
This is a WinForms based Wallpaper Generator that make Minimalist/Modern Art style wallpapers.

# Samples
https://imgur.com/gallery/y0OOdmI

# Getting started:
- Open the exe and punch in your resolution (in case it didnt autodetect)
- Open the settings tab to customize what kind of shapes you want to have
- Open the colors tab and make yourself a Color Pallet to use
- Select your color pallet on the main screen and hit 'Generate'
- There you go! Now save the image using the Save button.

# Features:
- Multisampling for even higher Resolutions!
- Flexible Color Pallet options that allow for unlimited Pallets and Colors per Pallet
- Shapes get drawn in random order, meaning even with the same settings, it will never look the same due to layering
- Import lots of Pallets at once by creating a /Resources/ColorPallets.json file and using the following format
```
{
  ""Pallets"": [
    {
      ""Pallet"": {
        ""Name"": ""your pallet name"",     /* change this to something unique*/
        ""Colors"":[                      /*add your colors here*/
          ""229,244,227"",
          ""93,169,233"",
          ""0,63,145"",
          ""255,255,255"",
          ""109,50,109""
        ]
      }
    }
  ]
}
```
# Planned Features
- Seed sharing! Type in a manual seed to copy settings easily.
- Element Exporting! Save the Layout of the wallpaper elements to recreate the same layout with different colors.
- More Shapes! So many more shapes!






#### Thanks
If you find any bugs or have ideas for improovements, feel free to create an issiue. help ALWAYS wanted!
",21,21,1,10,art,"[art, csharp, image, wallpaper, winforms]",0
venam,glitching_images,,https://github.com/venam/glitching_images,https://api.github.com/repos/glitching_images/venam,A small compilation of scripts and trivia related to glitching images. Based on the article on https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html,"# Corruption is lovely #

This repo contains scripts and ideas about glitching images

### Further Reading ###

- <https://beyondresolution.info/>
- <https://en.wikipedia.org/wiki/Error_correction_code>
- <https://en.wikipedia.org/wiki/Error_detection_and_correction>
- <http://datamoshing.com/>
- <http://datamoshing.com/2016/06/15/how-to-glitch-jpg-images-with-data-corruption/>
- <http://datamoshing.com/2016/06/26/how-to-glitch-images-with-wordpad/>
- <http://datamoshing.com/2016/06/16/how-to-glitch-images-using-pixel-sorting/>
- <https://github.com/kimasendorf/ASDFPixelSort/blob/master/ASDFPixelSort.pde>
- <http://datamoshing.com/2016/06/29/how-to-glitch-images-using-rgb-channel-shifting/>
- <http://datamoshing.com/2016/06/16/how-to-glitch-images-using-processing-scripts/>
- <http://datamoshing.com/2016/06/15/how-to-glitch-images-using-audio-editing-software/>
- <https://github.com/Hugosslade/smackmyglitchupjs/blob/master/glitch.html>
- <https://github.com/jeffThompson/PixelSorting>
- <https://github.com/snorpey/jpg-glitch/blob/master/scripts/workers/glitchworker.js>
- <https://photomosh.com/>
- <https://www.airtightinteractive.com/demos/js/imageglitcher/>
- <https://www.wired.co.uk/article/glitch-art-databending>
- <https://en.wikipedia.org/wiki/Databending>
- <https://en.wikipedia.org/wiki/Glitch_art>
- <http://blog.animalswithinanimals.com/2008/08/databending-and-glitch-art-primer-part.html>
- <http://blog.animalswithinanimals.com/2008/09/databending-and-glitch-art-primer-part.html>
- <http://blog.animalswithinanimals.com/2014/10/databending-and-glitch-art-primer-part.html>
- [sonification](https://en.wikipedia.org/wiki/Sonification)
- [sox instead of audacity](https://maryknize.com/blog/glitch_art_with_sox_imagemagick_and_vim/)
- <https://github.com/aguaviva/micro-jpeg-visualizer/>
- <https://github.com/corkami/formats/blob/master/image/jpeg.md>
- <https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/>
- <https://en.wikipedia.org/wiki/Entropy_encoding>
- <https://www.blackhat.com/docs/asia-14/materials/Ortiz/Asia-14-Ortiz-Advanced-JPEG-Steganography-And-Detection.pdf>
- <https://www.impulseadventure.com/photo/jpeg-huffman-coding.html>
- <https://www.impulseadventure.com/photo/jpeg-minimum-coded-unit.html>
- <https://www.w3.org/Graphics/JPEG/itu-t81.pdf>
- [accidental glitches](https://www.reddit.com/r/glitchart/)
- [intentional glitches](https://www.reddit.com/r/glitch_art/)
- [video datamoshing](https://www.reddit.com/r/datamoshing/)
- [glitchlock](https://github.com/xero/glitchlock)


",20,20,4,1,art,"[art, datamosh, glitch-art, glitch-effect, image-processing]",0
0xflotus,hashpic,,https://github.com/0xflotus/hashpic,https://api.github.com/repos/hashpic/0xflotus,"Hashpic creates an image from a MD5, SHA512, SHA3-512, Blake2b or SHAKE256 hash","# Hashpic

Hashpic creates an image from the *MD5* hash of your input.

Since _v0.2.0_ it is also possible to create an image from a *SHA-512* hash.

Since _v0.4.8_ it is also possible to create an image from a *SHAKE-256* hash with variable digest length of _4_, _9_, _16_, _25_, _36_, _64_, _100_, _144_, _225_ or _255_.

Since _v0.3.5_ it is also possible to create an image from a *SHA3-512* and a *BLAKE2b* hash.

Since _v0.4.0_ it is possible to create an image as *SVG*.

_v0.6.0_ brought a huge performance boost.

## Install

`pip3 install hashpic`

## Usage

```bash
python3 -m hashpic 'Hashpic rocks!'
```

This should create a file `output.png` in your current directory. 
The input `Hashpic rocks!` should create the following image:

![hashpic image](./docs/rocks.png)

## Piping from another program

All this commands should produce the same image as above.

```bash
printf 'Hashpic rocks!' | md5 | python3 -m hashpic --bypass

printf 'Hashpic rocks!' | python3 -m hashpic
```

## SVG Mode 🎉🎉🎉

Since _v0.4.0_ it is possible to create an image as *SVG*. The following command will create a file `output.svg` in your current directory. 

```bash
python3 -m hashpic 'Hashpic rocks!' --svg
```

![svg](./docs/rocks_on_svg.svg)

Since _v0.5.0_ it is possible to create circles instead of squares. But this is limited to the `SVG Mode`.

```bash
python3 -m hashpic 'Hashpic rocks!' --svg --round
```

![rounded](./docs/rounded.svg)

Since _v0.7.0_ it is possible to create hexagons instead of squares. But this is limited to the `SVG Mode`. 
If you pass also the `--round` flag when using `--hexagon`, `--round` will be ignored.

```bash
python3 -m hashpic 'Hashpic rocks!' --svg --hexagon
```

![rounded](./docs/hexagon_md5.svg)

Since _v0.5.2_ it is possible to add a background color to the SVG.

```bash
python3 -m hashpic 'Hashpic rocks!' --svg --round --background '#000000'
```

## Console Mode

![console](./docs/console.png)

## Hashing a file

It is also possible to create an image from a hash of a file. Use the `--file` argument for that.

```bash
python3 -m hashpic --file README.md
```

## SHA-512 Mode

It is also possible to create an image from a *SHA-512* hash. All arguments for *MD5 Mode* are also available for *SHA512 Mode*.

```bash
python3 -m hashpic --sha512 'Hashpic rocks!'

printf 'Hashpic rocks!' | python3 -m hashpic --sha512
```

This commands should create the following image:

![sha512 image](./docs/rocks_on_sha512.png)

## SHAKE256 Mode

You can create an image from a *SHAKE256* hash with variable digest lengths. Valid lengths are _4_, _9_, _16_, _25_, _36_, _64_, _100_, _144_, _225_ and _255_. You must specify the length of the digest if you want to create an image from a *SHAKE256* hash.

```bash
python3 -m hashpic --shake256 --length 100 'Hashpic rocks!'
```

The command above should produce the following image:

![shake256](./docs/shake256/100.png)

### More SHAKE256 examples

<details>
  <summary>Click to see more examples.</summary>

  ### Digest Length of 4
  
  ```bash
  python3 -m hashpic --shake256 --length 4 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/4.png)

  ### Digest Length of 9
  
  ```bash
  python3 -m hashpic --shake256 --length 9 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/9.png)

  ### Digest Length of 16

  ```bash
  python3 -m hashpic --shake256 --length 16 'Hashpic rocks!'
  ```
  ![shake256](./docs/shake256/16.png)

  ### Digest Length of 25

  ```bash
  python3 -m hashpic --shake256 --length 25 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/25.png)

  ### Digest Length of 36

  ```bash
  python3 -m hashpic --shake256 --length 36 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/36.png)

  ### Digest Length of 64

  ```bash
  python3 -m hashpic --shake256 --length 64 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/64.png)

  ### Digest Length of 100

  ```bash
  python3 -m hashpic --shake256 --length 100 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/100.png)

  ### Digest Length of 144

  ```bash
  python3 -m hashpic --shake256 --length 144 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/144.png)

  ### Digest Length of 225

  ```bash
  python3 -m hashpic --shake256 --length 225 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/225.png)

  ### Digest Length of 255

  It adds a `padding byte of 0xff` to the end of the hash to fit it into a `16x16 grid`. Please keep this in mind.

  ```bash
  python3 -m hashpic --shake256 --length 255 'Hashpic rocks!'
  ```

  ![shake256](./docs/shake256/255.png)
</details>
<hr/>

## SHA3 Mode

It is possible to create an image from a *SHA3* hash. 

```bash
python3 -m hashpic 'Hashpic rocks!' --sha3
```

![sha3](./docs/rocks_on_sha3.png)

## BLAKE2b Mode

It is possible to create an image from a *BLAKE2b* hash. 

```bash
python3 -m hashpic 'Hashpic rocks!' --blake2b
```

![sha3](./docs/rocks_on_blake2b.png)

## Using with Docker

Since _v0.4.4_ there is a dockerized version available on [`ghcr.io`](https://github.com/0xflotus/hashpic/pkgs/container/hashpic). You can pull the image from there and use it e.g.:

```bash
docker run -it -v ""$(pwd)"":/app --rm ghcr.io/0xflotus/hashpic:0.6.2 deadbeef --bypass --shake256 --length 4
```

You can also pipe to docker:

```bash
printf 'ff0030ffe589b7a4e1320f12c4c8de73' | docker run -i --rm ghcr.io/0xflotus/hashpic:0.6.2 -c --shake256 --length 16 --bypass
```

## Examples

Bypassing a hash directly:

```bash
python3 -m hashpic ff00ff00ff00ff0000ff00ff00ff00ffff00ff00ff00ff0000ff00ff00ff00ffff00ff00ff00ff0000ff00ff00ff00ffff00ff00ff00ff0000ff00ff00ff00ff --bypass --sha512
```

This command will produce the following image:

![bypassed](./docs/bypassed.png)

So we can call the hash above the so called `chessboard hash`.

<hr>

You can also bypass a hash from another program:

```bash
printf 'Hashpic rocks!' | sha512sum | awk '{print $1}' | python3 -m hashpic --sha512 -c --bypass 
```

![bypassed from another program](./docs/bypassed_pipe.svg)

<hr>

With all this in mind you can also use hashpic to create an image not only from a hash but e.g. from the current time in hex:

```bash
python3 -c ""import time; print(hex(int(time.time()))[2:])"" | python3 -m hashpic --shake256 --length 4 --bypass
```

Or e.g. an IP address in hexadecimal form:

```bash
# localhost hex(127.0.0.1) == 7f000001
python3 -m hashpic 7f000001 --shake256 --length 4 --bypass

# e.g. an IPv6 address of Googles DNS server
printf 2001:4860:4860:0000:0000:0000:0000:8844 | tr -d ':' | python3 -m hashpic --bypass 
```

If you have installed [`h3`](https://h3geo.org/) you can transform a geo coordinate to an image. 
The example below uses the geo coordinates of the `Eiffel Tower in Paris, France`.

```bash
python3 -c ""import h3; print(h3.geo_to_h3(48.8583230030819, 2.294450300083837, 15).zfill(18))"" | python3 -m hashpic --bypass --shake256 --length 9
```

It is also possible to create an image from an `uuid`.

```bash
python3 -c ""import uuid; print(str(uuid.uuid4()).replace('-', ''))"" | python3 -m hashpic --bypass -c
```

You can also create an image from any 64-bit integer.

```bash
printf 8724325378325383578 | python3 -c ""import sys, textwrap; print(''.join([hex(int(bit))[2:].zfill(2) for bit in textwrap.fill(bin(int(sys.stdin.read()))[2:].zfill(64), 1).split('\n')]))"" | python3 -m hashpic --bypass --svg --round --sha3
```

<details>
  <summary>Click to see more examples.</summary>

```bash
# compute the bypassed number
python3 -c ""print(2**56-1)"" | python3 -c ""import sys, textwrap; print(''.join([hex(int(bit))[2:].zfill(2) for bit in textwrap.fill(bin(int(sys.stdin.read()))[2:].zfill(64),1).split('\n')]))"" | python3 -m hashpic --bypass --svg --round --sha3

# bypass the binary directly
printf 0110100111001100001101001110011000111110011100110000111100111011 | python3 -c ""import sys, textwrap; print(''.join([hex(int(bit))[2:].zfill(2) for bit in textwrap.fill(bin(int(sys.stdin.read(), 2))[2:].zfill(64),1).split('\n')]))"" | python3 -m hashpic --bypass --svg --round --sha3

# map the colors 
printf 0110100111001100001101001110011000111110011100110000111100111011 | python3 -c ""import sys, textwrap; print(''.join(map(lambda x: '00' if x == '01' else 'ff', [hex(int(bit))[2:].zfill(2) for bit in textwrap.fill(bin(int(sys.stdin.read(), 2))[2:].zfill(64),1).split('\n')])))"" | python3 -m hashpic --bypass --svg --round --sha3
```

</details>

## Disclaimer

The color palette in [`data.py`](./hashpic/data.py) was influenced by the [`string-color`](https://gitlab.com/shindagger/string-color) library. 
Thanks for this!
",20,20,5,0,art,"[art, blake2b, hacktoberfest, hash, hex, md5, png, python, sha3, sha512, shake256, svg]",0
Creativeguru97,InteractiveProjection,,https://github.com/Creativeguru97/InteractiveProjection,https://api.github.com/repos/InteractiveProjection/Creativeguru97,Practice Interactive projection with processing and Kinect,"# InteractiveProjection
My interactive projection works.

I use processing or p5.js for coding, and Kinect v2, PoseNet or handPose for sensing human body.
Hope this repository can help other beginner creative coder.
",20,20,1,0,art,"[art, creative-coding, creativecoding, handpose, interactive, kinect, kinectv2, posenet, processing, tensorflow, tensorflowjs]",0
ak15199,rop,,https://github.com/ak15199/rop,https://api.github.com/repos/rop/ak15199,"ROP is a simple and extensible framework to display a set of art demos on an LED array (such as FadeCandy) or in ASCII Art on a terminal, and includes a 2D drawing primitive implementation.","Introduction
------------

This project is designed to generate a number of distinctive animations on a
grid of LEDs via OPC, to a FadeCandy board.

Here's a test picture of the plasma art running on a physical array:

![example](http://i.imgur.com/KlEZBC8m.jpg)

If you want a quick sample of what ROP can do in a terminal, you can follow this link to Asciinema:

[![asciicast](https://asciinema.org/a/51HLupl32PvU5ecqg9kZGd4PM.svg?width=10)](https://asciinema.org/a/51HLupl32PvU5ecqg9kZGd4PM)

Installation
------------

The code has been run on OSX with Python 2.7 and Python 3.6. There are a few
extras you'll need before you can start. Typically you'd run something like:

    # pip3 install -r requirements.txt

Or maybe - if you prefer - you'd install in a `virtualenv`. On the off-chance
that the installation gets a hiccup:

  - `numpy` is pretty well documented and you should be able to figure it out.
    Some distros have a natively installable package to use instead of the pip
    equivalent. If you do install but get poor performance, then it may be that
    there are some ancillary packages missing which `numpy` relies on for
    optimum performance. Again, the `numpy` docs are pretty good.

  - Either `Pillow` or it's predecessor `PIL` should work just fine, although
    the former is preferred.

Getting Started
---------------

To get started and display on your terminal, make sure that the terminal is at
least 35x35 and run:

    % python3 art.py

You can also pick a specific subset to render by listing the particular modules
in the art directory, for example:

    % python3 art.py rain.py fortune.py

Be aware that the down-sampled image when displaying to the terminal is super
lossy, since it's reducing 24 bit color to a handful of ascii-art characters...
although if your tty has a 256 color mode, then things will look quite a bit
better than 16 colors. 

If you want higher quality output and can run against a physical LED display,
then update `config.py` to suit your display configuration, and start the OPC
service as appropriate.

The `config.py` file contains tunable parameters relating to the display, such
as geometry, as well as configuration options specific to the individual art
files.

Most textual logging is delivered to `art.log`. If something doesn't look
right, then check in this file for exceptions and other diagnostics.

It's also possible to limit number of cycles that `art.py` runs through, adjust
the duration that each art is displayed before moving on to the next, or to
switch on profiling. Run with `--help` for more information.

The directories are:

    .                  application directory
    ./art              contains classes for each of the animations.
                       You'll notice a template.py file for the bare
                       bones
    ./art/utils        helper modules shared between animations
    ./art/baseclasses  base classes that animations may derive from
    ./assets           files that are used by the animations
    ./config.py        various configuration options
    ./opc              an extended interface for using OPC via python
    ./opc/utils        various utilities used by the framework

To help get up to speed on the library, you can use `pydoc`. For example:

    % pydoc opc.matrix

Check out the existing animations for use as examples, and please commit back
code that you create!

Other People's Work
-------------------

The opc code is taken from the copy embedded in FadeCandy. If you're not already
familiar, go check out [FadeCandy](https://github.com/scanlime/fadecandy)
for more background on the project.

Hopefully attributions are correct. If you see one missing, then please let me
know and I'll fix.

Contributing
------------

There aren't any formal guidelines for contributing. If you'd like to submit
a pull request for review, or open an issue, though, then that's awesome.
",20,20,6,1,art,"[animation, art, fadecandy, leds, opc, raspberry-pi]",0
gd-codes,mc-pixelart-maker,,https://github.com/gd-codes/mc-pixelart-maker,https://api.github.com/repos/mc-pixelart-maker/gd-codes,"A client-side web application that creates add-ons for the popular game Minecraft, allowing you to bring any image from your computer into the game !","![Logo](./images/android-chrome-192x192.png)

------

## Map Art Maker for Minecraft

**[https://gd-codes.github.io/mc-pixelart-maker/](https://gd-codes.github.io/mc-pixelart-maker/)**

------

A client-side web application that creates add-ons for the popular game Minecraft, to bring any image from your computer into the game!

### Using the App

The application is coded in the form of a static website, which is hosted publicly using Github Pages, at the URL above.

It is also a Progressive Web Application, so you can install a complete, functional offline copy of it (in compatible browsers) by clicking the '_Try Offline_' button on the website footer.

Alternately, you can download a copy of the source code from here on Github, and open the `index.html` file in a browser, or, (better method) serve the files using any static web server (such as the simple `python -m http.server` for example)

### Previous Versions

The app is updated occasionally, to keep in sync with changes made to the latest version of the Minecraft Bedrock game. To use the app at an older version, you can clone the source code at these specific releases:

 Minecraft Version | App Code on Github |
| - | - |
| 1.17.0 ""Caves & Cliffs Part 1"" | [v3.1](https://github.com/gd-codes/mc-pixelart-maker/tree/v3.1) |
| 1.18.0 ""Caves & Cliffs Part 2"" | [v4.1](https://github.com/gd-codes/mc-pixelart-maker/tree/v4.1) |
| 1.19.0 ""Wild Update"" | [v4.3](https://github.com/gd-codes/mc-pixelart-maker/tree/v4.3) |

### Contributing

Bug reports, fixes and pull requests about the website are always welcome! Do also refer to the [closed issues](https://github.com/gd-codes/mc-pixelart-maker/issues?q=is%3Aissue+is%3Aclosed) to see previous discussion that took place. Open a new issue for suggestions and feedback.
",19,19,3,1,art,"[art, client-side, game, image-processing, minecraft, minecraft-addon, pixel-art]",0
StoneT2000,Polytomizator,,https://github.com/StoneT2000/Polytomizator,https://api.github.com/repos/Polytomizator/StoneT2000,A website that helps make/generate poly art with an uploaded image.,"# Polytomizator
A web applet that helps generate poly art using an uploaded background image.

<p align=""center"">
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/PolyFlowerEffect2.gif"" width=""800"" height=""auto""></img>
</p>
This was made using JS and HTML. Primary library used was p5.js.

## Using this program
A working link to this program is provided here https://stonet2000.github.io/Polytomizator

Or... (the following is less recommended as it takes longer and was really done because I was learning how to use Electron, npm etc.)

You can clone and run this repository through <a href=""https://www.npmjs.com/"">npm</a>. You will need <a href=""https://git-scm.com/"">Git</a> and <a href=""https://nodejs.org/en/download/"">Node.js</a> installed however. Using your command line (e.g Terminal on Mac OSX), run

``` bash
# To clone this repository
git clone https://github.com/StoneT2000/Polytomizator.git
# Then to enter the repostory
cd Polytomizator
# Install dependencies and start up the app
npm install && npm start
```

To compile this into an app run

``` bash
# Download all app distributions
npm run build
# Mac OSX
npm run build:osx
# Windows
npm run build:win
# Linux
npm run build:linux
```

Or if you want to skip all this techy stuff, head over to the <a href=""https://github.com/StoneT2000/Polytomizator/releases"">releases page</a> to download the latest version. This is built with <a href=""https://electronjs.org"">Electron</a>.


## Features
### Making Poly Art
- Upload local image files to the page to make poly art with
- Different brushes, brush sizes, and densities to play around with to add or remove points onto the canvas
- Triangulates the points using Delaunay triangulation. Algorithm used provided by https://github.com/mapbox/delaunator
- Poly art can be created instantly or with a ""flowering effect"" with the colors being added to the triangles starting from the center and radially expanding outwards
- Poly art can be auto-generated by computer. A combination of randomness and edge detection algorithms help make the poly art look better.
- Can auto-generate two kinds of poly art, normal, and cubic like
- Can snap vertices or draw vertices on to a set grid
- Can undo or redo placement of vertices
- Has other display modes of the triangulation (e.g. displaying the respective circumcircles instead of the triangles)
- Can download at varying sizes depending on the desired number of megapixels. (On a MacBook Air 2017, I was able to create a 120MP sized poly art image)
- Can adjust canvas size to work on for bigger or smaller screens
### Downloading and Loading Work
- Creates poly art from triangulation and can be downloaded at high resolutions
- Save created points, triangles, and colors in between browsing sessions (Just don't clear cache)
- Save poly art to a .svg file for further editing or manual scaling with other applications

## Planned Features
- Other cool/interesting forms of poly art that can be generated by computer
- More options to work with
- Improved auto-generated poly art (basically make it look even nicer)

## Some poly art made by this program
<p align=""center"">
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/NasaShuttle.jpg"" width=""399"" height=""auto""></img>
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/NasaShuttlePolyArt.png"" width=""399"" height=""auto""></img>
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/MountainHimilayas.jpg"" width=""800"" height=""auto""></img>
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/MountainHimilayasPoly.jpg"" width=""800"" height=""auto""></img>
  <img src =""https://github.com/StoneT2000/StoneT2000.github.io/blob/old/images/PolyFlowerEffect2.gif"" width=""800"" height=""auto""></img>
</p>

## Further Technical Details

### How it works:
Vertices stored in a hash map for quick searches (allows for far faster erasing of vertices)

Delaunay Triangulation algorithm generates triangles from vertices.
The program finds the average color of all pixels within each triangle and stores into an array for colors.
The program then runs a loop through all the triangles and displays the triangles and their corresponding colors.

#### Downloading the poly art
First, an off-screen canvas is made with p5. That canvas is then enlarged, and the coordinates of all the triangles are all scaled upwards, creating larger triangles. Then the enlarged canvas is downloaded.

The SVG file is created by creating a file with the proper SVG formatting. The program goes through all the triangle vertices and their colors to create an SVG file (primarily using the <polygon ... /> tag. Allows users to import these shapes into a program that parses SVG files.

#### Poly Art Auto Generation
Algorithms run are done on a separate thread using web-workers, allowing for a nice loading screen to be displayed.

Edge detection algorithms created through the convolution of a 3x3 smoothing kernel and 3x3 edge detection kernel. The kernels create a photo where edges are bright, which are detected by scanning through the entire array of pixels and for those that are bright, an 'edge' vertex is placed at its position. Then a for loop is run through the detected edge vertices in order of decreasing brightness, and vertices around the detected edge vertex are erased, a form of Poisson disk sampling.

Then some filler vertices are placed randomly around the canvas.

Once scanned and filtered with edges detected, it doesn't need to be run again unless a new image is put up or if the canvas is resized.

In general, a combination of edge detection methods and some vertex filtering functions help create neat looking poly art.

## Acknowledgements
Many thanks to @Vince14Genius and many others as well for giving suggestions and great feedback.
",19,19,1,5,art,"[art, canvas, css, edge-detection, generative-art, html, javascript, lowpoly, p5js, poly-art, triangulation]",0
JamesMatchett,ExCell-Art-Generator,,https://github.com/JamesMatchett/ExCell-Art-Generator,https://api.github.com/repos/ExCell-Art-Generator/JamesMatchett,A program for making pixel art from a source image in an excel spreadsheet,"# ExCell-Art-Generator
A program for making pixel art from a source image, in Excel using the microsoft office interop for excel.
## This program takes in any source image
<image src=""https://i.imgur.com/CxSseyp.jpg""/>  
  
## And returns it as an Excel spreadsheet for further Pixel art manipulations


<image src=""https://i.imgur.com/nnlmCVo.png""/>
<image src=""https://i.imgur.com/hSDUlma.png""/>

  
  Hope it helps save some time in creating large areas e.g. backgrounds etc
",19,19,7,8,art,"[art, csharp, excel, excelgenerator, pixel, pixel-art, pixel-editor]",0
pagespeed-pro,css-art.com,pagespeed-pro,https://github.com/pagespeed-pro/css-art.com,https://api.github.com/repos/css-art.com/pagespeed-pro,A gallery for pure CSS web art.,"# 🖼 CSS-ART.COM PURE CSS ART GALLERY

[CSS-ART.COM](https://css-art.com/) is a gallery for pure CSS web art and a crowdsourced test environment for [$async](https://github.com/pagespeed-pro/async), a high performance CSS and script loader for frontend optimization.

The gallery is self-maintained and open source. The rankings are based on Google Analytics data.

### About CSS-ART.COM

CSS-ART.COM is visited by tens of thousands of art viewers per week from almost all countries in the world with 80% entering the website with a search related to CSS art. In 2021 the website was visited from 177 countries.

![Screenshot_2021-09-30 Analytics](https://user-images.githubusercontent.com/8843669/135505499-545d83ca-6cd9-4263-848f-d86364f7d526.png) ![Screenshot_2021-09-30 Analytics(1)](https://user-images.githubusercontent.com/8843669/135505484-09258be0-4e03-44f4-98b7-59c7844ccd4c.png) 

![Screenshot_2021-09-30 css art - Google Search](https://user-images.githubusercontent.com/8843669/135506708-deee3788-865a-4064-90c4-145d244768a0.png)

### About the author

A fan of pure CSS design and once a regular follower of cssbeauty.com (down since 2006).

![CSS Beauty ](https://user-images.githubusercontent.com/8843669/222985425-ad9250fb-5b11-4fdc-a3b1-0fe8e85d9c16.jpg)

![CSS Beauty website 2001 ](https://user-images.githubusercontent.com/8843669/222985428-450d6c0a-e722-4098-9446-5b0328d6532f.jpg) ",19,19,2,3,art,"[app, art, artwork, css, gallery, pure-css, pure-css-art, single-div]",0
diksown,gado,,https://github.com/diksown/gado,https://api.github.com/repos/gado/diksown,📜 Generate poetry with gcc diagnostics,"

<p align=""center""><img src=""https://user-images.githubusercontent.com/49994083/146096949-671b2608-664a-4471-ac4b-7f3510ad6bde.png""></p>


<h1 align=""center"">gado</h1>
<p align=""center"">
  generate poetry with gcc diagnostics
</p>

## 🖋️ About 

**gado** (**g**cc **a**wesome **d**iagnostics **o**rchestrator) is a wrapper of gcc that outputs its errors and warnings in a more poetic format.

You can see [some examples on its website](https://gado.dikson.xyz) and read [an article about how it works](https://dev.to/diksown/generating-poetry-using-gcc-diagnostics-302o).

It currently takes rhymes from a database of all Shakespeare's works.

## 🔎 Usage 

After installing, you will be able to call `gado` and `gado++`. You can use them just like `gcc/g++`!

Type `gado --help` for more info.

**Examples:**

```
gado source.c -o executable
gado++ source.cpp -o executable
```

**💡 Tip:** There are `C/C++` source files in the `examples` folder. Why don't you try to compile them (with `gado errors.c` or `gado++ errors.cpp`)?


## 📝 Requirements

You need gcc>=9, python3 and pip in order to install gado.

## ⬇️ Installing

### PyPI

As gado is written in python, installation by pip is recommended.

```
sudo pip install gado
```

### Manual

You can manually install gado by cloning this repository and running the install script.

```
git clone https://github.com/diksown/gado
cd gado
sudo python setup.py install
```

## 🤝 Contributing

**gado** is open source. You are more than welcome to [help on it](https://github.com/diksown/gado/issues)!
",18,18,1,0,art,"[art, gcc, natural-language-processing, poetry]",0
ruofeidu,MyShadertoy,,https://github.com/ruofeidu/MyShadertoy,https://api.github.com/repos/MyShadertoy/ruofeidu,"My real-time graphics demos online at Shadertoy.com. Poisson Blending, Gnomonic Projections, Post-processing Effects... ","# MyShadertoy
Here stores some of my GLSL code written in Shadertoy.com
[My ShaderToy Public Profile](https://www.shadertoy.com/user/starea)

## Demos and blog posts
![Interactive Poisson Blending](http://www.duruofei.com/Public/trailer/poisson.jpg)
* [Interactive Poisson Blending](https://www.shadertoy.com/view/4l3Xzl)
    * [Blog post](http://blog.ruofeidu.com/interactive-poisson-blending)

![UNIFIED GNOMONIC AND STEREOGRAPHIC PROJECTIONS](http://blog.ruofeidu.com/wp-content/uploads/2017/04/p2.jpg)
* [Unified Gnomonic & Stereographic](https://www.shadertoy.com/view/ldBczm)
	* [Blog post](http://blog.ruofeidu.com/unified-gnomonic-stereographic-projections/)
* [Cubemap to Gnomonic Projection](https://www.shadertoy.com/view/4sjcz1)
	* [Blog post](http://blog.ruofeidu.com/equirectangular-gnomonic-projections-cubemaps/)
* [Foveated Rendering via Quadtree](https://www.shadertoy.com/view/Ml3SDf)
* [Dotted Drawing / Sketch Effect](https://www.shadertoy.com/view/ldSyzV)
	* [Blog post](http://blog.ruofeidu.com/dotted-drawing-sketch-effect/)
* [Edges with Bilateral Filters](https://www.shadertoy.com/view/MlG3WG)

![Instgram Brannan Filter](http://blog.ruofeidu.com/wp-content/uploads/2017/11/earlybird.jpg)
* [Instgram Brannan Filter](https://www.shadertoy.com/view/4lSyDK)
* [Instgram Earlybird Filter](https://www.shadertoy.com/view/XlSyWV)
    * [Blog post](http://blog.ruofeidu.com/implementing-instagram-filters-brannan/)
* [0-4 Order of Spherical Harmonics](https://www.shadertoy.com/view/4dsyW8)
* [Cubemap to Gnomonic Projection](https://www.shadertoy.com/view/4sjcz1)
* [Unified Gnomonic & Stereographic](https://www.shadertoy.com/view/ldBczm)
* [Low-Poly Style Image](https://www.shadertoy.com/view/llGGz3)
* [404 Not Found](http://duruofei.com/404) 
    * [Blog post](http://blog.ruofeidu.com/404-not-found-two-triangles/)
* [Postprocessing Thermal](https://www.shadertoy.com/view/4dcSDH)
* [2D Affine Transformation](https://www.shadertoy.com/view/llBSWw)
* [Image Fade-In Effect](https://www.shadertoy.com/view/MlcSz2)

![Code Golf: Halftone Image](http://blog.ruofeidu.com/wp-content/uploads/2017/10/golf.jpg)
* [Dot Screen / Halftone](https://www.shadertoy.com/view/4sBBDK)
	* [Blog post](http://blog.ruofeidu.com/code-golf-halftone-image/)
* [Equirectangular Fibonacci Sphere](https://www.shadertoy.com/view/Ms2yDK)
* [Parameterized Gabor Filters](https://www.shadertoy.com/view/4sBcRV)
* [Bilateral Filter to Look Younger](https://www.shadertoy.com/view/XtVGWG)

![Brightness, Contrast, Hue, Saturation, Vibrance](http://blog.ruofeidu.com/wp-content/uploads/2017/10/hue.jpg)
* [Brightness, Contrast, Hue, Saturation, Vibrance](https://www.shadertoy.com/view/MdjBRy)
	* [Blog post] (http://blog.ruofeidu.com/postprocessing-brightness-contrast-hue-saturation-vibrance/)

Author
----
Ruofei Du


License
----
Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.",18,18,2,1,art,"[art, bilateral, blending, glsl, graphics, poisson, rendering, shadertoy]",0
felixmariotto,art-salad,,https://github.com/felixmariotto/art-salad,https://api.github.com/repos/art-salad/felixmariotto,VR puzzle game on the web.,"# Art Salad

Not about salads.

![miniature-pour-oculus-browser](https://user-images.githubusercontent.com/46470486/192108520-abb6e498-d1a4-41a8-9f9d-6fec82b9f7bf.jpg)


## Art Jigsaw puzzles in VR. On the web. Free and open-source.

Art Salad is a website that you can visit in immersive VR (with a virtual reality headset such as Meta Quest).     
Play around in VR with jigsaw puzzles made from 3D scans of art and history objects.   
It's fun, educative, and free.

Most models come from [Sketchfab](https://sketchfab.com/), and all of them are under Creative Common license.

Want to give it a try ? Very simple:
1) Put on a virtual reality headset (Meta Quest is supported).
2) Launch the web browser.
3) Go to https://artsalad.net.
4) Click on `enter VR`.
5) Enjoy

___

https://user-images.githubusercontent.com/46470486/187314383-41cf0121-002d-43f9-ad3d-6b597b0d8a6f.mp4

<span>
  <img alt=""puzzles browser"" target=""_blank"" src=""https://user-images.githubusercontent.com/46470486/187453906-6b4cb291-0289-442d-bc97-a5123f1420ab.jpg"" width=""35%"">
</span>

<span>
  <img alt=""puzzles pieces"" target=""_blank"" src=""https://user-images.githubusercontent.com/46470486/187453914-f9bfd08e-51cc-4095-98c6-146117a6aafd.jpg"" width=""35%"">
</span>

<span>
  <img alt=""puzzle in process"" target=""_blank"" src=""https://user-images.githubusercontent.com/46470486/187453915-688aab8b-9194-466f-aee4-0add9bac68eb.jpg"" width=""35%"">
</span>

<span>
  <img alt=""puzzle finished"" target=""_blank"" src=""https://user-images.githubusercontent.com/46470486/187453917-c3502a59-084d-4941-ad59-c085f40a4b9e.jpg"" width=""35%"">
</span>

## How to contribute

Thank you for considering a contribution.
You can add a new puzzle to the list, please read the readme file [in the puzzles folder](https://github.com/felixmariotto/art-salad/tree/master/assets/puzzles).   
For all other contribution feel free to file a PR, and I will review it. Only useful PRs will be merged.
",17,17,3,2,art,"[art, puzzle, vr]",0
upstage-org,upstage,upstage-org,https://github.com/upstage-org/upstage,https://api.github.com/repos/upstage/upstage-org,UpStage is a platform for cyberformance: remote players combine digital media in real-time for an online audience. All you need is a web browser!,"# UpStage

[![CI](https://github.com/upstage-org/upstage/actions/workflows/devapp1.yml/badge.svg)](https://github.com/upstage-org/upstage/actions/workflows/devapp1.yml)

UpStage is a platform for cyberformance - remote players combine digital media in real-time for an online audience. All you need is a web browser!

In 2020, as part of the Mobilise/Demobilise project, UpStage is getting a complete rebuild. We are removing its dependency on Flash so that it will function on mobile devices, and making numerous enhancements. Please star the repository and join the team - all contributors welcome!

For more information, visit https://mobilise-demobilise.eu and https://upstage.org.nz/

# Documentation

[User Manual](https://docs.upstage.live/)

# Installation Guide

## Infrastructure

A complete instance of UpStage should consist of:

- **Upstage Service**: backend code written in Python, Flask, Graphene, SQLAlchemy. This service provides the necessary API Endpoint, mainly in GraphQL to manage stages/media/players and configurations such as foyer, permissions and notifications.
- **Dashboard**: frontend code written in Vue 3, Anime.js, Moveable, Bulma and many canvas operations. This is where most of the user interactions took place, such as the foyer, live stage, backstage and the admin section.
- **MQTT Broker**: this is the magic behind UpStage's performance work. The broker has many topics to be subscribed, such as `meta/demo/chat` can be used to deliveries chat messages between players and audiences in Demo Stage at the `meta` instance. The same broker can also be used for multiple instance of UpStage.
- **PostgresSQL**: our primary database, where all the data of players, stages, media, permissions, replays, configs,... are stored.
- **MongoDB**: we don't persist data in MongoDB, instead we use it as a queue for processing heavy computation and caching.
- **Event Archive Service**: since MQTT doesn't save all the messages that have ever been sent along it, we need to build a service that listens to every message and stores it to our Postgres database. You can run an instance of UpStage without event archive running, but all stage changes will be lost after a browser reload, and no replays would be saved.
- **Studio**: just another frontend code written in Vue 3, but using a more modern technology stack, including Vite, TypeScript, TailwindCSS, Antd and Apollo client. Studio focuses on a better media upload/edit workflow, providing a better UI/UX than the version that was created in `Dashboard`.
- **Nginx**: we use Nginx to serve uploaded media and front-end compiled source code as static files. It is also used to pass incoming requests to UpStage service.
- **Streaming Service**: we use the [Node Media Server](https://github.com/illuspas/Node-Media-Server) which is an open source streaming server built with Node.JS as our streaming service. This is a 3rd-party project but is considered part of the infrastructure of UpStage because we use it closely to broadcast streams and play them on stages.

## Setup

`PostgresSQL`, `MongoDB`, `Nginx` and `MQTT Broker` can be installed using the system package manager, we don't cover them in this section. For a mqtt broker, we recommend using [Mosquitto](https://github.com/eclipse/mosquitto).

1. Clone the repository

```bash
git clone https://github.com/upstage-org/upstage.git
```

2. Setup `UpStage Service`:

```bash
# Install dependencies
pip install -r requirements.pip

# Create the systemd service using our example configuration
cp config/prod/upstage.service /etc/systemd/system/upstage.service

# Start the service
systemctl start upstage.service

# Enable the service if you want it start automatically on boot
systemctl enable upstage.service
```

3. Setup `Dashboard`:

```bash
cd dashboard

# Install dependencies
yarn

# Build source
yarn build
```

The compiled source code will be stored in the `dist` folder. Later we will set up `Nginx` to serve these content on our root path.

4. Setup `Studio` (very similar to Dashboard):

```bash
cd studio

# Install dependencies
yarn

# Build source
yarn build
```

Studio will be served at `/studio` path of our instance.

5. Setup `Event Archive Service`:

```bash
# Create the systemd service using our example configuration
cp config/prod/event_archive.service /etc/systemd/system/event_archive.service

# Start the service
systemctl start event_archive.service

# Enable the service if you want it start automatically on boot
systemctl enable event_archive.service
```

6. Setup `Streaming Service`:

```bash
# Clone the Node-Media-Server repository
git clone https://github.com/illuspas/Node-Media-Server.git

# Create the systemd service using our example configuration
cp config/dev/streaming.service /etc/systemd/system/upstage-streaming.service

# Start the service
systemctl start upstage-streaming.service

# Enable the service if you want it start automatically on boot
systemctl enable upstage-streaming.service
```

7. Setup `Upstage Send Email Token To Cient Server`:

```bash

# Only setup on Upstage Prod
# Create the systemd service using our example configuration
cp config/prod/upstage_email_token.service /etc/systemd/system/upstage_email_token.service

# Start the service
systemctl start upstage_email_token.service

# Enable the service if you want it start automatically on boot
systemctl enable upstage_email_token.service
```

## Configurations

UpStage was designed to have multiple instances of it working independently. Each instance could have its own configurations set to get worked.

1. `UpStage Service` and `Event Archive Service` configurations

The two services load the same configurations, which is a Python file located at `config/settings/` folder

```bash
# Use our example config file as a template
cp config/settings/your_hostname.py config/settings/$HOSTNAME.py
```

There are many configurations here, here are the most importants:

```python
# PostgresSQL connection. You won't be able to read and write data without this property
DB_NAME=""""
DB_USER=""""
DB_PASSWD=""""
DB_HOST=""""
DB_PORT=5432
```

```python
# MongoDB connection. Event Archive won't be able to put messages in queue without this configuration setup properly, which can lead to inconsistent stage behavior
MONGO_HOST = """"
MONGO_PORT = 27018
MONGO_DB = ""upstage""
EVENT_COLLECTION = ""events""
```

```python
# Event Archive will use this MQTT connection to archive events
MQTT_BROKER = """"
MQTT_PORT = 1884
MQTT_TRANSPORT = ""tcp""
MQTT_USER = """"
MQTT_PASSWORD = """"
PERFORMANCE_TOPIC_RULE = ""#""
```

```python
# You can get these keys from running these python files below. Your users won't be able to log in if you change these keys after creating them, so don't touch them after generating them!
CIPHER_KEY='' # Paste the result from fernet_crypto.py
SECRET_KEY='' # Paste the result from running __init__.py
```

```python
# When setup Send Email Service, only the Upstage server has permission to send the email. The Client-server has to call the external API of the Upstage server.
# Upstage server will generate and send a token to each client server every 10 minutes. That token has expired in 10 minutes. Client-server stores that token in MongoDB and uses that token to call the sendEmailExternal API of the Upstage server
EMAIL_USE_TLS = True
EMAIL_HOST = 'mail.gandi.net'
EMAIL_HOST_USER = ''
EMAIL_HOST_PASSWORD = ''
EMAIL_PORT = 465
SUPPORT_EMAILS = '' # A list admin email always in bcc
EMAIL_HOST_DISPLAY_NAME = 'UpStage Support'
ACCEPT_SERVER_SEND_EMAIL_EXTERNAL = ['http://127.0.0.1:8000/'] # This is setup only in app1 server, All client server endpoint having permission using Upstage Send Email service
```

```python
# When setuping Streaming Service, a secret key is recommended so that we can set up password protection and prevent your streaming server from being used by strangers. You will need to paste that key here so that we can generate QR codes with correct stream sign, only then the players will be able to broadcast.
STREAM_KEY=''
```

2. `Dashboard` configurations

When building UpStage's frontend code, Vue will look for `.env` files to load configurations. A `.env` file should contain these configurations (all the key must start with VUE_APP otherwise it won't be imported):

```yaml
VUE_APP_API_ENDPOINT=https://upstage.live/V4.0/ # Rest API endpoint, primary used for login and register operations
VUE_APP_GRAPHQL_ENDPOINT=https://upstage.live/V4.0/ # GraphQL endpoint, used for all other common operations
VUE_APP_STATIC_ASSETS_ENDPOINT=https://upstage.live/static/assets/ # Static asset endpoint, which is served by nginx
VUE_APP_STUDIO_ENDPOINT=/studio/ # Studio endpoint, usually /studio
VUE_APP_MQTT_NAMESPACE=meta # A broker can be shared between multiple instances of UpStage. Namespacing is required for prevent conflicts
VUE_APP_MQTT_ENDPOINT=wss://svc.upstage.live:9002/mqtt # MQTT Broker endpoint, must be served in wss protocol so that it can be loaded over https
VUE_APP_MQTT_USERNAME=
VUE_APP_MQTT_PASSWORD=
VUE_APP_STREAMING_PUBLISH_ENDPOINT=rtmp://streaming.upstage.live/live # Endpoint for broadcasting streams
VUE_APP_STREAMING_SUBSCRIBE_ENDPOINT=https://streaming.upstage.live # Endpoint for subscribing streams, to show them on stages
VUE_APP_STREAMING_USERNAME=admin # Username and password to access the node media server's public API, we use this to detect running streams
VUE_APP_STREAMING_PASSWORD=admin
```

3. `Studio` configurations

Studio and dashboard share the same access token and configurations base. In other word, you don't have to set up separate environment for studio.

4. `Nginx` configurations

Redirect all `http` request from port 80 to the secured version with `https`

```nginx
server {
        server_name _;
        listen 80;
        rewrite ^ https://upstage.live$request_uri? permanent;
}
```

Setup SSL certificates and listen on port 443

```nginx
server {
        server_name upstage.live;
        listen 443 ssl;
        ssl_dhparam /etc/nginx/ssl/dhparam.pem;
        ssl_ecdh_curve secp384r1;
        ssl_certificate /etc/letsencrypt/live/upstage.live/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/upstage.live/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384;
```

Serve `Dashboard` on root path of our instance

```nginx
        location / {
            alias /home/upstage/upstage/dashboard/dist/;
            try_files $uri $uri/ /index.html;
        }
```

Serve `Studio` on `/studio` path of our instance. If you change the path, remember to update `VUE_APP_STUDIO_ENDPOINT` to match

```nginx
        location /studio {
            alias /home/upstage/upstage/studio/dist/;
            try_files $uri $uri/ /V4.0/studio/index.html;
        }
```

Serve user uploaded media in `/static` path. Caching is important in this config block because without caching, preload media before playing a performance won't work!

```nginx
       location /static {
            alias /home/upstage/upstage/uploads;
            expires off;
            add_header Cache-Control 'no-cache, must-revalidate';
        }

```

Finally, pass the incoming request to `UpStage Service`

```nginx
        location /api {
            uwsgi_pass unix:///home/upstage/uwsgi_sockets/upstage.socket;
            uwsgi_read_timeout 1800s;
            uwsgi_send_timeout 900s;
            uwsgi_ignore_client_abort on;
            include uwsgi_params;
            uwsgi_hide_header       Content-Security-Policy;
            uwsgi_hide_header       X-Content-Security-Policy;
        }
}
```

## Recipes

### Scaffolding demo content & base media

Execute the scaffold script at:

```bash
python3 scripts/devtools/scaffold-base-media.py
```

The script uses the same configuration as the `upstage.service`, so there is no need to do additional setup.

It will use the media inside `dashboard/demo` folder to create base media, the subfolder of the media will decide its type (for example, an image inside `dashboard/demo/avatar` folder will be uploaded as an avatar, while another image inside `dashboard/demo/prop` would be uploaded as a prop). You will be asked for a username to whom these media will belong. A demo stage will be created afterward, in which all these media are assigned as the default.

## Troubleshooting

### Stages offline when entering with firefox

If you are using firefox and doesn't have the red `LIVE` status on the top right when entering a stage although the stage is live using other browsers, it's because the version of Mosquitto (MQTT Broker) you are using doesn't use `libwebsockets` or it's using a version of `libwebsockets` that having an issue in protocol handling of HTTP2. Whilst Chromium does not attempt a HTTP2 connection in this case, Firefox tries it first and gets a denied reply from the server. More explanation can be found [here](https://www.bluhm-de.com/content/os-tools/en/applications/mqtt/websocket-connections-fail-with-javascript-paho-client.html).

The solution is to build `libwebsockets` and `mosquitto` from source and use it instead of the one provided by your distro.

Instruction on how to do this:

```bash
apt install libssl-dev xsltproc docbook-xsl
git clone https://github.com/warmcat/libwebsockets.git
cd libwebsockets
mkdir build
cd build
cmake .. -DLWS_WITH_HTTP2=OFF
make
make install
ldconfig
cd ../..
git clone https://github.com/eclipse/mosquitto.git
cd mosquitto
make install WITH_WEBSOCKETS=yes WITH_CJSON=no
sudo systemctl edit mosquitto.service
```

Put this into the override file of the service:

```ini
[Unit]
ConditionPathExists=/etc/mosquitto/mosquitto.conf
Requires=network.target

[Service]
Type=
Type=simple
ExecStart=
ExecStart=/usr/local/sbin/mosquitto -c /etc/mosquitto/mosquitto.conf
```

Finally restart the service

```bash
sudo systemctl restart mosquitto.service
```

## License

[GPL-3.0 License](https://github.com/upstage-org/upstage/blob/main/LICENSE)
",17,17,9,102,art,"[art, cyberformance, real-time, theatre]",0
Vitineth,ascii-art-generator,,https://github.com/Vitineth/ascii-art-generator,https://api.github.com/repos/ascii-art-generator/Vitineth,A basic ASCII art generator feeding from images,"# ascii-art-generator
A basic ASCII art generator feeding from images

## Code Breakdown

### Calculating Character Density

``` python
from PIL import Image, ImageFont, ImageDraw
from operator import itemgetter

test = list(""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!\""£$%^&*()-_=+`¬#~'@;:/?.>,<\\| "")
cor = ImageFont.truetype(r""cour.ttf"", 12)

def generateImg(char, font):
    im = Image.new(""RGBA"", font.getsize(char), (0, 0, 0))
    draw = ImageDraw.Draw(im)
    draw.text((0, 0), char, (255, 255, 255), font=font)
    return im

def getDensity(image):
    t = 0
    for x in range(image.width):
        for y in range(image.height):
            p = image.getpixel((x, y))
            t += round((p[0] + p[1] + p[2]) / 3)
    return t / (image.width * image.height)

output = []
for char in test:
    output += [(char, getDensity(generateImg(char, cor)))]
output = sorted(output, key=itemgetter(1))
```

#### Imports

``` python
from PIL import Image, ImageFont, ImageDraw
from operator import itemgetter
```

Within this, we need to calculate the lightness of each character when drawn to an image. Therefore, in order to achieve this we need to be able to create new images, open system fonts and draw to the images which cover the PIL imports. We use the itemgetter at the end of the process in order to sort a list of lists by a specific element in the sublists which we will cover shortly.

#### Initialisation

``` python
test = list(""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!\""£$%^&*()-_=+`¬#~'@;:/?.>,<\\| "")
cor = ImageFont.truetype(r""cour.ttf"", 12)
```

`test` outlines the characters that we will be using within the final input. In order to allow easy changes, this is intially entered as a string and is then converted to a list which will split every character into its own entry. Any character than can be handled by PIL and has a valid entry in the Courier New font can be entered into this string and it will be used in the final output. 
`cor` holds a reference to the Courier New font that should be installed as standard on Windows installations. If running on another platform, the `cour.ttf` should be replaced with a reference to an installed font. Due to the nature of ASCII art, this should be a monospace font, otherwise the output will look sub-par. We initialise the font with a size of 12 as we are only using this to determine the white density of the characters. This could be set to any value but 12 gives a reasonable output without using much memory and allows quick generation times.

#### Image Generation

``` python 
def generateImg(char, font):
    im = Image.new(""RGBA"", font.getsize(char), (0, 0, 0))
    draw = ImageDraw.Draw(im)
    draw.text((0, 0), char, (255, 255, 255), font=font)
    return im
```

When we calculate the density, we first need to create the image to find the pixels in use. To do this, we create a RGBA image with the size of the character to be drawn as provided by PILs font metrics of the given font. This means that the character should fit perfectly inside of the image. Next we generate an ImageDraw instance which will allow us to actually edit and draw to our image. Using this we draw the given character in white which directly contrasts the black background of the image. This is important as white has a high RGB value `(255, 255, 255)` whereas black has a low `(0, 0, 0)`. This means that we can find out the level of white in the image and then sort it to find the characters with the highest and lowest densities. This could be adapted for other colours but for the sake of simplicity, white on black is the easiest combination. We must ensure that we draw the character with the font that we used to calculate the size of everything goes to hell. Finally just return the image instance.

#### Density Calculation

``` python

def getDensity(image):
    t = 0
    for x in range(image.width):
        for y in range(image.height):
            p = image.getpixel((x, y))
            t += round((p[0] + p[1] + p[2]) / 3)
    return t / (image.width * image.height)
```

In short, when we are calculating the density, we are just looking for how much white is included in the image. So to do this, we go through each pixel, sum the RGB value and divide it by 3. This is ultimately pointless as all pixels should be a shade of grey and therefore `R = G = B` but this was just included for completeness sake. This total is then divided by the number of pixels to give the average amount of white per pixel in the image. This effectivly averages the color of the entire image and returns the color value which we can then interpret as the density.

#### Execution and Ordering

``` python
output = []
for char in test:
    output += [(char, getDensity(generateImg(char, cor)))]
output = sorted(output, key=itemgetter(1))
```

Here we finally get to the actual calculation of the density for each character. For each character in the test string, we generate the image using the Courier New font, and calculate the density of it and insert it into the output array as a tuple storing the density value and the actual character which we eventually use in order to get the characters when drawing the image. Finally, we sort the entire array by the second value in the tuples which is the density value. Due to white being a high value and black being low as discussed before, this naturally sorts the list so that the most pixel dense characters are at the end and the least are at the front. For example, using the test string shown above, ' ' (space) is shown as the least dense and 'B' is the most.

### Image Generation

``` python
def toASCII(in_file, out_file=""ascii.txt"", rotation=0):
    im = PILImg.open(in_file).convert(""RGB"")
    im = im.rotate(rotation)
    with open(out_file, ""w"") as f:
        for h in range(0, im.height, 2):
            for w in range(im.width):
                f.write(getChar(toHSL(im.getpixel((w, h)))[2]))
            f.write(""\n"")
    
def toHSL(rgb):
    rgb_f = list(map(lambda x: x / 255, rgb))
    margb, mirgb = max(rgb_f), min(rgb_f)
    if margb - mirgb == 0:
        h = 0
    else:
        if rgb_f[0] == margb:
            h = (rgb_f[1] - rgb_f[2]) / (margb - mirgb)
        if rgb_f[1] == margb:
            h = 2.0 + ((rgb_f[2] - rgb_f[0])/(margb - mirgb))
        if rgb_f[2] == margb:
            h = 4.0 + ((rgb_f[0] - rgb_f[1]) / (margb - mirgb))
    h = round(h * 60)
    if h < 0:
        while h < 0:
            h += 360
    l = round(((mirgb + margb) / 2) * 100)
    if margb - mirgb == 0:
        s = 0
    else:
        if l < 50:
            s = (margb - mirgb) / (margb + mirgb)
        else:
            s = (margb-mirgb) / (2.0 - margb - mirgb)
    s = round(s * 100)
    return (h, s, l)

def getChar(l):
    index = round(l/(100/len(output)))
    if index >= len(output):
        index = len(output) - 1
    return output[index][0]
```

We are going to need to explore these in a slightly strange order in order to properly explain what each section is actually doing.

#### Converting to ASCII

``` python
def toASCII(in_file, out_file=""ascii.txt"", rotation=0):
    im = PILImg.open(in_file).convert(""RGB"")
    im = im.rotate(rotation)
    with open(out_file, ""w"") as f:
        for h in range(0, im.height, 2):
            for w in range(im.width):
                f.write(getChar(toHSL(im.getpixel((w, h)))[2]))
            f.write(""\n"")
```

Converting to ASCII is the main bulk of the program and actually produces the final output. This function loads the given image file and converts it to an RGB image (this should strip out alpha values and if possible convert the image type. This isn't a perfect method as there is a chance that it can't convert the format, at which the program will fall over). I added a section to rotate the image by a given angle as a helper function when handling photos taken off my old phone so I didn't have to rotate them myself because I'm lazy. 

Then the fun big begins, the output file is opened ready for writing and we iterate through every other row of pixels in the image. We do this due to the size differences between widths and heights. If you go through every pixel, the image becomes significantly longer than it should, and while it is preserving the actual content of the image, it looks wrong. Therefore, we use every other line which seems to maintain the apparent aspect ratio much better. Then for every pixel in that row, we convert it to HSL and get the character before writing it to the file. After each line we print a new line character so the art is actually produced, pretty self explanatory. 

I've kind of glossed over the actual content of what the function does in order to convert to ASCII but that is because we are exploring that next.

#### Converting RGB to HSL

``` python 
def toHSL(rgb):
    rgb_f = list(map(lambda x: x / 255, rgb))
    margb, mirgb = max(rgb_f), min(rgb_f)
    if margb - mirgb == 0:
        h = 0
    else:
        if rgb_f[0] == margb:
            h = (rgb_f[1] - rgb_f[2]) / (margb - mirgb)
        if rgb_f[1] == margb:
            h = 2.0 + ((rgb_f[2] - rgb_f[0])/(margb - mirgb))
        if rgb_f[2] == margb:
            h = 4.0 + ((rgb_f[0] - rgb_f[1]) / (margb - mirgb))
    h = round(h * 60)
    if h < 0:
        while h < 0:
            h += 360
    l = round(((mirgb + margb) / 2) * 100)
    if margb - mirgb == 0:
        s = 0
    else:
        if l < 50:
            s = (margb - mirgb) / (margb + mirgb)
        else:
            s = (margb-mirgb) / (2.0 - margb - mirgb)
    s = round(s * 100)
    return (h, s, l)
```

I'm not a complete expert on how this function works, this is adapted from a conversion guide I found online so I won't cover how it performs it, but I will explain why we do this. RGB is one of the default methods of representing colours and it is represented by 3 values ranging from either 0 to 1 or 0 to 255. In the case of PIL it uses 0 to 255. While this is a good method of representing it as it makes sense (we can individually see how much red, how much green and how much blue), it doesn't help too much when we are handling ASCII art. At the basic level, when generating ASCII art, we are converting a grayscale version of the image as the characters we are outputting can only be one color and the background can only be one color (sort of, we can do more complicated colors but at that point aren't we just painting the image again but with more steps and lower quality?). Therefore, we can use a much more helpful method of representing the colors called HSL. This also uses three values but instead they represent Hue (expressed as an angle between 0 and 360 degrees which represents the colors position on the color wheel), Saturation (which represents how much color there actually is. This is a percentage from 0 to 100 which represents how far out from the center of the color wheel the color actually is), and Lightness which represents how bright the color is unsuprisingly (expressed as another percentage from 0 to 100). Therefore, if we are wanting to work on a grayscale version of the image, we only need the lightness value. As a result, this function is overkill and could be reduced to the following:

``` python
def getLightness(rgb):
    rgb_f = list(map(lambda x: x / 255, rgb))
    margb, mirgb = max(rgb_f), min(rgb_f)
    return round(((mirgb + margb) / 2) * 100)
```

But this was also kind of a learning experience for me so I left it.

#### Converting Lightness to a Character

``` python
def getChar(l):
    index = round(l/(100/len(output)))
    if index >= len(output):
        index = len(output) - 1
    return output[index][0]
```

Now that we can figure out how light each pixel of the image is, we can actually figure out which character to represent it with. If we are using white text on a black background then we want to use the character with the highest density in order to represent whites and the lowest to represent blacks and visa versa for black on white. As my Notepad++ uses white on black, this is the theme that I went with my outputs.

Seeing as we have an array containing the possible characters, sorted by the density with the least (representing blacks) at the start and the highest (representing whites) at the end and we have a lightness value with a low value representing a black and a high value representing a white, we can simply just use this to gain an index in the array. To do this, we divide the lightness value by how much (in terms of percent) each character represents between 0 and 100. This is a strange thing to explain but effectively, if we have 10 characters, each one has a share of 10% of the total lightness value in order for each value to be used. Therefore we use this idea to find the index in the characters array. I will likely try and produce a better explanation for this at a later date but for now try and wrap your head around how it works.

Due to the nature of the round function, it may give an output out of range, therefore if it is larger or equal to the length of the array, we just select the last element. This could be mitigated by using `math.floor` but I wanted to avoid another import for some reason. Then we just return the character at that index in the characters array (remember we stored it as a tuple with the density and the character).

This isn't the best way to perform this, in hindsight. A better way would be to use the density value in order to map the lightness value as this would produce a much better output as the character chosen would be selected because it shares an equivalent value instead of just being in the right place. This would be much harder to program though and because I'm lazy and I compromised and used this function which does give passable outputs.

### Running

All that is left after this is to call the `toASCII` function with an input and output file and let it run. The rest of the program is just sugar in order to make it work nice such as a Tkinter window for entering the values. 

## Example Outputs

|Input|Output|
|-|-|
|![Example 1 Input](images/1_before.png)|![Example 1 Output](images/1_after.png)|
||Image has been reduced in size to save space|",17,17,2,0,art,"[art, ascii-art-generator, character, image]",0
KilledByAPixel,generative,,https://github.com/KilledByAPixel/generative,https://api.github.com/repos/generative/KilledByAPixel,Generative Art by Frank Force,"## Generative Art by Frank Force

Here you will find the source code for some of my longform generative works.

These programs will produce a different result every time you refresh. Just right click to save.

This code is not licensed for any use other then learning from. Check out some of my other MIT licenced projects if you are interested.

# Chaosplot

- [Live Demo](https://killedbyapixel.github.io/generative/chaosplot.html) - A plottable algorithm of chaos vs order.

- [Based on this Dweet by me](https://www.dwitter.net/d/24661)

- [Chaosplot on fxhash](https://www.fxhash.xyz/generative/14874)

![Chaosplot Image](/images/chaosplot.jpg)

# Grayscale Bytes

- [Live Demo](https://killedbyapixel.github.io/generative/grayscaleBytes.html) - Tiny code monochrome composition study.

- [Based on this Dweet by me](https://www.dwitter.net/d/24449)

- [Grayscale Bytes on fxhash](https://www.fxhash.xyz/generative/2370)

![Grayscale Bytes Image](/images/grayscaleBytes.jpg)

# Byte City Night

- [Live Demo](https://killedbyapixel.github.io/generative/byteCityNight.html) - An abstract cityscape using bitwise operators.

- [Based on this Dweet by me](https://www.dwitter.net/d/17507)

- [Byte City Night on fxhash](https://www.fxhash.xyz/generative/10914)

- [I made a video that explains how the code works](https://youtu.be/vnx8kI4EcVc)

![Byte City Night Image](/images/byteCityNight.jpg)

# More of my work

- [fxhash](https://www.fxhash.xyz/u/KilledByAPixel) - All my most recent generative art on fxhash.

- [dwitter](https://www.dwitter.net/u/KilledByAPixel) - I have released over 1000 programs on Dwitter.

- [portfolio](https://generative.3d2k.com) - I made a special website to share my best work.

Thank you. ✌️😄 - FF
",16,16,2,0,art,"[art, generative, generative-art]",0
geometric-intelligence,pirounet,geometric-intelligence,https://github.com/geometric-intelligence/pirounet,https://api.github.com/repos/pirounet/geometric-intelligence,Conditional dance generator,"# PirouNet #

Official PyTorch implementation of the paper “PirouNet: Creating Dance through Artist-Centric Deep Learning”

[[Pre-print](https://arxiv.org/abs/2207.12126)] [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-28993-4_31)], shared at [[EAI ArtsIT 2022](https://artsit.eai-conferences.org/2022/)]. **Best Paper Award.** 

[[Summary](https://neuripscreativityworkshop.github.io/2022/papers/ml4cd2022_paper06.pdf)], shared at [[NeurIPS Workshop for Creativity and Design 2022](https://neuripscreativityworkshop.github.io/2022/#/)]


![Overview of PirouNet's LSTM+VAE architecture.](/images/pirounet_model.jpg)

PirouNet is a semi-supervised conditional recurrent variational autoencoder. This code is responsible for training and evaluating the model. Labels must be created separately prior to training. We propose this [dance labeling web application](https://github.com/mathildepapillon/pirounet_label) which can be customized to the user's labeling needs.


## 🌎 Bibtex ##
If this code is useful to your research, please cite:

```
@InProceedings{papillon2023pirounet,
author=""Papillon, Mathilde
and Pettee, Mariel
and Miolane, Nina"",
editor=""Brooks, Anthony L."",
title=""PirouNet: Creating Dance Through Artist-Centric Deep Learning"",
booktitle=""ArtsIT, Interactivity and Game Creation"",
year=""2023"",
publisher=""Springer Nature Switzerland"",
address=""Cham"",
pages=""447--465"",
isbn=""978-3-031-28993-4""
}
```

**Conditionally created dance sequences:**
![Animated dance sequences conditionally created by PirouNet.](/images/side_by_side_pirounet_originals.gif)

**Reconstructed dance sequence:**
![PirouNet reconstructs input dance.](/images/side_by_side_recon.gif)


https://user-images.githubusercontent.com/50878631/197310007-62b1e89a-12d9-44f1-a4de-c2c991e626c3.mp4



## 🏡 Installation ##

This codes runs on Python 3.8. We recommend using Anaconda for easy installation. To create the necessary conda environment, run:
```
cd pirounet
conda env create -f environment.yml
conda activate choreo
```

## 🚀 Training ##

To train a new model (see below for loading a saved model), follow the steps below.

#### 1. Set up [Wandb](https://wandb.ai/home) logging.

Wandb is a powerful tool for logging performance during training, as well as animation artifacts. To use it, simply [create an account](https://wandb.auth0.com/login?state=hKFo2SBNb0U4SjE0ZWN3OGZtbTlJWTRpYkNmU0dUTWZKSDk3Y6FupWxvZ2luo3RpZNkgODhWd254WW1zdG51RTREd0pWOGVKWVVzZkVOZ0dydGqjY2lk2SBWU001N1VDd1Q5d2JHU3hLdEVER1FISUtBQkhwcHpJdw&client=VSM57UCwT9wbGSxKtEDGQHIKABHppzIw&protocol=oauth2&nonce=dEZVS3dvYXFVSjdjZFFGdw%3D%3D&redirect_uri=https%3A%2F%2Fapi.wandb.ai%2Foidc%2Fcallback&response_mode=form_post&response_type=id_token&scope=openid%20profile%20email&signup=true), then run:
```
wandb login
```
to sign into your account.

#### 2. Specify hyperparameters in default_config.py.

For wandb: Specify your wandb account under “entity” and title of the project under “project_name”. “run_name” will title this specific run within the project.

If specified, “load_from_checkpoint” indicates the saved model to load. Leave as “None” for training a new model.

Other hyperparameters are organized by category: hardware (choice of CUDA device), training, input data, LSTM VAE architecture, and classifier architecture.

#### 3. Train!
For a single run, use the command:
```
python main.py
```
For a hyperparameter sweep (multiple runs), we invite you to follow wandb’s [Quickstart guide](https://docs.wandb.ai/guides/sweeps/quickstart) and run the resulting wandb sweep command.

### 📕 Load a saved model.
There are three basic types of models to load:
* $\text{PirouNet}_\text{watch}.$
Copy contents of saved_models/pirounet_watch_config.py file into default_config.py.

* $\text{PirouNet}_\text{dance}.$
Copy contents of saved_models/pirounet_dance_config.py file into default_config.py.

* *Your new model.*
In default_config.py, specify “load_from_checkpoint” as the name and epoch corresponding your new model:“checkpoint_{run_name}_epoch{epoch}”.
Make sure the rest of the hyperparameters match those you used during training.

Once this is done, there are two options:
1. Continue training using this saved model as a starting point. See “Training” section.
2. Evaluate this saved model.

## 🕺 Evaluation ##

1. Follow the “Load a saved model” instructions to configure default_config.py.
2. Specify the parameters of the evaluation in eval_config.py. Note that “plot_recognition_accuracy” should only be set to True once a human labeler has blindly labeled PirouNet-generated dance sequences (using generate_for_blind_labeling and the web-labeling app), and exported the csv of labels to the pirounet/pirounet/data directory.
3. Unzip the pre-saved classifier model in saved_models/classifier.
4. Run the command:
```
python main_eval.py
```
This will produce a subfolder in pirounet/results containing all the qualitative and quantitative metrics included in our paper, as well as extra plots of the latent space and its entanglement. Among the qualitative generation metrics, two examples are provided below.


## 💃 Authors ##
[Mathilde Papillon](https://mathildep.ca)

[Mariel Pettee](https://mariel-pettee.github.io/)

[Nina Miolane](https://www.ninamiolane.com/)
",16,16,1,2,art,"[art, dance, deep-learning, lstm, machine-learning, semi-supervised-learning, variational-autoencoder]",0
lesliexin,sounds-of-home,,https://github.com/lesliexin/sounds-of-home,https://api.github.com/repos/sounds-of-home/lesliexin,"An audiovisual experience—step into my home 🏠. Created with React, TypeScript, Styled Components, Procreate...","# Sounds of Home 🎧🏠

![Alt text](src/assets/sohReadme.png?raw=true ""Title"")

# How Sounds of Home was built

## Available Scripts

In the project directory, you can run:

- `yarn start` [http://localhost:3000](http://localhost:3000)
- `yarn test` 
- `yarn build`
- `yarn eject`

## Architecture
This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).

## Audio Credits

Chinese Music:
Song: The Best Chinese Music Without Words (Beautiful Chinese Music)
Promoted by Amazing Music.
Original Video: https://youtu.be/N6dWQLhTkQM

Cicada: https://freesound.org/people/cupido-1/sounds/529572/

Nature: https://freesound.org/people/kevp888/sounds/440448/

Birds: https://freesound.org/people/xserra/sounds/162105/

Mahjong: https://freesound.org/people/al.barbosa/sounds/149041/

Street Ambience: https://freesound.org/people/Pashee/sounds/187356/
",16,16,2,5,art,"[art, audiovisual, creative-coding, react, sound, typescript]",0
