repo,user,organization,url (HTML),url (API),description,readme,stargazer count,watcher count,subscriber count,open issue count,topic (search),topics,NAICS Code
sebastianhaas,medical-appointment-scheduling,,https://github.com/sebastianhaas/medical-appointment-scheduling,https://api.github.com/repos/medical-appointment-scheduling/sebastianhaas,"Concept showcase for ""Appointment Scheduling System for Small and Medium-Sized Medical Facilities""","# Medical Appointment Scheduling

[![Greenkeeper badge](https://badges.greenkeeper.io/sebastianhaas/medical-appointment-scheduling.svg)](https://greenkeeper.io/)
[![Build Status](https://travis-ci.org/sebastianhaas/medical-appointment-scheduling.svg?branch=master)](https://travis-ci.org/sebastianhaas/medical-appointment-scheduling)
[![Dependency Status](https://david-dm.org/sebastianhaas/medical-appointment-scheduling.svg)](https://david-dm.org/sebastianhaas/medical-appointment-scheduling)
[![Join the chat at https://gitter.im/sebastianhaas/medical-appointment-scheduling](https://badges.gitter.im/sebastianhaas/medical-appointment-scheduling.svg)](https://gitter.im/sebastianhaas/medical-appointment-scheduling?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

Concept showcase for ""Design of a Web-Based Appointment Scheduling System for Small and Medium-Sized Medical Facilities"".

## Live showcase
An up-to-date snapshot of this repository is always available on [Heroku](https://scheduling-client.herokuapp.com).
> Due to the limitations of Heroku's free dynos and database service, it might take a while for the application to load initially. Also, there is a 10k row limit for free databases. Sometimes you might have to wipe test data other users created before being able to add new content. Test data can be inserted and deleted using the app-bar menu in the upper right corner.

## How to deploy
This application can be easily deployed to Heroku. tbd

## How to run locally
After checkout, run:
```
$ npm install
$ npm start
```
This requires node >=4 together with npm to be installed. This repository doesn't contain any backend, you need to have an instance of [medical-appointment-scheduling-server](https://github.com/sebastianhaas/medical-appointment-scheduling-server) running.

## Internationalization
Prepared for internationalization. The application is currently available in English and German. Translations are managed on POEditor.com in a [publicly available project](https://poeditor.com/projects/view?id=102821). The locale will be determined based on the user's browser settings and persisted to local storage. The logic can be found [here](https://github.com/sebastianhaas/medical-appointment-scheduling/blob/master/src/app/i18n-providers.ts#L47).

## Tests
Both unit and end-to-end tests do exist for most parts of the application.

### Unit tests
```
$ npm run test
```

### End-to-end tests
Make sure you have a running instance in another terminal before running end-to-end tests.
```
$ npm run e2e
```

## Code style
Code quality is ensured by `tslint` with `codelyzer` for Angular 2 specific linting.

## Technology stack
### Core technologies
* [Angular 2](https://angular.io/)
* [Angular Material](https://material.angular.io/)
* [SASS](http://sass-lang.com/)

### Bundling and packaging
* [webpack](https://webpack.github.io/)
* [npm](http://npmjs.com/)

### Testing
* [Karma](https://karma-runner.github.io/1.0/index.html)
* [Jasmine](http://jasmine.github.io/)
* [Protractor](http://www.protractortest.org/)
* [Selenium](http://docs.seleniumhq.org/)

### Code style
* [codelyzer](https://github.com/mgechev/codelyzer)
* [tslint](https://palantir.github.io/tslint/)

### Documentation
* [Typedoc](https://github.com/TypeStrong/typedoc)

### Internationalization
* [Angular 2's `ng-xi18n` tool](https://angular.io/docs/ts/latest/cookbook/i18n.html#!#ng-xi18n)
* [POEditor](https://poeditor.com/)

## License
[MIT](/LICENSE)
",133,133,9,113,health-care,"[angular, appointment-scheduling, concept-showcase, e-health, health-care, heroku, material-design, practice-management-software, scheduling, web-application]",62
JuliaHealth,juliahealth.github.io,JuliaHealth,https://github.com/JuliaHealth/juliahealth.github.io,https://api.github.com/repos/juliahealth.github.io/JuliaHealth,Website for the JuliaHealth organization (powered by Franklin.jl).,"# juliahealth.github.io

This repository contains the source code for the JuliaHealth website ([https://juliahealth.org](https://juliahealth.org)).

The website is powered by [Franklin.jl](https://github.com/tlienart/Franklin.jl) and the [Julia programming language](https://julialang.org).

",10,10,14,6,health-care,"[biomedical-informatics, biomedical-research, clinical-informatics, computational-health, digital-health, electronic-health-records, franklin, health, health-care, health-informatics, health-information-technology, healthcare, julia, julia-language, julia-programming-language, juliahealth, juliamedical, juliamedicine, medicine, public-health]",62
IKKIM00,Fall_Detection_using_multihorizon_forecasting,,https://github.com/IKKIM00/Fall_Detection_using_multihorizon_forecasting,https://api.github.com/repos/Fall_Detection_using_multihorizon_forecasting/IKKIM00,,"# General Description
This is original code for paper ""[Fall Detection using Biometric Information Based on Multi-Horizon Forecasting](https://ieeexplore.ieee.org/document/9956568)""(ICPR'22)

A fall detection method with multi-horizon forecasting usring Temporal Fusion Transformers and other deep learning methods.

For other deep learning methods, 1D CNN, single LSTM, stacked LSTM were used.

All models were configured to forecast falls through the window size of data from the perspective of regression instead of classification.

For the last predicted value, the class of the predicted values was classified on the basis of the threshold value. 

To verify benchmark performance, we faithfully reproduced the 1D CNN and LSTM-basedmodels, although the model structures were modified to enable regression in both cases because they were tailored to the classification task.

1D CNN model architecture is based on the model structure proposed in 2020 by Kraft et al([paper](https://github.com/IKKIM00/Fall_Detection_using_multihorizon_forecasting/files/6866631/Deep.Learning.Based.Fall.Detection.Algorithms.for.Embedded.Systems.Smartwatches.and.IoT.Devices.Using.Accelerometers.pdf)).

Signle LSTM and stacked LSTM model is based on the model architecture proposed in 2019 by Luna et al ([paper](https://github.com/IKKIM00/Fall_Detection_using_multihorizon_forecasting/files/6866652/sensors-19-04885-v2.pdf)).

# Requirements
`python==3.7.3`

`tensorflow-gpu==2.5.3` or `tensorflow==2.5.3`

`sklearn==0.24.2`

## Multi-horizon forecasting result
![model_pred](https://user-images.githubusercontent.com/37397258/126738142-7fc1218d-eb55-4f88-9c24-4112b320354b.jpg)
Prediction results for the SmartFall, Notch, DLR and MobiAct datasets in order using:

(a)-(d) TFT method, (e)-(h) Single LSTM, (i)-(l) Stacked LSTM, (m)-(p) 1D CNN

# Download Dataset
For `SmartFall` and `Notch` dataset, I have uploaded zip files in `dataset/`. You can also download data through the link below.

### SmartFall and Notch dataset
dataset url - https://userweb.cs.txstate.edu/~hn12/data/SmartFallDataSet/

paper - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6210545/


### DLR dataset
dataset url - https://www.dlr.de/kn/en/desktopdefault.aspx/tabid-12705/22182_read-50785/

### MobiAct dataset
dataset url - https://bmi.hmu.gr/the-mobifall-and-mobiact-datasets-2/


# How to use

## Data Preprocess

Please download all datasets through the URL or `zip` files provided in `dataset/`.

### SmartFall Dataset
1. Put dataset into directory named `dataset/SmartFall_Dataset/`.
2. For SmartFall dataset, preprocessing codes are included in `ipynb` files. 

### Notch Dataset
1. Put dataset into directory named `dataset/Notch_Dataset/`
2. For Notch dataset, preprocessing codes are included in `ipynb` files.

### DLR Dataset
1. Put dataset into directory named `dataset/ARS DLR Data Set/`.
2. Use `dataset/DLR_preprocess.ipynb` for preprocessing. Run all cells in the ipynb file. 
3. Save all preprocessed files in `dataset/dlr_preprocessed`. 

### MobiAct Dataset
1. Put dataset into directory named `dataset/MobiAct_Dataset_v2.0`.
2. Use `dataset/MobiAct_preprocess.ipynb` for preprocessing. Run all cells in the ipynb file.
3. Save all preprocessed files in `dataset/mobiact_preprocessed`.

## For DL Methods

> run `python dl_main.py <dataset_name> <model> <use_gpu>`

- `dataset_name`: choose between <mobiact, dlr, notch, smartfall>
- `model`: choose between <singleLSTM, stackedLSTM, CNN>
- `use_gpu`: if like to use GPU set to `yes` or set to `no`

-----
- You can find all previous ipynb files in `prev_jupyter_files/` .


## For TFT Method

### All files included are modified version of [original github repo](https://github.com/google-research/google-research/tree/master/tft) with all version error fixed(with tensorflow v2).

> run `python tft_main.py <dataset_name> <save_dir_name> <use_gpu> <restart_opt>`

- `dataset_name`: choose between <mobiact, dlr, notch, smartfall>
- `save_dir_name`: set save name
- `use_gpu`: if like to use GPU set to `yes` or set to `no`
- `restart_opt`: if like to restart set to `yes` or set to `no`

----
- You can find all previous ipynb files in `prev_jupyter_files/` .
- For the cases of personal biometric information removed, use files: `prev_jupyter_files/dlr_tft_wo_bioinfo.ipynb ` and `prev_jupyter_files/mobi_tft_no_bioinfo.ipynb`
",9,9,2,0,health-care,"[deep-learning, fall-detection, health-care, multi-horizon-forecasting]",62
pfftdammitchris,react-icd10,,https://github.com/pfftdammitchris/react-icd10,https://api.github.com/repos/react-icd10/pfftdammitchris,Search the International Classification of Diseases (ICD10) table,"# react-icd10

> Search the International Classification of Diseases table

ICD-10-CM (International Classification of Diseases, 10th Revision, Clinical Modification) is a medical coding system for classifying diagnoses and reasons for visits in U.S. health care settings ([source](https://clinicaltables.nlm.nih.gov/apidoc/icd10cm/v3/doc.html))

[![NPM](https://img.shields.io/npm/v/react-icd10.svg)](https://www.npmjs.com/package/react-icd10)

## Install

```bash
# NPM
npm install --save react-icd10

# Yarn
yarn add react-icd10
```

You will need to have a react version that supports [react hooks](https://reactjs.org/docs/hooks-overview.html) (v16.6+) to use this library, or you will receive errors.

## Usage

To use the component version, import directly from `react-icd10`. The default export is a render prop component that exposes the necessary states to use on your interface, along with a few handy utilities:

```jsx
import React from 'react'
import ReactICD10 from 'react-icd10'

const App = () => (
   <ReactICD10
    render={({
      onSearch,
      fetching,
      fetched,
      fetchError,
      data,
      reset,
    }) => (
      <div className='container'>
        <input
          onChange={(e) => onSearch(e.target.value)}
          type='text'
          placeholder='Search diagnosis'
        />
      </div>
    )}
  />
)

export default App
```

You can limit the results returned by passing in a `limit` prop to the render component. For example, passing in a limit of 100 will return a maximum of 100 results:

```js
const App = () => (
   <ReactICD10
    limit={100}
    render={({
      onSearch,
      fetching,
      fetched,
      fetchError,
      data,
      reset,
    }) => (
      <div className='container'>
        <input
          onChange={(e) => onSearch(e.target.value)}
          type='text'
          placeholder='Search diagnosis'
        />
      </div>
    )}
  />
)
```

If you need an additional constraint to return results that *must* include a second keyword somewhere in each result, you can pass in `include` and your keyword to it:

```js
const App = () => (
   <ReactICD10
    include=""medicine"" // Will also take an array of strings 
    render={({
      onSearch,
      fetching,
      fetched,
      fetchError,
      data,
      reset,
    }) => (
      <div className='container'>
        <input
          onChange={(e) => onSearch(e.target.value)}
          type='text'
          placeholder='Search diagnosis'
        />
      </div>
    )}
  />
)
```

You can either use the render prop component version that is exported as default, but you can optionally use the react hook version instead which is basically the same flow:

```js
import React from 'react'
import { useICD10 } from 'react-icd10'

const App = () => {
  const { onSearch, ...rest } = useICD10({ limit: 7 })

  const onChange = (e) => {
    onSearch(e.target.value)
  }

  return (
    <div className='container'>
      <div className='content'>
        <pre>
          <code>{JSON.stringify(rest, null, 2)}</code>
        </pre>
        <div>
          <input
            onChange={onChange}
            type='text'
            placeholder='Search diagnosis'
          />
        </div>
      </div>
    </div>
  )
}

export default App
```

### Methods

#### `onSearch`: (keyword: string) => Promise<void>

`onSearch` will use your keyword to query for diagnoses. After the call has finished, `data` will be provided as arguments to the render prop. The data is an object that with this shape:

```ts
interface Data {
  codes: string[]
  results: { [code: string]: ICD10Object, ...others }
  total: number
}

interface ICD10Object {
  code?: string
  description?: string
  comment?: string
}
```

For those who would like to see it from a visual perspective:

![react-icd10 international classification of diseases library](https://pfftdammitchris-react.s3-us-west-1.amazonaws.com/react-icd10/icd10.jpg)

If an error occurred while fetching for the results, `fetchError` will be returned as an `Error` object as part of the render props.

`onSearch` is also optimized internally to avoid duplicate requests, so you can assure that users who are constantly typing for results won't be making mass amounts of requests in between.

#### `reset`: () => void

If you need to reset your results back to an empty state, you can call `reset`, provided from render props as well.

## Dependencies

- axios

## License

MIT © [pfftdammitchris](https://github.com/pfftdammitchris)
",7,7,0,27,health-care,"[diagnoses, disease-classification, diseases, doctor, health, health-care, health-check, health-informatics, healthcare, icd10, medical, medicinal, medicine, medicine-classification, pharmacy, react, react-components, search, telemedicine, telemedicine-api]",62
neemiasbsilva,NeemiasBuceli-ds-portfolio,,https://github.com/neemiasbsilva/NeemiasBuceli-ds-portfolio,https://api.github.com/repos/NeemiasBuceli-ds-portfolio/neemiasbsilva,"Hello guys, welcome to my Data Science Portfolio. I include some knowledges I earn in my journey. I'll include some case study, papers, and code. Please check the readme.","# Neemias Buceli Portfolio

![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-%233F4F75.svg?style=for-the-badge&logo=plotly&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white)
![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)

## Context

Hello guys, welcome to my Data Science Portfolio. I include some knowledges I earn in my journey. I'll include some case study, papers, and code.

**Note**: This repository was created recently and I upgrade as soon as I can.

## Table of Contents

- [Pogramming Skills](programming-skills);
- [Math & Stat](math--stat);
- [Machine Learning](machine-learning).

## Math & Stat

- [Fundamental of Statistic](https://github.com/neemiasbsilva/NeemiasBuceli-ds-portfolio/tree/main/mathematic-and-statistics/fundamental-of-statistics);
  - Population vs Sample;
  - Mean;
  - Variance;
  - Standard Deviation (STD);
  - Correlation;
  - Covariance;
  - Probability Distribution Functions;
  - Bayes Theorem.
- [Bootstraping](mathematic-and-statistics/bootstrapping);
- [Expectation Algorithm](mathematic-and-statistics/expectation_algorithm);

## Programming Skills

- [Code Challenge](https://github.com/neemiasbsilva/programming-skills);
- [knapsack-problem-using-dp-grasp-tabu](https://github.com/neemiasbsilva/knapsack-problem-using-dp-grasp-tabu);
  - Dynamic programming;
  - Grasp Heuristic;
  - TABU Search.

## Machine Leaning

- [Machine Leaning Algorithms - Tutorial](https://github.com/neemiasbsilva/machine-learning-algorithm);
  - [Regression in Convolutional Neural Network for Applied to Plant Leaf Count](https://github.com/neemiasbsilva/regression-in-CNNs-applied-to-plant-leaf-count);
  - [Case Studies: Data Science Projects](https://github.com/neemiasbsilva/case-study-data-science);
  - [Forecasting Data Analysis](forecasting/);
- [Pattern Recognition](pattern-recognition/):
  - Linear Algebra - Singular Value Decomposition;
    - Vector Calculus;
    - Probability and Distribution;
    - Optimization and Convex Optimization.
    - Machine Learning Algorithm:
      - Linear:
        - Perceptron;
        - Adaline;
        - Logistic Regression.
      - Non Linear:
        - SVM;
        - Decision Tree;
        - Random Forest;
        - Adaboost;
        - Gradient Boosting;
        - XGBoost.
",1,1,3,0,health-care,"[case-study, churn-prediction, code-challenges, data-analysis, data-science, deep-learning, forecasting, fundamental-of-statistics, health-care, image-recognition, machine-learnin, machine-learning, math, mathematics, pattern-recognition, portfolio, programming-skills, speech-emotion-detection, statistics, voice-activity-detection]",62
ArpitSachan,dedatom-A-digital-health-care-system,,https://github.com/ArpitSachan/dedatom-A-digital-health-care-system,https://api.github.com/repos/dedatom-A-digital-health-care-system/ArpitSachan,This repository contains a health care app based on geolocation and digitization of the health system. It includes real-time chat (to be encrypted) enabled with image-picker and hostpital finder using google maps api.,"# dedatom : A digital Health care system

This repository contains a health care app based on geolocation and digitization of the health system. It includes real-time chat (to be encrypted) enabled with image-picker and hostpital finder using google maps api.

### Key Features:
 - Hostpital finder using google map API
 - One to one chat
 - BMI calculator

<img src=""https://user-images.githubusercontent.com/29403783/83930992-03ee6e80-a7b8-11ea-81d1-9601aa0cf61c.png"" width=200>
<img src=""https://user-images.githubusercontent.com/29403783/83931000-094bb900-a7b8-11ea-8e2a-8eb093276bcd.png"" width =200>
<img src=""https://user-images.githubusercontent.com/29403783/83931010-0ea90380-a7b8-11ea-944d-25922211b47c.png"" width=200>
",0,0,1,0,health-care,"[android, android-application, authentication, dart, firebase, flutter, google-maps-api, health-care, health-care-application, ios, place-search, realtime-chat]",62
warnbergg,pemett,,https://github.com/warnbergg/pemett,https://api.github.com/repos/pemett/warnbergg,Python Ensemble Model for Emergency department Trauma Triage (EMETT).,"pemett
==============================

Python Ensemble Model for Emergency department Trauma Triage (EMETT).

Work in progress! Porting from R in the `emett` package to python, as ensemble learning is more convenient with python.

Code follows the [Google style guide](https://google.github.io/styleguide/pyguide.html).

Part of the TTRIS project. Website: https://www.titco.org/projects

Naming Conventions
------------
Follow the naming conventions of cookiecutter,
> Follow a naming convention that shows the owner and the order the analysis was done in. We use the format `<step>-<ghu> ser>-<description>.ipynb` (e.g., `0.3-bull-visualize-distributions.ipynb`).

Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target=""_blank"" href=""https://drivendata.github.io/cookiecutter-data-science/"">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
",0,0,0,0,health-care,"[data-science, health-care, machine-learning]",62
lindbrook,cholera,,https://github.com/lindbrook/cholera,https://api.github.com/repos/cholera/lindbrook,R Package for Analyzing John Snow's 1854 Cholera Map,"
<!-- README.md is generated from README.Rmd. Please edit that file -->
[![CRAN\_Status\_Badge](http://www.r-pkg.org/badges/version/cholera)](https://cran.r-project.org/package=cholera)
[![GitHub\_Status\_Badge](https://img.shields.io/badge/GitHub-0.8.0.9150-red.svg)](https://github.com/lindbrook/cholera/blob/master/NEWS.md)
## cholera: amend, augment and aid analysis of Snow’s cholera map

#### package features

- Fixes two sets of errors in Dodson and Tobler’s 1992 digitization of
  Snow’s map: 1) [three misplaced
  cases/fatalities](https://github.com/lindbrook/cholera/blob/master/docs/notes/duplicate.missing.cases.notes.md)
  and 2) [one missing road
  segment](https://github.com/lindbrook/cholera/blob/master/docs/notes/clifford.md)
  (part of Clifford Street).
- “Unstacks” the data in two ways to make analysis and visualization
  easier and more meaningful.
- Computes and visualizes “pump neighborhoods” based on Euclidean
  distance (Voronoi tessellation) and walking distance.
- Overlay graphical elements and features like kernel density estimates,
  Voronoi diagrams, Snow’s Broad Street neighborhood, and notable
  landmarks (John Snow’s residence, the Lion Brewery, etc.) via `add*()`
  functions.
- Includes a variety of functions to find and highlight cases, roads,
  pumps and paths.
- Appends street names to the `roads` data set.
- Includes the revised pump data used in the second version of Snow’s
  map from the Vestry report, which also includes the “correct” location
  of the Broad Street pump.
- Adds two aggregate time series fatalities data sets, taken from the
  Vestry report.
- Support for parallel computation on Linux, macOS and Windows.
- With ‘cholera’ version \>= 0.8.0, preliminary and provisional support
  for georeferenced (longitude and latitude) versions of data and
  functions. [Details below](#longitude-and-latitude).

#### getting started

To install ‘cholera’ from CRAN:

``` r
install.packages(""cholera"")
```

To install the current development version from GitHub:

``` r
# You may need to first install the 'remotes' via install.packages(""remotes"").
remotes::install_github(""lindbrook/cholera"", build_vignettes = TRUE)
```

## background

John Snow’s map, published in his *On The Mode Of Communication Of
Cholera*, of the 1854 cholera outbreak in London is one of the best
known examples of data visualization and information design:

![](vignettes/msu-snows-mapB.jpg)

By plotting the number and location of fatalities using stacks of bars
on a map, Snow was able to perform a task that is now easily taken for
granted: he visualized a spatial distribution. Looking at the results,
the pattern on the map seems unmistakable. The map appears to support
Snow’s claims that cholera is a waterborne disease and that the pump on
Broad Street is the source of the outbreak.

And yet, despite its virtues, the map failed to convince either the
authorities or Snow’s colleagues in the medical and scientific
communities. Even today, many are skeptical of the map’s ability to
support such claims. Beyond considerations of time and place, what
critics past and present are picking up on is that a concentration of
cases around the Broad Street pump alone should not be enough to
convince us. The problem is the map does not refute the primary rival
explanation to waterborne transmission: the pattern we see is not unlike
what airborne transmission (miasma theory) might look like. In other
words, while the presence of a pump at or near the epicenter of the
distribution of fatalities is strong circumstantial evidence, it is
nonetheless circumstantial.

## pump neighborhoods

This may be the reason why Snow added a graphical annotation to a second
lesser-known version of the map, published in the *Report On The Cholera
Outbreak In The Parish Of St. James, Westminster, During The Autumn Of
1854*.

![](vignettes/fig12-6.png)

Despite its hand-drawn, back-of-the-envelope appearance, Snow writes:
“The inner dotted line on the map shews \[sic\] the various points which
have been found by careful measurement to be at an equal distance by the
nearest road from the pump in Broad Street and the surrounding pumps …”
(Ibid., p. 109). My interpretation of this statement is that, guided by
the principle that all else being equal people tend to choose the
closest pump, Snow is computing a *pump neighborhood*: the set of
addresses or locations defined by their relative proximity to a specific
water pump. By doing so, Snow’s annotation sets limits on where we
should and should *not* find fatalities. In short, Snow’s annotation is
a hypothesis or prediction.

#### computing pump neighborhoods

While his actual data and the specifics method of computation appear to
be lost to history, I reverse engineer what I infer to be his approach
by doing the following. First, from the quotation above I assume that
his measure of proximity is the walking distance along the streets of
Soho. Second, putting aside aside questions about the map’s accuracy
(it’s actually a commercial map that Snow annotated), I consider the map
to be the definitive “text” and make it the de facto source of data.

I then wrote functions that compute and visualize walking distances on
the map. The value of these functions go beyond the ability to replicate
and validate Snow’s efforts. By allowing you to compute hypothetical
neighborhoods via selective inclusion or exclusion of pumps or to allow
for different measures of proximity (e.g., Euclidean), they also allow
you to explore counterfactual scenarios. Ultimately, this can help us to
better assess whether we really can use the map to “prove” Snow’s
claims.

#### walking v. Euclidean neighborhoods

While walking distanced based neighborhoods are based on paths that
follow streets, Euclidean distance based neighborhoods are based on
straight line paths between a location and the nearest (or selected)
pump:

``` r
streetNameLocator(zoom = 1, cases = NULL, highlight = FALSE, add.subtitle = FALSE, add.title = FALSE)
title(main = ""Walking Distances"")
invisible(lapply(c(1, 191, 46, 363, 85), addWalkingPath))

streetNameLocator(zoom = 1, cases = NULL, highlight = FALSE, add.subtitle = FALSE, add.title = FALSE)
title(main = ""Euclidean Distances"")
invisible(lapply(c(1, 191, 46, 363, 85), addEuclideanPath))
```

<img src=""man/figures/README-unnamed-chunk-4-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-4-2.png"" width=""50%"" />

To build a neighborhood, we apply this algorithm to each location or
“address” with at least one observed fatality. This builds the
“observed” neighborhood:

``` r
plot(neighborhoodWalking())
plot(neighborhoodEuclidean())
```

<img src=""man/figures/README-unnamed-chunk-5-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-5-2.png"" width=""50%"" />

Ultimately, for testing purposes we want the “expected” neighborhoods.
For walking neighborhoods, I use the same approach but use simulated
data. Using `sp::spsample()` and `sp::Polygon()`, I place 20,000
regularly spaced points, which lie approximately 6 meters apart,
`unitMeter(dist(regular.cases[1:2, ]))`, across the face of the map and
then compute the shortest path to the nearest pump.

``` r
plot(neighborhoodWalking(case.set = ""expected""), ""area.polygons"")
```

<img src=""man/figures/README-unnamed-chunk-6-1.png"" width=""50%"" />

For Euclidean distance based neighborhoods, we can use the same
simulated data and compute the as-the-crow-flies distance to the nearest
pump. Or, we can leverage a more computationally efficient approach,
Voronoi tessellation, which will produce the same neighborhoods.

``` r
plot(neighborhoodEuclidean(case.set = ""expected""))
plot(neighborhoodVoronoi())
```

<img src=""man/figures/README-unnamed-chunk-7-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-7-2.png"" width=""50%"" />

#### exploring walking neighborhoods

To explore “observed” walking neighborhoods, use `neighborhoodWalking()`
with the `pump.select` argument:

``` r
plot(neighborhoodWalking(pump.select = 6:7))
plot(neighborhoodWalking(pump.select = -7))
```

<img src=""man/figures/README-unnamed-chunk-8-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-8-2.png"" width=""50%"" />

To explore “expected” walking neighborhoods, add the case.set =
“expected” argument:

``` r
plot(neighborhoodWalking(pump.select = 6:7, case.set = ""expected""), type = ""area.polygons"")
plot(neighborhoodWalking(pump.select = -7, case.set = ""expected""), type = ""area.polygons"")
```

<img src=""man/figures/README-unnamed-chunk-9-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-9-2.png"" width=""50%"" />

#### exploring Euclidean neighborhoods

To explore “observed” Euclidean neighborhoods, use
`neighborhoodEuclidean()` with the `pump.select` argument:

``` r
plot(neighborhoodEuclidean(pump.select = 6:7))
plot(neighborhoodEuclidean(pump.select = -7))
```

<img src=""man/figures/README-unnamed-chunk-10-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-10-2.png"" width=""50%"" />

To explore “expected” Euclidean neighborhoods, use
`neighborhoodVoronoi()` with the `pump.select` argument:

``` r
plot(neighborhoodVoronoi(pump.select = 6:7))
plot(neighborhoodVoronoi(pump.select = -7))
```

<img src=""man/figures/README-unnamed-chunk-11-1.png"" width=""50%"" /><img src=""man/figures/README-unnamed-chunk-11-2.png"" width=""50%"" />

#### parallelization

Parallelization is implemented using the ‘parallel’ package, which is
part of the base R distribution. Where applicable, parallelization is
enabled by default via `multi.core = TRUE` (you can also set or limit
the number of cores by passing an integer or by setting
`multi.core = FALSE`. Note that although some precautions are taken in
the R application, the developers of the ‘parallel’ package strongly
discourage against using parallelization within a GUI or embedded
environment. See `vignette(""Parallelization"")` for details. That said,
I’ve had few, if any, problems with using the package in parallel on
macOS with either the [R application](https://www.r-project.org/) or the
[RStudio IDE](https://posit.co/products/open-source/rstudio/).

#### longitude and latitude

[‘cholera’](https://cran.r-project.org/package=cholera) now has
preliminary, limited support for georeferenced (longitude and latitude)
versions of some data and functions. This support goes beyond a proof of
concept but is currently less than a complete re-implementation of the
package’s native (non-georeferenced) functionality. The georeferencing
was done manually using [QGIS](https://qgis.org/en/site/); specifically
its Georeferencer tool and its interface to
[OpenStreetMap](https://www.openstreetmap.org). The target coordinate
reference system (CRS) of these data is EPSG:4326. What makes this
effort preliminary is that the choice of ground control points,
transformation type (e.g., thin plate spine), and resampling method
(e.g., nearest neighbor) are still in flux. Thus, results and
coordinates may change in the future.

Six functions are available:

``` r
snowMap(latlong = TRUE)
```

<img src=""man/figures/README-latlong-1.png"" width=""50%"" />

``` r
plot(latlongWalkingPath())
plot(walkingPath())  # Dodson and Tobler native scale for comparison
```

<img src=""man/figures/README-latlong_walking_path-1.png"" width=""50%"" /><img src=""man/figures/README-latlong_walking_path-2.png"" width=""50%"" />

``` r
plot(latlongEuclideanPath())
plot(euclideanPath())  # Dodson and Tobler native scale for comparison
```

<img src=""man/figures/README-latlong_euclidean_path-1.png"" width=""50%"" /><img src=""man/figures/README-latlong_euclidean_path-2.png"" width=""50%"" />

``` r
plot(latlongNeighborhoodEuclidean())
```

<img src=""man/figures/README-latlong_euclidean-1.png"" width=""50%"" />

``` r
plot(latlongNeighborhoodVoronoi())
```

<img src=""man/figures/README-latlong_voronoi-1.png"" width=""50%"" />

``` r
plot(latlongNeighborhoodWalking())
```

<img src=""man/figures/README-latlong_walking-1.png"" width=""50%"" />

#### vignettes

The vignettes are available in the package as well as online at the
links below.

[Duplicate and Missing
Cases](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/duplicate.missing.cases.md)
describes the two coding errors and the three misplaced cases that I
argue are present in Dodson and Tobler’s (1992) digitization of Snow’s
map.

[“Unstacking”
Bars](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/unstacking.bars.md)
discusses the inferential and visual reasons to “unstack” bars. Then, it
describes the two “unstacked” data sets: one using “fatalities” and one
using “addresses” as the unit of observation.

[Roads](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/roads.md)
covers issues related to roads. This includes discussion of how and why
I move pump \#5 from Queen Street (I) to Marlborough Mews, the overall
structure of the `roads` data set, “valid” road names, and my
back-of-the-envelope translation from the map’s nominal scale to meters
(and yards).

[voronoiPolygons(): Tiles, Triangles and
Polygons](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/tiles.polygons.md)
focuses on the `voronoiPolygons()` function, which extracts the vertices
of triangles (Delaunay triangulation) and tiles (Dirichelet or Voronoi
tessellation) from `deldir::deldir()` for use with polygon() and other
functions.

[Kernel Density
Plot](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/kernel.density.md)
discusses the the syntax of `addKernelDensity()`, which allows you to
define “populations” and subsets of pumps. This syntax is used in many
of the functions in ‘cholera’.

[Time
Series](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/time.series.md)
discusses functions and data related to the aggregate time series
fatalities data and the questions surrounding the effect of the removal
of the handle from the Broad Street pump.

[Parallelization](https://github.com/lindbrook/cholera/blob/master/docs/vignettes/parallelization.md)
discusses the parallelization of selected functions and provides
benchmark timings.

#### lab notes

The lab notes, which are only available online, go into detail about
certain issues and topics discussed in the vignettes:

[note on duplicate and missing
cases](https://github.com/lindbrook/cholera/blob/master/docs/notes/duplicate.missing.cases.notes.md)
documents the specifics of how I fixed the two apparent coding errors
and three apparently misplaced case in Dodson and Tobler’s data.

[Clifford Street missing
segment](https://github.com/lindbrook/cholera/blob/master/docs/notes/clifford.md)
describes what I believe is far Western part (segment) of Clifford
Street is missing from Dodson and Tobler’s (1992) digitization of Snow’s
map.

[computing street
addresses](https://github.com/lindbrook/cholera/blob/master/docs/notes/unstacking.bars.notes.md)
discusses how I use orthogonal projection and hierarchical cluster
analysis to “unstack” bars and compute a stack’s “address”.

[Euclidean v. Voronoi
neighborhoods](https://github.com/lindbrook/cholera/blob/master/docs/notes/euclidean.voronoi.md)
discusses why there are separate functions, `neighborhoodEuclidean()`
and `neighborhoodVoronoi()`, for Euclidean distance based neighborhoods.

[points v.
polygons](https://github.com/lindbrook/cholera/blob/master/docs/notes/pump.neighborhoods.notes.md)
discusses the tradeoff between using points() and polygon() to plot
“expected” neighborhood using area plots and the computation of polygon
vertices.

[computing Voronoi diagrams with geographic
data](https://github.com/lindbrook/cholera/blob/master/docs/notes/latlongVoronoi.md)
describes the problems and a working solution for computing Voronoi
diagrams with data that use latitude and longitude.

[references](https://github.com/lindbrook/cholera/blob/master/docs/notes/references.md)
is an informal list of articles and books about cholera, John Snow and
the 1854 outbreak.
",138,138,5,1,public-health,"[cholera, data-visualization, datasets, epidemiology, john-snow, public-health, r, triangulation-delaunay, voronoi, voronoi-polygons]",62
ropensci,fingertipsR,ropensci,https://github.com/ropensci/fingertipsR,https://api.github.com/repos/fingertipsR/ropensci,R package to interact with Public Health England’s Fingertips data tool,"
<!-- README.md is generated from README.Rmd. Please edit that file -->

[![codecov](https://codecov.io/gh/ropensci/fingertipsR/branch/master/graph/badge.svg?token=MpVheRqaRo)](https://codecov.io/gh/ropensci/fingertipsR)
[![](https://badges.ropensci.org/168_status.svg)](https://github.com/ropensci/software-review/issues/168)
[![R build
status](https://github.com/ropensci/fingertipsR/workflows/R-CMD-check/badge.svg)](https://github.com/ropensci/fingertipsR/actions)

# fingertipsR

This is an R package to interact with Public Health England’s
[Fingertips](http://fingertips.phe.org.uk/) data tool. Fingertips is a
major public repository of population and public health indicators for
England. The site presents the information in many ways to improve
accessibility for a wide range of audiences ranging from public health
professionals and researchers to the general public. The information
presented is a mixture of data available from other public sources, and
those that are available through user access agreements with other
organisations. The source of each indicator presented is available using
the `indicator_metadata()` function.

This package can be used to load data from the Fingertips API into R for
further use.

## Installation

### rOpenSci

Get the latest released, stable version from rOpenSci:

``` r
# Enable repository from ropensci
options(repos = c(
  ropensci = 'https://ropensci.r-universe.dev',
  CRAN = 'https://cloud.r-project.org'))

# Download and install fingertipsR in R
install.packages('fingertipsR')
```

### With remotes

You can install the latest development version from github using
[remotes](https://github.com/r-lib/remotes):

``` r
# install.packages(""remotes"")
remotes::install_github(""rOpenSci/fingertipsR"",
                        build_vignettes = TRUE,
                        dependencies = ""suggests"")
```

## Example

This is an example of a workflow for downloading data for the indicator
on *Healthy Life Expectancy at Birth* from the *Public Health Outcomes
Framework* profile.

The `profiles()` function presents all of the available profiles:

``` r
library(fingertipsR)
profs <- profiles()
profs <- profs[grepl(""Public Health Outcomes Framework"", profs$ProfileName),]
head(profs)
#> # A tibble: 6 x 4
#>   ProfileID ProfileName                        DomainID DomainName              
#>       <int> <chr>                                 <int> <chr>                   
#> 1        19 Public Health Outcomes Framework    1000049 A. Overarching indicato~
#> 2        19 Public Health Outcomes Framework    1000041 B. Wider determinants o~
#> 3        19 Public Health Outcomes Framework    1000042 C. Health improvement   
#> 4        19 Public Health Outcomes Framework    1000043 D. Health protection    
#> 5        19 Public Health Outcomes Framework    1000044 E. Healthcare and prema~
#> 6        19 Public Health Outcomes Framework 1938132983 Supporting information
```

This table shows that the `ProfileID` for the Public Health Outcomes
Framework is 19. This can be used as an input for the `indicators()`
function:

``` r
profid <- 19
inds <- indicators(ProfileID = profid)
print(inds[grepl(""Healthy"", inds$IndicatorName), c(""IndicatorID"", ""IndicatorName"")])
#> # A tibble: 2 x 2
#>   IndicatorID IndicatorName                          
#>         <int> <fct>                                  
#> 1       90362 A01a - Healthy life expectancy at birth
#> 2       93505 A01a - Healthy life expectancy at 65
```

Healthy Life Expectancy at Birth has the `IndicatorID` equal to 90362.

Finally, the data can be extracted using the `fingertips_data()`
function using that `IndicatorID`:

``` r
indid <- 90362
df <- fingertips_data(IndicatorID = indid, AreaTypeID = 202)
head(df)
#>   IndicatorID                    IndicatorName ParentCode ParentName  AreaCode
#> 1       90362 Healthy life expectancy at birth       <NA>       <NA> E92000001
#> 2       90362 Healthy life expectancy at birth       <NA>       <NA> E92000001
#> 3       90362 Healthy life expectancy at birth  E92000001    England E12000001
#> 4       90362 Healthy life expectancy at birth  E92000001    England E12000002
#> 5       90362 Healthy life expectancy at birth  E92000001    England E12000003
#> 6       90362 Healthy life expectancy at birth  E92000001    England E12000004
#>                          AreaName AreaType    Sex      Age CategoryType
#> 1                         England  England   Male All ages         <NA>
#> 2                         England  England Female All ages         <NA>
#> 3               North East region   Region   Male All ages         <NA>
#> 4               North West region   Region   Male All ages         <NA>
#> 5 Yorkshire and the Humber region   Region   Male All ages         <NA>
#> 6            East Midlands region   Region   Male All ages         <NA>
#>   Category Timeperiod    Value LowerCI95.0limit UpperCI95.0limit
#> 1     <NA>  2009 - 11 63.02647         62.87787         63.17508
#> 2     <NA>  2009 - 11 64.03794         63.88135         64.19453
#> 3     <NA>  2009 - 11 59.71114         59.19049         60.23179
#> 4     <NA>  2009 - 11 60.76212         60.39880         61.12544
#> 5     <NA>  2009 - 11 60.84033         60.38649         61.29417
#> 6     <NA>  2009 - 11 62.60207         62.07083         63.13332
#>   LowerCI99.8limit UpperCI99.8limit Count Denominator Valuenote RecentTrend
#> 1               NA               NA    NA          NA      <NA>        <NA>
#> 2               NA               NA    NA          NA      <NA>        <NA>
#> 3               NA               NA    NA          NA      <NA>        <NA>
#> 4               NA               NA    NA          NA      <NA>        <NA>
#> 5               NA               NA    NA          NA      <NA>        <NA>
#> 6               NA               NA    NA          NA      <NA>        <NA>
#>   ComparedtoEnglandvalueorpercentiles ComparedtoRegionvalueorpercentiles
#> 1                        Not compared                       Not compared
#> 2                        Not compared                       Not compared
#> 3                               Worse                       Not compared
#> 4                               Worse                       Not compared
#> 5                               Worse                       Not compared
#> 6                             Similar                       Not compared
#>   TimeperiodSortable Newdata Comparedtogoal Timeperiodrange
#> 1           20090000    <NA>           <NA>              3y
#> 2           20090000    <NA>           <NA>              3y
#> 3           20090000    <NA>           <NA>              3y
#> 4           20090000    <NA>           <NA>              3y
#> 5           20090000    <NA>           <NA>              3y
#> 6           20090000    <NA>           <NA>              3y
```

## Use

Please see the vignettes for information on use.

``` r
browseVignettes(""fingertipsR"")
```

## More information

-   Please note that the ‘fingertipsR’ project is released with a
    [Contributor Code of
    Conduct](https://github.com/ropensci/fingertipsR/blob/master/CODE_OF_CONDUCT.md).
    By contributing to this project, you agree to abide by its terms.
-   License: [GPL-3](https://opensource.org/licenses/GPL-3.0)

[![ropensci_footer](https://ropensci.org/public_images/ropensci_footer.png)](https://ropensci.org)
",79,79,22,24,public-health,"[api-wrapper, cran, fingertips, health, open-data, peer-reviewed, public-health, public-health-england, r, r-package, rstats]",62
ConnorDonegan,geostan,,https://github.com/ConnorDonegan/geostan,https://api.github.com/repos/geostan/ConnorDonegan,Bayesian spatial analysis,"
<!-- README.md is generated from README.Rmd. Please edit that file -->

<img src=""man/figures/logo.png"" align=""right"" width=""160"" />

## geostan: Bayesian spatial analysis

The [**geostan**](https://connordonegan.github.io/geostan/) R package
supports a complete spatial analysis workflow with Bayesian models for
areal data, including a suite of functions for visualizing spatial data
and model results. For demonstrations and discussion, see the package
[help
pages](https://connordonegan.github.io/geostan/reference/index.html) and
[vignettes](https://connordonegan.github.io/geostan/articles/index.html)
on spatial autocorrelation, spatial measurement error models, and
spatial regression with raster layers.

The package is particularly suitable for public health research with
spatial data, and complements the
[**surveil**](https://connordonegan.github.io/surveil/) R package for
time series analysis of public health surveillance data.

**geostan** models were built using [**Stan**](https://mc-stan.org), a
state-of-the-art platform for Bayesian modeling.

[![DOI](https://joss.theoj.org/papers/10.21105/joss.04716/status.svg)](https://doi.org/10.21105/joss.04716)

### Disease mapping and spatial regression

Statistical models for data recorded across areal units like states,
counties, or census tracts.

### Observational uncertainty

Incorporate information on data reliability, such as standard errors of
American Community Survey estimates, into any **geostan** model.

### Censored observations

Vital statistics and disease surveillance systems like CDC Wonder censor
case counts that fall below a threshold number; **geostan** can model
disease or mortality risk with censored observations.

### Spatial analysis tools

Tools for visualizing and measuring spatial autocorrelation and map
patterns, for exploratory analysis and model diagnostics.

### The RStan ecosystem

Interfaces easily with many high-quality R packages for Bayesian
modeling.

### Custom spatial models

Tools for building custom spatial models in
[Stan](https://mc-stan.org/).

## Installation

Install **geostan** from CRAN using:

``` r
install.packages(""geostan"")
```

## Support

All functions and methods are documented (with examples) on the website
[reference](https://connordonegan.github.io/geostan/reference/index.html)
page. See the package
[vignettes](https://connordonegan.github.io/geostan/articles/index.html)
for more on exploratory spatial data analysis, spatial measurement error
models, and spatial regression with large raster layers.

To ask questions, report a bug, or discuss ideas for improvements or new
features please visit the
[issues](https://github.com/ConnorDonegan/geostan/issues) page, start a
[discussion](https://github.com/ConnorDonegan/geostan/discussions), or
submit a [pull request](https://github.com/ConnorDonegan/geostan/pulls).

## Usage

Load the package and the `georgia` county mortality data set (ages
55-64, years 2014-2018):

``` r
library(geostan)
data(georgia)
```

The `sp_diag` function provides visual summaries of spatial data,
including a histogram, Moran scatter plot, and map:

``` r
A <- shape2mat(georgia, style = ""B"")
sp_diag(georgia$rate.female, georgia, w = A)
#> 3 NA values found in x; they will be dropped from the data before creating the Moran plot. If matrix w was row-standardized, it no longer is. You may want to use a binary connectivity matrix using style = 'B' in shape2mat.
#> Warning: Removed 3 rows containing non-finite values (`stat_bin()`).
```

<img src=""man/figures/README-unnamed-chunk-3-1.png"" style=""display: block; margin: auto;"" />

There are three censored observations in the `georgia` female mortality
data, which means there were 9 or fewer deaths in those counties. The
following code fits a spatial conditional autoregressive (CAR) model to
female county mortality data. By using the `censor_point` argument we
include our information on the censored observations to obtain results
for all counties:

``` r
cars <- prep_car_data(A)
#> Range of permissible rho values:  -1.661134 1
fit <- stan_car(deaths.female ~ offset(log(pop.at.risk.female)),
                censor_point = 9,
        data = georgia,
        car_parts = cars,
        family = poisson(),
        cores = 4, # for multi-core processing
        refresh = 0) # to silence some printing
#> 
#> *Setting prior parameters for intercept
#> Distribution: normal
#>   location scale
#> 1     -4.7     5
#> 
#> *Setting prior for CAR scale parameter (car_scale)
#> Distribution: student_t
#>   df location scale
#> 1 10        0     3
#> 
#> *Setting prior for CAR spatial autocorrelation parameter (car_rho)
#> Distribution: uniform
#>   lower upper
#> 1  -1.7     1
```

Passing a fitted model to the `sp_diag` function will return a set of
diagnostics for spatial models:

``` r
sp_diag(fit, georgia, w = A)
#> Using sp_diag(y, shape, rates = TRUE, ...). To examine data as (unstandardized) counts, use rates = FALSE.
#> 3 NA values found in x; they will be dropped from the data before creating the Moran plot. If matrix w was row-standardized, it no longer is. You may want to use a binary connectivity matrix using style = 'B' in shape2mat.
#> Warning: Removed 3 rows containing missing values
#> (`geom_pointrange()`).
```

<img src=""man/figures/README-unnamed-chunk-5-1.png"" style=""display: block; margin: auto;"" />

The `print` method returns a summary of the probability distributions
for model parameters, as well as Markov chain Monte Carlo (MCMC)
diagnostics from Stan (Monte Carlo standard errors of the mean
`se_mean`, effective sample size `n_eff`, and the R-hat statistic
`Rhat`):

``` r
print(fit)
#> Spatial Model Results 
#> Formula: deaths.female ~ offset(log(pop.at.risk.female))
#> Spatial method (outcome):  CAR 
#> Likelihood function:  poisson 
#> Link function:  log 
#> Residual Moran Coefficient:  0.0021755 
#> WAIC:  1291.91 
#> Observations:  159 
#> Data models (ME): none
#> Inference for Stan model: foundation.
#> 4 chains, each with iter=2000; warmup=1000; thin=1; 
#> post-warmup draws per chain=1000, total post-warmup draws=4000.
#> 
#>             mean se_mean    sd   2.5%    25%    50%    75%  97.5% n_eff  Rhat
#> intercept -4.673   0.002 0.093 -4.843 -4.716 -4.674 -4.630 -4.497  1636 1.000
#> car_rho    0.922   0.001 0.058  0.778  0.893  0.935  0.967  0.995  3214 1.001
#> car_scale  0.458   0.001 0.035  0.393  0.433  0.455  0.481  0.532  3867 1.000
#> 
#> Samples were drawn using NUTS(diag_e) at Wed Oct  4 12:20:45 2023.
#> For each parameter, n_eff is a crude measure of effective sample size,
#> and Rhat is the potential scale reduction factor on split chains (at 
#> convergence, Rhat=1).
```

More demonstrations can be found in the package [help
pages](https://connordonegan.github.io/geostan/reference/index.html) and
[vignettes](https://connordonegan.github.io/geostan/articles/index.html).
",47,47,3,0,public-health,"[bayesian, bayesian-inference, bayesian-statistics, epidemiology, modeling, public-health, r, r-package, rspatial, rstats, spatial, stan]",62
COVID19-Malta,COVID19-Data,COVID19-Malta,https://github.com/COVID19-Malta/COVID19-Data,https://api.github.com/repos/COVID19-Data/COVID19-Malta,This is an Open Aggregated Dataset for the COVID19 Cases in Malta,"# COVID-19 in Malta - Open Dataset

This is an Official Open Dataset on COVID19 in Malta from the COVID-19 Public Health Response Team (Ministry for Health).

## Number of COVID-19 Tests

These figures include PCR and Rapid Antigen Tests that have been included from 20th July 2020 onwards that have been published.

## Number of Vaccination Doses

The current data reflects the cumulative number of vaccination doses, the number of individuals that are fully vaccinated (either received two doses of two-dose course or one dose of one-dose course), and the number of individuals that took a first dose (including of the one-dose course Johnson and Johnson vaccine), reported by date taken.

## COVID Alert Malta - Statistics Table

COVID Alert Malta (https://covidalert.gov.mt) is the Government of Malta's Official Proximity Tracing Application developed through a close collaboration between Malta Information Technology (https://github.com/GOVMT-MITA), Malta Digital Innovation Authority and the Ministry for Health. In the first version of this Statistics Table we look at the number of downloads and the percentage of population above the digital age of consent (13+).

## Number of COVID-19 App Check Responses

The COVID-19 Public Health Response Team developed a Digital Risk Assessment Tool known as COVID-19 Check. This repository records the number of submissions received through https://covid19check.gov.mt

This site has been archived and the archived code is available on: https://github.com/COVID19-Malta/covid19check


",35,35,18,6,public-health,"[covid19, covid19-data, covid19-malta, data-science, malta, public-health]",62
epiverse-trace,sivirep,epiverse-trace,https://github.com/epiverse-trace/sivirep,https://api.github.com/repos/sivirep/epiverse-trace,Data Wrangling and Automated Reports from 'SIVIGILA' source,"
<!-- README.md is generated from README.Rmd. Please edit that file -->

``` r
library(sivirep)
```

## *sivirep*: Generación automatizada de reportes a partir de bases de datos de vigilancia epidemiológica <img src=""man/figures/logo.svg"" align=""right"" width=""120""/>

<!-- badges: start -->

[![License:
MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![R-CMD-check](https://github.com/epiverse-trace/sivirep/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/epiverse-trace/sivirep/actions/workflows/R-CMD-check.yaml)
[![Codecov test
coverage](https://codecov.io/gh/epiverse-trace/readepi/branch/main/graph/badge.svg)](https://app.codecov.io/gh/epiverse-trace/readepi?branch=main)
[![lifecycle-maturing](https://raw.githubusercontent.com/reconverse/reconverse.github.io/master/images/badge-maturing.svg)](https://www.reconverse.org/lifecycle.html#maturing)

<!-- badges: end -->

La versión actual de *sivirep* 0.0.2 proporciona funciones para la
manipulación de datos y la generación de reportes automatizados basados
en las bases de datos individualizadas de casos de
[SIVIGILA](https://www.ins.gov.co/Direcciones/Vigilancia/Paginas/SIVIGILA.aspx),
que es el sistema oficial de vigilancia epidemiológica de Colombia.

## Motivación

América Latina ha progresado en la calidad de sus sistemas de
notificación y vigilancia epidemiológica. En particular, Colombia ha
mejorado a lo largo de los años la calidad, la accesibilidad y la
transparencia de su sistema oficial de vigilancia epidemiológica,
[SIVIGILA](https://www.ins.gov.co/Direcciones/Vigilancia/Paginas/SIVIGILA.aspx).
Este sistema está regulado por el [Instituto Nacional de
Salud](https://www.ins.gov.co) de Colombia y es operado por miles de
trabajadores de la salud en las secretarías de salud locales, hospitales
y unidades primarias generadoras de datos.

Sin embargo, todavía existen desafíos, especialmente a nivel local, en
cuanto a la oportunidad y la calidad del análisis epidemiológico y de
los informes epidemiológicos. Estas tareas pueden requerir una gran
cantidad de trabajo manual debido a limitaciones en el entrenamiento
para el análisis de datos, el tiempo que se requiere invertir, la
tecnología y la calidad del acceso a internet en algunas regiones de
Colombia.

El objetivo de `sivirep` es proporcionar un conjunto de herramientas
para:

1)  Descargar, preprocesar y preparar los datos de SIVIGILA para su
    posterior análisis.
2)  Generar informes epidemiológicos automatizados adaptables al
    contexto.
3)  Proporcionar retroalimentación sobre el sistema de vigilancia al
    proveedor de la fuente de datos.

## Potenciales usuarios

- Profesionales de salud pública y de epidemiología de campo que
  utilizan la fuente de datos de SIVIGILA a nivel local.
- Estudiantes del área de la salud y epidemiología.
- Investigadores y analistas de datos a nivel nacional e internacional.

## Instalación

Puedes instalar la versión de desarrollo de `sivirep` desde GitHub con
el siguiente comando:

``` r
install.packages(""pak"")
pak::pak(""epiverse-trace/sivirep"")
```

## Inicio rápido

Puedes revisar las enfermedades y los años disponibles de forma libre
utilizando:

``` r
lista_eventos <- list_events()
knitr::kable(lista_eventos)
```

|     | enfermedad                                                            | aa                                                                                                   |
|:----|:----------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------|
| 1   | Accidente ofídico                                                     | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 2   | Agresiones Por Animales Potencialmente Transmisores De Rabia          | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 3   | Anomalías congénitas                                                  | 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                         |
| 4   | Bajo Peso Al Nacer                                                    | 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                     |
| 5   | Cáncer De La Mama Y Cuello Uterino                                    | 2016, 2017, 2018, 2019, 2020, 2021                                                                   |
| 6   | Cáncer Infantil                                                       | 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                                 |
| 7   | Chagas                                                                | 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                     |
| 8   | Chikunguya                                                            | 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                                 |
| 9   | Dengue                                                                | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 10  | Dengue Grave                                                          | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 11  | ESI - Irag (Vigilancia Centinela)                                     | 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022             |
| 12  | Evento Adverso Grave Posterior A La Vacunación                        | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 13  | Exposición A Flúor                                                    | 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019                                                       |
| 14  | Fiebre Amarilla                                                       | 2007, 2008, 2009, 2013, 2016, 2018                                                                   |
| 15  | Fiebre Tifoidea Y Paratifoidea                                        | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 16  | Hepatitis A                                                           | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 17  | Hepatitis B, C Y Coinfección Hepatitis B Y Delta                      | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 18  | Hepatitis C                                                           | 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                                 |
| 19  | Hipotiroidismo congénito                                              | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 20  | Infección Respiratoria Aguda Grave Irag Inusitada                     | 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                   |
| 65  | INTENTO DE SUICIDIO                                                   |                                                                                                      |
| 21  | Intoxicación Por Gases                                                | 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                         |
| 22  | Intoxicación Por Medicamentos                                         | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 23  | Intoxicación Por Metales Pesados                                      | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 24  | Intoxicación Por Metanol                                              | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 25  | Intoxicación Por Otras Sustancias químicas                            | 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                     |
| 26  | Intoxicación Por Plaguicidas                                          | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 27  | Intoxicación Por Solventes                                            | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 28  | Intoxicación Por Sustancias Psicoactivas                              | 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                         |
| 29  | Leishmaniasis cutánea                                                 | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 30  | Leishmaniasis Mucosa                                                  | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 31  | Leishmaniasis Visceral                                                | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 32  | Lepra                                                                 | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 33  | Leptospirosis                                                         | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 34  | Lesiones Por pólvora Y Explosivos                                     | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014                                                       |
| 35  | Leucemia Aguda Pediátrica Linfoide                                    | 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022             |
| 36  | Leucemia Aguda Pediátrica Mieloide                                    | 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022             |
| 64  | MALARIA                                                               |                                                                                                      |
| 37  | Malaria Asociada (Formas Mixtas)                                      | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 38  | Malaria Complicada                                                    | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 39  | Malaria Falciparum                                                    | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 40  | Malaria Vivax                                                         | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 41  | Meningitis Bacteriana Y Enfermedad Meningocócica                      | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022 |
| 42  | Meningitis Meningocócica                                              | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 43  | Meningitis Por Haemophilus Influenzae                                 | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 44  | Meningitis Por Neumococo                                              | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 45  | Meningitis Tuberculosa                                                | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 46  | Mortalidad Materna                                                    | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 47  | Mortalidad Perinatal Y Neonatal Tardía                                | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 48  | Mortalidad Por Dengue                                                 | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 49  | Mortalidad Por Desnutrición                                           | 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                           |
| 50  | Mortalidad Por Eda 0-4 Años                                           | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 51  | Mortalidad Por Ira                                                    | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 52  | Parotiditis                                                           | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 53  | Rabia Humana                                                          | 2007, 2008, 2009, 2010, 2012, 2015, 2016, 2017, 2020                                                 |
| 54  | Sarampión                                                             | 2011, 2012, 2013, 2015, 2018, 2019, 2020                                                             |
| 55  | Tétanos Accidental                                                    | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 56  | Tétanos Neonatal                                                      | 2007, 2008, 2009, 2010, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                   |
| 57  | Tos Ferina                                                            | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 58  | Tracoma                                                               | 2017, 2018, 2019, 2022                                                                               |
| 59  | Tuberculosis Extra Pulmonar                                           | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 60  | Tuberculosis Farmacorresistente                                       | 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                               |
| 61  | Tuberculosis Pulmonar                                                 | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 62  | Varicela Individual                                                   | 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022       |
| 63  | Vigilancia En Salud Pública De La Violencia De Género E Intrafamiliar | 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022                                     |

## Versiones futuras

Las versiones futuras de `sivirep` podrían incluir:

- Interacción con otras fuentes de datos en Colombia.
- Otros sistemas de vigilancia epidemiológica en América Latina.

## Contribuciones

Las contribuciones son bienvenidas via [pull
requests](https://github.com/epiverse-trace/sivirep/pulls).

Los contribuyentes al paquete incluyen:

- [Geraldine Gómez-Millán](https://github.com/GeraldineGomez) (author)

- [Zulma M. Cucunubá](https://github.com/zmcucunuba) (author)

- [Hugo Gruson](https://github.com/Bisaloo) (contributor)

- [Laura Gómez-Bermeo](https://github.com/lgbermeo) (contributor to
  documentation)

- [Miguel Gámez](https://github.com/megamezl) (contributor)

- Jennifer Méndez-Romero (contributor)

- Johan Calderón (contributor)

- Claudia Huguett-Aragón (contributor)

- Lady Flórez-Tapiero (contributor)

- Verónica Tangarife-Arredondo (contributor)

## Código de conducta

Por favor, ten en cuenta que el proyecto `sivirep` se publica con un
[Código de Conducta para
Contribuyentes](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).
Al contribuir a este proyecto, aceptas cumplir con sus términos.

## Comenzar

### Para reportes automatizados

Después de la instalación de `sivirep`, puedes comenzar importando el
paquete a través del siguiente comando:

``` r
library(sivirep)
```

Ante de iniciar con el reporte automatizado, revisa la lista de
enfermedades disponibles para hacer un reporte con `sivirep` en:

``` r
list_events()
```

Actualmente, `sivirep` provee una plantilla de reporte llamada
`Reporte Básico {sivirep}`, la cual contiene seis secciones y recibe los
siguientes parámetros de entrada: el nombre de la enfermedad, el año, el
nombre de departamento (opcional) y nombre del municipio (opcional) para
descargar los datos de la fuente de SIVIGILA.

Para hacer uso de la plantilla del reporte se deben seguir los
siguientes pasos:

1.  En RStudio hacer click *‘File/New File/R’* Markdown:

<img src=""man/figures/file_rmarkdown.png"" class=""rmarkdown-img""
style=""margin-left: 2.8em; margin-top: 0.8em; margin-bottom: 0.8em;""
data-align=""center"" width=""560"" />

2.  Selecciona la opción del panel izquierdo: *‘From Template’*, después
    selecciona el template del reporte llamado
    `Reporte Básico {sivirep}`, indica el nombre que deseas para el
    reporte (i.e. Reporte_Laura), la ubicación donde deseas guardarlo y
    presiona *‘Ok’*.

<img src=""man/figures/reporte_basico.png"" class=""rmarkdown-img""
style=""margin-left: 2.8em; margin-top: 0.8em; margin-bottom: 0.8em;""
data-align=""center"" width=""550"" />

3.  A continuación, podrás seleccionar el nombre de la enfermedad, el
    año, el departamento (opcional) y el municipio (opcional) del
    reporte. Esta acción descargará los datos deseados y también
    proporcionará la plantilla en un archivo R Markdown (.Rmd). Para
    esto, es importante encontrar el botón *‘Knit’*, desplegar las
    opciones y seleccionar *‘Knit with parameters’*.

<img src=""man/figures/button_knit.png"" class=""rmarkdown-img""
style=""margin-left: 2.8em; margin-top: 0.8em; margin-bottom: 0.8em;""
data-align=""center"" width=""560"" />

4.  Espera unos segundos mientras el informe se genera en un archivo
    PDF.

5.  Puedes agregar, editar, eliminar y personalizar las secciones del
    reporte en el archivo R Markdown generado anteriormente.

<img src=""man/figures/editable_rmarkdown.png"" class=""rmarkdown-img""
style=""margin-left: 2.8em; margin-top: 0.8em; margin-bottom: 0.8em;""
data-align=""center"" width=""560"" />

Para obtener más detalles sobre plantillas y reportes genéricos de R
Markdown, por favor consulta [rmarkdown
templates](https://rstudio.github.io/rstudio-extensions/rmarkdown_templates.html).

## Para análisis o reportes personalizados

Esta sección proporciona un conjunto básico de instrucciones para usar
`sivirep` 0.0.2 si: - Ya has producido un archivo .Rmd y deseas editar
un reporte. - Deseas realizar análisis personalizados sin un archivo
.Rmd.

### 1. Importación de datos de SIVIGILA

La fuente de SIVIGILA proporciona los datos de la lista de casos
históricos hasta el último año epidemiológico cerrado. El cierre de un
año epidemiológico generalmente ocurre en abril del siguiente año (por
ejemplo, si estás utilizando `sivirep` en marzo de 2023, es posible que
puedas acceder a los datos históricos hasta diciembre de 2021) para la
mayoría de las enfermedades, con algunas excepciones.

Por favor, verifica las enfermedades y años disponibles utilizando:

``` r
lista_eventos <- list_events()
```

Una vez que hayas decidido la enfermedad y el año de la cual deseas
obtener la información, `import_data_event` es la función que permite la
importación de datos desde la fuente de SIVIGILA utilizando un formato
parametrizado basado en la enfermedad y el año.

``` r
data_event <-  import_data_event(year = 2020,
                                 nombre_event = ""dengue"")
```

##### 💡 Tip 1 - Evita retrasos en el tiempo al importar los datos

- `sivirep` 0.0.2 está diseñado para ayudar con el acceso a la fuente de
  SIVIGILA. Este proceso de descarga de información puede tomar unos
  minutos dependiendo del tamaño del conjunto de datos. Para evitar
  descargar los mismos datos repetidamente, puedes utilizar
  `cache = TRUE` en la función `import_data_event`. Esta opción está
  configurada de forma predeterminada.

### 2. Limpieza de datos de SIVIGILA

Los datos de SIVIGILA son una fuente de información oficial altamente
confiable, con certificación ISO de calidad de datos. Sin embargo, a
veces puede haber algunos valores atípicos en los datos que requieran
una limpieza adicional.

`sivirep` proporciona una función genérica llamada
`limpiar_data_sivigila` que envuelve diversas tareas para identificar y
corregir errores, inconsistencias y discrepancias en los conjuntos de
datos con el fin de mejorar su calidad y precisión. Este proceso puede
incluir la eliminación de duplicados, la corrección de errores
tipográficos, el reemplazo de valores faltantes y la validación de
datos, entre otras tareas, como eliminar fechas improbables, limpiar
códigos de geolocalización y estandarizar los nombres de las columnas y
las categorías de edad.

``` r
data_event_limp <- limpiar_data_sivigila(data_event = data_event, year = 2020)
```

Las funciones de limpieza dentro de `limpiar_data_sivigila` se han
recopilado y creado en base a la experiencia de epidemiólogos de campo.
Estas pueden incluir funciones internas como:

- `limpiar_encabezado`: función que limpia y estandariza los nombres de
  las columnas de los datos de lista de casos de SIVIGILA basándose en
  el diccionario de datos de SIVIGILA.

- `limpiar_edad_event`: función que limpia las edades de los datos de
  lista de casos de SIVIGILA.

- `format_fecha`: función que da un formato específico a una fecha.

- `limpiar_fecha_event`: función que limpia las fechas de los datos de
  enfermedades.

- `limpiar_cods_dpto`: función que limpia los códigos geográficos de
  departamentos en los datos de enfermedades.

El usuario puede utilizar estas funciones individualmente o simplemente
utilizar la función envolvente genérica `limpiar_data_sivigila`.

### 3. Filtrar casos

`sivirep` proporciona una función que permite filtrar los datos de
enfermedades por departamento o nombre del municipio llamada
`geo_filtro`. Esto permite al usuario crear un informe a nivel
subnacional, seleccionando casos específicos basados en la ubicación
geográfica.

``` r
data_event_filtrada <- geo_filtro(data_event = data_event_limp,
                                  nombre_dpto = ""Antioquia"")
```

### 4. Distribución temporal de casos

En `sivirep`, la distribución temporal de casos se define por las
variables de fecha de inicio de síntomas y fecha de notificación. Para
cada una de estas variables, existen funciones especializadas para
agrupar los datos y generar los gráficos.

#### 4.1. Agrupar los datos por fecha de inicio de síntomas en la escala temporal deseada

Para generar la distribución de casos por fecha de inicio de síntomas,
es necesario agrupar los datos por estas variables. `sivirep`
proporciona una función que permite esta agrupación llamada
`agrupar_fecha_inisintomas`, en la cual puedes especificar la unidad de
tiempo para agrupar estas fechas. Los valores permitidos para este
parámetro son: día y mes.

``` r
casos_ini_sintomas_dia <- agrupar_fecha_inisintomas(data_event =
                                                      data_event_limp,
                                                    tipo = ""day"")
casos_ini_sintomas_mes <- agrupar_fecha_inisintomas(data_event =
                                                      data_event_limp,
                                                    tipo = ""month"")
```

##### 💡 Tip 2 - Obtén los primeros n meses con más casos

- Al construir una sección del reporte o analizar estos datos, puede ser
  útil obtener los meses con más casos. En `sivirep`, puedes utilizar la
  función `obtener_meses_mas_casos` para obtener esta información.

El gráfico que permite visualizar esta distribución se debe generar con
la función `plot_fecha_inisintomas`. Ten en cuenta que, incluso si has
agrupado los datos por día, es posible que prefieras representarlo por
mes, como en:

``` r
plot_fecha_inisintomas(data_agrupada = casos_ini_sintomas_dia,
                       uni_marca = ""months"")
```

![](man/figures/plot_fecha_inicio_sintomas-1.png)<!-- -->

#### 4.2. Agrupar los datos por fecha de notificación en la escala temporal deseada

El proceso para generar la distribución de casos por fecha de
notificación consiste en agrupar los datos de enfermedades por esta
variable. Puedes utilizar la siguiente función de `sivirep` para hacer
esto:

``` r
casos_fecha_notificacion_dia <- agrupar_fecha_notifica(data_event =
                                                         data_event_limp,
                                                       tipo = ""day"")
casos_fecha_notificacion_mes <- agrupar_fecha_notifica(data_event =
                                                         data_event_limp,
                                                       tipo = ""month"")
```

El gráfico que permite visualizar esta distribución debe generarse con
la función `plot_fecha_notifica`. Ten en cuenta que, aunque hayas
agrupado los datos por día, es posible que prefieras representarlos por
mes, como en:

``` r
plot_fecha_notifica(data_agrupada = casos_fecha_notificacion_dia,
                    uni_marca = ""months"")
```

![](man/figures/plot_fecha_notificacion-1.png)<!-- -->

### 5. Edad y sexo

### 5.1. Variable de sexo

Cuando se analizan o se informan datos de enfermedades, a menudo es
necesario determinar la distribución de casos por género o sexo. Sin
embargo, la fuente de SIVIGILA solo registra el sexo.

`sivirep` proporciona una función que agrega y calcula automáticamente
los porcentajes por sexo después del proceso de limpieza.

``` r
casos_sex <- agrupar_sex(data_event = data_event_limp,
                         porcentaje = TRUE)
```

Además, `sivirep` cuenta con una función para generar el gráfico por
esta variable llamada `plot_sex`:

``` r
plot_sex(data_agrupada = casos_sex)
```

![](man/figures/plot_sexo-1.png)<!-- -->

La distribución de casos por sexo y semana epidemiológica se puede
generar utilizando la función `agrupar_sex_semanaepi` proporcionada por
`sivirep`.

``` r
casos_sex_semanaepi <- agrupar_sex_semanaepi(data_event = data_event_limp)
```

La función de visualización correspondiente es `plot_sex_semanaepi`, que
`sivirep` proporciona para mostrar la distribución de casos por sexo y
semana epidemiológica.

``` r
plot_sex_semanaepi(data_agrupada = casos_sex_semanaepi)
```

![](man/figures/plot_sex_semana_epidemiologica-1.png)<!-- -->

### 5.2. Variable de edad

La edad es una variable importante para analizar, ya que es un factor de
riesgo conocido para muchas enfermedades. Ciertas enfermedades y
condiciones tienden a ocurrir con más frecuencia en grupos de edad
específicos, y esta distribución puede ayudar a identificar poblaciones
con mayor riesgo e implementar estrategias de prevención y control
dirigidas.

`sivirep` proporciona una función llamada `agrupar_edad`, que puede
agrupar los datos de enfermedades por grupos de edad. De forma
predeterminada, esta función produce rangos de edad con intervalos de 10
años. Además, los usuarios pueden personalizar un rango de edad
diferente.

``` r
casos_edad <- agrupar_edad(data_event = data_event_limp, interval_edad = 10)
```

La función de visualización correspondiente es `plot_edad`.

``` r
plot_edad(data_agrupada = casos_edad)
```

![](man/figures/plot_edad-1.png)<!-- -->

### 5.3. Edad y sexo simultáneamente

`sivirep` proporciona una función llamada `agrupar_edad_sex`, que puede
agrupar los datos de enfermedades por rangos de edad y sexo de forma
simultánea y obtener el número de casos y los porcentajes
correspondientes. Además, permite personalizar el intervalo de edad.

``` r
casos_edad_sex <- agrupar_edad_sex(data_event = data_event_limp,
                                   interval_edad = 10)
```

La función de visualización correspondiente es `plot_edad_sex`.

``` r
plot_edad_sex(data_agrupada = casos_edad_sex)
```

![](man/figures/plot_edad_sexo-1.png)<!-- -->

### 6. Distribución espacial de casos

Obtener la distribución espacial de los casos es útil para identificar
áreas con una alta concentración de casos, agrupaciones de enfermedades
y factores de riesgo ambientales o sociales.

En Colombia, existen 32 unidades geográficas administrativas (adm1)
llamadas departamentos. `sivirep` proporciona una función llamada
`agrupar_mun` que permite obtener un data.frame de casos agrupados por
departamento o municipio.

``` r
dist_esp_dept <- agrupar_mun(data_event = data_event_filtrada,
                             dept_nombre = ""Antioquia"")
```

Actualmente, con la función llamada `plot_map`, el usuario puede generar
un mapa estático de Colombia que muestra la distribución de casos por
departamentos y municipios.

``` r
mapa
```

![](man/figures/mapa-1.png)<!-- -->

##### 💡 Tip 3 - Obtén la fila con más casos

- Al construir una sección del reporte o analizar estos datos, puede ser
  útil saber cuál es la variable que tiene la mayoría de los casos. En
  `sivirep`, puedes utilizar la función `obtener_fila_mas_casos` para
  obtener esta información. Esta función funciona con cualquier conjunto
  de datos que contenga una columna llamada “casos” en cualquier nivel
  de agregación.
",20,20,1,6,public-health,"[colombia, epidemiological-surveillance, epiverse, public-health, r, r-package]",62
docligot,aedesproject,,https://github.com/docligot/aedesproject,https://api.github.com/repos/aedesproject/docligot,Advanced Early Dengue Prediction and Exploration Service,,18,18,3,0,public-health,"[dengue, google-search, machine-learning, public-health, satellite-data]",62
njtierney,conmat,,https://github.com/njtierney/conmat,https://api.github.com/repos/conmat/njtierney,Create Contact Matrices from Population Data,"
<!-- README.md is generated from README.Rmd. Please edit that file -->

# conmat

<!-- badges: start -->

[![R-CMD-check](https://github.com/njtierney/conmat/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/njtierney/conmat/actions/workflows/R-CMD-check.yaml)
[![Codecov test
coverage](https://codecov.io/gh/njtierney/conmat/branch/master/graph/badge.svg)](https://codecov.io/gh/njtierney/conmat?branch=master)
<!-- badges: end -->

The goal of conmat is to make it easy to generate synthetic contact
matrices for a given age population.

**What is a contact matrix?**

Contact matrices describe the degree of contact between individuals of
given age groups.

For example, this matrix describes the number of contacts between
individuals

    #>       0-4 5-9 10-14
    #> 0-4    10   3     4
    #> 5-9     3  11     5
    #> 10-14   4   5    13

The rows and columns represent the age groups of the people. On the main
diagonal we see that we have a higher number of contacts - showing that
people of similar ages tend to interact more with one another.

We can use the information in these matrices to model how diseases such
as COVID-19 spread in a population through social contact.

**Why do we need *synthetic* contact matrices?**

Contact matrices are produced from empirical data resulting from a
contact survey, which requires individuals to diary the amount and
manner of contact a person has in a day.

However, these surveys are highly time-consuming and expensive to run,
meaning that only a handful of these empirical datasets exist globally.

We can use statistical methods to create *synthetic contact matrices*,
which are new contact matrices that have been generalised to new
countries based on existing surveys.

**Why do we need `conmat`?**

Existing methods only provide outputs of the contact matrices for each
country, or at best, for urban and rural areas for a given country.

We need methods that allow for flexibly creating synthetic contact
matrices for a specified age population, as the age population
distribution of many countries (e.g., Australia), are quite
heterogeneous, and assuming it is homogeneous would result in inaccurate
representation of community infection in many regions.

## Installation

You can install the development version with:

``` r
install.packages(""conmat"", repos = ""https://njtierney.r-universe.dev"")
```

Or alternatively you can use `remotes`

``` r
# install.packages(""remotes"")
remotes::install_github(""njtierney/conmat"")
```

## Example

First we want to fit the model to the POLYMOD data, which contains
various survey and population data.

``` r
library(conmat)
polymod_contact_data <- get_polymod_contact_data(setting = ""work"")
polymod_survey_data <- get_polymod_population()
```

The contact data is a data frame containing the age from and to, and the
number of contacts for each of the specified settings, “home”, “work”,
“school”, “other”, or “all” as well as the number of participants. By
default, `polymod_contact_data` contains data from “all”, but we’re
going to use the “work” set of data, as it produces an interesting
looking dataset. Each row contains survey information of the number of
contacts. Specifically, the number of contacts from one age group to
another age group, and then the number of participants in that age
group.

The survey data, `polymod_survey_data` contains the lower age limit and
the population in that age group.

``` r
polymod_survey_data
#> # A tibble: 21 × 2 (conmat_population)
#>  - age: lower.age.limit
#>  - population: population
#>    lower.age.limit population
#>              <int>      <dbl>
#>  1               0   1852682.
#>  2               5   1968449.
#>  3              10   2138897.
#>  4              15   2312032.
#>  5              20   2407486.
#>  6              25   2423602.
#>  7              30   2585137.
#>  8              35   2969393.
#>  9              40   3041663.
#> 10              45   2809154.
#> # … with 11 more rows
```

## Predicting the contact rate

We can create a model of the contact *rate* with the function
`fit_single_contact_model`

``` r
set.seed(2022 - 09 - 06)
contact_model <- fit_single_contact_model(
  contact_data = polymod_contact_data,
  population = polymod_survey_data
)
#> Warning in bgam.fit(G, mf, chunk.size, gp, scale, gamma, method = method, :
#> fitted rates numerically 0 occurred
```

This fits a generalised additive model (GAM), predicting the contact
rate, based on a series of prediction terms that describe various
features of the contact rates.

``` r
contact_model
#> 
#> Family: poisson 
#> Link function: log 
#> 
#> Formula:
#> contacts ~ s(gam_age_offdiag) + s(gam_age_offdiag_2) + s(gam_age_diag_prod) + 
#>     s(gam_age_diag_sum) + s(gam_age_pmax) + s(gam_age_pmin) + 
#>     school_probability + work_probability + offset(log_contactable_population)
#> 
#> Estimated degrees of freedom:
#> 1.00 4.27 5.51 6.23 7.89 7.36  total = 35.26 
#> 
#> fREML score: 24060.58     rank: 55/57
```

We can use this contact model to then predict the contact rate in a new
population.

As a demonstration, let’s take an age population from a given LGA in
Australia (this was the initial motivation for the package, so there are
some helper functions for Australian specific data).

``` r
fairfield <- abs_age_lga(""Fairfield (C)"")
fairfield
#> # A tibble: 18 × 4 (conmat_population)
#>  - age: lower.age.limit
#>  - population: population
#>    lga           lower.age.limit  year population
#>    <chr>                   <dbl> <dbl>      <dbl>
#>  1 Fairfield (C)               0  2020      12261
#>  2 Fairfield (C)               5  2020      13093
#>  3 Fairfield (C)              10  2020      13602
#>  4 Fairfield (C)              15  2020      14323
#>  5 Fairfield (C)              20  2020      15932
#>  6 Fairfield (C)              25  2020      16190
#>  7 Fairfield (C)              30  2020      14134
#>  8 Fairfield (C)              35  2020      13034
#>  9 Fairfield (C)              40  2020      12217
#> 10 Fairfield (C)              45  2020      13449
#> 11 Fairfield (C)              50  2020      13419
#> 12 Fairfield (C)              55  2020      13652
#> 13 Fairfield (C)              60  2020      12907
#> 14 Fairfield (C)              65  2020      10541
#> 15 Fairfield (C)              70  2020       8227
#> 16 Fairfield (C)              75  2020       5598
#> 17 Fairfield (C)              80  2020       4006
#> 18 Fairfield (C)              85  2020       4240
```

We can then pass the contact model through to `predict_contacts`, along
with the fairfield age population data, and some age breaks that we want
to predict to.

``` r
set.seed(2022 - 09 - 06)
synthetic_contact_fairfield <- predict_contacts(
  model = contact_model,
  population = fairfield,
  age_breaks = c(seq(0, 85, by = 5), Inf)
)

synthetic_contact_fairfield
#> # A tibble: 324 × 3
#>    age_group_from age_group_to contacts
#>    <fct>          <fct>           <dbl>
#>  1 [0,5)          [0,5)         0.00213
#>  2 [0,5)          [5,10)        0.00360
#>  3 [0,5)          [10,15)       0.00305
#>  4 [0,5)          [15,20)       0.00444
#>  5 [0,5)          [20,25)       0.0110 
#>  6 [0,5)          [25,30)       0.0218 
#>  7 [0,5)          [30,35)       0.0317 
#>  8 [0,5)          [35,40)       0.0345 
#>  9 [0,5)          [40,45)       0.0341 
#> 10 [0,5)          [45,50)       0.0330 
#> # … with 314 more rows
```

## Plotting

Let’s visualise the matrix to get a sense of the predictions with
`autoplot`. First we need to transform the predictions to a matrix:

``` r
synthetic_contact_fairfield %>%
  predictions_to_matrix() %>%
  autoplot()
```

<img src=""man/figures/README-plot-matrix-differents-1.png"" width=""100%"" />

## Applying the model across all settings.

You can also fit a model for all of the settings all at once with a
series of functions, `fit_setting_contacts`, and
`predict_setting_contacts`. This means we can do the above, but for each
setting, “home”, “work”, “school”, “other”, and “all”. We would
recommend this when using conmat, as it is a pretty common use case.
However for demonstration purposes we wanted to show how it works for a
single matrix here first. We also provide details on how to fit the
model to each of these settings in parallel. For more details on that
workflow, see the “getting started” vignette.

## Data sources

This package provides data and helper functions for the data, for use in
calculating contact matrices. The data sources are from the Australian
Bureau of Statistics (ABS), as we were using these a lot when we created
the package. In the future we might wrap these data sources and helpers
into another package, but for the time being they are here. Below are a
couple of examples of data provided, see the “data sources” vignette and
helpful at the website for full details.

You can extract the age population structure for the LGA, Brisbane, like
so:

``` r
abs_age_lga(""Brisbane (C)"")
#> # A tibble: 18 × 4 (conmat_population)
#>  - age: lower.age.limit
#>  - population: population
#>    lga          lower.age.limit  year population
#>    <chr>                  <dbl> <dbl>      <dbl>
#>  1 Brisbane (C)               0  2020      72894
#>  2 Brisbane (C)               5  2020      75933
#>  3 Brisbane (C)              10  2020      73990
#>  4 Brisbane (C)              15  2020      72010
#>  5 Brisbane (C)              20  2020     104564
#>  6 Brisbane (C)              25  2020     119000
#>  7 Brisbane (C)              30  2020     110798
#>  8 Brisbane (C)              35  2020     100493
#>  9 Brisbane (C)              40  2020      86630
#> 10 Brisbane (C)              45  2020      86791
#> 11 Brisbane (C)              50  2020      76063
#> 12 Brisbane (C)              55  2020      69273
#> 13 Brisbane (C)              60  2020      59666
#> 14 Brisbane (C)              65  2020      49134
#> 15 Brisbane (C)              70  2020      42252
#> 16 Brisbane (C)              75  2020      29927
#> 17 Brisbane (C)              80  2020      20898
#> 18 Brisbane (C)              85  2020      22683
```

Note that you need to use the exact LGA name - you can look up LGA names
in the data set `abs_lga_lookup`:

``` r
abs_lga_lookup
#> # A tibble: 544 × 3
#>    state lga_code lga                  
#>    <chr>    <dbl> <chr>                
#>  1 NSW      10050 Albury (C)           
#>  2 NSW      10180 Armidale Regional (A)
#>  3 NSW      10250 Ballina (A)          
#>  4 NSW      10300 Balranald (A)        
#>  5 NSW      10470 Bathurst Regional (A)
#>  6 NSW      10500 Bayside (A)          
#>  7 NSW      10550 Bega Valley (A)      
#>  8 NSW      10600 Bellingen (A)        
#>  9 NSW      10650 Berrigan (A)         
#> 10 NSW      10750 Blacktown (C)        
#> # … with 534 more rows
```

Or get the information for states like so:

``` r
abs_age_state(state_name = ""QLD"")
#> # A tibble: 18 × 4 (conmat_population)
#>  - age: lower.age.limit
#>  - population: population
#>     year state lower.age.limit population
#>    <dbl> <chr>           <dbl>      <dbl>
#>  1  2020 QLD                 0     314602
#>  2  2020 QLD                 5     339247
#>  3  2020 QLD                10     345205
#>  4  2020 QLD                15     319014
#>  5  2020 QLD                20     338824
#>  6  2020 QLD                25     370468
#>  7  2020 QLD                30     362541
#>  8  2020 QLD                35     354219
#>  9  2020 QLD                40     325208
#> 10  2020 QLD                45     348003
#> 11  2020 QLD                50     321168
#> 12  2020 QLD                55     317489
#> 13  2020 QLD                60     288317
#> 14  2020 QLD                65     254114
#> 15  2020 QLD                70     226033
#> 16  2020 QLD                75     156776
#> 17  2020 QLD                80     100692
#> 18  2020 QLD                85      94266
```

## Note

The contact matrices created using this package are transposed when
compared to the contact matrices discussed by
[Prem](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005697)
and
[Mossong](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0050074).
That is, the rows are “age group to”, and the columns are “age group
from”.

## Code of Conduct

Please note that the conmat project is released with a [Contributor Code
of
Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html).
By contributing to this project, you agree to abide by its terms.
",11,11,2,27,public-health,"[contact-matrices, infectious-diseases, population-data, public-health, r]",62
IQTLabs,Viziflu,IQTLabs,https://github.com/IQTLabs/Viziflu,https://api.github.com/repos/Viziflu/IQTLabs,An open-source visualization tool to help make multi-model seasonal influenza forecasts more actionable for decision-makers,"Background on Viziflu
======

<a href=""https://bnext-iqt.github.io/Viziflu/""><img src=""./docs/images/viziflu-logo.svg"" width=""700""></a>

Viziflu is a visualization tool that displays multiple predictions about the timing of ```""U.S. National""/""Peak Week,""``` the week with the highest predicted number of flu cases, using the results of forecasts submitted to the Centers for Disease Control and Prevention (CDC) as part of the agency's annual [FluSight influenza forecasting challenge](https://github.com/cdcepi/FluSight-forecasts). By displaying the outputs of multiple influenza models and allowing users to compare the uncertainty across those models, Viziflu can help make influenza forecasts more actionable for decision-makers.

If you would like to explore Viziflu, you can access 
* early season forecasts⁑ for the current (2019–20) flu season [here](https://bnext-iqt.github.io/Viziflu/docs/2019-2020-Forecasts-v4/EW42.html)  [![Demo](https://img.shields.io/badge/2019--20_forecast_results_timeline_with_modal-dimgrey.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2019-2020-Forecasts-v4/EW42.html)
* early season forecasts* for part of the 2018–19 season [here](https://bnext-iqt.github.io/Viziflu/docs/2018-2019-Forecasts-v4/EW42.html)  [![Demo](https://img.shields.io/badge/2018--19_forecast_results_timeline_with_modal-dimgrey.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2018-2019-Forecasts-v4/EW42.html)
  * forecast skill scores for the 2018–19 flu season [here](https://bnext-iqt.github.io/Viziflu/docs/2018-2019-Forecasts-v5-USPkWkSkillScore/index.html)  [![Demo](https://img.shields.io/badge/2018--19_forecast_skill_small_multiples-dimgrey.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2018-2019-Forecasts-v5-USPkWkSkillScore/index.html)
* full season early season forecasts from the 2017-18 flu season [here](https://bnext-iqt.github.io/Viziflu/docs/2017-2018-Forecasts-v4/EW43.html)  [![Demo](https://img.shields.io/badge/2017--18_forecast_results_timeline_with_modal-dimgrey.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2017-2018-Forecasts-v4/EW43.html)
  * forecast skill scores for the the 2017-18 flu season [here](https://bnext-iqt.github.io/Viziflu/docs/2017-2018-Forecasts-v5-USPkWkSkillScore/index.html)  [![Demo](https://img.shields.io/badge/2017--18_forecast_skill_small_multiples-dimgrey.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2017-2018-Forecasts-v5-USPkWkSkillScore/index.html)


<sub>* Preliminary results only. ⁑ Note that skill scores for the 2019-20 flu season are not currently available.</sub>

Description and Generalizability
-----------
In this visualization, the duration of the flu season is represented as a horizontal timeline from October through May. Several models are listed alphabetically on the left side of the display and a color gradient indicates each models’ predicted probability that flu will peak in each week of the flu season. Although Viziflu was designed to show seasonal influenza forecasts, we imagine the tool could easily be adapted for other applications where users would benefit from the ability to compare forecasted probabilities of occurrence over time, as predicted by multiple models.  

:bulb: Project Origins
-----------
Viziflu was developed following a B.Next Roundtable and whitepaper on Technology to advance infectious disease forecasting for outbreak management that identified the need for improved communication about public health data, including new visualization techniques that help convey risks and uncertainties to decision-makers and the public, with the Centers for Disease Control and Prevention (CDC) Influenza Division providing [valuable feedback and domain expertise](https://medium.com/bioquest/viziflu-a-q-a-between-iqt-labs-and-the-cdc-influenza-division-336342e4dadc).

:calendar: Converting [MMWR Weeks](https://wwwn.cdc.gov/nndss/document/MMWR_Week_overview.pdf) to [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html)
-----------

|2018-2019 Flu Season [![Visualization](https://img.shields.io/badge/Demo-black.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2018-2019-Forecasts-v2/EW42.html) [![PDF](https://img.shields.io/badge/-PDF-black.svg?logo=adobe&style=plastic)](https://wwwn.cdc.gov/nndss/document/W2018-19.pdf) [![Source Data](https://img.shields.io/badge/FluSight-Data-black.svg?logo=GitHub&style=plastic)](https://github.com/cdcepi/FluSight-forecasts/tree/master/2018-2019) | 2017-2018 Flu Season [![Visualization](https://img.shields.io/badge/Demo-black.svg?logo=Javascript&style=plastic)](https://bnext-iqt.github.io/Viziflu/docs/2017-2018-Forecasts-v2/EW43.html) [![PDF](https://img.shields.io/badge/-PDF-black.svg?logo=adobe&style=plastic)](https://wwwn.cdc.gov/nndss/document/w2017-18.pdf) [![Source Data](https://img.shields.io/badge/FluSight-Data-black.svg?logo=GitHub&style=plastic)](https://github.com/cdcepi/FluSight-forecasts/tree/master/2017-2018) |
|--|--|
| <table> <thead> <tr> <th align=""center"">MMWR Week</th> <th align=""center"">From</th> <th align=""center"">To</th> </tr> </thead> <tbody> <tr> <td align=""center"">40</td> <td align=""center"">2018-09-29</td> <td align=""center"">2018-10-06</td> </tr> <tr> <td align=""center"">41</td> <td align=""center"">2018-10-06</td> <td align=""center"">2018-10-13</td> </tr> <tr> <td align=""center"">42</td> <td align=""center"">2018-10-13</td> <td align=""center"">2018-10-20</td> </tr> <tr> <td align=""center"">43</td> <td align=""center"">2018-10-20</td> <td align=""center"">2018-10-27</td> </tr> <tr> <td align=""center"">44</td> <td align=""center"">2018-10-27</td> <td align=""center"">2018-11-03</td> </tr> <tr> <td align=""center"">45</td> <td align=""center"">2018-11-03</td> <td align=""center"">2018-11-10</td> </tr> <tr> <td align=""center"">46</td> <td align=""center"">2018-11-10</td> <td align=""center"">2018-11-17</td> </tr> <tr> <td align=""center"">47</td> <td align=""center"">2018-11-17</td> <td align=""center"">2018-11-24</td> </tr> <tr> <td align=""center"">48</td> <td align=""center"">2018-11-24</td> <td align=""center"">2018-12-01</td> </tr> <tr> <td align=""center"">49</td> <td align=""center"">2018-12-01</td> <td align=""center"">2018-12-08</td> </tr> <tr> <td align=""center"">50</td> <td align=""center"">2018-12-08</td> <td align=""center"">2018-12-15</td> </tr> <tr> <td align=""center"">51</td> <td align=""center"">2018-12-15</td> <td align=""center"">2018-12-22</td> </tr> <tr> <td align=""center"">52</td> <td align=""center"">2018-12-22</td> <td align=""center"">2018-12-29</td> </tr> <tr> <td align=""center"">01</td> <td align=""center"">2018-12-29</td> <td align=""center"">2019-01-05</td> </tr> <tr> <td align=""center"">02</td> <td align=""center"">2019-01-05</td> <td align=""center"">2019-01-12</td> </tr> <tr> <td align=""center"">03</td> <td align=""center"">2019-01-12</td> <td align=""center"">2019-01-19</td> </tr> <tr> <td align=""center"">04</td> <td align=""center"">2019-01-19</td> <td align=""center"">2019-01-26</td> </tr> <tr> <td align=""center"">05</td> <td align=""center"">2019-01-26</td> <td align=""center"">2019-02-02</td> </tr> <tr> <td align=""center"">06</td> <td align=""center"">2019-02-02</td> <td align=""center"">2019-02-09</td> </tr> <tr> <td align=""center"">07</td> <td align=""center"">2019-02-09</td> <td align=""center"">2019-02-16</td> </tr> <tr> <td align=""center"">08</td> <td align=""center"">2019-02-16</td> <td align=""center"">2019-02-23</td> </tr> <tr> <td align=""center"">09</td> <td align=""center"">2019-02-23</td> <td align=""center"">2019-03-02</td> </tr> <tr> <td align=""center"">10</td> <td align=""center"">2019-03-02</td> <td align=""center"">2019-03-09</td> </tr> <tr> <td align=""center"">11</td> <td align=""center"">2019-03-09</td> <td align=""center"">2019-03-16</td> </tr> <tr> <td align=""center"">12</td> <td align=""center"">2019-03-16</td> <td align=""center"">2019-03-23</td> </tr> <tr> <td align=""center"">13</td> <td align=""center"">2019-03-23</td> <td align=""center"">2019-03-30</td> </tr> <tr> <td align=""center"">14</td> <td align=""center"">2019-03-30</td> <td align=""center"">2019-04-06</td> </tr> <tr> <td align=""center"">15</td> <td align=""center"">2019-04-06</td> <td align=""center"">2019-04-13</td> </tr> <tr> <td align=""center"">16</td> <td align=""center"">2019-04-13</td> <td align=""center"">2019-04-20</td> </tr> <tr> <td align=""center"">17</td> <td align=""center"">2019-04-20</td> <td align=""center"">2019-04-27</td> </tr> <tr> <td align=""center"">18</td> <td align=""center"">2019-04-27</td> <td align=""center"">2019-05-04</td> </tr> <tr> <td align=""center"">19</td> <td align=""center"">2019-05-04</td> <td align=""center"">2019-05-11</td> </tr> <tr> <td align=""center"">20</td> <td align=""center"">2019-05-11</td> <td align=""center"">2019-05-18</td> </tr> </tbody> </table>|<table> <thead> <tr> <th align=""center"">MMWR Week</th> <th align=""center"">From</th> <th align=""center"">To</th> </tr> </thead> <tbody> <tr> <td align=""center"">41</td> <td align=""center"">2017-10-07</td> <td align=""center"">2017-10-14</td> </tr> <tr> <td align=""center"">42</td> <td align=""center"">2017-10-14</td> <td align=""center"">2017-10-21</td> </tr> <tr> <td align=""center"">43</td> <td align=""center"">2017-10-21</td> <td align=""center"">2017-10-28</td> </tr> <tr> <td align=""center"">44</td> <td align=""center"">2017-10-28</td> <td align=""center"">2017-11-04</td> </tr> <tr> <td align=""center"">45</td> <td align=""center"">2017-11-04</td> <td align=""center"">2017-11-11</td> </tr> <tr> <td align=""center"">46</td> <td align=""center"">2017-11-11</td> <td align=""center"">2017-11-18</td> </tr> <tr> <td align=""center"">47</td> <td align=""center"">2017-11-18</td> <td align=""center"">2017-11-25</td> </tr> <tr> <td align=""center"">48</td> <td align=""center"">2017-11-25</td> <td align=""center"">2017-12-02</td> </tr> <tr> <td align=""center"">49</td> <td align=""center"">2017-12-02</td> <td align=""center"">2017-12-09</td> </tr> <tr> <td align=""center"">50</td> <td align=""center"">2017-12-09</td> <td align=""center"">2017-12-16</td> </tr> <tr> <td align=""center"">51</td> <td align=""center"">2017-12-16</td> <td align=""center"">2017-12-23</td> </tr> <tr> <td align=""center"">52</td> <td align=""center"">2017-12-23</td> <td align=""center"">2017-12-30</td> </tr> <tr> <td align=""center"">01</td> <td align=""center"">2017-12-30</td> <td align=""center"">2018-01-06</td> </tr> <tr> <td align=""center"">02</td> <td align=""center"">2018-01-06</td> <td align=""center"">2018-01-13</td> </tr> <tr> <td align=""center"">03</td> <td align=""center"">2018-01-13</td> <td align=""center"">2018-01-20</td> </tr> <tr> <td align=""center"">04</td> <td align=""center"">2018-01-20</td> <td align=""center"">2018-01-27</td> </tr> <tr> <td align=""center"">05</td> <td align=""center"">2018-01-27</td> <td align=""center"">2018-02-03</td> </tr> <tr> <td align=""center"">06</td> <td align=""center"">2018-02-03</td> <td align=""center"">2018-02-10</td> </tr> <tr> <td align=""center"">07</td> <td align=""center"">2018-02-10</td> <td align=""center"">2018-02-17</td> </tr> <tr> <td align=""center"">08</td> <td align=""center"">2018-02-17</td> <td align=""center"">2018-02-24</td> </tr> <tr> <td align=""center"">09</td> <td align=""center"">2018-02-24</td> <td align=""center"">2018-03-03</td> </tr> <tr> <td align=""center"">10</td> <td align=""center"">2018-03-03</td> <td align=""center"">2018-03-10</td> </tr> <tr> <td align=""center"">11</td> <td align=""center"">2018-03-10</td> <td align=""center"">2018-03-17</td> </tr> <tr> <td align=""center"">12</td> <td align=""center"">2018-03-17</td> <td align=""center"">2018-03-24</td> </tr> <tr> <td align=""center"">13</td> <td align=""center"">2018-03-24</td> <td align=""center"">2018-03-31</td> </tr> <tr> <td align=""center"">14</td> <td align=""center"">2018-03-31</td> <td align=""center"">2018-04-07</td> </tr> <tr> <td align=""center"">15</td> <td align=""center"">2018-04-07</td> <td align=""center"">2018-04-14</td> </tr> <tr> <td align=""center"">16</td> <td align=""center"">2018-04-14</td> <td align=""center"">2018-04-21</td> </tr> <tr> <td align=""center"">17</td> <td align=""center"">2018-04-21</td> <td align=""center"">2018-04-28</td> </tr> <tr> <td align=""center"">18</td> <td align=""center"">2018-04-28</td> <td align=""center"">2018-05-05</td> </tr> <tr> <td align=""center"">19</td> <td align=""center"">2018-05-05</td> <td align=""center"">2018-05-12</td> </tr> <tr> <td align=""center"">20</td> <td align=""center"">2018-05-12</td> <td align=""center"">2018-05-19</td> </tr> <tr> <td align=""center"">21</td> <td align=""center"">2018-05-19</td> <td align=""center"">2018-05-26</td> </tr> </tbody> </table> |

:warning: Important Disclaimers
-----------
Multiple outside research teams have developed different models that provide flu activity forecasts to CDC, and more information and visualizations of forecasts can be found on the [FluSight website](https://predict.cdc.gov/post/5ba1504e5619f003acb7e18f) and [GitHub repo](https://github.com/cdcepi/FluSight-forecasts).

> N.B. These are neither CDC nor IQT Labs forecasts and the model results on this page are not endorsed or approved by CDC or IQT Labs. These forecasts are based on different models, can vary significantly, and may be inaccurate. These forecasts and data are provided “as is” with no warranties of any kind, and use of this information is at your sole risk. To the maximum extent provided by law, neither IQT Labs and its affiliates nor any government agency or third party shall be liable for any damages of any kind relating to or resulting from use of the information on this site. For more information visit https://www.iqt.org/terms-of-use/. Anyone interested in using these data for additional research or publications is requested to contact CDC for information regarding attribution of the source forecasts.

Copyright
-------
Copyright :copyright: 2018-2022 [IQT Labs LLC](https://www.iqt.org/labs/), a wholly owned research venture of [In-Q-Tel, Inc.](https://www.iqt.org)

:scroll: License
-------
```ascii

  _|_|    _|_|_|      _|_|      _|_|_|  _|    _|  _|_|_|_|        _|_|          _|    
_|    _|  _|    _|  _|    _|  _|        _|    _|  _|            _|    _|      _|  _|  
_|_|_|_|  _|_|_|    _|_|_|_|  _|        _|_|_|_|  _|_|_|            _|        _|  _|  
_|    _|  _|        _|    _|  _|        _|    _|  _|              _|          _|  _|  
_|    _|  _|        _|    _|    _|_|_|  _|    _|  _|_|_|_|      _|_|_|_|  _|    _|    


```
Viziflu is available to the public under the [Apache 2.0 License](https://github.com/BNext-IQT/Viziflu/blob/master/LICENSE).
",5,5,6,0,public-health,"[dataviz, epidemiology, flu-season, flusightnetwork, forecasting, infectious-disease-models, influenza-forecasts, public-health, visualization]",62
data-intelligence-for-health-lab,Lpheada-Labelled-Public-HEAlth-DAtaset,data-intelligence-for-health-lab,https://github.com/data-intelligence-for-health-lab/Lpheada-Labelled-Public-HEAlth-DAtaset,https://api.github.com/repos/Lpheada-Labelled-Public-HEAlth-DAtaset/data-intelligence-for-health-lab,"LPHEADA is a multicountry and fully Labelled digital Public HEAlth DAtaset of tweets originated in Australia, Canada, UK, or US between November 28th, 2018 to June 19th, 2020. This dataset contains 366,405 crowd-generated labels (three labels per tweet) for 122,135 PASS-related tweets, labelled by 708 unique annotators on Amazon Mechanical Turk.","## Lpheada- Labelled Public HEAlth DAtaset
[![DOI](https://zenodo.org/badge/354686567.svg)](https://zenodo.org/badge/latestdoi/354686567)


<img src=""/Images/lpheada.jpg"" width=""370"">
 
This repository contains three six labelled datasets on digital public health surveillance. 



## How to Access the Data

To retrive a complete tweet object including text, data, user information, and location you will need to apply for a [developer account](https://developer.twitter.com/en/solutions/academic-research) to access Twitter APIs.


<img src=""/Images/twarc.jpg"" width=""700"">

After creating the account, install `twarc`, an API to hydrate tweetr data from TweetIDs. 

`pip install twarc`

To configure your twart requests, run the following script and enter the four credentials explained earlier.

`twarc configure`

Now you are ready to pass the files in the IDs folder to Twitter API and collect all the metadata associated with each ID.

### Rehydrate the Dataset using TweetIDs or UersIDs

To rehydrate the dataset, you can use Twarc’s hydrate command can be used to rehydrate the full dataset using unique tweet identifiers. The output will be saves as a json file. Please use the Tweet_IDs folder for this purpose.  

`twarc hydrate PhysicalActivity-TweetIDs-Canada.txt > Canada_PA.jsonl`

 To only retrieve user's information (metadata), use Twarc's **user** command:
 
 `twarc users UserIDs.txt > user_meta.jsonl`
 
 #### Example

------------------------------------------------------------------


## Geospatial Data Inference
To extract the location data, we use the {place} and {full place} fields of the Twitter dataset. For each country, we need a metadata of the geographical locations to map these fields to actual city/province/state names.

<img src=""/Images/LocationProcessU.jpg"" width=""650"">

To infer the location data associated with each tweet, in addition to the `place` and `full.place` fields, we use user's profile information as well as the tweet text. The example provided in the above figure illustrated the overal process of this task. Please refer to `LocationInference.ipynb` for the script. 

## Citation

The manuscript that presents this dataset has been accepted for publication at JMIR Public Health and Surveillance. Please cite our paper if you use this dataset in your project.

``` 
@article{abad2022physical,
  title={Physical Activity, Sedentary Behavior, and Sleep on Twitter: Multicountry and Fully Labeled Public Data Set for Digital Public Health Surveillance Research},
  author={Abad, Zahra Shakeri Hossein and Butler, Gregory P and Thompson, Wendy and Lee, Joon and others},
  journal={JMIR Public Health and Surveillance},
  volume={8},
  number={2},
  pages={e32355},
  year={2022},
  publisher={JMIR Publications Inc., Toronto, Canada}
}
```

## More Questions

Please use issues on this Github for any questions or feedback. You can also contact us at dih[at]ucalgary.ca or joonwu.lee[at]ucalgary.ca for specific inquiries.  
",5,5,2,0,public-health,"[dataset, machine-learning, physical-activity, public-health, sedentary-life, sleep, social-media]",62
antz22,MedCheck,,https://github.com/antz22/MedCheck,https://api.github.com/repos/MedCheck/antz22,"Webscraping and APIs to diagnose patients based on symptoms, providing and logging insightful data and treatment solutions through a friendly mobile user interface. (2nd Place Winner at MontyHacks IV)","# MedCheck

A mobile application that lets users smartly diagnose their symptoms by providing the most likely condition for the symptom, a summary of the condition (using web-scraping and a medical database) and the nearest location to receive treatment (through a geolocation API).

## Inspiration

We were inspired to allow people to easily diagnose their medical symptoms and recieve the proper steps for treatment.

## What it does

The users input their symptoms into an autocomplete search bar and receive their most likely diagnosis and severity of the condition through a machine learning API. Next, a web-scraper scrapes a medical database to retrieve the most relevant information about the condition, and displays it for the user. Finally, an API filters for the nearest locations that can provide the necessary treatment and provides the address.

## How we built it

We used Vue for the front-end of the app, Django for the back-end, and Selenium for the web-scraping portion. The database we used was malacards.org. Our APIs consisted of the APIMedic and the HERE-geocoder API.

## Challenges we ran into

Portability was an issue we faced because we were trying to coordinate code on different machines with different dependencies, especially when trying to make the webscraper as robust as possible.
Accomplishments that we're proud of

We are proud to have programmed a fully-functional full-stack application in just twelve hours time.

## What we learned

We learned about developing a full-stack app, web-scraping in python, and general research practices to use when dealing with an API. We also got better at reading and understanding documentation.

## What's next for MedCheck

We plan to use machine learning to optimize our diagnosis, and to find a more robust API for providing diagnoses and symptoms.

## Built With

    apimedic
    django
    django-rest-framework
    nativescript
    python
    selenium
    vue
	here-geocoder

## Screenshots

<img src=""https://github.com/antz22/MedCheck/blob/master/assets/medcheck.png"" width=""300""> <img src=""https://github.com/antz22/MedCheck/blob/master/assets/home.png"" width=""300"">
<img src=""https://github.com/antz22/MedCheck/blob/master/assets/logs.png"" width=""300""> <img src=""https://github.com/antz22/MedCheck/blob/master/assets/diagnosis.png"" width=""300"">

:)",5,5,1,0,public-health,"[app-development, django, django-rest-framework, nativescript, public-health, python, restful-api, ui-design, vuejs, webscraping]",62
amarshall1,prescribeR,,https://github.com/amarshall1/prescribeR,https://api.github.com/repos/prescribeR/amarshall1,An R package containing functions for quantifying drug exposure using routinely collected prescribing databases,"# prescribeR

## Introduction
prescribeR is an R package developed as part of my PhD work, the main aim of which was to create a set of 
flexible, reusable functions for generating common drug exposure variables based on routinely collected 
prescribing data for use in pharmacoepidemiological and pharmacovigilance research, with a view to providing 
structured and standardised methods for quantifying drug exposure and reporting on how data were prepared to
aid in the reproducibility and transparency of research.

The package was developed primarily for use on Scottish prescribing data, but is largely content neutral,
and uses functions from the tidyverse family of packages to manipulate the data. At present, the package 
contains functions for deriving variables describing ever use vs. never use, use at specified time points or
within time periods, prescription durations based on dosage instructions or assumptions and persistence calculated
using the refill gap method.

## Documentation
At present, the main form of documentation for this package can be found within the R manual files,
which provide descriptions of the individual functions, their arguments and their outputs. A wiki is 
currently under construction to provide more detail and examples for each function.

### Citing prescribeR
[![DOI](https://zenodo.org/badge/175052538.svg)](https://zenodo.org/badge/latestdoi/175052538)
",4,4,0,0,public-health,"[big-data, data-cleaning, epidemiology, exposure, pharmacology, pharmacovigilance, public-health, r]",62
raj-kotak,Online-Social-Network-Analysis,,https://github.com/raj-kotak/Online-Social-Network-Analysis,https://api.github.com/repos/Online-Social-Network-Analysis/raj-kotak,"Exploring the latest algorithms which include sentiment classification, information extraction, clustering, and topic modeling for analyzing online social networks, considering both their structure and content.","<h3><b>Online Social Network Analysis</b></h3>
Exploring the latest algorithms which include sentiment classification, information extraction, clustering, and topic modeling for analyzing online social networks, considering both their structure and content.<br>
Emphasis is placed on the application of the mentioned technology to areas such as public health, crisis response, politics, and marketing.
",4,4,3,0,public-health,"[crisis-related, marketing, politics, public-health]",62
wxwx1993,TS_Stochastic,,https://github.com/wxwx1993/TS_Stochastic,https://api.github.com/repos/TS_Stochastic/wxwx1993,"Public Available Code and Data to Reproduce Analyses in ""Assessing the causal effects of a stochastic intervention in time series data: Are heat alerts effective in preventing deaths and hospitalizations?""","# Assessing the causal effects of a stochastic intervention in time series data: Are heat alerts effective in preventing deaths and hospitalizations?
This is the data repository for publicly available code and data to reproduce analyses in Wu X, Weinberger KR, Wellenius GA, Dominici F, Braun D. Assessing the causal effects of a stochastic intervention in time series data: are heat alerts effective in preventing deaths and hospitalizations? Biostatistics. 2023. doi: 10.1093/biostatistics/kxad002.

<b>Simulation Code: </b><br>
[`ts_ips_fun_v4.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Simulation/ts_ips_fun_v4.R) contains the main functions to estimate the IPW estimator and the corresponding upper bound of the variance estimator; the influence-function-based estimator and the corresponding empirical variance estimator.

[`FAS folder`](https://github.com/wxwx1993/TS_Incremental/tree/main/Simulation/FAS) contains all the necessary implementation code to run simulation at the Odyssey cluster, supported by the FAS Division of Science, Research Computing Group at Harvard University.

[`Table2.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Simulation/Table2.R) contains the code to reproduce Table 2 in the manuscript.

[`Figure2&S1.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Simulation/Figure2&S1.R) contains the code to reproduce Figure 2 and Figure S1 of the simulation.

<b>Application Code: </b><br>
[`ts_ipw_function_v3.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/ts_ipw_function_v3.R) contains the function to estimate the proposed estimator and the corresponding upper bound of the variance estimator..

[`RCE folder`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/RCE) contains all the necessary implementation code to analyze the real data to estimate the causal effects of increasing the probability of issuing heat alerts  in reducing deaths and hospitalizations among Medicare population in each of 2,837 US counties at the Level-3 secured data platform on Research Computing Environment, supported by the Institute for Quantitative Social Science in the Faculty of Arts and Sciences at Harvard University.

[`spatial_meta.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/spatial_meta.R) contains the code to run spatial random-effect meta-analysis that pooled causal effect cruve from 2,837 US counties.

[`Table1.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/Table1.R) contains the code to reproduce Table 1: Characteristics for NWS-issued heat alerts, deaths and hospitalizations among Medicare enrollees.

[`Figure1.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/Figure1.R) contains the code to reproduce Figure 1: NWS-issued heat alerts for Los Angeles County during the warm months (April-October) of 2006-2016.

[`Figure3.R`](https://github.com/wxwx1993/TS_Incremental/blob/main/Application/Figure3.R) contains the code to reproduce Figure 2: The estimated pooled 2-lag causal effect curves of average all-cause deaths and cause-specific hospitalizations for five heat-related diseases per day per county among 2,837 counties.

<b>Data: </b><br>
The authors acquired daily time series data during the warm months (April-October) of 2006-2016 for N = 2,837 U.S. counties. For each county, we obtained 1) daily maximum heat index (an index that combines air temperature and relative humidity to posit a human-perceived equivalent temperature); 2) daily issuance of heat alerts (binary); and 3) daily number of all-cause deaths and cause-specific hospitalizations for five heat-related diseases (heat stroke, urinary tract infections, septicemia, renal failure, fluid and electrolyte disorders) among Medicare enrollees. Causes of hospitalizations was classfied using Clinical Classifications Software (CCS) groupings of principal discharge diagnosis codes among the Medicare Fee-for-Service (FFS) enrollees.

Heat Alert: We gathered text files containing records of all non-precipitation alerts issued by NWS between 2006 and 2016 from the National Oceanic and Atmospheric Administration (NOAA). We used the information in the file header, which contains information on the type, location, and timing of each alert in a standard format, to identify the date and location of each heat alert issued between April 1st and October 31st for the years 2006 to 2016 in the contiguous US. We then created a daily time series containing a binary variable for the issuance of heat alerts for each of the 2,837 US counties. We defined “heat alerts” to include both heat advisories (a type of heat alert issued when less severe heat is forecast) and excessive heat warnings (a type of heat alert issued when more severe heat is forecast).

Heat Index: We obtained 4-km gridded estimates of daily maximum temperature and vapor-pressure deficit using the Parameter-elevation Regressions on Independent Slopes Model (PRISM). From these variables, the time series of population-weighted daily maximum heat index is calculated for each county as previously described by Spangler et al, 2019. 

Medicare Outcome: We obtained daily all-cause deaths among the entire Medicare enrollees and cause-specific hospitalizations for five heat-related diseases among the Medicare Fee-for-Service (FFS) enrollees.

For Medicare data, Research Identifiable Files (RIF) on the Medicare population has previously been disclosed to team members at the Harvard School of School of Public Health (HSPH) by the Centers for Medicare and Medicaid Services (CMS) under the strict terms of a CMS Data Use Agreement, which requires stringent privacy protections. Medicare population individual-level data are stored at a Level-3 secured data platform on Research Computing Environment, supported by the Institute for Quantitative Social Science in the Faculty of Arts and Sciences at Harvard University. Interested parties may submit their research proposals to CMS and request the same data files that we use in this paper. More information can be found in the CMS website (https://www.cms.gov/Research-Statistics-Data-and-Systems/Files-for-Order/Data-Disclosures-Data-Agreements/Overview).
",2,2,4,1,public-health,"[causal-inference, heat-index, public-health]",62
Mosquito-Alert,Mosquito-Alert-Mobile-App,Mosquito-Alert,https://github.com/Mosquito-Alert/Mosquito-Alert-Mobile-App,https://api.github.com/repos/Mosquito-Alert-Mobile-App/Mosquito-Alert,,"# **Mosquito Alert** 
## What is Mosquito Alert?
Mosquito Alert is a mobile phone application that is part of a larger citizen science system bringing together ordinary people, scientists and public health officials to fight against mosquitoes that can transmit diseases like Zika, dengue and chikungunya. More information about the project can be found at http://www.mosquitoalert.com.

![Mosquito_Alert](https://user-images.githubusercontent.com/30580652/162627346-7018489f-7525-40ca-a3f6-b0dd59b519f3.png)

## How to compile the app
1. Clone the repository to your local machine
2. Go to android/local.properties and at the end of the file add the following lines: (If the file doesn't exist, just create it yourself)
```
# By leaving the values empty, the app will compile successfully but packages using those licenses will display an error (this is ok!)
transistorsoft.Key=
googlemaps.Key=
```
3. Run the following commands, one by one
```
flutter channel stable
flutter pub get
flutter upgrade
```
4. Connect your device or emulator and run the command ```flutter run```
5. That's all! If you have problems, don't hesitate to open an issue on [Github Issues](https://github.com/Mosquito-Alert/Mosquito-Alert-Mobile-App/issues) and we'll be happy to help you!

## How to contribute
Do you want to contribute?

Feel free to fork our repository, create a new branch, make your changes and submit a pull request. We'll review it as soon as possible and merge it.

It would be awesome if you assign yourself to an existing task or you open a new issue in [Github Issues](https://github.com/Mosquito-Alert/Mosquito-Alert-Mobile-App/issues), to keep other contributors informed on what you're working on.

If this project is useful for you, please consider starring this repository and giving us 5 stars on the app stores to give us more visibility.

## Features
* Report mosquito bite.
* Report mosquito sighting.
* Report breeding site.
* See your data in a map.
* Scoreboard of the contributors.
* Mosquito guide to learn.
* Free, open source software. You'll never have to pay anything or watch any ad to use it.

## Download the app
For more information, please visit the project [website](http://www.mosquitoalert.com/en/). 

- [Google Play (Android)](https://play.google.com/store/apps/details?id=ceab.movelab.tigatrapp).
- [Apple Store (iOS)](https://itunes.apple.com/app/id890635644)

## License
Mosquito Alert is free software: it can be redistributed and/or modified under the terms of the GNU General Public License published by the Free Software Foundation (license version 3 or higher).
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.

If you want to see the license in more detail, there are two options.
- Open the app from your phone > Settings > Mosquito Alert License
- See [the license file in english](https://github.com/Mosquito-Alert/Mosquito-Alert-Mobile-App/blob/master/assets/html/license_en.html) or see [the translated license into multiple other languages](https://github.com/Mosquito-Alert/Mosquito-Alert-Mobile-App/blob/master/assets/html)

",2,2,4,17,public-health,"[citizen-science, mosquitoes, public-health]",62
RiosNicholas,food4thought,,https://github.com/RiosNicholas/food4thought,https://api.github.com/repos/food4thought/RiosNicholas,Website that aims to share resources and bring awareness to child hunger in America,"# Food4Thought
<i>CodePath Web Development 101 Project</i>

<h2>About the Project</h1>
<p>
  This website aims to bring awareness to child hunger in America – an often overlooked social justice issue. The content is informative and also serves as a tool to help children and families facing difficulty affording or accessing healthy food. The website emphasizes that today's children are our future, and a lack of nutrition stifles them from reaching their potential.
</p>

***
<h3>Intended Users</h3>
The website primarily targets families facing food insecurity because of its food bank locator. Still, its informative section is intended to spread awareness to people uninformed about the social justice issue. In summary, the intended users of the website would be people interested in accessing food resources, finding local food banks to volunteer in, and those interested in learning about child hunger in the United States.

***

<h3>Current Progress</h3>
<p align=""center"">
  <img src=""preview/Food4Thought-Walkthrough.gif"" alt=""Live website walkthrough"" width=""500"" height=""auto"">
</p>

***

<h3>Mockup</h3>
<p align=""center"">
  <img src=""preview/food4thought-figma-mockup.png"" alt=""Website mockup"">
</p>


",2,2,1,0,public-health,"[codepath, public-health, social-issues, web-development]",62
CBDRH,GP-networks,CBDRH,https://github.com/CBDRH/GP-networks,https://api.github.com/repos/GP-networks/CBDRH,Supplemental material for MJA article “Overcoming the data drought: exploring general practice in Australia by network analysis of big data”,"Supplemental material for “Overcoming the data drought: exploring general practice in Australia by network analysis of big data”
================

Contents:

1.  [About Blockmodelling](#about-blockmodelling)
2.  [Extracting hierarchical
    blockmodels](#extracting-hierarchical-blockmodels)
3.  [Analysis of the block structure](#analysis-of-the-block-structure)
4.  [Plotting](#plotting)

Files:

  - The Python module [`MBS_analysis.py`](/py/MBS_analysis.py) (imported
    as `mbs`) contains our most important methods.
  - The Jupyter Notebook [`supplemental.ipynb`](/py/supplemental.ipynb)
    shows a minimal example.
  - The folder [`pbs`](/pbs) contains Unix scripts which were run on the
    high-performance computing cluster at UNSW Science.

## About Blockmodelling

The network we consider is bipartite: there are two types of nodes (GPs
and patients), and there are only edges connecting GPs with patients.
Most previous studies have used unipartite networks (or one-mode
networks), which discard patient nodes and connect GP nodes according to
some (increasing) function of the number of their shared patients. These
“projected” networks contains less information, and make it virtually
impossible to identify solo GPs. Identifying GP communities (or Provider
Practice Communities -PPCs) is a process of graph partitioning,
communities detection or finding clusters in the networks. The commonly
used approach has been modularity maximisation, which, however, suffers
from the “resolution limit problem”, the phenomenon that small
communities “escape” the separation effort.

In this analysis, we utilise the [hierarchical stochastic blockmodelling
approach](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.4.011047)
developed by [Tiago Peixoto](https://skewed.de/tiago). In a blockmodel,
GPs and patients are clustered into blocks, and two connections, e.g.
(GP 1, patient 1) and (GP 2, patient 2), are equally likely if GP1 and
GP2 are from the same block of GPs and patient 1 and patient 2 are from
the same block of patients. (Connections between nodes are equally
likely if source and target are from the same block.) A partition which
maximizes the likelihood is deemed optimal; such a partition consists of
blocks of GPs which tend to be connected to the same group(s) of
patients. The hierarchical approach fits blockmodels at different
resolution levels, and thus the resolution limit problem is ameliorated.
Moreover, overfitting (i.e. identifying too many blocks) is counteracted
via a clever choice of prior probabilities for the distribution of node
and edge numbers. From a point of view of information theory, a model is
deemed ‘best’ if it best compresses the data (s. [Occam’s
Razor](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.4.011047)).

## Extracting hierarchical blockmodels

### Preprocessing of MBS claims data

[`mbs.make_df()`](/py/MBS_analysis.py#L7) turns the `csv` data into a
pandas dataframe.

### Generation of patient – GP graphs

[`mbs.patient_doctor_graph()`](/py/MBS_analysis.py#L25) turns the
dataframe into a `graph_tool.Graph`

### Fitting hierarchical blockmodels

[`mbs.blockmodel()`](/py/MBS_analysis.py#L55) fits a hierarchical
blockmodel, using the Python library
[`graph-tool`](https://graph-tool.skewed.de/). It returns a
[NestedBlockState](https://graph-tool.skewed.de/static/doc/inference.html#graph_tool.inference.NestedBlockState)
object, containing the hierarchical clustering structure. The bipartite
structure is preserved, in the sense that on each level, a block
contains either only patient nodes or only GP nodes. For each year from
1994–2014 and each region from 1–5, this `mbs.blockmodel()` is run 4
times, and the best fitting model (highest likelihood / lowest entropy)
is retained; see [`fit-blockmodel.py`](/py/fit-blockmodel.py). The
`minimize_nested_blockmodel_dl()` of `graph-tool` is not parallelizable,
and runs on one core with up to 32 GB of memory, for up to 6 hours.

### Heuristic for further subdivision

The hierarchical blockmodel is suited to overcome the [“resolution
limit” problem](http://www.pnas.org/content/104/1/36.short) for
community detection, but communities of very small size (1-4) still
escape detection. It is likely that sometimes multiple PPCs are lumped
into the same block, even at the bottom level of the hierarchy. Hence on
the bottom level we extract groups of GPs which are disjoint, in the
sense that they do not share any patients. Such disjoint groups within
the bottom level blocks we interpret as PPCs, provider practice
communities. This is implemented in
[`mbs.extract_PPCs()`](/py/MBS_analysis.py#L89), which adds a layer at
the bottom with this final subdivision.

## Analysis of the block structure

For the analysis of PPCs, we define the following patient- and
GP-properties:

### Patient properties

  - `upc`: usual provider continuity. This is defined as
    \(\max\{n_i\} / \sum n_i\), where \(n_i\) are the numbers of visits
    of a patient to a distinct *provider*.
  - `upppc`: usual PPC continuity. This is defined similarly as `upc`,
    except that the \(n_i\)’s denote numbers of visits to distinct
    *PPCs*.
  - `ppd`: patient degree in PPC. For each patient in a PPC-centric
    graph \[1\], calculate their degree and average it within the PPC.

### GP property

  - `spf`: For each GP, the fraction of shared patients within a PPC.
    This fraction is averaged over all GPs in the PPC.

These properties are calculated by the method
[`mbs.add_props()`](/py/MBS_analysis.py#176). Once calculated,
[`mbs.get_ppc_stats()`](/py/MBS_analysis.py#281) collates these into a
pandas dataframe, with one row per PPC.

## Plotting

A PPC-centric graph is extracted using
[`mbs.PPCgraph()`](/py/MBS_analysis.py#152), and plotted via
[`mbs.plot_PPCgraph()`](/py/MBS_analysis.py#168).

1.  A PPC-centric graph contains only the GP nodes from that PPC and the
    patients of each GP.
",1,1,2,0,public-health,"[community-detection, networks, public-health]",62
JonMinton,life_expectancy_limits,,https://github.com/JonMinton/life_expectancy_limits,https://api.github.com/repos/life_expectancy_limits/JonMinton,,# life_expectancy_limits,1,1,2,0,public-health,"[demography, life-expectancy, mortality, public-health]",62
adam-rumpf,covid-pharmacy-access,,https://github.com/adam-rumpf/covid-pharmacy-access,https://api.github.com/repos/covid-pharmacy-access/adam-rumpf,Code for a research project about measuring COVID vaccine access levels in various geographic areas.,"# COVID-19 Vaccine Accessibility Study

A collection of data processing scripts for use in an ongoing research project about measuring accessibility levels to COVID-19 vaccines. These scripts are unlikely to be of use to anyone ourside our research group, but are provided here for anyone interested. Python packages used can be found in the root-level `requirements` file.

## Contents

This repo is organized into several major subdirectories, each with its own README to explain its contents in more detail.

* `data/` is divided into subdirectories by location, and includes raw data files obtained from external sources. The data files, themselves, have been excluded from this repo, but their sources can be found in this subdirectory's README.
* `graphs/` is divided into subdirectories by location, and includes simplified graph representations of raw map files for use in distance computations.
* `maps/` is divided into subdirectories by location, and includes raw map files downloaded for use in travel time calculation.
* `processed/` is divided into subdirectories by location, and includes data files derived from the raw data, such as collated data tables and calculated travel time matrices.
* `results/` is divied into subdirectories by location, and includes the output files from the statistical analysis.
* `scripts/` contains the programs actually used to preprocess the data and to conduct a statistical analysis.

## Files

The raw data files, themselves, are not included in this repo, but their sources are indicated in the various subdirectory READMEs. Some of the scripts also require the use of a user email address or API token. These are meant to be stored in local files called `email.txt` or `token.txt`, which are also not included in this repo.
",1,1,2,0,public-health,"[covid-19, data-science, geospatial, math, public-health, research]",62
TSGreen,bd-covid19-dash-app,,https://github.com/TSGreen/bd-covid19-dash-app,https://api.github.com/repos/bd-covid19-dash-app/TSGreen,:chart_with_upwards_trend: Built an interactive data visualisation dashboard of Bangladeshi Covid-19 data. This includes national time series data and mapped regional (district and divisional) figures. The dashboard is hosted on Heroku. ,"# Data Dash for Covid-19 Data for Bangladesh

Repo for deploying a data visulation web-app of COVID-19 data in Bangladesh to Heroku. 

This app is built using Dash in Python and displays interactive Plotly visualtions. 

The data used in this repo is scraped, cleaned and analysed regularly and fed into the app. 

The app is avilable [here on Heroku](https://bangladesh-covid19.herokuapp.com/). 
Note it is deployed on Heroku's free tier so may take some time to wake from sleep. Please be patient!

The web app includes the daily test, case, death and recovery numbers along with 7-day rolling averages:
![image](https://user-images.githubusercontent.com/62939263/117174375-749a7280-adef-11eb-8634-08028e76bb94.png)

It also includes the daily positivity rate:
![image](https://user-images.githubusercontent.com/62939263/117174620-ba573b00-adef-11eb-8de9-c13d3ed35ee9.png)

It also shows the regional data on an interactive map:
![image](https://user-images.githubusercontent.com/62939263/117175117-4d907080-adf0-11eb-83db-f6ea66add389.png)
",1,1,0,6,public-health,"[bangladesh, covid-19, dashboard, data-visualization, plotly-dash, public-health]",62
E-Health,phis-dw,E-Health,https://github.com/E-Health/phis-dw,https://api.github.com/repos/phis-dw/E-Health,:hospital: Public Health Data Warehouse using FHIR and Kibana,"# :hospital: Public Health Data Warehouse Framework on FHIR

## Deprecated. Moved to: [https://github.com/E-Health/fhir-server-phis-dw](https://github.com/E-Health/fhir-server-phis-dw) 

## About

Public health databases are vital for the community for efficient planning, surveillance and effective interventions. PHIS-DW adopts FHIR as the data model for storage with Lucene for search. Kibana provides the visualization engine. [:eyes: Drishti](https://github.com/E-Health/drishti) is our framework for FHIR based behavioural intervention repository. PHIS-DW is based on :eyes: Drishti, and can support complex algorithms for disease surveillance such as machine learning methods, hidden Markov models, and Bayesian to multivariate analytics. PHIS-DW is work in progress and code contributions are welcome. We intend to use [Bunsen](https://github.com/cerner/bunsen) to integrate PHIS-DW with [Apache Spark](https://spark.apache.org/) for big data applications.

## Author

[Bell Eapen](https://nuchange.ca) (McMaster U)
",1,1,2,0,public-health,"[data-visualization, data-warehouse, fhir, public-health]",62
Rapid-Deployment-Vaccine-Collaborative,Gen-11,Rapid-Deployment-Vaccine-Collaborative,https://github.com/Rapid-Deployment-Vaccine-Collaborative/Gen-11,https://api.github.com/repos/Gen-11/Rapid-Deployment-Vaccine-Collaborative,"SARS-CoV-2 Peptide Vaccine, Gen 11","# Gen-11
SARS-CoV-2 Peptide Vaccine, Gen 11 _(Published September 16, 2021: Version 4-1-3)_

Latest versions always hosted on https://radvac.org/white-paper

**TERMS OF USE/INFORMED CONSENT (updated 2021-04-30)**

This document describes the rationale, design, formulation, and self-administration of a vaccine for SARS-CoV-2. By using this information you agree to the following: 1) you are a consenting adult (in the USA, at least 18 years of age); and 2) you take full responsibility for your use of RaDVaC information and vaccine or material--including redistribution, modification, vaccine formulation, production and administration.

A foundational principle of the vaccine development and deployment strategy of RaDVaC is rapid iteration and testing of vaccine designs, based on newly published information from the forefront of biomedical research. This agile approach has the potential to produce better vaccines much more quickly than traditional approaches. However, such rapid design improvements currently are not compatible with established clinical trial requirements of fixed vaccine design, nor with review and approval by ethics committees (due to shifting vaccine design and continually updating self-experimentation and testing protocols). Therefore, the information presented within has not been approved by an institutional review board or any other type of ethics committee, and you understand and agree that any implementation of this information constitutes self-experimentation.

The purpose of this open-source vaccine effort is to reduce risk of harm from SARS-CoV-2. In addition to providing the results of our own research and experimentation, we hope to motivate others to build on our work, and to pursue diverse evidence-based approaches. Given the immense complexity and variability of individual human biology, it is not possible to predict all potential physiological responses to any vaccine. But as is true for most or all vaccines used on a large scale, there is a tradeoff between a larger known risk from the disease the vaccine is designed to prevent or mitigate, and the smaller risk introduced by the vaccine itself. Any vaccine poses risks, and, if used in enough people, will cause some degree of harm. Furthermore, certain harm, such as allergic and possibly anaphylactic response, will be readily seen and measured, whereas benefit is more difficult and takes longer to assess. This vaccine is no different; and because quality of delivery is highly dependent on the meticulousness of individual end users, it might pose unique risks not posed by typical commercial vaccines.


**Does Not Constitute or Substitute for Medical Advice**

Information presented here is ongoing research, and is not intended as a substitute for medical advice. RaDVaC is not responsible for the decision to administer, or to receive administration of, any vaccine.


**No Promises or Guarantees of Efficacy**

Vaccines are often received with the false hope of efficacy, without testing to determine the degree of individual immune response. For example, influenza killed about 100,000 people in the U.S. between late 2016 and early 2018. Yet, the influenza vaccines available in that period were substantially less than 50% effective against H3N2, the flu strain mainly responsible for the death toll. Many who died were vaccinated but not protected from the virus, and testing for vaccine-induced immunity was essentially non-existent. Vaccine-induced immunity can be more challenging to assess than immunity due to viral infection, and such is probably the case for the nasal vaccine described here. Because this work is a research undertaking, no expectation is given regarding any degree of efficacy in granting protection against SARS-CoV-2. On the contrary, see possible risks and uncertain benefits below. 


**Preventive, Not Therapeutic**

Even if this vaccine works as intended, it will not help someone who has been infected. It will only work as a preventive measure taken weeks in advance of virus exposure.


**Not a Clinical Trial**

Any use of the information in this document, or provided in correspondence with us does not constitute ‘partnership’ or ‘recruitment’ for an organized trial in any way. The supported conjecture here is given as a starting point for additional individual or organized, sponsored research. As of public release of this information, no organized clinical trials have been performed to test this vaccine. 


**Not Approved or Reviewed by the FDA**

The information, procedures, and conclusions presented here have not been approved, or reviewed by the FDA, or any other regulatory body. 


**Possible Risks and Uncertain Benefits**

- Immediate allergic or other serious reaction
- Unforeseen long-term effects
- Instillation/administration of the vaccine in an inappropriate way or in an infected area might increase the risk of infection by enhancing viral entry into the body
- Benefits are uncertain. There are extensive published histories of the materials and procedures described in this document, but every novel vaccine should be considered experimental, with the possibility there will be no benefit.
- Even if there are signs of immune response there is no guarantee this response is indicative of protection from SARS-CoV-2 infection, or if protection is achieved, how long it will last.
- Even if the vaccine confers protection from the virus, certain methods for assessing protection--such as measuring antibodies due to previous infection--might not capture vaccine-induced immunity. In such cases, infection, and thus a positive test result, are unlikely to occur. Immunity passports and other privileges given to convalescents might be difficult to obtain for those with vaccine-induced immunity.
- Use of this vaccine may change the efficacy of any future vaccines you may take or that are administered to you, in unknown ways


**No Offer of Service and No Access to Materials**

All information in this document or via correspondence is made available as open science. We do not sell equipment or services, e.g. we will not prepare this formulation or any other on behalf of a requestor. All vaccine materials at our disposal are kept in a secured laboratory. We cannot and will not keep materials outside the lab for easy access or distribution. We will not provide laboratory or equipment access for vaccine production.


**Probability and Coincidence**

Vaccines have become associated with negative outcomes that do not result from the vaccine, but that occur soon after administration. Increasing use of any vaccine will increase the probability of recipients experiencing an unconnected negative outcome. By using the information presented here, you acknowledge the increasing likelihood of such coincidences, and assume full responsibility for any use of the information herein and for real or perceived negative outcomes, irrespective of the cause.


**Self-Experimentation**

By utilizing the information and scientific opinions in this document, and in any correspondence with us, you acknowledge and agree that any use to develop and self-administer a substance is an act of self-experimentation. Laws and regulations on such actions may differ in your national or state jurisdiction, and it is your responsibility to be informed about them.

Additionally, the type of work described in this document requires certain equipment and level of skill with laboratory techniques. You agree to assume full responsibility for acquiring proper equipment, knowledge, and training, and for attempting to formulate or administer vaccine. 


**Licenses**

All contents of the RaDVaC website and white papers are covered by a Creative Commons Attribution 4.0 License (CC BY 4.0), and by an Open COVID License – Patent 1.1 (OCL-P v1.1). You are free to Share (copy and redistribute the material in any medium or format), and Adapt (fork, alter, and build upon) the material for any purpose. The only requirement is Attribution.
",1,1,0,0,public-health,"[antigen-config, chitosan, global-health, immunology, microbiology, open-science, open-source, peptide, public-health, rapid-deployment, rapid-development, vaccine, vaccinology, virology]",62
jinhyokh,pyairhealth,,https://github.com/jinhyokh/pyairhealth,https://api.github.com/repos/pyairhealth/jinhyokh,An Unofficial BenMap in Python,"# pyairhealth

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

The goal of this project is to develop a Python package that can conduct
public health assessments of air quality, similar to as the U.S. EPA’s
U.S. EPA’s [Environmental Benefits Mapping and Analysis Program -
Community Edition (BenMAP-CE)](https://www.epa.gov/benmap).

BenMAP-CE is a tool that calculates the public health benefits resulting
from changes in air quality, such as premature death, lung cancer, and
hospitalization. It is a de facto standard and is developed and updated
by the U.S. Environmental Protection Agency. Although it is an excellent
tool, its graphical user interface is not ideal for conducting public
health assessments programmatically.

This package uses a part of BenMAP-CE’s internal database and allows you
to calculate the impact of air quality on public health and its economic
value using Python. It will also provide a summary of atmospheric
science, public health, and economics in the context of assessing the
public health effect of air quality.

## Install (not working yet!)

## pip

``` sh
pip install pyairhealth
```

## conda

``` sh
conda install pyairhealth
```
",1,1,1,0,public-health,"[air-quality, benmap, fine-particulate-matter, public-health, vsl]",62
marymlucas,COVID-19,,https://github.com/marymlucas/COVID-19,https://api.github.com/repos/COVID-19/marymlucas,Exploring different aspects of the COVID-19 pandemic,"# COVID-19
Exploring different aspects of the COVID-19 pandemic
",1,1,0,2,public-health,"[coronavirus, coronavirus-tracking, health, healthcare, public-health]",62
simpledotorg,hypertension-dashboard,simpledotorg,https://github.com/simpledotorg/hypertension-dashboard,https://api.github.com/repos/hypertension-dashboard/simpledotorg,"A free, open source, template for creating a very useful hypertension dashboard to support public health projects.","# Hypertension Dashboard
[![hypertension dashboard](dashboard.png)](https://simpledotorg.github.io/hypertension-dashboard/)

## About
This dashboard is a template that can be used by any team working on a hypertension control project. Our team has learned many lessons while developing the [Simple.org](https://simple.org/) project and we want to share our best practices with the world. A similar dashboard has been used in India, Bangladesh, Sri Lanka, Ethiopia, and Nigeria to successfully manage over 4 million patients with hypertension.

Please feel free to copy any of the code or ideas that you see in this hypertension dashboard (see [open source license](https://github.com/simpledotorg/hypertension-dashboard#license) open source license below).

## See a live example
[View a live example](https://simpledotorg.github.io/hypertension-dashboard/)

## Data & definitions

### Basic Data
A very good public health hypertension dashboard only requires a small number of longitudinal patient data as building blocks:
* `Enrolled patients diagnosed with hypertension` with `Enrollment date` and `Enrollment facility`
* `Patients who had a BP measure in the last 3 months` and was the BP measure ≥140/90 or <140/90?
* `Patients who had a BP measure in the last 12 months`
* `Patient status as living or died`

### Useful Data
Data that shows how much of a region's population has lowered blood pressure is also very helpful. If a region does public health surveys, including the `Estimated population with hypertension` allows you to easily report coverage metrics.

### Inventory data
Adding data on drug stock and functioning BP devices helps round out the dashboard to make it even more useful.

## License
The generic dashboard is licensed under an MIT License. Please take this code and use it for your own project in any way.

Copyright 2023 Resolve to Save Lives

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
",1,1,1,0,public-health,"[dashboard-templates, hypertension, hypertension-detection, public-health]",62
polaris-maps,polaris,polaris-maps,https://github.com/polaris-maps/polaris,https://api.github.com/repos/polaris/polaris-maps,An open-source website and framework for universities and organizations to develop campus maps that crowdsource data on accessible routes and potential obstacles.,"**NOTE: This repository is no longer updated. Please see https://github.com/polaris-maps for up-to-date code.**


INTRODUCTION
----------------------------------------------------------------------


Polaris is an open source project created to display an open source website for University of North Carolina at Chapel Hill students and employees detailing accessible walking paths within the University. Polaris lists current accessibility hazards and allows users to post issues to notify other students and faculty of disruptions such as a broken elevator. On the about page is a form to submit feedback. 

In the future, users will have the ability to use the map to navigate around inaccessible paths, filter by favorited locations, and upvote/downvote others' notifications.

This app has not been deployed due to lack of functionality for user authentication, although endpoints and initial pages exist for users to register an account, update their information, see their information somewhere, and delete their account.

This project was built with a MEAN stack (MongoDB, Express, Angular, and Node.js). Other package dependency and version information can be found in `package.json` or in the dependency list below.


DEPENDENCY LIST
----------------------------------------------------------------------
Dependency | Version 
--- | ---
Bootstrap-Icons | 1.8.1 
Node-fetch | 3.2.3
Body-Parser | 1.19.2
Cors | 2.8.5
Dotenv | 16.0.0
Express | 4.17.3
Mongodb | 4.4.0
Nodemon | 2.0.15
@Angular/animations | 13.0.0
@Angular/common | 13.0.0
@Angular/compiler | 13.0.0
@Angular/core | 13.0.0
@Angular/forms	| 13.0.0
@Angular/platform-browser | 13.0.0
@Angular/platform-browser-dynamic | 13.0.0
@Angular/router | 13.0.0
Bootstrap | 5.1.3
Jquery | 3.6.0
Leaflet | 1.7.1
Popper.js | 1.16.1
Rxjs | 7.4.0
Tslib | 2.3.0
Zone.js | 0.11.4


INSTRUCTIONS
----------------------------------------------------------------------

1. Ask one of the project admins for a config.env file to be placed directly in the [api directory](https://github.com/comp426-2022-spring/a99-polaris/tree/main/api).
2. Run `npm install` inside the `api` directory and the `client` directory.
3. Run `npm start` inside the `api` directory and the `client` directory to start the app in localhost. The api should run on http://localhost:5001, while the client should come up on http://localhost:4200.


POLARIS API DOCUMENTATION
----------------------------------------------------------------------
Full API documentation can be found in [the README of the `docs` directory](https://github.com/comp426-2022-spring/a99-polaris/blob/main/docs/README.md#polaris-api-documentation).


DEVELOPMENT TEAM
----------------------------------------------------------------------


The Polaris Project was created by Team Polaris as our final project for COMP 426: Modern Web Programming at UNC-CH. The roles and duties of each person who contributed is detailed [in team.md in the docs](https://github.com/comp426-2022-spring/a99-polaris/blob/main/docs/team.md).


ACKNOWLEDGMENTS
----------------------------------------------------------------------


- Team Polaris of COMP 426 (Spring 2022)
- Professor John D. Martin III, Dr. Gary Bishop, and Dr. Jennifer Diliberto of UNC-CH
- [Tar Heels at the Table](https://tarheels.live/tarheelsatthetable/)
- UNC-CH Undergraduate Senate
",1,1,4,0,public-health,"[accessibility, navigation, public-health]",62
anniebritton,NASA-Extreme-Weather-Geohealth-Research,,https://github.com/anniebritton/NASA-Extreme-Weather-Geohealth-Research,https://api.github.com/repos/NASA-Extreme-Weather-Geohealth-Research/anniebritton,☂️🛰️ This work is for a NASA-funded project using Earth observations to improve methods available for estimating the health damages of extreme weather events in Texas.,"# NASA-Extreme-Weather-Geohealth-Research
☂️🛰️ This work is for a NASA-funded project using Earth observations to improve methods available for estimating the health damages of extreme weather events in Texas.

Scripts are built to acquire, process, and analyze geospatial data relating to cold and heat events, flooding, and air quality across the state of Texas, but can be used for a variety of data products across different spatial extents.

This work is performed as part of Johns Hopkins University's [Hydroclimate Research Group](https://pages.jh.edu/bzaitch1/).

#### Data Inputs
 - <a href=""https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2022&layergroup=Census+Tracts"">US Census Tigerline Shapefile of Texas Census Tracts</a>
 - <a href=""https://developers.google.com/earth-engine/datasets/catalog/OREGONSTATE_PRISM_AN81d"">PRISM Daily Spatial Climate Dataset</a> (Variables: ppt, tdmean, tmax, tmin, tmean, vpdmax, vpdmin)
 - <a href=""https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_GRIDMET"">GRIDMET Gridded Surface Meteorological Dataset</a> (Variables: rmax, rmin, srad, vs)
 - <a href=""https://www.aer.com/weather-risk-management/floodscan-near-real-time-and-historical-flood-mapping/"">Floodscan SFED</a>
",1,1,1,0,public-health,"[climate, earth-observations, extreme-weather, flooding-events, geospatial-analysis, geospatial-data, geospatial-processing, google-earth-engine, gridmet, heat-index, public-health, python, r, remote-sensing, texas]",62
PiotrTymoszuk,hyposmia_analysis_pipeline,,https://github.com/PiotrTymoszuk/hyposmia_analysis_pipeline,https://api.github.com/repos/hyposmia_analysis_pipeline/PiotrTymoszuk,The complete analysis pipeline for the hyposmia project by Health After COVID-19 in Tyrol Study Team,"# hyposmia_analsis_pipeline

## Summary

The complete analysis pipeline for the hyposmia project by Health After COVID-19 in Tyrol and CovILD Study Teams aiming at identification of recovery phenotypes of post-COVID-19 condition and resolution of post-COVID-19 olfactory dysfunction.

<p align = ""center""> 
<img src = ""https://user-images.githubusercontent.com/80723424/229633138-426a6922-0468-463b-a770-86aaf7951796.png"" width = ""80%"">
</p>

<br>

## Terms of use

Please cite the repository, and our [preprint](https://www.medrxiv.org/content/10.1101/2022.06.02.22275932v1) (DOI: 10.1101/2022.06.02.22275932) or the [peer-reviewed publication of the analysis results](https://link.springer.com/article/10.1007/s00405-023-08163-x) (DOI: 10.1007/s00405-023-08163-x). The raw .RData data files will be made available upon request to the study authors, [Prof. Judith Löffler-Ragg](mailto:judith.loeffler@i-med.ac.at) and [Prof. Raimund Helbok](mailto:raimund.helbok@tirol-kliniken.at).

## Usage

The following development packages are required to run the pipeline:

```r

devtools::install_github('PiotrTymoszuk/soucer') ## script sourcing
devtools::install_github('PiotrTymoszuk/ExDA') ## exploratory data analysis and staristical hypothesis testing
devtools::install_github('PiotrTymoszuk/clustTools') ## factor analysis and unsupervised clustering
devtools::install_github('PiotrTymoszuk/somKernels') ## extra distances for self-organizing maps
devtools::install_github('PiotrTymoszuk/figur') ## management of figures and tables in Rmd documents
devtools::install_github('PiotrTymoszuk/trafo') ## handling of tabular data
devtools::install_github('PiotrTymoszuk/microViz') ## visualization

```

Source 'exec.R' to launch the entire pipeline:

```r

source('exec.R')

```

## Contact

The repository maintainer is [Piotr Tymoszuk](mailto:piotr.s.tymoszuk@gmail.com). Data requests should be addressed to [Prof. Judith Löffler-Ragg](mailto:judith.loeffler@i-med.ac.at) and [Prof. Raimund Helbok](mailto:raimund.helbok@tirol-kliniken.at).
",0,0,1,0,public-health,"[apriori, covid-19, kinetics, long-covid, mental-health, olfaction, psychometrics, public-health, quality-of-life, semi-supervised-clustering]",62
danielseussler,ssahealthriskfactors,,https://github.com/danielseussler/ssahealthriskfactors,https://api.github.com/repos/ssahealthriskfactors/danielseussler,Replication files for my master's thesis. Component-wise boosting for identification of health risk factors.,"# ssahealthriskfactors

This repository contains the replication files for my master's thesis at the Department of Statistics, University of Munich.

*Identification of Health Risk Factors in Developing Countries using Intrinsic Model Selection Approaches*


**Abstract**

In low- and middle-income countries, nationally representative household surveys such as the Demographic and Health Surveys provide a wealth of primary data on health, nutrition, and socio-economic outcomes. For epidemiological studies, the survey data is often drawn upon to identify health risk factors, both at the individual and geographical levels. In practice, the functional form of the risk factors is not known beforehand. For instance, an effect could be linear or non-linear, if included at all. Furthermore, the increased availability of remotely sensed data provides a new data source that can be integrated into the analyses of health conditions but is not necessarily informative. The increased dimensionality of such analyses demands methods of variable selection and model choice, both to remain interpretable and generalise well to future observations. In this thesis, I employ component-wise boosting to identify risk factors of two prevalent health conditions in sub-Saharan Africa. The approach is applied in two case studies, where risk factors of individual-level outcomes of chronic childhood malnutrition and environmental correlates of the geographic prevalence of malaria are modelled. The flexible estimation of linear, non-linear and spatial effects is found to be central in the understanding of both outcomes, even improving on other non-parametric models in terms of predictive capacity. When estimating malaria risk, component-wise boosting allows for response distributions that account for excess variability at the cluster level while being superior in interpretability compared to competing approaches proposed in the literature on predictive disease mapping.


**Replication**

To replicate the analyses done here, you first need to request access to the microdata from the Demographic and Health Survey Program (DHS) [here](https://dhsprogram.com/). Then set the following environment variables in your R project: 

```
email=""yourmail@mail.com""
project=""yourprojectname""
```
To set up the API of the `rdhs` package run `src/configs/rdhs.R`. The files to download all required data are in the folder `src/data/`. For the malaria risk mapping of Mali, Data from the [Google Earth Engine](https://earthengine.google.com/) has to be retrieved. See also [here](https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api) for an introduction. The Python environment is documented in `requirements.txt` and can be used to set up a local virtual environment. Finally, the data exported from the Google Earth Engine has to be manually copied into the folder `data/raw/earthengine`. 

Each analysis has separate files to prepare the microdata and remote sensing data, those have to be executed first. After all `src/analysis/*country*/*` files were run, the figures can be created with the files in `src/figures`. 


**References**

(Only main references, see also report.)

P. Bühlmann and T. Hothorn, ‘Boosting Algorithms: Regularization, Prediction and Model Fitting’, Statist. Sci., vol. 22, no. 4, Nov. 2007, doi: 10.1214/07-STS242.

N. Fenske, T. Kneib, and T. Hothorn, ‘Identifying Risk Factors for Severe Childhood Malnutrition by Boosting Additive Quantile Regression’, Journal of the American Statistical Association, vol. 106, no. 494, pp. 494–510, Jun. 2011, doi: 10.1198/jasa.2011.ap09272.

T. Kneib, T. Hothorn, and G. Tutz, ‘Variable Selection and Model Choice in Geoadditive Regression Models’, Biometrics, vol. 65, no. 2, pp. 626–634, Jun. 2009, doi: 10.1111/j.1541-0420.2008.01112.x.

J. Thomas, A. Mayr, B. Bischl, M. Schmid, A. Smith, and B. Hofner, ‘Gradient boosting for distributional regression: faster tuning and improved variable selection via noncyclical updates’, Stat Comput, vol. 28, no. 3, pp. 673–687, May 2018, doi: 10.1007/s11222-017-9754-6.

T. Q. Dong and J. Wakefield, ‘Modeling and presentation of vaccination coverage estimates using data from household surveys’, Vaccine, vol. 39, no. 18, pp. 2584–2594, Apr. 2021, doi: 10.1016/j.vaccine.2021.03.007.

Institut National de la Statistique (INSTAT) and ICF, ‘Enquête Démographique et de Santé à Madagascar (EDSMD-V) 2021’, Antananarivo, Madagascar et Rockville, Maryland, USA, 2022. [Online]. Available: https://www.dhsprogram.com/pubs/pdf/FR376/FR376.pdf

Institut National de la Statistique (INSTAT), Programme National de Lutte contre le Paludisme (PNLP), and The DHS Program, ‘Enquête sur les Indicateurs du Paludisme au Mali 2021’, Bamako, Mali et Rockville, Maryland, USA, 2022. [Online]. Available: https://www.dhsprogram.com/pubs/pdf/FR376/FR376.pdf
",0,0,1,0,public-health,"[additive-model, aiforsocialgood, boosting-algorithms, public-health, sae]",62
casaper,swiss_wastewater_covid_virus_load,,https://github.com/casaper/swiss_wastewater_covid_virus_load,https://api.github.com/repos/swiss_wastewater_covid_virus_load/casaper,R Notebook with Swiss covid waste water analysis cuves for different cities,"# Swiss Covid Wastewater Analysis Data

R Notebook with Swiss covid waste water analysis cuves for different localities.

## Contribute

My knowledge of R is extremely limited.  
I've chunked this document together quickly, and I may have done some ugly things for your R experts taste.

Contributions by someone with more R expertise than myself (likely anyone with R knowledge) are of course highly welcome.
",0,0,1,0,public-health,"[covid-19, public-health, statistics, switzerland, wastewater-surveillance]",62
Abhishekpandey2000,Covid-19-Data-Analysis,,https://github.com/Abhishekpandey2000/Covid-19-Data-Analysis,https://api.github.com/repos/Covid-19-Data-Analysis/Abhishekpandey2000,Analyze Covid-19 data to extract insights and trends. Explore pandemic-related statistics for informed awareness.,"# Covid-19-Data-Analysis
- Analyzed Covid-19 dataset for future insights and preparedness.
- Pandas, JSON for gathering and sanitization of the data from API.
- Analyzed the data using SQL.
- created Dashboard using Excel.

# Challenges and learnings
JSON | Nested Dictionaries | Error handling | Teamwork

# Techstack
JSON | API | Pandas | SQL | Excel
",0,0,1,0,public-health,"[covid-19, data-analysis, data-visualization, epidemiology, health-data, pandemic, public-health, statistics]",62
savannahwild,SIR_model_for_COVID-19,,https://github.com/savannahwild/SIR_model_for_COVID-19,https://api.github.com/repos/SIR_model_for_COVID-19/savannahwild,"Using the SIR model to predict COVID-19 infection patterns. It is a compartmental model with the variables S, I and R for the number of susceptible, infectious and resistant individuals, respectively. ","# SIR_model_for_COVID-19
Using the SIR model to predict COVID-19 infection patterns. It is a compartmental model with the variables S, I and R for the number of susceptible, infectious and resistant individuals, respectively. 
An SVIR model can adapt the SIR model to incorporate the effect of vaccination on the predictions
",0,0,1,0,public-health,"[compartmental-models, covid-19, differential-equations, epidemiology, population-dynamics, public-health, reproductive-number, sir-model, vaccination]",62
JonMinton,bayes_factor_slowdown,,https://github.com/JonMinton/bayes_factor_slowdown,https://api.github.com/repos/bayes_factor_slowdown/JonMinton,Calculate bayes factors for various hypotheses about extent of slowdown,"# Mortality Projections and Probability of Slowdown

This repository contains analysis of publically available mortality data on two linked research areas

* Projections of mortality in UK nations (and UK as a whole) up to and beyond 2012 based on trends in $e_0$ up to 2011
* Estimates of the likelihood there's been a slowdown in life expectancy from 2012 onwards given recent observations and past trends, and the relatively likelihood of different proposed magnitudes of decline

This statement needs to be reviewed and accepted

Here is a link to an intro to [markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)

## Figures 

Here is a figure from within the repo

![Can this be read?](figures/allnations_projected_observed.png)

",0,0,3,0,public-health,"[bayes-factor, mortality, public-health]",62
DiaAzul,Covid-19-Environment-Risk-Analysis,,https://github.com/DiaAzul/Covid-19-Environment-Risk-Analysis,https://api.github.com/repos/Covid-19-Environment-Risk-Analysis/DiaAzul,DASH Application for Covid-19 Environment Risk Analysis,"# Covid-19 Environment Risk Analysis
![Radar plot](./assets/example-plot.png)

Infectious diseases are transmitted in many ways, including through direct contact with an infected individual or indirectly through contact with their bodily fluids, fomites (particles of infectious material), and exhaled respiratory droplets. With each new infectious disease there is a period of time whilst research is carried out until it is clear which modes of transmission are most dominant in transmitting the diseases from an infectious to a susceptible person.

In the case of Covid-19 (caused by the SARS-Cov-2 virus), infection is thought to be transmitted in respiratory droplets, thought that doesn't mean that infection can be passed through other modes of transmission. There is debate whether transmission is predominantly due to spew, the large respiratory droplets which are ejected during breathing, sneezing and coughing; or whether infectious particles are also aerosolised. Spew droplets are typically greater than five to ten micrometers in size and fall close to the infectious person, whereas aerosols are much smaller and can travel great distances floating on air currents.

The extent to which respiratory droplets are aerosolised and whether they remain infectious is important, and determines whether additional mitigations are required. A disease which is predominantly transmitted in spew and where there is minimal aerosol generated is mitigated by recommending adequate physical distance between people, the wearing of face coverings, hand washing and making sure the environment is cleaned. However, if large numbers of respiratory particles are aerosolised and they remain in the air for long periods of time, travelling significant distances and creating clouds of concentrated infectious particles, then an increased number of people are likely to become infected. It should be noted that aerosolised infectious disease are not new and the health service has significant experience minimising risks associated with them.

The purpose of this risk assessment is to identify situations where infectious disease transmission through aerosol may be a significant risk, and where mitigations may need to be considered to reduce the risk of infection. It must be noted that whilst there is strong evidence that Covid-19 is transmitted as an aerosol, whether it is a greater risk than spew or other modes of transmission will take time to establish. Even if this tool identifies that that aerosol transmission is a risk, precautions will still need to be taken to minimise the risk of transmission due to spew and fomites by encouraging social distancing and hand washing.

# Installation

The risk assessment is implement as a DASH application that will run on any WSGI server. It was developed and tested using Visual Studio Code, though should work in any suitable Python environment.

Dependencies for the project are:
* dash == 1.4.1
* plotly == 4.7.1
* yaml == 0.1.7

# Code overview
The main code, which defines the structure of the Dash app, is contained within appy.py. This should be called from the WSGI server.

The text content and controls for the app are defined separately, with text held in two yaml files: content.yml for headings and text descriptions; and, controls.yml to define the controls in the app. This facilitates rapid text changes without impacting the code. These files are read when the application starts by classes in apptext.py and appcontrols.py.

The header and footer are defined within Appdecoration.py which is called from appy.py

The radar graph and the calculations used to determine the risk assessment are included in Appgraph.py.

All custom CSS used to style the app is included in app_specific.css within the assets folder.
",0,0,2,0,public-health,"[covid-19, healthcare, healthcare-application, public-health]",62
PythonCoderUnicorn,Health-and-Society,,https://github.com/PythonCoderUnicorn/Health-and-Society,https://api.github.com/repos/Health-and-Society/PythonCoderUnicorn,undergraduate course on Health & Society,"# Health-and-Society
undergraduate course on Health &amp; Society

Course slides that analyze the theories of why society functions that way it does in terms
of health both from the personal and public point of view. The Social Determinants of Health 
factor into everyone's health in society.
",0,0,1,0,public-health,"[determinants-of-health, health-systems, public-health, social-health, theory]",62
bonilab,malariaibm-spatial-BurkinaFaso-2022,bonilab,https://github.com/bonilab/malariaibm-spatial-BurkinaFaso-2022,https://api.github.com/repos/malariaibm-spatial-BurkinaFaso-2022/bonilab,Complete source code and intermediary files to accompany the manuscript.,"# malariaibm-spatial-BurkinaFaso-2022

[Penn State](https://www.psu.edu/) - [Center for Infectious Disease Dynamics (CIDD)](https://www.huck.psu.edu/institutes-and-centers/center-for-infectious-disease-dynamics) - [Boni Lab](http://mol.ax/)

---

# Overview

This repository contains a frozen snapshot of the code and intermediate data used to prepare the manuscript in perpetration by Zupko et al. (2023). Due to the size of the intermediate data (67.6 MB) this repository uses [Git Large File Storage](https://git-lfs.github.com/) and may be limited in terms of bandwidth as a result.  All studies run by the simulation use YAML files (in `Studies`) to provide the configuration and ASC files (in `Data/GIS`) for spatial data. 

Due to the complex nature of the simulation, [primary living documentation](https://github.com/rjzupkoii/PSU-CIDD-Malaria-Simulation) to build and run the simulation is hosted with the repository that contains active development. The version 4.1.1 code base was used to run the replicates used for the analysis described in the manuscript. 

## Binary Files

The compiled version of the simulation used for the studies is provided in the `Binaries` directory, which was  compiled and ran on in the following environment:

```
LSB Version:    :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch
Distributor ID: RedHatEnterpriseServer
Description:    Red Hat Enterprise Linux Server release 7.9 (Maipo)
Release:        7.9
Codename:       Maipo
```

---

### Original Repositories
- Malaria Simulation, version 4.1.1: https://github.com/rjzupkoii/PSU-CIDD-Malaria-Simulation
- Burkina Faso analysis and plots: https://github.com/rjzupkoii/PSU-CIDD-Burkina-Faso
- Support scripts and infrastructure: https://github.com/bonilab/PSU-CIDD-MaSim-Support",0,0,3,0,public-health,"[burkina-faso, individual-based-model, malaria, public-health, spaital-modeling]",62
graemeleehickey,epi2014,,https://github.com/graemeleehickey/epi2014,https://api.github.com/repos/epi2014/graemeleehickey,Spatial and Temporal Statistical Modelling for Population Health Sciences,"# Spatial and Temporal Statistical Modelling for Population Health Sciences

This repository contains the course material for the Survival Analayis delievred on Thursday 27 November 2014 at Leahurst Campus, University of Liverpool.

The course was jointly delivered by [Professor Peter Diggle](http://www.lancaster.ac.uk/staff/diggle/), [Dr Elisabeth Waldmann](http://www.imbe.med.uni-erlangen.de/ma/E.Waldmann/), and [Dr Jonathan Read](http://www.lancaster.ac.uk/fhm/about-us/people/jonathan-read). If you would like to access their material, please contact them directly.
",0,0,2,0,public-health,"[course, data, epidemiology, public-health, r, spatial, spatial-analysis, statistics, survival, veterinary, workshop]",62
brad-cannell,epi_3_public,brad-cannell,https://github.com/brad-cannell/epi_3_public,https://api.github.com/repos/epi_3_public/brad-cannell,Public repository for Brad Cannell’s Epidemiology III course at UTHealth,"
<!-- README.md is generated from README.Rmd. Please edit that file -->

# Epidemiology III Public Repository

<!-- badges: start -->

[![Lifecycle:
experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![CRAN
status](https://www.r-pkg.org/badges/version/project)](https://CRAN.R-project.org/package=project)
<!-- badges: end -->

This is the public repository for Brad Cannell’s Epidemiology III course
at UTHealth. It is still under development. Currently, this repository
is for:

1.  R code for lab warm-ups.
2.  R code for labs.
3.  Other files intended to be shared with students and/or the public.
4.  Loading practice data sets.

## Installation

You can install the development version of project from
[GitHub](https://github.com/) with:

``` r
# install.packages(""devtools"")
devtools::install_github(""brad-cannell/epi_3_public"")
```

Currently, there isn’t a reason to install this package. In the future,
we imagine that we will use this package to share R code (including
functions) and example data sets.
",0,0,2,23,public-health,"[course, epidemiology, public-health, r, rstats]",62
dgaitsgo,PublicHealthPost,,https://github.com/dgaitsgo/PublicHealthPost,https://api.github.com/repos/PublicHealthPost/dgaitsgo,Source-code and resources for visualizations of public health data,"Source-code, resources and raw files for custom visualizations produced for Boston University's [Public Health Post](https://publichealthpost.org/).
",0,0,2,0,public-health,"[data-analysis, public-health, water-quality]",62
BBC-Data-Unit,takeaways,BBC-Data-Unit,https://github.com/BBC-Data-Unit/takeaways,https://api.github.com/repos/takeaways/BBC-Data-Unit,More takeaways on high street despite anti-obesity push,"# More takeaways on high street despite anti-obesity push

![](https://ichef.bbci.co.uk/news/660/cpsprodpb/595C/production/_103967822_gettyimages-951506644.jpg)

In October 2018 the BBC Shared Data Unit [reported](https://www.bbc.co.uk/news/uk-45875294) UK high streets had the highest concentration of fast food outlets since 2010.

Research suggests people most exposed to them are nearly twice as likely to be obese.

We analysed the latest business figures with population estimates from the Office for National Statistics (ONS) and found:

- The UK had seen a 34% increase in fast food outlets from 2010 to 2018
- In 2010, the average number of fast food outlets per 100,000 people was 47. It had risen to 61 by 2018
- In nearly every area (204 out of 215) the rate of takeaways per 100,000 people was higher in 2018 than 2010

The Shared Data Unit makes data journalism available to news organisations across the media industry, as part of a partnership between the BBC and the News Media Association. Stories generated by the partnership included:

* The Scotsman: [Calls to tackle the soaring number of fast food outlets in Scotland](https://www.scotsman.com/news/health/calls-to-tackle-the-soaring-number-of-fast-food-outlets-in-scotland-1-4818401) *23 October 2018*
* The Scotsman: [Leader comment: How Japan can help Scotland kick junk food habit](https://www.scotsman.com/news/opinion/leader-comment-how-japan-can-help-scotland-kick-junk-food-habit-1-4818389) *23 October 2018*
* LBC radio: [How can you eat well when unhealthy food is everywhere?](https://twitter.com/LBC/status/1054750993345380352) *23 October 2018*
* The Sun: [FAST FOOD NATION Number of takeaways soars by a third in just eight years — fuelling obesity epidemic](https://www.thesun.co.uk/news/7567910/obesity-epidemic-takeaway-fears/) *24 October 2018*
* The Times: [Takeaways surge along with obesity](https://www.thetimes.co.uk/article/takeaways-surge-along-with-obesity-c5l9bfpzc) *24 October 2018*
* talkRADIO: [Chair of the National Obesity Forum: ‘We are all eating far too much’](https://talkradio.co.uk/news/chair-national-obesity-forum-we-are-all-eating-far-too-much-18102328462#C5hUD8WGCP58VscO.99) *23 October 2018*
* Daily Mail: [Nation gorging on fast food: Record surge in takeaways on almost every high street is feeding Britain's crippling obesity crisis](https://www.dailymail.co.uk/news/article-6309241/Record-surge-takeaways-high-street-feeding-Britains-crippling-obesity-crisis.html) *24 October 2018*
* The i: [Takeaway Cardiff: is the city really addicted to fast food?](https://inews.co.uk/news/long-reads/takeaway-cardiff-addicted-fast-food/) *26 October 2018*
* Mail Online: [Ten years ago, Jamie Oliver chose Rotherham to kick start a healthy eating revolution. Since then its takeaways have DOUBLED to 170, writes DAVID JONES on Britain's fast food road to ruin](https://www.dailymail.co.uk/news/article-6322541/DAVID-JONES-Britain-fast-food-track-obesity.html) *27 October 2018*
* ITV Wales: [73% of Blaenau Gwent's restaurants 'serve fast food'](https://www.itv.com/news/wales/2018-10-23/73-of-blaenau-gwents-restaurants-serve-fast-food/) *23 October 2018*
* Morpeth Herald: [Figures reveal increase in fast-food outlets in Northumberland](https://www.morpethherald.co.uk/news/figures-reveal-increase-in-fast-food-outlets-in-northumberland-1-9408492) *22 October 2018*
* Berwick Advertiser: [Figures reveal increase in fast-food outlets in Northumberland](https://www.berwick-advertiser.co.uk/news/figures-reveal-increase-in-fast-food-outlets-in-northumberland-1-4818299) *22 October 2018*
* Rochdale Online: [Takeaway-saturated Rochdale is one of UK’s hotspots](https://www.rochdaleonline.co.uk/news-features/2/news-headlines/123195/takeawaysaturated-rochdale-is-one-of-uk%E2%80%99s-hotspots) *23 October 2018*
* Cornish Stuff: [Fast Food taking over the high street – but Cornish kids buck trend](https://cornishstuff.com/2018/10/23/fast-food-taking-over-the-high-street-but-cornish-kids-buck-trend) *23 October 2018*
* Yorkshire Evening Post: [Number of fast food outlets in Leeds is on the rise, figures reveal](https://www.yorkshireeveningpost.co.uk/news/number-of-fast-food-outlets-in-leeds-is-on-the-rise-figures-reveal-1-9408435) *23 October 2018*
* News Guardian: [North Tyneside in top 30 for numbers of fast-food outlets](https://www.newsguardian.co.uk/news/north-tyneside-in-top-30-for-numbers-of-fast-food-outlets-1-9408500) *23 October 2018*
* ITV News Bradford: [Hull and Bradford have country's highest proportions of fast food shops](https://www.itv.com/news/calendar/2018-10-23/hull-and-bradford-have-one-of-countrys-highest-proportions-of-fast-food-shops/) *23 October 2018*
* Northumberland Gazette: [Figures reveal increase in fast-food outlets in Northumberland](https://www.northumberlandgazette.co.uk/news/figures-reveal-increase-in-fast-food-outlets-in-northumberland-1-9408492https://www.northumberlandgazette.co.uk/news/figures-reveal-increase-in-fast-food-outlets-in-northumberland-1-9408492) *23 October 2018*
* Redditch & Alcester Advertiser: [Worcestershire sees rise in fast food outlets, BBC's Shared Data Unit reveals](https://www.redditchadvertiser.co.uk/news/16999825.worcestershire-sees-rise-in-fast-food-outlets-bbcs-shared-data-unit-reveals/) *23 October 2018*
* ITV Central: [Rise in fast food outlets across the Midlands as obesity rates reach record high](https://www.itv.com/news/central/2018-10-23/rise-in-fast-food-outlets-across-the-midlands-as-obesity-rates-reach-record-high/) *23 October 2018*
* Northampton Chronicle & Echo: [Takeaways make up a smaller slice of Northamptonshire's food outlets than in 2010](https://www.northamptonchron.co.uk/news/takeaways-make-up-a-smaller-slice-of-northamptonshire-s-food-outlets-than-in-2010-1-8678166) *23 October 2018*
* Kidderminster Shuttle: [Worcestershire sees rise fast food outlets, BBC's Shared Data Unit reveals](https://www.kidderminstershuttle.co.uk/news/16999825.worcestershire-sees-rise-fast-food-outlets-bbcs-shared-data-unit-reveals/) *23 October 2018*
* ITV News Anglia: [Number of takeaways up by a third in less than a month (sic)](https://www.itv.com/news/anglia/2018-10-23/number-of-takeaways-up-by-a-third-in-less-than-a-month/)
* Sunderland Echo: [Sunderland is named as takeaway blackspot as obesity levels grow](https://www.sunderlandecho.com/news/health/sunderland-is-named-as-takeaway-blackspot-as-obesity-levels-grow-1-9409043) *23 October 2018*
* Bromsgrove Advertiser: [Worcestershire sees rise fast food outlets, BBC's Shared Data Unit reveals](https://www.bromsgroveadvertiser.co.uk/news/16999825.worcestershire-sees-rise-fast-food-outlets-bbcs-shared-data-unit-reveals/) *23 October 2018*
* Edinburgh Evening News: [Number of Edinburgh fast food outlets soaring, according to report](https://www.edinburghnews.scotsman.com/news/health/number-of-edinburgh-fast-food-outlets-soaring-according-to-report-1-4818437) *23 October 2018*
* Stourbridge News: [Wellbeing boss talks tough as BBC data shows rise in fast food takeaways](https://www.stourbridgenews.co.uk/news/16999682.wellbeing-boss-talks-tough-as-bbc-data-shows-rise-in-fast-food-takeaways/) *23 October 2018*
* Barking and Dagenham Post: [Fast food shop makes up majority of eateries in Barking and Dagenham](http://www.barkinganddagenhampost.co.uk/news/health/fast-food-barking-and-dagenham-junk-food-ons-office-for-national-statistics-1-5747523) *23 October 2018*
* The Shields Gazette: [South Tyneside named as country’s fourth worst takeaway blackspot](https://www.shieldsgazette.com/news/south-tyneside-named-as-country-s-fourth-worst-takeaway-blackspot-1-9409038) *23 October 2018*
* Pirate FM: [Revealed... how many fast food outlets there are in Cornwall](https://www.piratefm.co.uk/news/latest-news/2719192/revealed-how-many-fast-food-outlets-there-are-in-cornwall/) *23 October 2018*
* Grimsby Live: [Grimsby and Cleethorpes ranked in national top 20 for highest concentration of takeaways](https://www.grimsbytelegraph.co.uk/news/grimsby-news/more-takeaways-ever-hit-grimsby-2138768) *23 October 2018*
* South Wales Argus: [Blaenau Gwent is top of the table for takeaways among all council areas nationally](https://www.southwalesargus.co.uk/news/17002175.blaenau-gwent-is-top-of-the-table-for-takeaways/) *23 October 2018*
* ecnmy.org: [Brits are getting fatter. Are takeaway joints to blame?](https://www.ecnmy.org/engage/forget-fried-chicken-says-uk-gov-obesity-not-peng-life/) *23 October 2018*
* Catering Today: [UK takeaways increase 34% in eight years despite anti-obesity push](https://www.cateringtoday.co.uk/news/government/uk-takeaways-increase-34-in-eight-years-despite-anti-obesity-push/) *23 October 2018*
* Ilford Recorder: [Takeaways up almost 50pc in Redbridge despite anti-obesity push](http://www.ilfordrecorder.co.uk/news/takeaways-grow-obesity-redbridge-1-5749035) *24 October 2018*
* Blackpool Gazette: [Surge in Blackpool takeaways coincides with rise in obesity](https://www.blackpoolgazette.co.uk/news/health/surge-in-blackpool-takeaways-coincides-with-rise-in-obesity-1-9411409) *24 October 2018*
* Lincolnshire Reporter: [Rise in takeaways defies efforts to tackle obesity](https://lincolnshirereporter.co.uk/2018/10/rise-in-takeaways-defies-efforts-to-tackle-obesity/) *24 October 2018*
* Wigan Today: [Hefty increase in the number of Wigan takeaways](https://www.wigantoday.net/news/hefty-increase-in-the-number-of-wigan-takeaways-1-9410207) *24 October 2018*
* Bradford Telegraph & Argus: [Number of takeaways in Bradford more than doubles in eight years](https://www.thetelegraphandargus.co.uk/news/17003385.number-of-takeaways-in-bradford-more-than-doubles-in-eight-years/) *24 October 2018*
* Kent Online: [Does Kent have too many fast food outlets?](https://www.kentonline.co.uk/kmtv/video/does-kent-have-too-many-fast-food-outlets-22665/) *24 October 2018*
* Daddyhood.net: [Record surge in takeaways on almost every high street](https://daddyhood.net/record-surge-in-takeaways-on-almost-every-high-street-4489.html) *24 October 2018*
* Stoke Sentinel/StokeonTrentLive: [Revealed: The HUGE number of takeaways we now have in Stoke-on-Trent - so are we a city of fast food addicts?](https://www.stokesentinel.co.uk/news/health/revealed-huge-number-takeaways-now-2143595) *25 October 2018*
* Footprint: [NEW POWERS FAILING TO RESTRICT TAKEAWAYS](http://www.foodservicefootprint.com/news/new-powers-failing-to-restrict-takeaways) *25 October 2018*
* Rotherham Advertiser: [""Ditch the junk food"" call as Rotherham takeaway numbers soar](https://www.rotherhamadvertiser.co.uk/news/view,ditch-the-junk-food-call-as-rotherham-takeaway-numbers-soar_29139.htm) *26 October 2018*
* Kent Online: [Rising number of fast food outlets in Kent](https://www.kentonline.co.uk/kent/news/big-rise-in-fast-food-outlets-192218/) *26 October 2018*
* Daily Echo: [The crazy growth of coffee shops and fast food outlets](https://www.bournemouthecho.co.uk/news/17068591.the-crazy-growth-of-coffee-shops-and-fast-food-outlets/) *27 October 2018*
* Romford Recorder: [Takeaways grow in number in Havering despite anti-obesity push](http://www.romfordrecorder.co.uk/news/havering-takeaway-increase-1-5754689) *29 October 2018*
* Wales: Daily Post: [Conwy revealed to be one of the fast food capitals of the UK](https://www.dailypost.co.uk/news/north-wales-news/conwy-revealed-one-fast-food-15348905) *31 October 2018*
* Scotland: Border Telegraph: [Fast food outlets on rise in Borders](https://www.bordertelegraph.com/news/17194767.fast-food-outlets-on-rise-in-borders/?ref=rss) *1 November 2018*
* Southwark News: [NUMBER OF SOUTHWARK FAST FOOD OUTLETS INCREASE DESPITE LINK TO HIGH CHILD OBESITY FIGURES](https://www.southwarknews.co.uk/news/fast-food-takeaway-southwark-increase/) *1 November 2018*
* Scotland: Peeblesshire News: [Fast food outlets on rise in Borders](https://www.peeblesshirenews.com/news/17194769.fast-food-outlets-on-rise-in-borders/) *1 November 2018*
* Eastern Daily Press: [Norfolk sees drop in fast food outlets despite more opening](http://www.edp24.co.uk/news/norfolk-fast-food-restuarants-cafe-1-5766351) *6 November 2018*
* Diss Mercury: [Norfolk sees drop in fast food outlets despite more opening](http://www.dissmercury.co.uk/news/norfolk-fast-food-restuarants-cafe-1-5766351) *6 November 2018*


* The story was also used by BBC Breakfast, the [Victoria Derbyshire programme](https://drive.google.com/open?id=1cnRYWyza04RB0dSKjj_XMYHcPj2dDM2H), [the BBC's national 6pm news](https://drive.google.com/open?id=1EQbqeQRpDf0TnIBauVtArdQIfdKRuAcj), BBC Radio 4 Today, BBC Radio 5 Live, [BBC Sunday Morning Live](https://drive.google.com/open?id=1MtUIW8nfYa46AqTyr-k1SNvSXEg64zAY), BBC Business Live on BBC World, [Afternoon Live on the BBC News Channel](https://drive.google.com/open?id=1AYa5JYd_4wPhGoJ3uObgu3adfWMTWFDY), BBC Homepage, [BBC Wales online](https://www.bbc.co.uk/news/uk-wales-45943124), BBC Radio Wales, BBC Radio Leeds, BBC Three Counties Radio, BBC Radio Sheffield, BBC Look North TV, BBC South Today TV, BBC Radio Humberside, BBC Wiltshire, BBC Radio Cambridgeshire, BBC Radio Lincolnshire, BBC Radio Cumbria, BBC Radio York, BBC Radio Kent, BBC Radio Cornwall, BBC Hereford & Worcester, BBC Radio Solent, BBC Radio Suffolk, BBC Radio Shropshire and was distributed by the Press Association


## Get the data

* [Takeaway rates data](https://docs.google.com/spreadsheets/d/1v9Cv6wBAAspfUiBQUjAUON1h5GJ5WAO1xZOU3d_URJM/edit?usp=sharing)

## Visualisation

* Map: Where takeaways are most common

## Background and briefing

* [Project briefing](https://docs.google.com/document/d/1R9BEIyhXE4L6gDcihtlWm5kvedWjwt39RzdJUs_wTG4/edit)
",0,0,5,0,public-health,"[health, obesity, public-health, shareddataunit]",62
dpploy,covid-surge,dpploy,https://github.com/dpploy/covid-surge,https://api.github.com/repos/covid-surge/dpploy,COVID-19 mortality surge period calculation for communities afflicted by the corona virus SARS-CoV-2,"# Covid-surge
COVID-19 mortality surge period calculation for communities afflicted by the corona virus SARS-CoV-2.

+ [University of Massachusetts Lowell](https://www.uml.edu/)
+ [Dept. of Chemical Engineering](https://www.uml.edu/Engineering/Chemical/) (Nuclear Program)
+ [Prof. Valmor F. de Almeida](https://www.uml.edu/Engineering/Chemical/faculty/de-Almeida-Valmor.aspx) (valmor_dealmeida@uml.edu)

-----------

[![NBViewer](https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/dpploy/covid-surge/tree/master/notebooks/)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dpploy/covid-surge/master)

[![PyPI Version](https://img.shields.io/pypi/v/covid-surge)](https://pypi.org/project/covid-surge/)
[![PyPI Python Version](https://img.shields.io/pypi/pyversions/covid-surge)](https://pypi.org/project/covid-surge/)
[![Repo Size](https://img.shields.io/github/repo-size/dpploy/covid-surge)](https://github.com/dpploy/covid-surge)

[![CircleCI](https://img.shields.io/circleci/build/github/dpploy/covid-surge/master)](https://circleci.com/gh/dpploy/covid-surge)
[![codecov](https://codecov.io/gh/dpploy/covid-surge/branch/master/graph/badge.svg)](https://codecov.io/gh/dpploy/covid-surge)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/8ba73ff25b264beb8a15f2172cf81aa7)](https://www.codacy.com/gh/dpploy/covid-surge?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=dpploy/covid-surge&amp;utm_campaign=Badge_Grade)

------------

**Preprint**: [How Long is the Worst Part of the COVID-19 Mortality Surge?](https://doi.org/10.31219/osf.io/z59uy)


|   |
|:---|
|----------------------------------------------------\|**WORLD**\|---------------------------------------------------------|
|<img  width=""900"" src=""https://raw.githubusercontent.com/dpploy/covid-surge/master/readme/group_surge_periods_global.png"" title=""Surge Periods""> |
| [Data source](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data). |
| Distribution of mortality critical surge periods for the countries with fully evolved epidemics. The average critical surge period is the number of days between the points of maximum and minimum curvatures on the sigmoid curve approximating the data. Countries to the right are less stressed than countries to the left. The colored bar plot shows locations grouped by 2-day bin widths. |
| The world average critical surge period at the date indicated by the plot is **23 days with a 3-day standard deviation**.|
| *To update this plot with live data, [run this Jupyter Notebook](https://nbviewer.jupyter.org/github/dpploy/covid-surge/blob/master/notebooks/countries-surge.ipynb).* |
|---------------------------------------------------------\|**US**\|-------------------------------------------------------|
|<img  width=""900"" src=""https://raw.githubusercontent.com/dpploy/covid-surge/master/readme/group_surge_periods_us.png"" title=""Surge Periods""> |
| [Data source](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data). |
| Distribution of mortality critical surge periods for the US states with fully evolved epidemics. The average critical surge period is the number of days between the points of maximum and minimum curvatures on the sigmoid curve approximating the data. Countries to the right are less stressed than countries to the left. The colored bar plot shows locations grouped by 2-day bin widths. |
| The US state average critical surge period at the date indicated by the plot is **25 days with a 3-day standard deviation**.|
| *To update this plot with live data, [run this Jupyter Notebook](https://nbviewer.jupyter.org/github/dpploy/covid-surge/blob/master/notebooks/us-states-surge.ipynb).*  |
|--------------------------------------------\|**US State Counties/Towns (Top 3)**\|---------------------------------------|
|<img  width=""900"" src=""https://raw.githubusercontent.com/dpploy/covid-surge/master/readme/group_surge_periods_us_new_york.png"" title=""Surge Periods""> |
| [Data source](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data). |
| Distribution of mortality critical surge periods for the US state New York with fully evolved epidemics. The average critical surge period is the number of days between the points of maximum and minimum curvatures on the sigmoid curve approximating the data. Countries to the right are less stressed than countries to the left. The colored bar plot shows locations grouped by 2-day bin widths.|
| The average critical surge period at the date indicated by the plot is **21 days with a 3-day standard deviation**.|
| *To update this plot with live data, [run this Jupyter Notebook](https://nbviewer.jupyter.org/github/dpploy/covid-surge/blob/master/notebooks/us-state-counties-surge.ipynb).*  |
|-------------------------------------------------------------------------------------------------------------------------|
|<img  width=""900"" src=""https://raw.githubusercontent.com/dpploy/covid-surge/master/readme/group_surge_periods_us_new_jersey.png"" title=""Surge Periods""> |
| [Data source](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data). |
|-------------------------------------------------------------------------------------------------------------------------|
|<img  width=""900"" src=""https://raw.githubusercontent.com/dpploy/covid-surge/master/readme/group_surge_periods_us_massachusetts.png"" title=""Surge Periods""> |
| [Data source](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data). |
",0,0,2,0,public-health,"[analytics, covid-19, covid-surge, curve-fitting, epidemics, jupyter-notebook, non-linear-optimization, public-health, python, surge-periods]",62
sidens,rater-app,,https://github.com/sidens/rater-app,https://api.github.com/repos/rater-app/sidens,Restaurant health rating app - using Socrata open-data sources ,"README
_______

Todos:
 - Add typeahead suggestions
 - Performance improvements
 - Better string searches (""The Ragtrader"" ~= ""The Rag Trader"" ~= ""The Rag Trader/"""")
 - Fix Casing for results list
 - UX v2",0,0,2,0,public-health,"[gh-pages, open-data, public-health, socrata]",62
QIDSOD,QIDSOD-documentation,QIDSOD,https://github.com/QIDSOD/QIDSOD-documentation,https://api.github.com/repos/QIDSOD-documentation/QIDSOD,"Documentation related to the project ""Quantifying the Impact of Data Sharing on Outbreak Dynamics"" (QIDSOD)","# About

This repository contains documentation related to the project ""Quantifying the Impact of Data Sharing on Outbreak Dynamics"" (QIDSOD) that is 
- jointly led by 
  - [Jundong Li](https://github.com/jundongl) (School of Engineering and Applied Science &mdash; Electrical and Computer Engineering / Computer Science &mdash; and School of Data Science at the University of Virginia) and 
  - [Daniel Mietchen](https://github.com/Daniel-Mietchen) (School of Data Science at the University of Virginia)
- jointly funded through a [COVID-19 Rapid Response grant](http://web.archive.org/web/20200525045741/https://gidi.virginia.edu/covid-19-rapid-response) by 
  - the [Global Infectious Diseases Institute](https://gidi.virginia.edu/) (GIDI) at the University of Virginia, in partnership with 
  - the [Office of the Vice-President for Research](https://research.virginia.edu/) of the University of Virginia.

# Project summary

In this project, we will explore the range of data-related decisions made during public health emergencies like the ongoing [COVID-19 pandemic](https://en.wikipedia.org/wiki/COVID-19_pandemic) and analyze the flow of information, data, and metadata within networks of such decisions.

Data sharing is now considered a key component of addressing present, future, and even past public health emergencies, from local to global levels. Researchers, research institutions, journals and others have taken steps towards increasing the sharing of data around the ongoing COVID-19 pandemic and in preparation for future pandemics.

We will quantify the effects of data flow modifications to identify parameter sets under which specific modes of sharing or withholding information have the largest effects on outbreak dynamics. For these high-impact parameter sets, we will then assess the current and past availability of corresponding data, metadata, and misinformation, and estimate the effects on outbreak mitigation and preparedness efforts.

# Further information

Here are some pointers to help you get into the mood of thinking along.

## Research proposal

More details on our plans are available through the research proposal:
* Mietchen D, Li J (2020) Quantifying the Impact of Data Sharing on Outbreak Dynamics (QIDSOD). Research Ideas and Outcomes 6: e54770. https://doi.org/10.3897/rio.6.e54770

## Background reading

* We have begun to curate a corpus of relevant literature, based on the [intersection](https://tools.wmflabs.org/scholia/topics/Q5227350,Q95612615,Q1331926,Q4417999,Q84263196,Q202864,Q88434121,Q87745177,Q10538943,Q88835036,Q1149776,Q309901,Q29032648,Q45933174,Q1460420,Q1252988,Q50410669,Q1128437,Q29056927,Q12184,Q182672,Q901464,Q45881698,Q525512,Q192995,Q764527,Q609748,Q2725393,Q59485450,Q17076801) of literature on a range of subjects related to the project (the page might take a minute to render, as it is based on live queries).
* In parallel, we are assembling a [list of publications](bibliography.md) that zoom in on selected aspects of our planned research.

## Decision networks

Outbreak dynamics are determined by a combination of factors, including decisions by different [stakeholders](stakeholders.md) within or associated with the affected populations. In order to describe the network of their collective decisions, we will consider different kinds of stakeholders in the context of the actions they may or may not take, how decisions related to these actions can be informed by data, and how the resulting actions affect outbreak dynamics.
",0,0,3,0,public-health,"[covid-19, covid19, data-integration, data-science, data-sharing, datasharing, documentation, epidemiological-investigation, epidemiology, next-pandemic, outbreak, outbreak-data-analysis, outbreak-dynamics, outbreak-severity, outbreaks, public-health, sars-cov-2, sarscov2]",62
itinerum,HESRT,,https://github.com/itinerum/HESRT,https://api.github.com/repos/HESRT/itinerum,Health Economic Services for RadioTherapy,"# HESRT
Health Economic Services for RadiotTherapy

Health Economics Services for RadioTherapy (HESRT) is a repository of r-scripts and documentation on health economics to help decision-making related to the use of radiotherapy in the management of cancer. The information contained in HESRT can be used in any income or regional setting, but is intended to help decision-making in low- and middle-income countries (LMIC) 

Health economic evaluation studies are used in public health to assess health strategies/interventions in terms of their cost-effectiveness and inform public policies. Health economic evaluation does not substitute but rather complement the evidence-based medicine paradigm for decision making in public health.
",0,0,1,0,public-health,"[health-economic-evaluations, health-economics, public-health, radiotherapy]",62
cidm-ph,obsim,cidm-ph,https://github.com/cidm-ph/obsim,https://api.github.com/repos/obsim/cidm-ph,Outbreak simulation based on a branching process,"# obsim

> **Outbreak simulation based on a branching process**

Simulate outbreaks of a communicable disease.
This is both a simulation framework and an implementation that uses very
simplistic modelling assumptions.

## How to use

This is a Rust library, and can be added to your `Cargo.toml` with:

```toml
[dependencies]
obsim = { git = ""https://github.com/cidm-ph/obsim"" }
```

See the [development documentation](https://cidm-ph.github.io/obsim/obsim).

You do not necessarily need to be familiar with Rust to make use of this
library as it comes with some [examples](./examples) that you can modify.
See [Installing Rust](https://www.rust-lang.org/tools/install) to get set up.
With the repository checked out, you can edit the configuration in the examples
and then e.g. `cargo run --example simple > simulation.fa` to get an annotated
FASTA file with the simulation result.

## Purpose

The currently implemented models are too simplistic to capture many real
features of microbial evolution. They are intended for simple approximations
that apply on short timescales where only a few mutations are expected to occur
over the duration of outbreaks.

The framework can be extended with more sophisticated models using the same
simple interfaces to drive simulations.

## Citation

This framework was created for the following study

> Suster CJE, Arnott A, Blackwell G, Gall M, Draper J, Martinez E, Drew AP, Rockett RJ, Chen SC-A, Kok J, Dwyer DE and Sintchenko V (2022)
> Guiding the design of SARS-CoV-2 genomic surveillance by estimating the resolution of outbreak detection.
> Front. Public Health 10:1004201. doi: [10.3389/fpubh.2022.1004201](https://doi.org/10.3389/fpubh.2022.1004201)

## Licence

Dual-licensed under [MIT](LICENSE-MIT) or [Apache 2.0](LICENSE-APACHE).

© 2022 Western Sydney Local Health District, NSW Health
",0,0,2,0,public-health,"[outbreak, public-health, simulation]",62
abdellahai,IFolder,,https://github.com/abdellahai/IFolder,https://api.github.com/repos/IFolder/abdellahai,"This is a prototype of the first fully functionalities telemedicine platform that integrates omics, it's started as a platform for managing the data of the pandemic, including genomics data of the virus and the host, and using them for creating AI tools. The complete version of this platform will serve as a model for any future epidemic situation This project uses Python and Django for scripting and backend and flutter from dart for frontend.","# Omics_telemed
This is a prototype of the first fully functionalities telemedicine platform that integrates omics, it's started as a platform for managing the data of the pandemic, including genomics data of the virus and the host, and using them for creating AI tools. The complete version of this platform will serve as a model for any future epidemic situation This project uses Python and Django for scripting and backend and flutter from dart for frontend.
",0,0,1,0,public-health,"[data-science, epidemiology, genomics, metagenomics, public-health, transcriptomics, webapp]",62
tyg3rr,HM878-Biostats,,https://github.com/tyg3rr/HM878-Biostats,https://api.github.com/repos/HM878-Biostats/tyg3rr,Coursework for Advanced Biostats; Learning Playground for R,"# HM878-Biostats
Coursework for HM 878 Applied Biostatistics for Public Health Practitioners

The focus of this course is on applied biostatistical techniques but builds upon theoretical concepts from introductory biostatistics courses. As such, we will focus on actually analyzing data and interpreting the meaning of these analyses. Upon completion of the course, students will have attained proficiency in conducting data analysis using techniques commonly encountered in public health research literature.

Course Learning Objectives:

1. Analyze data using the multivariable techniques (i.e. MANOVA, Multiple Linear Regression, Logistic Regression, Factor Analysis, and Survival Analysis).

2. Interpret results of data analysis from multivariable techniques (i.e. MANOVA, Multiple Linear Regression, Logistic Regression, Factor Analysis, and Survival Analysis, Time-Series Analysis, Path Analysis, and Structural Equation Modeling).

3. Write a statistical analysis plan for a public health data set.

4. Implement a statistical analysis plan for a public health data set.

5. Create reports of the results of a statistical analysis plan.",0,0,1,0,public-health,"[biostatistical-computing, biostatistics, public-health, rlanguage]",62
humanetech-community,awesome-humane-tech,humanetech-community,https://github.com/humanetech-community/awesome-humane-tech,https://api.github.com/repos/awesome-humane-tech/humanetech-community,"Promoting Solutions that Improve Wellbeing, Freedom and Society","# Awesome Humane Tech [![Awesome](https://awesome.re/badge.svg)](https://github.com/sindresorhus/awesome) [![Awesome Humane Tech](https://raw.githubusercontent.com/humanetech-community/awesome-humane-tech/main/humane-tech-badge.svg?sanitize=true)](https://github.com/humanetech-community/awesome-humane-tech)

[![Humane Tech Community](https://raw.githubusercontent.com/humanetech-community/awesome-humane-tech/main/humanetech-tech-distraction.jpg)](https://community.humanetech.com)

## About this list

Tech and social media is having a big impact on our society. While many innovative technology inventions are improving our lives, there is increasing awareness on negative impacts that come with these trends, such as large-scale privacy invasion, surveillance capitalism, and tech monopolies. They lead to social media addiction, mental health issues, and are even eroding the fabric of our society.

[![Humane Tech Community](https://raw.githubusercontent.com/humanetech-community/awesome-humane-tech/main/logo/humanetech-community-logo.svg?sanitize=true)](https://humanetech.community)

Our mission is: [**To Help Improve Wellbeing, Freedom and Society!**](https://community.humanetech.com/t/3322) 

We gladly invite you to our [Humane Tech Community Forum](https://community.humanetech.com) to read more about interesting Humane Technology subjects, participate in our discussions, and become a true :heart:  _Humane Tech Activist!_

You can also follow us on the fediverse at [@humanetech@mastodon.social](https://mastodon.social/@humanetech).

# Give Up GitHub

This project has given up GitHub.  ([See Software Freedom Conservancy's *Give Up  GitHub* site for details](https://GiveUpGitHub.org).)

You can now find this project at [https://codeberg.org/teaserbot-labs/delightful-humane-design](https://codeberg.org/teaserbot-labs/delightful-humane-design) instead.

Any use of this project's code by GitHub Copilot, past or present, is done without our permission.  We do not consent to GitHub's use of this project's code in Copilot.

Join us; you can [give up GitHub](https://GiveUpGitHub.org) too!

![Logo of the GiveUpGitHub campaign](https://sfconservancy.org/img/GiveUpGitHub.png)
",2962,2962,109,0,health,"[awesome-list, decentralization, democracy, ergonomics, ethics, fediverse, freedom-of-information, freedom-of-speech, giveupgithub, health, humane, humane-tech, mindfulness, privacy, privacy-protection, social, social-media, social-networks, society, transparency]",62
openemr,openemr,openemr,https://github.com/openemr/openemr,https://api.github.com/repos/openemr/openemr,The most popular open source electronic health records and medical practice management solution.,"![Syntax Status](https://github.com/openemr/openemr/workflows/Syntax/badge.svg?branch=master)
![Styling Status](https://github.com/openemr/openemr/workflows/Styling/badge.svg?branch=master)
![Testing Status](https://github.com/openemr/openemr/workflows/Test/badge.svg?branch=master)

[![Backers on Open Collective](https://opencollective.com/openemr/backers/badge.svg)](#backers) [![Sponsors on Open Collective](https://opencollective.com/openemr/sponsors/badge.svg)](#sponsors)

# OpenEMR

[OpenEMR](https://open-emr.org) is a Free and Open Source electronic health records and medical practice management application. It features fully integrated electronic health records, practice management, scheduling, electronic billing, internationalization, free support, a vibrant community, and a whole lot more. It runs on Windows, Linux, Mac OS X, and many other platforms.

### Contributing

OpenEMR is a leader in healthcare open source software and comprises a large and diverse community of software developers, medical providers and educators with a very healthy mix of both volunteers and professionals. [Join us and learn how to start contributing today!](https://open-emr.org/wiki/index.php/FAQ#How_do_I_begin_to_volunteer_for_the_OpenEMR_project.3F)

> Already comfortable with git? Check out [CONTRIBUTING.md](CONTRIBUTING.md) for quick setup instructions and requirements for contributing to OpenEMR by resolving a bug or adding an awesome feature 😊.

### Support

Community and Professional support can be found [here](https://open-emr.org/wiki/index.php/OpenEMR_Support_Guide).

Extensive documentation and forums can be found on the [OpenEMR website](https://open-emr.org) that can help you to become more familiar about the project 📖.

### Reporting Issues and Bugs

Report these on the [Issue Tracker](https://github.com/openemr/openemr/issues). If you are unsure if it is an issue/bug, then always feel free to use the [Forum](https://community.open-emr.org/) and [Chat](https://www.open-emr.org/chat/) to discuss about the issue 🪲.

### Reporting Security Vulnerabilities

Check out [SECURITY.md](.github/SECURITY.md)

### API

Check out [API_README.md](API_README.md)

### Docker

Check out [DOCKER_README.md](DOCKER_README.md)

### FHIR

Check out [FHIR_README.md](FHIR_README.md)

### For Developers

If using OpenEMR directly from the code repository, then the following commands will build OpenEMR (Node.js version 18.* is required) :

```shell
composer install --no-dev
npm install
npm run build
composer dump-autoload -o
```

### Contributors

This project exists thanks to all the people who have contributed. [[Contribute]](CONTRIBUTING.md).
<a href=""https://github.com/openemr/openemr/graphs/contributors""><img src=""https://opencollective.com/openemr/contributors.svg?width=890"" /></a>


### Sponsors

Thanks to our [2015 Edition Major Sponsors](https://www.open-emr.org/wiki/index.php/OpenEMR_Certification_Stage_III_Meaningful_Use#Major_sponsors)!


### License

[GNU GPL](LICENSE)
",2375,2375,125,223,health,"[ehr, emr, fhir, global-health, health, healthcare, hit, international, linux, medical, medical-informatics, medical-information, medical-records, openemr, osx, php, practice-management, proprietary-counterparts, sponsors, windows]",62
carekit-apple,CareKit,carekit-apple,https://github.com/carekit-apple/CareKit,https://api.github.com/repos/CareKit/carekit-apple,CareKit is an open source software framework for creating apps that help people better understand and manage their health.,"![CareKit](https://user-images.githubusercontent.com/29666989/60061659-cf6acb00-96aa-11e9-90a0-459b08fc020d.png)

# CareKit

[![License](https://img.shields.io/badge/license-BSD-green.svg?style=flat)](https://github.com/carekit-apple/CareKit#license) [![Swift Versions](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fcarekit-apple%2FCareKit%2Fbadge%3Ftype%3Dswift-versions)](https://swiftpackageindex.com/carekit-apple/CareKit) [![OS's](https://img.shields.io/endpoint?url=https%3A%2F%2Fswiftpackageindex.com%2Fapi%2Fpackages%2Fcarekit-apple%2FCareKit%2Fbadge%3Ftype%3Dplatforms)](https://swiftpackageindex.com/carekit-apple/CareKit) ![Xcode 14.0+](https://img.shields.io/badge/Xcode-14.0%2B-blue.svg) [![SPM](https://img.shields.io/badge/Swift%20Package%20Manager-compatible-brightgreen.svg)](https://github.com/apple/swift-package-manager)

CareKit™ is an open source software framework for creating apps that help people better understand and manage their health. The framework provides modules that you can use out of the box, or extended and customized for more targeted use cases. It's composed of three SPM packages which can each be imported separately.

* **CareKit:** This is the best place to start building your app. CareKit provides view controllers that tie CareKitUI and CareKitStore together. The view controllers leverage Combine to provide synchronization between the store and the views.

* **CareKitUI:** Provides the views used across the framework. The views are open and extensible subclasses of UIView. Properties within the views are public, allowing for full control over the content.

* **CareKitStore:** Provides a Core Data solution for storing patient data. It also provides the ability to use a custom store, such as a third party database or API.

# Table of Contents
* [Requirements](#requirements)
* [Getting Started](#getting-started)
    * [OCKCatalog App](#ockcatalog-app)
    * [OCKSample App](#ocksample-app)
* [CareKit](#carekit)
    * [List View Controllers](#list-view-controllers)
    * [Synchronized View Controllers](#synchronized-view-controllers)
    * [Custom Synchronized View Controllers](#custom-synchronized-view-controllers)
* [CareKitUI](#carekitui)
    * [Tasks](#tasks)
    * [Charts](#charts)
    * [Contacts](#contacts)
    * [Styling](#styling)
* [CareKitStore](#carekitstore)
    * [Store](#store)
    * [Schema](#schema)
    * [Scheduling](#scheduling)
    * [Custom Stores and Types](#custom-stores-and-types)
* [Getting Help](#getting-help)
* [License](#license)

# Requirements <a name=""requirements""></a>

The primary CareKit framework codebase supports iOS and requires Xcode 12.0 or newer. The CareKit framework has a Base SDK version of 13.0.

# Getting Started <a name=""getting-started""></a>

* [Website](https://www.researchandcare.org)
* [Documentation](https://carekit-apple.github.io/CareKit/documentation/carekit/)
* [WWDC: ResearchKit and CareKit Reimagined](https://developer.apple.com/videos/play/wwdc2019/217/)

### Option One: Install using Swift Package Manager

You can install CareKit using Swift Package Manager. Create a new Xcode project and navigate to `File > Swift Packages > Add Package Dependency`. Enter the URL `https://github.com/carekit-apple/CareKit` and tap `Next`. Choose the `main` branch, and on the next screen, check off the packages as needed.

To add localized strings to your project, add the strings file to your project: [English Strings](CareKitUI/CareKitUI/Supporting%20Files/Localization/en.lproj)

### Option Two: Install as an embedded framework

Download the project source code and drag in CareKit.xcodeproj, CareKitUI.xcodeproj, and CareKitStore.xcodeproj as needed. Then, embed each framework in your app by adding them to the ""Embedded Binaries"" section for your target as shown in the figure below.

<img width=""1000"" alt=""embedded-framework"" src=""https://user-images.githubusercontent.com/51756298/69107216-7fa7ea00-0a25-11ea-89ef-9b8724728e54.png"">

### OCKCatalog App <a name=""ockcatalog-app""></a>

The included catalog app demonstrates the different modules that are available in CareKit: [OCKCatalog](https://github.com/carekit-apple/CareKitCatalog)

![ockcatalog](https://user-images.githubusercontent.com/51756298/69096972-66de0b00-0a0a-11ea-96f0-4605d04ab396.gif)


### OCKSampleApp <a name=""ocksample-app""></a>

The included sample app demonstrates a fully constructed CareKit app: [OCKSample](https://github.com/carekit-apple/CareKitSample)

![ocksample](https://user-images.githubusercontent.com/51756298/69107801-7586eb00-0a27-11ea-8aa2-eca687602c76.gif)

# CareKit <a name=""carekit""></a>

CareKit is the overarching package that provides view controllers to tie CareKitUI and CareKitStore together. When importing CareKit, CareKitUI and CareKitStore are imported under the hood.

### List view controllers <a name=""list-view-controllers""></a>

CareKit offers full screen view controllers for convenience. The view controllers query for and display data from a store, and stay synchronized with the data.

* `OCKDailyTasksPageViewController`: Displays tasks for each day with a calendar to page through dates.

* `OCKContactsListViewController`: Displays a list of contacts in the store.

### Synchronized View Controllers <a name=""synchronized-view-controllers""></a>

For each card in CareKitUI, there's a corresponding view controller in CareKit. The view controllers are self contained modules that you can place anywhere by using standard view controller containment. The view controller for each card provides synchronization between the view and the store. The following code creates a synchronized view controller.

```swift
// Create a store to hold your data.
let store = OCKStore(named: ""my-store"", type: .onDisk)

// Create a view controller that queries for and displays data. The view will update automatically whenever the data in the store changes.
let viewController = OCKSimpleTaskViewController(taskID: ""doxylamine"", eventQuery: OCKEventQuery(for: Date()), store: store)
```

All synchronized view controllers have a view synchronizer. The view synchronizer defines how to instantiate the view to display, and how to update the view when the data in the store changes. You can customize view synchronizers and inject them into a view controller to perform custom behavior.

```swift
// Define a custom view synchronizer.
class CustomSimpleTaskViewSynchronizer: OCKSimpleTaskViewSynchronizer {

    override func makeView() -> OCKSimpleTaskView {
        let view = super.makeView()
        // Customize the view when it's instantiated here.
        return view
    }

    override func updateView(_ view: OCKSimpleTaskView, context: OCKSynchronizationContext<OCKTaskEvents>) {
        super.updateView(view, context: context)
        // Update the view when the data changes in the store here.
    }
}

// Instantiate the view controller with the custom classes, then fetch and observe data in the store.
var query = OCKEventQuery(for: Date())
query.taskIDs = [""Doxylamine""]

let viewController = OCKSimpleTaskViewController(query: query, store: store, viewSynchronizer: CustomSimpleTaskViewSynchronizer())
```

### Custom Synchronized View Controllers <a name=""custom-synchronized-view-controllers""></a>

CareKit supports creating a custom view that can pair with a synchronized view controller. This allows synchronization between the custom view and the data in the store. 

``` swift
// Define a view synchronizer for the custom view.
class TaskButtonViewSynchronizer: ViewSynchronizing {

    // Instantiate the custom view.
    func makeView() -> UIButton {
        return UIButton(frame: CGRect(x: 0, y: 0, width: 200, height: 60))
    }

    // Update the custom view when the data in the store changes.
    func updateView(
        _ view: UIButton,
        context: OCKSynchronizationContext<OCKAnyEvent?>
    ) {
        let event = context.viewModel
        view.titleLabel?.text = event?.task.title
        view.isSelected = event?.outcome != nil
    }
}

var query = OCKEventQuery(for: Date())
query.taskIDs = [""Doxylamine""]

let events = store
    .anyEvents(matching: query)
    .map { $0.first }

let viewController = SynchronizedViewController(
    initialViewModel: nil,
    viewModels: events,
    viewSynchronizer: TaskButtonViewSynchronizer()
)
```

# CareKitUI <a name=""carekitui""></a>

CareKitUI provides cards to represent tasks, charts, and contacts. There are multiple provided styles for each category of card.

You build all cards in a similar pattern. This makes it easy to recognize and customize the properties of each card. Cards contain a `headerView` at the top that displays labels and icons. The contents of the card are inside a vertical `contentStackView`. This allows for easy placement of custom views into a card without breaking existing constraints.

For creating a card from scratch, see the `OCKCardable` protocol. Conforming to this protocol makes it possible for a custom card to match the styling used across the framework.

### Tasks <a name=""tasks""></a>

Here are the available task card styles:

![Task](https://user-images.githubusercontent.com/51756298/69107434-32784800-0a26-11ea-8075-0a8b8b57afd2.png)

This example instantiates and customizes the instructions task card:

```swift
let taskView = OCKInstructionsTaskView()

taskView.headerView.titleLabel.text = ""Doxylamine""
taskView.headerView.detailLabel.text = ""7:30 AM to 8:30 AM""

taskView.instructionsLabel.text = ""Take the tablet with a full glass of water.""

taskView.completionButton.isSelected = false
taskView.completionButton.label.text = ""Mark as Completed""
```

### Charts <a name=""charts""></a>

Here are the available chart card styles:

![Chart](https://user-images.githubusercontent.com/51756298/69107429-32784800-0a26-11ea-897d-0e3885c31e73.png)

This example instantiates and customizes the bar chart:

```swift
let chartView = OCKCartesianChartView(type: .bar)

chartView.headerView.titleLabel.text = ""Doxylamine""

chartView.graphView.dataSeries = [
    OCKDataSeries(values: [0, 1, 1, 2, 3, 3, 2], title: ""Doxylamine"")
]
```

### Contacts <a name=""contacts""></a>

Here are the available contact card styles:

![Contact](https://user-images.githubusercontent.com/51756298/69107430-32784800-0a26-11ea-98d2-9dcd06c0ab27.png)

This example instantiates and customizes the simple contact card:

```swift
let contactView = OCKSimpleContactView()

contactView.headerView.titleLabel.text = ""Lexi Torres""
contactView.headerView.detailLabel.text = ""Family Practice""
```

### Styling <a name=""styling""></a>

To provide custom styling or branding across the framework, see the `OCKStylable` protocol. All stylable views derive their appearance from a list of injected constants. You can customize this list of constants for quick and easy styling.

Here's an example that customizes the separator color in a view, and all of it's descendents:

```swift
// Define your custom separator color.
struct CustomColors: OCKColorStyler {
    var separator: UIColor { .black }
}

// Define a custom struct to hold your custom color.
struct CustomStyle: OCKStyler {
    var color: OCKColorStyler { CustomColors() }
}

// Apply the custom style to your view.
let view = OCKSimpleTaskView()
view.customStyle = CustomStyle()
````

Note that each view in CareKitUI is styled with `OCKStyle` by default. Setting a custom style on a view propagates the custom style down to any subviews that don't already have a custom style set. You can visualize the style propagation rules in this diagram demonstrating three separate view hierarchies:

![Styling](https://user-images.githubusercontent.com/51756298/69107433-32784800-0a26-11ea-9622-74bb30ce4abd.png)

For information on styling SwiftUI views with `OCKStylable`, see [SwiftUI in CareKitUI](#carekitui-swiftui).

# CareKitStore <a name=""carekitstore""></a>

The CareKitStore package defines the `OCKStoreProtocol` that CareKit uses to communicate to data stores, and a concrete implementation that leverages CoreData, called `OCKStore`.
It also contains definitions of most of the core structures and data types that CareKit relies on, such as `OCKAnyTask`, `OCKTaskQuery`, and `OCKSchedule`.

### Store <a name=""store""></a>

The `OCKStore` class is an append-only, versioned store packaged with CareKit. It's implemented on top of CoreData and provides fast, secure, on-device storage. `OCKStore` is designed to integrate with CareKit's synchronized view controllers, but is usable in isolation as well.

```swift
import CareKitStore

let store = OCKStore(named: ""my-store"", type: .onDisk)
let breakfastSchedule = OCKSchedule.dailyAtTime(hour: 8, minutes: 0, start: Date(), end: nil, text: ""Breakfast"")
let task = OCKTask(id: ""doxylamine"", title: ""Doxylamine"", carePlanID: nil, schedule: breakfastSchedule)

let storedTask = try await store.addTask(task)
```

The most important feature of `OCKStore` is that it's a versioned store with a notion of time. When querying the store using a date range, the result returned is for the state of the store during the interval specified. If no date interval is provided, the query returns all versions of the entity.

```swift
// On January 1st
let task = OCKTask(id: ""doxylamine"", title: ""Take 1 tablet of Doxylamine"", carePlanID: nil, schedule: breakfastSchedule)
let addedTask = try await store.addTask(task)

// On January 10th
let task = OCKTask(id: ""doxylamine"", title: ""Take 2 tablets of Doxylamine"", carePlanID: nil, schedule: breakfastSchedule)
let updatedTask = try await store.updateTask(task)

// On some future date.
let earlyQuery = OCKTaskQuery(dateInterval: /* Jan 1st - 5th */)
let earlyTasks = try await store.fetchTasks(query: earlyQuery)

let laterQuery = OCKTaskQuery(dateInterval: /* Jan 12th - 17th */)
let laterTasks = try await store.fetchTasks(query: laterQuery)

// Queries return the newest version of the task during the query interval.
let midQuery = OCKTaskQuery(dateInterval: /* Jan 5th - 15th */)
let midTasks = try await store.fetchTasks(query: laterQuery)

// Queries with no date interval return all versions of the task.
let allQuery = OCKTaskQuery()
let allTasks = try await store.fetchTasks(query: allQuery)
```

This graphic visualizes how to retrieve results when querying versioned objects in CareKit. Note how a query over a date range returns the version of the object that's valid in that date range.  
![3d608700-5193-11ea-8ec0-452688468c72](https://user-images.githubusercontent.com/51723116/74690609-8c5aec00-5194-11ea-919a-53196eeefb9f.png)

### Schema <a name=""schema""></a>

CareKitStore defines six high level entities in this diagram:

![Schema](https://user-images.githubusercontent.com/51756298/69107431-32784800-0a26-11ea-83fc-8987d7ef2e15.png)

* **Patient:** A patient represents the user of the app.

* **Care Plan**: A patient has zero or more care plans. A care plan organizes the contacts and tasks associated with a specific treatment. For example, a patient may have one care plan for heart disease and a second for obesity.

* **Contact:** A care plan has zero or more associated contacts. Contacts might include doctors, nurses, insurance providers, or family.

* **Task:** A care plan has zero or more tasks. A task represents some activity that the patient performs. Examples include taking a medication, exercising, journaling, or checking in with their doctor.

* **Schedule:** Each task must have a schedule. The schedule defines occurrences of a task, and may optionally specify target or goal values, such as how much of a medication to take.

* **Outcome:** Each occurrence of a task may have an associated outcome. The absence of an outcome indicates no progress was made on that occurrence of the task.

* **Outcome Value:** Each outcome has zero or more values associated with it. A value might represent how much medication was taken, or a plurality of outcome values could represent the answers to a survey.

It's important to note that tasks, contacts, and care plans can exist *without* a parent entity. Many CareKit apps target well defined use cases, and it can often be expedient to simply create tasks and contacts without defining a patient or care plan.

### Scheduling <a name=""scheduling""></a>

The scheduling tools provided in CareKit allow very precise and customizable scheduling of tasks. You create an instance of `OCKSchedule` by composing one or more
`OCKScheduleElements`. Each element defines a single repeating interval.

Static convenience methods exist to help with common use cases.

```swift
let breakfastSchedule = OCKSchedule.dailyAtTime(hour: 8, minutes: 0, start: Date(), end: nil, text: ""Breakfast"")
let everySaturdayAtNoon = OCKSchedule.weeklyAtTime(weekday: 7, hours: 12, minutes: 0, start: Date(), end: nil)
```

You can create highly precise, complicated schedules by combining schedule elements or other schedules.

```swift
// Combine elements to create a complex schedule.
let elementA = OCKScheduleElement(start: today, end: nextWeek, interval: DateComponents(hour: 36))
let elementB = OCKScheduleElement(start: lastWeek, end: nil, interval: DateComponents(day: 2))
let complexSchedule = OCKSchedule(composing: [elementA, elementB])

// Combine two schedules into a composed schedule.
let dailySchedule = OCKSchedule.dailyAtTime(hour: 8, minutes: 0, start: tomorrow, end: nextYear, text: nil)
let crazySchedule = OCKSchedule(composing: [dailySchedule, complexSchedule])
```

Schedules have a number of other useful properties that you can set, including target values, durations, and textual descriptions.

```swift
let element = OCKScheduleElement(
    start: today,  // The date and time this schedule begins.
    end: nextYear, // The date and time this schedule ends.
    interval: DateComponents(day: 3), // Occurs every 3 days.
    text: ""Before bed"", // Show ""Before bed"" instead of clock time.
    targetValues: [OCKOutcomeValue(10, units: ""mL"")], // Specifies what counts as ""complete"".
    duration: Duration = .hours(2) // The window of time to complete the task.
)
```

* `text`: By default, CareKit view controllers prompt users to perform tasks using clock time, such as ""8:00PM"". If you provide a `text` property, then CarKit uses the text to prompt the user instead, such as ""Before bed"" in the code above.

* `duration`: If you provide a duration, CareKit prompts the user to perform the scheduled task within a window, such as ""8:00 - 10:00 PM"". You can also set the duration to `.allDay` if you don't wish to specify any time in particular.

* `targetValues`: CareKit uses target values to determine if a user completed a specific task. See `OCKAdherenceAggregator` for more information.


### Custom Stores and Types <a name=""custom-store-and-types""></a>

The `OCKStore` class that CareKit provides is a fast, secure, on-device store that serves most use cases. It may not fully meet the needs of all developers, so CareKit also allows you to write your own store. For example, you could write a wrapper around a web server, or even a simple JSON file. You can use any class that conforms to the `OCKStoreProtocol` in place of the default store.

Writing a CareKit store adapter requires defining the entities that live in your store, and implementing asynchronous **Create**, **Read**, **Update**, and **Delete** methods for each. Stores are free to define their own types, as long as those types conform to a certain protocol. For example, if you're writing a store that can hold tasks, you might do it like this.

```swift
import CareKitStore

struct MyTask: OCKAnyTask & Equatable & Identifiable {

    // MARK: OCKAnyTask
    let id: String
    let title: String
    let schedule: String
    /* ... */

    // MARK: Custom Properties
    let difficulty: DifficultyRating
    /* ... */
}

struct MyTaskQuery: OCKAnyTaskQuery {

    // MARK: OCKAnyTaskQuery
    let ids: [String]
    let carePlanIDs: [String]
    /* ... */

    // MARK: Custom Properties
    let difficult: DifficultyRating?
}

class MyStore: OCKStoreProtocol {

    typealias Task = MyTask
    typealias TaskQuery = MyTaskQuery
    /* ... */

    // MARK: Task CRUD Methods
    func fetchTasks(query: TaskQuery, callbackQueue: DispatchQueue, completion: @escaping OCKResultClosure<[Task]>) { /* ... */ }
    func addTasks(_ tasks: [Task], callbackQueue: DispatchQueue, completion: OCKResultClosure<[Task]>?) { /* ... */ }
    func updateTasks(_ tasks: [Task], callbackQueue: DispatchQueue, completion: OCKResultClosure<[Task]>?) { /* ... */ }
    func deleteTasks(_ tasks: [Task], callbackQueue: DispatchQueue, completion: OCKResultClosure<[Task]>?) { /* ... */ }

    /* ... */
}
```

Using the four basic CRUD methods you supply, CareKit is able to use protocol extensions to imbue your store with extra functionality. For example, a store that implements the four CRUD methods for tasks automatically receives the following methods.

```swift
func fetchTask(withID id: String, callbackQueue: DispatchQueue, completion: @escaping OCKResultClosure<Task>)
func addTask(_ task: Task, callbackQueue: DispatchQueue, completion: OCKResultClosure<Task>?)
func updateTask(_ task: Task, callbackQueue: DispatchQueue, completion: OCKResultClosure<Task>?)
func deleteTask(_ task: Task, callbackQueue: DispatchQueue, completion: OCKResultClosure<Task>?)
```

The provided methods employ naive implementations. You're free to provide your own implementations that leverage the capabilities of your underlying data store to achieve greater performance or efficiency.

If you're considering implementing your own store, read over the protocol notes and documentation carefully.

# Getting Help <a name=""getting-help""></a>

GitHub is our primary forum for CareKit. Feel free to open up issues about questions, problems, or ideas.

# License <a name=""license""></a>

This project is made available under the terms of a BSD license. See the [LICENSE](LICENSE) file.
",2327,2327,143,85,health,"[carekit, combine, core-data, darkmode-ios13, health, swift-package-manager, swift5, uiframework]",62
kakoni,awesome-healthcare,,https://github.com/kakoni/awesome-healthcare,https://api.github.com/repos/awesome-healthcare/kakoni,"Curated list of awesome open source healthcare software, libraries, tools and resources.","# Awesome Health [![Awesome](https://cdn.jsdelivr.net/gh/sindresorhus/awesome@d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

Curated list of awesome open source healthcare software, libraries, tools and resources. Each link has been vetted to ensure the project is active and provides value to healthcare facilities, providers, developers, policy experts, and/or research scientists.

## Contents

- [EHR](#ehr)
- [Specifications](#specifications)
- [Prescribing](#prescribing)
- [Nursing](#nursing)
- [Imaging](#imaging)
- [Dental](#dental)
- [Laboratory](#laboratory)
- [Libraries](#libraries)
- [Frameworks](#frameworks)
- [Applications](#applications)
- [Personal Health Record](#phr)
- [Integration](#integration)
- [Research](#research)
- [Hardware](#hardware)
- [Bioinformatics](#bioinformatics)
- [Books](#books)
- [Data](#data)
- [Datasets](#datasets)
- [Design](#design)
- [Enterprise Master Patient Index](#empi)
- [Machine Learning](#machine-learning)
- [Compliance](#compliance)
- [Asset Management](#asset-management)
- [Logistics](#logistics)
- [Analytics](#analytics)

### EHR
  * [Bahmni](https://www.bahmni.org) - Electronic Medical Record and hospital system.
  * [Cottage Med](https://cottagemed.org/p/26/Download-Cottage-Med) - Electronic Medical Record software designed by physicians.
  * [GNU Health](https://www.gnuhealth.org) - Electronic Medical Record, Hospital Management, and Health Information System.
  * [GNUmed](https://www.gnumed.de/documentation/) - Electronic Medical Record software.
  * [EHRBase](https://ehrbase.org) OpenEHR Clinical Data Repository.
  * [EHRServer](https://github.com/ppazos/cabolabs-ehrserver) - CaboLabs EHRServer.
  * [ERPNext](https://github.com/frappe/erpnext) - Modules that help manage patients, appointments, consultations, lab tests, and billing.
  * [FreeMedForms EMR](https://freemedforms.com/fr/start) - Electronic Medical Record software.
  * [HospitalRun](https://hospitalrun.io) - Helps provide the most modern Hospital Information System possible to the least resourced environments.
  * [HOSxP](https://hosxp.net/wordpress/) - Thai Hospital Information System that aims to ease the healthcare workflow of health centers and central hospitals.
  * [LibreHealth EHR](https://librehealth.io/projects/lh-ehr/) - Clinically-focused Electronic Health Record System.
  * [MedinTux](https://medintux.org/) - French Medical Practice Management System.
  * [Medplum](https://github.com/medplum/medplum) - Developer platform that enables flexible and rapid development of healthcare apps.
  * [Odoo Medical](https://github.com/OCA/vertical-medical) - Universal Health and Hospital Information System.
  * [OpenClinic](https://github.com/jact/openclinic) - Medical Records System.
  * [OpenEMR](https://www.open-emr.org) - Electronic Health Records and Medical Practice Management application.
  * [OpenEyes](https://openeyes.apperta.org) - Electronic Medical Record application for ophthalmology.
  * [Open Hospital](https://sourceforge.net/projects/openhospital/) - Electronic Medical Record software for underprivileged rural hospitals.
  * [openMAXIMS](https://github.com/IMS-MAXIMS/openMAXIMS) - Full Patient Administration System designed for the NHS.
  * [OpenMRS](https://openmrs.org) - Enterprise Electronic Medical Record System platform.
  * [OSCAR EMR](https://bitbucket.org/oscaremr/oscar) - OSCAR McMaster Project.
  * [Ozone HIS](https://www.ozone-his.com) - The entreprise-grade integrated health information system built with OpenMRS 3
  * [Ripple](https://www.ripple.foundation) -  NHS-funded, community led initiative working towards an integrated Digital Care Record Platform.

### Specifications
  * [Continuity of Care Document](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=7) - Continuity of Care Document specifications
  * [Continuity of Care Record](https://hitsp.org/ConstructSet_Details.aspx?&PrefixAlpha=4&PrefixNumeric=32) - Specifications for the older form of CCD - sometimes called a ""C32"".
  * [DICOM Standards Browser](https://dicom.innolitics.com/ciods) - Provides an effective way to learn the DICOM standard and inspect DICOM attributes.
  * [FHIR](https://www.hl7.org/fhir/) - Fast Health Interoperability Resources.
  * [HL7 Version 2](https://www.hl7.org/implement/standards/product_brief.cfm?product_id=185) - Specifications for all versions of HL7v2
  * [OHDSI OMOP Common Data Model](https://www.ohdsi.org/data-standardization/) - Standardized data model for many healthcare concepts, awesome Github presence including scripts for many major relational databases.
  * [OpenEHR](https://www.openehr.org) - Open specification upon which software can be built.
  * [Open mHealth](https://www.openmhealth.org) - Open Standard For Mobile Health Data.
  * [SMART on FHIR](https://docs.smarthealthit.org/) - Open standards based technology platform.
  
### Prescribing
  * [OpenEP](https://github.com/ehrscape/examples/tree/master/openep) - Suite of medicines management apps that improve the safety and efficiency of prescribing and medicines management.

### Nursing
  * [open-eObs](https://openeobs.github.io/) - Observation and clinical assessment platform that offers a real-time view of all patients across a ward.

### Imaging
  * [3D Slicer](https://www.slicer.org) - Cross-platform application for analyzing, visualizing and understanding medical image data.
  * [Cornerstone](https://github.com/cornerstonejs/cornerstone) - Open source project with a goal to deliver a complete web based medical imaging platform.
  * [dcm4che](https://www.dcm4che.org/) - Clinical Image and Object Management.
  * [Dicoogle](https://github.com/bioinformatics-ua/dicoogle) - Dicoogle is an extensible, platform-independent and open-source PACS
  * [Drishti](https://github.com/nci/drishti/wiki) - Tomography and electron-microscopy data visualizer for both scientists and lay people.
  * [DICOMcloud](https://github.com/DICOMcloud/DICOMcloud) - A standalone DICOMweb server with RESTful implementation of the DICOMweb/WADO services.
  * [DICOM Server](https://github.com/microsoft/dicom-server) - OSS Implementation of DICOMweb standard.
  * [DICOM Web Viewer](https://ivmartel.github.io/dwv/) - JavaScript/HTML5-based DICOM viewer with standard tools and a focus on supporting various screen sizes.
  * [Fiji](https://imagej.net/software/fiji/) - Open-source platform for biological-image analysis.
  * [Horos](https://horosproject.org) - Medical image viewer.
  * [InVesalius](https://invesalius.github.io) - Open source software for reconstruction of computed tomography and magnetic ressonance images.
  * [ITK](https://itk.org/) - Toolkit used for the development of image segmentation and image registration programs with leading-edge algorithms in 2 and 3 dimensions.
  * [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php) - Interactive software for 3 dimensional image navigation, annotation, and automatic segmentation with an emphasis on user-friendliness.
  * [LibreHealth Radiology](https://librehealth.io/projects/lh-radiology/) - Customized version of LibreHealth Toolkit with additional tools for radiology and imaging professionals.
  * [Kaapana](https://github.com/kaapana/kaapana) - Open source toolkit for state of the art platform provisioning in the field of medical data analysis.
  * [Kheops](https://kheops.online) - Open source platform for sharing medical images
  * [OHIF](https://github.com/OHIF/Viewers) - OHIF zero-footprint DICOM viewer and oncology specific Lesion Tracker.
  * [Omero](https://github.com/ome/openmicroscopy) - open source client/server system written in Java for visualizing, managing, and annotating microscope images and metadata
  * [OpenREM](https://openrem.org/) - Radiation Exposure Monitoring for physicists.
  * [OpenSlide](https://github.com/openslide/openslide) - is a C library for reading whole slide image files.
  * [Orthanc](https://www.orthanc-server.com) - Lightweight DICOM server for healthcare and medical research.
  * [Papaya](https://github.com/rii-mango/Papaya) - Pure JavaScript medical research image viewer.
  * [Slim](https://github.com/ImagingDataCommons/slim) - Interoperable web viewer and annotation tool for computational pathology.
  * [Viv](https://github.com/hms-dbmi/viv) - multiscale visualization of high-resolution multiplexed bioimaging data on the web.
  * [VTK](https://vtk.org) - 3 dimensional visualization toolkit supporting a variety of algorithms and modeling techniques.

### Dental
  * [Open Dental](https://www.opendental.com) - Dental Practice Management Software.
  * [OpenMolar](https://openmolar.com/) - Dental Practice Management Software. 

### Laboratory
  * [OpenELIS](https://openelis-global.org) - Laboratory Information System for Global Health.
  * [SENAITE](https://www.senaite.com) - Laboratory Information Management System.

### Frameworks
  * [API Server](https://github.com/smart-on-fhir/api-server) - FHIR Server to support patient- and clinician-facing apps.
  * [Blaze](https://github.com/samply/blaze) - A FHIR Store with internal, fast CQL Evaluation Engine
  * [CareKit](https://github.com/carekit-apple/CareKit/) - Open source software framework for creating apps that help people better understand and manage their health.
  * [Clinical Meteor project](https://github.com/clinical-meteor) - Meteor for FDA, HIPAA, and HL7 compliant applications.
  * [Clinical Quality Language](https://github.com/cqframework/clinical_quality_language) - Clinical Quality Language is a HL7 standard for the expression of clinical knowledge.
  * [CyclOps](https://github.com/VectorInstitute/cyclops) - Framework for healthcare ML implementation.
  * [FHIRBase](https://fhirbase.github.io) - Storage based on the FHIR Standard.
  * [FHIR Proxy](https://github.com/microsoft/fhir-proxy) - secure application that acts as an intermediary in the transfer of FHIR data to and from Azure API.
  * [FHIR Works on AWS](https://github.com/awslabs/fhir-works-on-aws-deployment) - FHIR Works on AWS deployment.
  * [FHIR Server for Azure](https://github.com/Microsoft/fhir-server) - A .NET Core implementation of the FHIR standard.
  * [Intervention Engine FHIR Server](https://github.com/intervention-engine/fhir) - Generic FHIR server implementation in GoLang.
  * [LinuxForHealth FHIR Server](https://github.com/LinuxForHealth/FHIR) - Modular Java implementation of version 4 of the HL7 FHIR specification.
  * [Medblocks UI](https://github.com/medblocks/medblocks-ui) - Web Components for rapid development of openEHR and FHIR systems.
  * [Opal](https://opal.openhealthcare.org.uk/) - Framework for building clinical applications.
  * [ResearchKit](https://github.com/ResearchKit/ResearchKit) - Software framework that makes it easy to create apps for medical research or for other research projects.
  * [Spark](https://github.com/FirelyTeam/spark) - Public domain FHIR server developed in C#.
  * [Sushi](https://github.com/FHIR/sushi) - a reference implementation command-line interpreter/compiler for FHIR
  * [Swift-SMART](https://github.com/smart-on-fhir/Swift-SMART) - Swift SMART on FHIR framework for iOS and OS X.

### Libraries
  * [Android FHIR SDK](https://github.com/google/android-fhir) - The Android FHIR SDK 
  * [Archie](https://github.com/openehr/archie) - OpenEHR Library written in Java.
  * [Asymmetrik FHIR API Server](https://github.com/bluehalo/node-fhir-server-core) - A secure REST implementation for the HL7 FHIR Specification.
  * [Datamol](https://github.com/datamol-io/datamol) - Molecular Manipulation Made Easy. A light Python wrapper build on top of RDKit.
  * [DCMTK](https://dicom.offis.de/dcmtk.php.en) - DICOM Toolkit.
  * [dicom](https://github.com/suyashkumar/dicom) - High Performance DICOM Medical Image Parser in GoLang.
  * [ehrapy](https://github.com/theislab/ehrapy/) - Electronic Health Record analysis in Python.
  * [Evil-DICOM](https://github.com/rexcardan/Evil-DICOM) - C# DICOM Library.
  * [Fellow Oak DICOM](https://github.com/fo-dicom/fo-dicom) - DICOM for .NET, .NET Core, Universal Windows, Android, iOS, Mono, and Unity.
  * [FHIRKit Client](https://github.com/Vermonster/fhir-kit-client) - Node FHIR client library.
  * [FHIRModels](https://github.com/apple/FHIRModels) - FHIRModels is a Swift library for FHIR resource data models.
  * [FHIR .NET API](https://github.com/FirelyTeam/firely-net-sdk) - The official .NET API for HL7 FHIR.
  * [fhir.js](https://github.com/FHIR/fhir.js) - JavaScript client for FHIR.
  * [FHIR protocol buffers](https://github.com/google/fhir) - A Google implementation of protocol buffers for FHIR.
  * [Graphir](https://github.com/microsoft/graphir) - GraphQL interface over FHIR API
  * [HAPI FHIR](https://github.com/hapifhir/hapi-fhir) - Java API for HL7 FHIR Clients and Servers.
  * [Hearth](https://github.com/jembi/hearth) - A fast FHIR-compliant server focused on longitudinal data stores.
  * [Health data standards](https://github.com/projectcypress/health-data-standards) - Ruby library for generating and consuming various healthcare related formats. These include HITSP C32, QRDA Category I, and QRDA Category III.
  * [Hermes](https://github.com/wardle/hermes) - a SNOMED CT terminology server. 
  * [MITK](https://www.mitk.org/wiki/The_Medical_Imaging_Interaction_Toolkit_(MITK)) - The Medical Imaging Interaction Toolkit.
  * [Node HL7](https://github.com/MatthewVita/node-hl7-complete) - Node module that is bridged with the Java Hapi HL7 library.
  * [Node-hl7-parser](https://github.com/RedoxEngine/redox-hl7-v2) - Open source version of Redox's HL7 v2 to schema-fied JSON parser.
  * [php-fhir](https://github.com/dcarbone/php-fhir) - Tools for creating PHP classes from the HL7 FHIR Specification.
  * [pynetdicom](https://github.com/pydicom/pynetdicom) - A Python implementation of the DICOM networking protocol.
  * [Python HL7](https://github.com/johnpaulett/python-hl7) - Simple library for parsing messages of HL7 version 2.x into Python objects.
  * [Python SMART on FHIR client](https://github.com/smart-on-fhir/client-py) - Flexible Python client for FHIR servers supporting the SMART on FHIR protocol.
  * [Python 835 Parser](https://github.com/keironstoddart/edi-835-parser) - A simple-to-use Python interface to EDI 835 Health Care Claim Payment and Remittance Advice files.
  * [Ruby FHIR](https://github.com/fhir-crucible/fhir_client) - FHIR client implementation in Ruby.
  * [Ruby HL7](https://github.com/segfault/ruby-hl7) - Ruby HL7 library.
  * [Rust FHIR](https://github.com/itsbalamurali/rust-fhir) - Rust SDK for HL7 FHIR
  * [TorchXRayVision](https://github.com/mlmed/torchxrayvision) - A library for chest X-ray datasets and models. Including pre-trained models.

### Applications
  * [Intervention Engine](https://github.com/intervention-engine/ie) - Provides a web-application for data-driven team huddles.
  * [SMART Pediatric Growth Chart](https://github.com/smart-on-fhir/growth-chart-app) - Pediatric growth charts.
  * [Simple](https://github.com/simpledotorg/) - For clinicians to track patients with high blood pressure.

### PHR
  * [Tidepool](https://github.com/tidepool-org) - Data platform to reduce the burden of Type 1 Diabetes.
  * [HealthLocker](https://github.com/healthlocker/healthlocker) - Elixir-based personal health record.

### Research
  * [i2b2](https://www.i2b2.org) - Research data warehouse.
  * [LabKey Server](https://www.labkey.org) - Platform for Translational Research.

### Integration
  * [FHIR Converter](https://github.com/microsoft/FHIR-Converter) - an open source project that enables conversion of health data from legacy formats to FHIR.
  * [Google HCLS Data Harmonization](https://github.com/GoogleCloudPlatform/healthcare-data-harmonization) - an engine that converts data of one structure to another
  * [NextGen Connect Integration Engine](https://github.com/nextgenhealthcare/connect) - The swiss army knife of healthcare integration.
  * [Open eHealth Integration Platform](https://github.com/oehf/ipf) - An extension of the Apache Camel routing and mediation engine
  * [OpenHIM](http://openhim.org/) - Health information mediator.
  * [Zato](https://zato.io/en/industry/healthcare/index.html) - A Python-based ESB and integration platform for healthcare interoperability, automation and orchestration.

### Hardware
  * [echOpen](https://www.echopen.org) - Low-cost (affordable) echo-stethoscope.
  * [Gluco](https://github.com/nebulabio/gluco) - Glucometer.
  * [Murgen](https://hackaday.io/project/9281-murgen-open-source-ultrasound-imaging) - Ultrasound imaging development kit.
  * [OpenAPS](https://openaps.org/) - The Open Artificial Pancreas System project is an open and transparent effort to make safe and effective basic Artificial Pancreas System.

### Bioinformatics
  * [ADAM](https://github.com/bigdatagenomics/adam) - Genomics analysis platform.
  * [Bcbio](https://github.com/bcbio/bcbio-nextgen) - Validated, scalable, community developed variant calling, RNA-seq and small RNA analysis.
  * [Galaxy](https://galaxyproject.org/) - Open web-based platform for data intensive biomedical research.
  * [Wregex](https://ehubio.ehu.eus/wregex/) - Amino acid motif searching software with optional Position-Specific Scoring Matrix.

### Books
  * [Inspired EHRs](https://github.com/goinvo/EHR) - Ideas, designs, and techniques for designing an Electronic Health Record (EHR).

### Data
  * [Atlas BI Library](https://github.com/atlas-bi/Library) The unified report library.
  * [Caisis](http://www.caisis.org/) - Oncology research software with a Patient Data Management System.
  * [Cedar](https://github.com/mitre/cedar) - Open source tool for testing the strength of Electronic Clinical Quality Measure.
  * [cTAKES](https://ctakes.apache.org/) - Natural Language Processing System for extraction of information from Electronic Medical Record clinical free-text.
  * [EDS_NLP](https://github.com/aphp/edsnlp) - provides a set of spaCy components to extract information from clinical notes written in French
  * [eds-scikit](https://github.com/aphp/eds-scikit) - a tool to assist data scientists working on the AP-HP's Clinical Data Warehouse. It is specifically targeted for OMOP-standardized data. 
  * [IHRIS](https://www.ihris.org/toolkit-new/) - Health Information System for management of human resources for health.
  * [Inferno](https://github.com/onc-healthit/inferno) - Open source tool that tests whether patients can access their health data through a standard interface.
  * [OpenSAFELY](https://www.opensafely.org) - Secure analytics platform for Electronic Health Records in the NHS.
  * [Snow Owl](https://github.com/b2ihealthcare/snow-owl) - Highly scalable, open source terminology server with revision-control capabilities and collaborative authoring platform features. 
  * [Synthea Patient Generator](https://github.com/synthetichealth/synthea) - Synthetic patient generator that models the medical history of synthetic patients.

### Datasets
  * [Medical Data for Machine Learning](https://github.com/beamandrew/medical-data) - Curated list of medical data for machine learning.

### Design
  * [Determinants of Health](https://github.com/goinvo/HealthDeterminants) - Determinants of Health Visualization.
  * [Health Icons](https://github.com/resolvetosavelives/healthicons) - A collection of open source icons for public health projects.

### EMPI
  * [MEDIC Client Registry RI](https://github.com/MohawkMEDIC/client-registry) - The Mohawk College MARC-HI/MEDIC Client Registry EMPI Implementation.
  
### Machine learning
  * [Healthcare.ai](https://healthcare.ai) - Python and R tools for healthcare machine learning.
  * [MedicalGPT](https://github.com/shibing624/MedicalGPT/blob/main/README_EN.md) - Training Your Own Medical GPT Model with ChatGPT Training Pipeline.
  * [MONAI](https://github.com/Project-MONAI/MONAI) - AI Toolkit for Healthcare Imaging.
  * [PyHealth](https://github.com/sunlabuiuc/PyHealth) - A Deep Learning Python Toolkit for Healthcare Application.

### Asset Management
  * [Tapirx](https://github.com/virtalabs/tapirx) - Networked medical device discovery and identification.

### Logistics
  * [ID3C](https://github.com/seattleflu/id3c) - Data logistics system enabling real-time genomic epidemiology.
  * [OpenBoxes](https://github.com/openboxes/openboxes) - an Open Source Inventory and Supply Chain Management System.
  * [OpenLMIS](https://openlmis.org) - Open source, web-based, electronic logistics management information system (LMIS) software, purpose-built to manage health commodity supply chains.
",2285,2285,147,2,health,"[awesome, awesome-list, health, list]",62
kuberhealthy,kuberhealthy,kuberhealthy,https://github.com/kuberhealthy/kuberhealthy,https://api.github.com/repos/kuberhealthy/kuberhealthy,A Kubernetes operator for running synthetic checks as pods. Works great with Prometheus!,"
<center><img src=""https://github.com/kuberhealthy/kuberhealthy/blob/master/images/kuberhealthy.png?raw=true""></center><br />

**Kuberhealthy is a [Kubernetes](https://kubernetes.io) [operator](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/) for [synthetic monitoring](https://en.wikipedia.org/wiki/Synthetic_monitoring) and [continuous process verification](https://en.wikipedia.org/wiki/Continued_process_verification).**  [Write your own tests](docs/CHECK_CREATION.md) in any language and Kuberhealthy will run them for you.  Automatically creates metrics for [Prometheus](https://prometheus.io).  Includes simple JSON status page.  **Now part of the CNCF!**

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Go Report Card](https://goreportcard.com/badge/github.com/kuberhealthy/kuberhealthy)](https://goreportcard.com/report/github.com/kuberhealthy/kuberhealthy)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2822/badge)](https://bestpractices.coreinfrastructure.org/projects/2822)
[![Twitter Follow](https://img.shields.io/twitter/follow/kuberhealthy.svg?style=social)](https://twitter.com/kuberhealthy)  
[![Join Slack](https://img.shields.io/badge/slack-kubernetes/kuberhealthy-teal.svg?logo=slack)](https://kubernetes.slack.com/messages/CB9G7HWTE)

## What is Kuberhealthy?

Kuberhealthy lets you continuously verify that your applications and Kubernetes clusters are working as expected. By creating a custom resource (a [`KuberhealthyCheck`](hhttps://github.com/kuberhealthy/kuberhealthy/blob/master/docs/CHECKS.md#khcheck-anatomy)) in your cluster, you can easily enable [various synthetic tests](docs/CHECKS_REGISTRY.md) and get Prometheus metrics for them.

Kuberhealthy comes with [lots of useful checks already available](docs/CHECKS_REGISTRY.md) to ensure the core functionality of Kubernetes, but checks can be used to test anything you like.  We encourage you to [write your own check container](docs/CHECK_CREATION.md) in any language to test your own applications.  It really is quick and easy!

Kuberhealthy serves the status of all checks on a simple JSON status page, a [Prometheus](https://prometheus.io/) metrics endpoint (at `/metrics`), and supports InfluxDB metric forwarding for integration into your choice of alerting solution.



## Installation


### Deployment

Kuberhealthy requires Kubernetes 1.16 or above.  

#### Using Plain Ole' YAML

If you just want the rendered default specs without Helm, you can [use the static flat file](https://github.com/kuberhealthy/kuberhealthy/blob/master/deploy/kuberhealthy.yaml) or the [static flat file for Prometheus](https://github.com/kuberhealthy/kuberhealthy/blob/master/deploy/kuberhealthy-prometheus.yaml) or even the [static flat file for Prometheus Operator](https://github.com/kuberhealthy/kuberhealthy/blob/master/deploy/kuberhealthy-prometheus-operator.yaml).

Here are the one-line installation commands for those same specs:
```sh
# If you don't use Prometheus:
kubectl create namespace kuberhealthy
kubectl apply -f https://raw.githubusercontent.com/kuberhealthy/kuberhealthy/master/deploy/kuberhealthy.yaml

# If you use Prometheus, but not with Prometheus Operator:
kubectl create namespace kuberhealthy
kubectl apply -f https://raw.githubusercontent.com/kuberhealthy/kuberhealthy/master/deploy/kuberhealthy-prometheus.yaml

# If you use Prometheus Operator:
kubectl create namespace kuberhealthy
kubectl apply -f https://raw.githubusercontent.com/kuberhealthy/kuberhealthy/master/deploy/kuberhealthy-prometheus-operator.yaml
```

#### Using Helm

```sh
kubectl create namespace kuberhealthy
helm repo add kuberhealthy https://kuberhealthy.github.io/kuberhealthy/helm-repos
helm install -n kuberhealthy kuberhealthy kuberhealthy/kuberhealthy
```

If you have Prometheus

```
helm install --set prometheus.enabled=true -n kuberhealthy kuberhealthy kuberhealthy/kuberhealthy
```

If you have Prometheus via Prometheus Operator:

```
helm install --set prometheus.enabled=true --set prometheus.serviceMonitor.enabled=true -n kuberhealthy kuberhealthy kuberhealthy/kuberhealthy
```

#### Configure Service

After installation, Kuberhealthy will only be available from within the cluster (`Type: ClusterIP`) at the service URL `kuberhealthy.kuberhealthy`.  To expose Kuberhealthy to clients outside of the cluster, you **must** edit the service `kuberhealthy` and set `Type: LoadBalancer` or otherwise expose the service yourself.


#### Edit Configuration Settings

You can edit the Kuberhealthy configmap as well and it will be automatically reloaded by Kuberhealthy.  All configmap options are set to their defaults to make configuration easy.

`kubectl edit -n kuberhealthy configmap kuberhealthy`

#### See Configured Checks

You can see checks that are configured with `kubectl -n kuberhealthy get khcheck`.  Check status can be accessed by the JSON status page endpoint, or via `kubectl -n kuberhealthy get khstate`.


### Further Configuration


To configure Kuberhealthy after installation, see the [configuration documentation](https://github.com/kuberhealthy/kuberhealthy/blob/master/docs/CONFIGURATION.md).

Details on using the helm chart are [documented here](https://github.com/kuberhealthy/kuberhealthy/tree/master/deploy/helm/kuberhealthy).  The Helm installation of Kuberhealthy is automatically updated to use the latest [Kuberhealthy release](https://github.com/kuberhealthy/kuberhealthy/releases).

More installation options, including static yaml files are available in the [/deploy](/deploy) directory. These flat spec files contain the most recent changes to Kuberhealthy, or the master branch. Use this if you would like to test master branch updates.

## Visualized

Here is an illustration of how Kuberhealthy provisions and operates checker pods.  The following process is illustrated:

- An admin creates a [`KuberhealthyCheck`](hhttps://github.com/kuberhealthy/kuberhealthy/blob/master/docs/CHECKS.md#khcheck-anatomy) resource that calls for a synthetic Kubernetes daemonset to be deployed and tested every 15 minutes.  This will ensure that all nodes in the Kubernetes cluster can provision containers properly.
- Kuberhealthy observes this new `KuberhealthyCheck` resource.
- Kuberhealthy schedules a checker pod to manage the lifecycle of this check.
- The checker pod creates a daemonset using the Kubernetes API.
- The checker pod observes the daemonset and waits for all daemonset pods to become `Ready`
- The checker pod deletes the daemonset using the Kubernetes API.
- The checker pod observes the daemonset being fully cleaned up and removed.
- The checker pod reports a successful test result back to Kuberhealthy's API.
- Kuberhealthy stores this check's state and makes it available to various metrics systems.


<img src=""images/kh-ds-check.gif"">

## Included Checks

You can use any of [the pre-made checks](https://github.com/kuberhealthy/kuberhealthy/blob/master/docs/CHECKS_REGISTRY.md#khcheck-registry) by simply enabling them.  By default Kuberhealthy comes with several checks to test Kubernetes deployments, daemonsets, and DNS.

#### Some checks you can easily enable:

- [SSL Handshake Check](https://github.com/kuberhealthy/kuberhealthy/blob/master/cmd/ssl-handshake-check/README.md) - checks SSL certificate validity and warns when certs are about to expire.
- [CronJob Scheduling Failures](https://github.com/kuberhealthy/kuberhealthy/blob/master/cmd/cronjob-checker/README.md) - checks for events indicating that a CronJob has failed to create Job pods.
- [Image Pull Check](https://github.com/kuberhealthy/kuberhealthy/blob/master/cmd/test-check#image-pull-check) - checks that an image can be pulled from an image repository.
- [Deployment Check](https://github.com/kuberhealthy/kuberhealthy/blob/master/cmd/deployment-check/README.md) - verifies that a fresh deployment can run, deploy multiple pods, pass traffic, do a rolling update (without dropping connections), and clean up successfully.
- [Daemonset Check](https://github.com/kuberhealthy/kuberhealthy/blob/master/cmd/daemonset-check/README.md) - verifies that a daemonset can be created, fully provisioned, and torn down.  This checks the full kubelet functionality of every node in your Kubernetes cluster.
- [Storage Provisioner Check](https://github.com/ChrisHirsch/kuberhealthy-storage-check) - verifies that a pod with persistent storage can be configured on every node in your cluster.


## Create Synthetic Checks for Your APIs

You can easily create synthetic tests to check your applications and APIs with real world use cases. This is a great way to be confident that your application functions as expected in the real world at all times.

Here is a full check example written in `go`.  Just implement `doCheckStuff` and you're off!


```go
package main

import (
  ""github.com/kuberhealthy/kuberhealthy/v2/pkg/checks/external/checkclient""
)

func main() {
  ok := doCheckStuff()
  if !ok {
    checkclient.ReportFailure([]string{""Test has failed!""})
    return
  }
  checkclient.ReportSuccess()
}

```

You can read more about [how checks are configured](docs/CHECKS.md) and [learn how to create your own check container](docs/CHECK_CREATION.md). Checks can be written in any language and helpful clients for checks not written in Go can be found in the [clients directory](/clients).

### Status Page

You can directly access the current test statuses by accessing the `kuberhealthy.kuberhealthy` HTTP service on port 80.  The status page displays server status in the format shown below.  The boolean `OK` field can be used to indicate global up/down status, while the `Errors` array will contain a list of all check error descriptions.  Granular, per-check information, including how long the check took to run (Run Duration), the last time a check was run, and the Kuberhealthy pod ran that specific check is available under the `CheckDetails` object.

```json
{
    ""OK"": true,
    ""Errors"": [],
    ""CheckDetails"": {
        ""kuberhealthy/daemonset"": {
            ""OK"": true,
            ""Errors"": [],
            ""RunDuration"": ""22.512278967s"",
            ""Namespace"": ""kuberhealthy"",
            ""LastRun"": ""2019-11-14T23:24:16.7718171Z"",
            ""AuthoritativePod"": ""kuberhealthy-67bf8c4686-mbl2j"",
            ""uuid"": ""9abd3ec0-b82f-44f0-b8a7-fa6709f759cd""
        },
        ""kuberhealthy/deployment"": {
            ""OK"": true,
            ""Errors"": [],
            ""RunDuration"": ""29.142295647s"",
            ""Namespace"": ""kuberhealthy"",
            ""LastRun"": ""2019-11-14T23:26:40.7444659Z"",
            ""AuthoritativePod"": ""kuberhealthy-67bf8c4686-mbl2j"",
            ""uuid"": ""5f0d2765-60c9-47e8-b2c9-8bc6e61727b2""
        },
        ""kuberhealthy/dns-status-internal"": {
            ""OK"": true,
            ""Errors"": [],
            ""RunDuration"": ""2.43940936s"",
            ""Namespace"": ""kuberhealthy"",
            ""LastRun"": ""2019-11-14T23:34:04.8927434Z"",
            ""AuthoritativePod"": ""kuberhealthy-67bf8c4686-mbl2j"",
            ""uuid"": ""c85f95cb-87e2-4ff5-b513-e02b3d25973a""
        },
        ""kuberhealthy/pod-restarts"": {
            ""OK"": true,
            ""Errors"": [],
            ""RunDuration"": ""2.979083775s"",
            ""Namespace"": ""kuberhealthy"",
            ""LastRun"": ""2019-11-14T23:34:06.1938491Z"",
            ""AuthoritativePod"": ""kuberhealthy-67bf8c4686-mbl2j"",
            ""uuid"": ""a718b969-421c-47a8-a379-106d234ad9d8""
        }
    },
    ""CurrentMaster"": ""kuberhealthy-7cf79bdc86-m78qr""
}
```

## Contributing

If you're interested in contributing to this project:
- Check out the [Contributing Guide](CONTRIBUTING.md).
- If you use Kuberhealthy in a production environment, add yourself to the list of [Kuberhealthy adopters](docs/KUBERHEALTHY_ADOPTERS.md)!
- Check out [open issues](https://github.com/kuberhealthy/kuberhealthy/issues). If you're new to the project, look for the `good first issue` tag.
- We're always looking for check contributions (either in suggestions or in PRs) as well as feedback from folks implementing
Kuberhealthy locally or in a test environment.


## Monthly Community Meeting

If you would like to talk directly to the core maintainers to discuss ideas, code reviews, or other complex issues, we have a monthly Zoom meeting on the first Wednesday of the month.  [Click here to add the meeting to your calendar](https://zoom.us/j/96457488866?pwd=SDZxL1dEQTVZUTRWbFFTZWNDZWFwdz09).
",1794,1794,28,130,health,"[hacktoberfest, health, kubernetes, monitoring, synthetic]",62
tcgoetz,GarminDB,,https://github.com/tcgoetz/GarminDB,https://api.github.com/repos/GarminDB/tcgoetz,"Download and parse data from Garmin Connect or a Garmin watch, FitBit CSV, and MS Health CSV files into and analyze data in Sqlite serverless databases with Jupyter notebooks.","[![Screen shot of a daily graph](https://raw.githubusercontent.com/tcgoetz/GarminDB/master/Screenshots/Screen_Shot_jupyter_daily_sm.jpg)](https://github.com/tcgoetz/GarminDB/wiki/Screenshots)

---

[![Screen shot of an activity display](https://raw.githubusercontent.com/tcgoetz/GarminDB/master/Screenshots/Screen_Shot_activity_sm.jpg)](https://github.com/tcgoetz/GarminDB/wiki/Screenshots)

---

[![Screen shot of daily trend ](Screenshots/Screen_Shot_daily_trend.png)](https://github.com/tcgoetz/GarminDB/wiki/Screenshots)


# GarminDB

[Python](https://www.python.org/) scripts for parsing health data into and manipulating data in a [SQLite](http://sqlite.org/) database. SQLite is a light weight database that doesn't require a server.

What they can do:
* Automatically download and import Garmin daily monitoring files (all day heart rate, activity, climb/descend, stress, and intensity minutes) from the user's Garmin Connect ""Daily Summary"" page.
* Extract sleep, weight, and resting heart rate data from Garmin Connect, store it as JSON files, and import it into the DB.
* Download and import activity files from Garmin Connect. A summary table for all activities and more detailed data for some activity types. Lap and record entries for activities.
* Summarizing data into a DB with tables containing daily, weekly, monthly, and yearly summaries.
* Graph your data from the commandline or with Jupyter notebooks.
* Retain downloaded JSON and FIT files so that the DB can be regenerated without connecting to or redownloading data from Garmin Connect.
* Export activities as TCX files.

Once you have your data in the DB, I recommend using a supplied Jupyter notebooks, third party Jupyter notebooks, and/or SQLite browser like [SQLite Studio](http://sqlitestudio.pl) or [DB Browser for SQLite](https://sqlitebrowser.org/) for browsing and working with the data. The scripts create some default [views](http://www.tutorialspoint.com/sqlite/sqlite_views.htm) in the DBs that make browsing the data easier.

# Using It

## Releases

GarminDb releases are hosted on [PyPI](https://pypi.org/project/garmindb/). GarminDb requires [Python](https://www.python.org/) 3.x. With Python installed, install the latest release with [pip](https://pypi.org/project/pip/) by running `pip install garmindb` in a terminal.
* Copy `GarminConnectConfig.json.example` to `~/.GarminDb/GarminConnectConfig.json`, edit it, and add your Garmin Connect username and password and adjust the start dates to match the dats of your data in Garmin Connect.
* Starting out: download all of your data and create your db by running `garmindb_cli.py --all --download --import --analyze` in a terminal.
* Incrementally update your db by downloading the latest data and importing it by running `garmindb_cli.py --all --download --import --analyze --latest` in a terminal.
* Ocassionally run `garmin_cli.py --backup` to backup your DB files.

Update to the latest release with `pip install --upgrade garmindb`.

## From Source

The scripts are automated with [Make](https://www.gnu.org/software/make/manual/make.html). Run the Make commands in a terminal window.

* Git clone GarminDB repo using the [SSH clone method](https://github.com/git-guides/git-clone#git-clone-with-ssh). The submodules require you to use SSH and not HTTPS. Get the command from the green button on the project home page.
* Run `make setup` in the cloned tree to get the scripts ready to process data.
* Copy `GarminConnectConfig.json.example` to `~/.GarminDb/GarminConnectConfig.json`, edit it, and add your Garmin Connect username and password and adjust the start dates to match the dats of your data in Garmin Connect.
* Run `make create_dbs` once to fetch and process for you data.
* Keep all of your local data up to date by periodically running only one command: `make`.

There is more help on [using the program](https://github.com/tcgoetz/GarminDB/wiki/Usage) in the wiki.

# Jupyter Notebooks #

Jupyter notebooks for analzing data from the database can be found in the 'Jupyter' directory in the source tree. [Links](https://github.com/tcgoetz/GarminDB/wiki/Related-Projects#jupyter-notebooks) to user submitted notebooks can be found in the wiki.

# Plugins #

Plugins allow the user to expand the types of data that are processed and stored in the database. GarminDb already has a number of plugins for handling data from third-party Connect IQ apps and data fields. Read more about plugins [here](https://github.com/tcgoetz/GarminDbPlugins).

# Success Stories

Find out who's using GarminDb on what platforms, OSes, and python versions [here](https://github.com/tcgoetz/GarminDB/wiki/Success-Stories). If you're using GarminDB and your scenario isn't listed send me a message or file an issue with your success case.

# Notes

* You may get a DB version exception after updating the code, this means that the DB schema was updated and you need to rebuild your DBs by running `garmindb_cli.py --rebuild_db`. Your DBs will be regenerated from the previously downloaded data files. All of your data will not be redownloaded from Garmin.
* The scripts were developed on MacOS. Information or patches on using these scripts on other platforms are welcome.
* When a database update finishes, a summary of the data in the DB will be saved to stats.txt. The output includes the date ranges included in the downloaded daily monitoring files and activities. It includes the number of records for daily monitoring, activities, sleep, resting heart rate, weight, etc. Use the summary information to determine if all of your data has been downloaded from Garmin Connect. If not, adjust the dates in GarminConnectConfig.json and runt he download again.
* In `GarminConnectConfig.json` the ""steps"" element of the ""course_views"" is list of course ids that per course database views will be generated for. The database view allows you to compare all activities from that course.

# Bugs and Debugging

* If you have issues, file a bug here on the project. See the Issues tab at the top of the project page. Run `make bugreport` or `garmindb_bug_report.py` and include bugreport.txt in your bug report.
* Besides errors that appear on the screen, one of the first places to look for more information is the log files (garmin.log, graphs.log).
* If your having issues with a particular data files, please considering sharing so I can debug it and add support.

# Contributing

Please submit a pull request targeting the develop branch and add your self to the contributors file. Run `make flake8` at the top level and fix all errors before submitting your pull request.
",677,677,27,11,health,"[database, garmin, health, jupyter-notebooks, python, sqlite]",62
spatie,http-status-check,spatie,https://github.com/spatie/http-status-check,https://api.github.com/repos/http-status-check/spatie,CLI tool to crawl a website and check HTTP status codes,"# Check the HTTP status code of all links on a website

[![Latest Version on Packagist](https://img.shields.io/packagist/v/spatie/http-status-check.svg?style=flat-square)](https://packagist.org/packages/spatie/http-status-check)
[![Software License](https://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat-square)](LICENSE.md)
![Tests](https://github.com/spatie/http-status-check/workflows/Tests/badge.svg)
[![Total Downloads](https://img.shields.io/packagist/dt/spatie/http-status-check.svg?style=flat-square)](https://packagist.org/packages/spatie/http-status-check)

This repository provides a tool to check the HTTP status code of every link on a given website.

## Support us

[<img src=""https://github-ads.s3.eu-central-1.amazonaws.com/http-status-check.jpg?t=1"" width=""419px"" />](https://spatie.be/github-ad-click/http-status-check)

We invest a lot of resources into creating [best in class open source packages](https://spatie.be/open-source). You can support us by [buying one of our paid products](https://spatie.be/open-source/support-us).

We highly appreciate you sending us a postcard from your hometown, mentioning which of our package(s) you are using. You'll find our address on [our contact page](https://spatie.be/about-us). We publish all received postcards on [our virtual postcard wall](https://spatie.be/open-source/postcards).

## Installation

This package can be installed via Composer:

```bash
composer global require spatie/http-status-check
```

## Usage

This tool will scan all links on a given website:

```bash
http-status-check scan https://example.com
```

It outputs a line per link found. Here's an example on Laracast website scan:

![screenshot](https://freek.dev/uploads/2015/11/screenshot.png)

When the crawling process is finished a summary will be shown.

By default the crawler uses 10 concurrent connections to speed up the crawling process. You can change that number by passing a different value to the `--concurrency` option:

```bash
http-status-check scan https://example.com --concurrency=20
```

You can also write all urls that gave a non-2xx or non-3xx response to a file:

```bash
http-status-check scan https://example.com --output=log.txt
```

When the crawler finds a link to an external website it will by default crawl that link as well. If you don't want the crawler to crawl such external urls use the `--dont-crawl-external-links` option:

```bash
http-status-check scan https://example.com --dont-crawl-external-links
```

By default, requests timeout after 10 seconds. You can change this by passing the number of seconds to the `--timeout` option:

```bash
http-status-check scan https://example.com --timeout=30
```

By default, the crawler will respect robots data. You can ignore them though with the `--ignore-robots` option:

```bash
http-status-check scan https://example.com --ignore-robots
```

If your site requires a basic authentification, you can use the `--auth` option:

```bash
http-status-check scan https://example.com --auth=username:password
```

## Testing

To run the tests, first make sure you have [Node.js](https://nodejs.org/) installed. Then start the included node based server in a separate terminal window:

```bash
cd tests/server
npm install
node server.js
```

With the server running, you can start testing:

```bash
vendor/bin/phpunit
```

## Changelog

Please see [CHANGELOG](CHANGELOG.md) for more information on what has changed recently.

## Contributing

Please see [CONTRIBUTING](https://github.com/spatie/.github/blob/main/CONTRIBUTING.md) for details.

## Security

If you've found a bug regarding security please mail [security@spatie.be](mailto:security@spatie.be) instead of using the issue tracker.

## Credits

-   [Freek Van der Herten](https://github.com/freekmurze)
-   [Sebastian De Deyne](https://github.com/sebastiandedeyne)
-   [All Contributors](../../contributors)

## License

The MIT License (MIT). Please see [License File](LICENSE.md) for more information.
",585,585,20,0,health,"[curl, health, http, seo, statuscode]",62
chaoss,augur,chaoss,https://github.com/chaoss/augur,https://api.github.com/repos/augur/chaoss,Python library and web service for Open Source Software Health and Sustainability metrics & data collection. You can find our documentation and new contributor information easily here: https://chaoss.github.io/augur/ and learn more about Augur at our website https://augurlabs.io,"# Augur NEW Release v0.53.2

[![first-timers-only](https://img.shields.io/badge/first--timers--only-friendly-blue.svg?style=flat-square)](https://www.firsttimersonly.com/) We follow the [First Timers Only](https://www.firsttimersonly.com/) philosophy of tagging issues for first timers only, and walking one newcomer through the resolution process weekly. [You can find these issues tagged with ""first timers only"" on our issues list.](https://github.com/chaoss/augur/labels/first-timers-only).

[![standard-readme compliant](https://img.shields.io/badge/standard--readme-OK-green.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme) [![Build Docker images](https://github.com/chaoss/augur/actions/workflows/build_docker.yml/badge.svg)](https://github.com/chaoss/augur/actions/workflows/build_docker.yml) [![Hits-of-Code](https://hitsofcode.com/github/chaoss/augur?branch=main)](https://hitsofcode.com/github/chaoss/augur/view?branch=main) [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2788/badge)](https://bestpractices.coreinfrastructure.org/projects/2788)

## NEW RELEASE ALERT!
### [If you want to jump right in, updated docker build/compose and bare metal installation instructions are available here](docs/new-install.md)


Augur is now releasing a dramatically improved new version to the main branch. It is also available here: https://github.com/chaoss/augur/releases/tag/v0.53.2
- The `main` branch is a stable version of our new architecture, which features:
  - Dramatic improvement in the speed of large scale data collection (100,000+ repos). All data is obtained for 100k+ repos within 2 weeks.
  - A new job management architecture that uses Celery and Redis to manage queues, and enables users to run a Flower job monitoring dashboard
  - Materialized views to increase the snappiness of API’s and Frontends on large scale data
  - Changes to primary keys, which now employ a UUID strategy that ensures unique keys across all Augur instances
  - Support for https://github.com/oss-aspen/8knot dashboards (view a sample here: https://eightknot.osci.io/). (beautification coming soon!)
  - Data collection completeness assurance enabled by a structured, relational data set that is easily compared with platform API Endpoints
- The next release of the new version will include a hosted version of Augur where anyone can create an account and add repos “they care about”. If the hosted instance already has a requested organization or repository it will be added to a user’s view. If its a new repository or organization, the user will be notified that collection will take (time required for the scale of repositories added). 

## What is Augur?
Augur is a software suite for collecting and measuring structured data
about [free](https://www.fsf.org/about/) and [open-source](https://opensource.org/docs/osd) software (FOSS) communities.

We gather trace data for a group of repositories, normalize it into our data model, and provide a variety of metrics about said data. The structure of our data model enables us to synthesize data across various platforms to provide meaningful context for meaningful questions about the way these communities evolve.
Augur’s main focus is to measure the overall health and sustainability of open source projects, as these types of projects are system critical for nearly every software organization or company. We do this by gathering data about project repositories and normalizing that into our data model to provide useful metrics about your project’s health. For example, one of our metrics is Burstiness. Burstiness – how are short timeframes of intense activity, followed by a corresponding return to a typical pattern of activity, observed in a project?

This can paint a picture of a project’s focus and gain insight into the potential stability of a project and how its typical cycle of updates occurs. 

We are a [CHAOSS](https://chaoss.community) project, and many of our
metrics are implementations of the metrics defined by our awesome community. You can find a full list of them [here](https://chaoss.community/metrics/).

For more information on [how to get involved on the CHAOSS website](https://chaoss.community/participate/).

## Collecting Data

Augur supports Python3.6 through Python3.9 on all platforms. Python3.10 and above do not yet work because of machine learning worker dependencies. On OSX, you can create a Python 3.9 environment this way: `python3.9 -m venv path/to/venv`.

Augur's main focus is to measure the overall health and sustainability of open source projects.

Augur collects more data about open source software projects than any other available software. Augur's main focus is to measure the overall health and sustainability of open source projects.
One of Augur's core tenets is a desire to openly gather data that people can trust, and then provide useful and well-defined metrics that help give important context to the larger stories being told by that data. We do this in a variety of ways, one of which is doing all our own data collection in house. We currently collect data from a few main sources:

1. Raw Git commit logs (commits, contributors)
2. GitHub's API (issues, pull requests, contributors, releases, repository metadata)
3. The Linux Foundation's [Core Infrastructure Initiative](https://www.coreinfrastructure.org/) API (repository metadata)
4. [Succinct Code Counter](https://github.com/boyter/scc), a blazingly fast Sloc, Cloc, and Code tool that also performs COCOMO calculations

This data is collected by dedicated data collection workers controlled by Augur, each of which is responsible for querying some subset of these data sources. We are also hard at work building workers for new data sources. If you have an idea for a new one, [please tell us](https://github.com/chaoss/augur/issues/new?template=feature_request.md) - we'd love your input!


## Getting Started

If you're interested in collecting data with our tool, the Augur team has worked hard to develop a detailed guide to get started with our project which can be found [in our documentation](https://oss-augur.readthedocs.io/en/main/getting-started/toc.html).

If you're looking to contribute to Augur's code, you can find installation instructions, development guides, architecture references (coming soon), best practices and more in our [developer documentation](https://oss-augur.readthedocs.io/en/main/development-guide/toc.html). Please know that while it's still rather sparse right now,
but we are actively adding to it all the time. If you get stuck, please feel free to [ask for help](https://github.com/chaoss/augur/issues/new)!

## Contributing

To contribute to Augur, please follow the guidelines found in our [CONTRIBUTING.md](CONTRIBUTING.md) and our [Code of Conduct](CODE_OF_CONDUCT.md). Augur is a welcoming community that is open to all, regardless if you're working on your 1000th contribution to open source or your 1st. We strongly believe that much of what makes open source so great is the incredible communities it brings together, so we invite you to join us!

## License, Copyright, and Funding

Copyright © 2023 University of Nebraska at Omaha, University of Missouri, Brian Warner, and the CHAOSS Project.

Augur is free software: you can redistribute it and/or modify it under the terms of the MIT License as published by the Open Source Initiative. See the [LICENSE](LICENSE) file for more details.

This work has been funded through the Alfred P. Sloan Foundation, Mozilla, The Reynolds Journalism Institute, contributions from VMWare, Red Hat Software, Grace Hopper's Open Source Day, GitHub, Microsoft, Twitter, Adobe, the Gluster Project, Open Source Summit (NA/Europe), and the Linux Foundation Compliance Summit. Significant design contributors include Kate Stewart, Dawn Foster, Duane O'Brien, Remy Decausemaker, others omitted due to the  memory limitations of project maintainers, and 15 Google Summer of Code Students. 

Current maintainers
--------------------
- `Derek Howard <https://github.com/howderek>`_
- `Andrew Brain <https://github.com/ABrain7710>`_
- `Isaac Milarsky <https://github.com/IsaacMilarky>`_
- `John McGinnis <https://github.com/Ulincys>`_ 
- `Sean P. Goggins <https://github.com/sgoggins>`_ 



Former maintainers
--------------------
- `Carter Landis <https://github.com/ccarterlandis>`_
- `Gabe Heim <https://github.com/gabe-heim>`_
- `Matt Snell <https://github.com/Nebrethar>`_
- `Christian Cmehil-Warn <https://github.com/christiancme>`_
- `Jonah Zukosky <https://github.com/jonahz5222>`_
- `Carolyn Perniciaro <https://github.com/CMPerniciaro>`_
- `Elita Nelson <https://github.com/ElitaNelson>`_
- `Michael Woodruff <https://github.com/michaelwoodruffdev/>`_
- `Max Balk <https://github.com/maxbalk/>`_

Contributors
--------------------
- `Dawn Foster <https://github.com/geekygirldawn/>`_
- `Ivana Atanasova <https://github.com/ivanayov/>`_
- `Georg J.P. Link <https://github.com/GeorgLink/>`_

GSoC 2022 participants
-----------------------
- `Kaxada <https://github.com/kaxada>`_
- `Mabel F <https://github.com/mabelbot>`_
- `Priya Srivastava <https://github.com/Priya730>`_
- `Ramya Kappagantu <https://github.com/RamyaKappagantu>`_
- `Yash Prakash <https://gist.github.com/yash-yp>`_

GSoC 2021 participants
-----------------------
- `Dhruv Sachdev <https://github.com/Dhruv-Sachdev1313>`_
- `Rashmi K A <https://github.com/Rashmi-K-A>`_
- `Yash Prakash <https://github.com/yash2002109/>`_
- `Anuj Lamoria <https://github.com/anujlamoria/>`_
- `Yeming Gu <https://github.com/gymgym1212/>`_
- `Ritik Malik <https://gist.github.com/ritik-malik>`_

GSoC 2020 participants
-----------------------
- `Akshara P <https://github.com/aksh555/>`_
- `Tianyi Zhou <https://github.com/tianyichow/>`_
- `Pratik Mishra <https://github.com/pratikmishra356/>`_
- `Sarit Adhikari <https://github.com/sarit-adh/>`_
- `Saicharan Reddy <https://github.com/mrsaicharan1/>`_
- `Abhinav Bajpai <https://github.com/abhinavbajpai2012/>`_

GSoC 2019 participants
-----------------------
- `Bingwen Ma <https://github.com/bing0n3/>`_
- `Parth Sharma <https://github.com/parthsharma2/>`_

GSoC 2018 participants
-----------------------
- `Keanu Nichols <https://github.com/kmn5409/>`_

",542,542,23,54,health,"[chaoss, data-collection, data-modeling, data-visualization, defined-metrics, facade, git, github, hacktoberfest, hacktoberfest2020, health, linux, linux-foundation, metrics, open-source, opensource, python-library, research, sustainability, unix]",62
matthiasn,lotti,,https://github.com/matthiasn/lotti,https://api.github.com/repos/lotti/matthiasn,"Achieve your goals and keep your data private with Lotti. This life tracking app is designed to help you stay motivated and on track, all while keeping your personal information safe and secure. Now with on-device speech recognition.","# Lotti

[![CodeFactor](https://www.codefactor.io/repository/github/matthiasn/lotti/badge)](https://www.codefactor.io/repository/github/matthiasn/lotti) [![Flutter Test](https://github.com/matthiasn/lotti/actions/workflows/flutter-test.yml/badge.svg)](https://github.com/matthiasn/lotti/actions/workflows/flutter-test.yml)

Lotti helps you track habits, behavior, any data about yourself, in complete privacy.

![Habits Tab](https://raw.githubusercontent.com/matthiasn/lotti-docs/main/images/0.9.312+1968/habits_screen.png)

Read more on [**Substack**](https://matthiasnehlsen.substack.com).

**New in 06/2023:** Lotti can now transcribe audio recordings in 99 languages using
[`whisper.cpp`](https://github.com/ggerganov/whisper.cpp).

## How to use Lotti
Check out the [MANUAL](https://github.com/matthiasn/lotti/blob/main/docs/MANUAL.md). The images in
there are updated automatically in CI using [`Fluttium`](https://fluttium.dev).

## Core beliefs / the WHY

Lotti is a tool for self-improvement centered around these core beliefs:

1. Long-term outcomes in life can be improved by following good routines and establishing good 
   habits, such as healthy sleep, mindfulness and improved self-awareness, healthy eating, 
   enough physical activity and the like. Technology is essential when trying to establish and 
   monitor good habits. Paper-based checklists are undesirable.
2. Habits need to be monitored long-term. The 21-day habit theory, stating that it takes three 
   weeks to form a new habit and then subsequently sticking with it automatically is 
   questionable at best, and the only way to ensure that habits identified as important are 
   actually followed is to monitor them.
3. Any comprehensive attempt at tracking and monitoring the aforementioned areas of life 
   will result in collecting far more data than anyone should be willing to share with anyone 
   else.

Lotti is a tool for improving life via establishing good habits and monitoring their outcome.
All collected data stays on your devices. Encrypted and entirely private synchronisation
between your devices can be set up (instructions will follow).

Lotti currently supports recording the following data types:

* Habits, which can be defined and tracked. Habit tracking then involves recording daily 
  completions, which can be successes, failures, and also skipping the completion in case a habit 
  could not be completed due to external circumstances.
* Health-related data which can be imported automatically, such as steps, weight, sleep, blood 
  pressure, resting heart rate, and whatever else can be recorded in Apple Health (or the 
  Android equivalent).
* Custom data types, such as the intake of water, food, alcohol, coffee, but also exercises such 
  as pull-ups, you name (and define) it.
* Text journal entries.
* Tasks, with different statuses to track their lifecycle: open, groomed, in progress, blocked, 
  on hold, done, rejected.
* Audio recordings, as spoken journal entries, and also audio notes, for example when working on 
  a task and documenting progress and doing a quick brain dump that can be useful when picking 
  up a task again later.
* Time, as in recording time spent on a tasks, and also a related story.
* Tags for better organization and discoverability of journal entries.
* Stories, a special tag type that is useful for reporting time spent on tasks related to their 
  respective stories.
* People, a special tag type with no additional functionality yet, only a different tag color.


## Planned improvements:

* **Experiment/Intervention lifecycle.** The app is already useful for monitoring experiments or 
  interventions but those themselves currently remain implicit. For example, an experiment could be
  taking Vitamin D and see how that affects health parameters, or have a hypothesis what will happen,
  and then prove or disprove that, where a dashboard help monitor all relevant parameters. In 
  future versions, the lifecycle of interventions shall be made explicit, by defining them in 
  the first place, and then reviewing and refining them.
* Better **Reporting** how time is spent.
* **Upfront planning** of time budgets. 

Please check out [HISTORY.md](https://github.com/matthiasn/lotti/blob/main/docs/HISTORY.md) for all
the information on the project's history and back-story. You can find the previous version (written
in Clojure and ClojureScript) in this repo: [meins](https://github.com/matthiasn/meins).


## Principles

- Lotti is **private** and does not share any information with anyone - see the
  [Privacy Policy](https://github.com/matthiasn/lotti/blob/main/PRIVACY.md).
- Lotti is **open-source** and everyone is encouraged to contribute, be it via contributing to 
  code, providing feedback, testing, identifying bugs, etc.
- Lotti strives to be as **inclusive** as possible and any request for improved accessibility 
  will be addressed.
- Lotti is supposed to become a **friendly and welcoming community** of people who are 
  interested in data, improving their lives, and not or only very selectively sharing their data 
  in the process. Please head over to [Discussions](https://github.com/matthiasn/lotti/discussions) and say Hi.
- **Localization**. Lotti is multilingual and should be available in as many different languages as 
  possible. English is the primary language, and there are French, German, and Romanian translations. 
  Those need some update love, as the are many new UI labels that didn't exist when translations
  were last looked at. Please help, and also create [issues](https://github.com/matthiasn/lotti/issues)
  and PRs for languages you would like to see. Thanks!

## Beta testing

Lotti is currently available for beta testing for these platforms:

- **iOS** and **macOS** versions are available via a [Public Beta on TestFlight](https://testflight.apple.com/join/ZPgbDLGY).
  Development is primarily done on macOS and both the iOS and macOS versions are in constant use by
  the author. You can expect Lotti to work on these two platforms.
- The **Android** app is available as both `aab` and `apk` files on [GitHub Releases](https://github.com/matthiasn/lotti/releases).
  Both appeared to be working fine in some limited testing on both an Android phone and an Android
  tablet.
- **Windows** there's an installer named `lotti.msix` in [GitHub Releases](https://github.com/matthiasn/lotti/releases).
  That's not signed though. There's also a (currently hidden) release on the Microsoft Store which 
  appears to be working fine on Windows. However, some issues in the Microsoft Partner Center need
  to be resolved before making Lotti available on the Microsoft Store.
- **Linux**: the simplest way to release would be on the [Snap Store](https://snapcraft.io/snap-store),
  with automatic updates, but that's blocked by this [issue](https://github.com/matthiasn/lotti/issues/941).
  There's a file named `linux.x64.tar.gz` [GitHub Releases](https://github.com/matthiasn/lotti/releases)
  that contains the app. From limited testing, the app works fine on Linux, but is missing an app
  icon (could be a nice small PR).

**The goal is to get Lotti out on all app stores in 2023.**


## Blog posts

- [Introducing Lotti or how I learned to love Flutter and Buildkite](https://matthiasnehlsen.com/blog/2022/05/05/introducing-lotti/)
- [How I switched to Flutter and lost 10 kilos](https://matthiasnehlsen.com/blog/2022/05/15/switched-to-flutter-lost-10-kilos/)


## Getting Started

1. Install Flutter, see [instructions](https://docs.flutter.dev/get-started/install).
2. Clone repository and go to `./lotti`
3. Run `flutter pub get`
4. Run `make watch` or `make build_runner` for code generation
5. Open in your favorite IDE, e.g. [Android Studio](https://developer.android.com/studio) 
6. Run, either from the IDE or using e.g. `flutter run -d macos`


## Platform-specific setup

### Mac

Tested on `macOS 13.3`: no additional steps necessary. You only need to have Xcode installed.


### Linux

Tested on `Ubuntu 20.04.3 LTS` inside a virtual machine on VMWare Fusion In addition to the common
steps above, install missing dependencies:

```
$ sudo apt-get install libsecret-1-dev libjsoncpp-dev libjsoncpp1 libsecret-1-0 sqlite3 libsqlite3-dev
$ flutter packages get
$ make build_runner
``` 

In case the network in the virtual machine is not connecting after resuming: `$ sudo dhclient ens33`


### Windows

If your system is set up to run the Flutter counter example app, you should be good to go.


## Continuous Integration

This project uses [Buildkite](https://buildkite.com/docs/agent/v3/macos) on macOS for releasing to
TestFlight on iOS and macOS, and GitHub Actions for publishing to GitHub Releases for all other
platforms. 


## Contributions

Contributions to this project are very welcome. How can you help?

1. Please check under issues if there is anything specific that needs helping
   hands, or features to be discussed or implemented.
2. Improve the test coverage (currently at around 71%). Any additional tests are welcome,
   including code changes to make the code easier to test.
3. Create issues for feedback and ideas.
4. Help translate into more languages, and improve the existing translations.

Thanks!
",451,451,11,7,health,"[android-app, fitness-app, flutter, health, ios, journal, linux-app, macos, speech-recognition, speech-to-text, time-tracker, windows]",62
mraible,21-points,,https://github.com/mraible/21-points,https://api.github.com/repos/21-points/mraible,❤️ 21-Points Health is an app you can use to monitor your health. ,"# 21-Points Health
[![Build Status][github-actions-image]][github-actions-url] <!--[![Dependency Status][daviddm-image]][daviddm-url]--> <object id=""badge"" data=""https://snyk-widget.herokuapp.com/badge/npm/%mraible%21-points/7.0.0/badge.svg"" type=""image/svg+xml""></object> [![Known Vulnerabilities][snyk-image]][snyk-url]

> To track your health and improve your life. 😊

This application was generated using [JHipster 7.9.3](https://www.jhipster.tech/documentation-archive/v7.9.3), and serves as the sample application in the [JHipster Mini-Book](https://www.infoq.com/minibooks/jhipster-mini-book).

## Project Structure

Node is required for generation and recommended for development. `package.json` is always generated for a better development experience with prettier, commit hooks, scripts and so on.

In the project root, JHipster generates configuration files for tools like git, prettier, eslint, husky, and others that are well known and you can find references in the web.

`/src/*` structure follows default Java structure.

- `.yo-rc.json` - Yeoman configuration file
  JHipster configuration is stored in this file at `generator-jhipster` key. You may find `generator-jhipster-*` for specific blueprints configuration.
- `.yo-resolve` (optional) - Yeoman conflict resolver
  Allows to use a specific action when conflicts are found skipping prompts for files that matches a pattern. Each line should match `[pattern] [action]` with pattern been a [Minimatch](https://github.com/isaacs/minimatch#minimatch) pattern and action been one of skip (default if ommited) or force. Lines starting with `#` are considered comments and are ignored.
- `.jhipster/*.json` - JHipster entity configuration files

- `npmw` - wrapper to use locally installed npm.
  JHipster installs Node and npm locally using the build tool by default. This wrapper makes sure npm is installed locally and uses it avoiding some differences different versions can cause. By using `./npmw` instead of the traditional `npm` you can configure a Node-less environment to develop or test your application.
- `/src/main/docker` - Docker configurations for the application and services that the application depends on

## Development

Before you can build this project, you must install and configure the following dependencies on your machine:

1. [Node.js][]: We use Node to run a development web server and build the project.
   Depending on your system, you can install Node either from source or as a pre-packaged bundle.

After installing Node, you should be able to run the following command to install development tools.
You will only need to run this command when dependencies change in [package.json](package.json).

```
npm install
```

We use npm scripts and [Angular CLI][] with [Webpack][] as our build system.

Run the following commands in two separate terminals to create a blissful development experience where your browser
auto-refreshes when files change on your hard drive.

```
./gradlew -x webapp
npm start
```

Npm is also used to manage CSS and JavaScript dependencies used in this application. You can upgrade dependencies by
specifying a newer version in [package.json](package.json). You can also run `npm update` and `npm install` to manage dependencies.
Add the `help` flag on any command to see how you can use it. For example, `npm help update`.

The `npm run` command will list all of the scripts available to run for this project.

### PWA Support

JHipster ships with PWA (Progressive Web App) support, and it's turned off by default. One of the main components of a PWA is a service worker.

The service worker initialization code is disabled by default. To enable it, uncomment the following code in `src/main/webapp/app/app.module.ts`:

```typescript
ServiceWorkerModule.register('ngsw-worker.js', { enabled: false }),
```

### Managing dependencies

For example, to add [Leaflet][] library as a runtime dependency of your application, you would run following command:

```
npm install --save --save-exact leaflet
```

To benefit from TypeScript type definitions from [DefinitelyTyped][] repository in development, you would run following command:

```
npm install -D --save-exact @types/leaflet
```

Then you would import the JS and CSS files specified in library's installation instructions so that [Webpack][] knows about them:
Edit [src/main/webapp/app/app.module.ts](src/main/webapp/app/app.module.ts) file:

```
import 'leaflet/dist/leaflet.js';
```

Edit [src/main/webapp/content/scss/vendor.scss](src/main/webapp/content/scss/vendor.scss) file:

```
@import '~leaflet/dist/leaflet.css';
```

Note: There are still a few other things remaining to do for Leaflet that we won't detail here.

For further instructions on how to develop with JHipster, have a look at [Using JHipster in development][].

### Using Angular CLI

You can also use [Angular CLI][] to generate some custom client code.

For example, the following command:

```
ng generate component my-component
```

will generate few files:

```
create src/main/webapp/app/my-component/my-component.component.html
create src/main/webapp/app/my-component/my-component.component.ts
update src/main/webapp/app/app.module.ts
```

### JHipster Control Center

JHipster Control Center can help you manage and control your application(s). You can start a local control center server (accessible on http://localhost:7419) with:

```
docker-compose -f src/main/docker/jhipster-control-center.yml up
```

## Building for production

### Packaging as jar

To build the final jar and optimize the TwentyOnePoints application for production, run:

```
./gradlew -Pprod clean bootJar
```

This will concatenate and minify the client CSS and JavaScript files. It will also modify `index.html` so it references these new files.
To ensure everything worked, run:

```
java -jar build/libs/*.jar
```

Then navigate to [http://localhost:8080](http://localhost:8080) in your browser.

Refer to [Using JHipster in production][] for more details.

### Packaging as war

To package your application as a war in order to deploy it to an application server, run:

```
./gradlew -Pprod -Pwar clean bootWar
```

## Testing

To launch your application's tests, run:

```
./gradlew test integrationTest jacocoTestReport
```

### Client tests

Unit tests are run by [Jest][]. They're located in [src/test/javascript/](src/test/javascript/) and can be run with:

```
npm test
```

UI end-to-end tests are powered by [Cypress][]. They're located in [src/test/javascript/cypress](src/test/javascript/cypress)
and can be run by starting Spring Boot in one terminal (`./gradlew bootRun`) and running the tests (`npm run e2e`) in a second one.

#### Lighthouse audits

You can execute automated [lighthouse audits][https://developers.google.com/web/tools/lighthouse/] with [cypress audits][https://github.com/mfrachet/cypress-audit] by running `npm run e2e:cypress:audits`.
You should only run the audits when your application is packaged with the production profile.
The lighthouse report is created in `build/cypress/lhreport.html`

For more information, refer to the [Running tests page][].

### Code quality

Sonar is used to analyse code quality. You can start a local Sonar server (accessible on http://localhost:9001) with:

```
docker-compose -f src/main/docker/sonar.yml up -d
```

Note: we have turned off authentication in [src/main/docker/sonar.yml](src/main/docker/sonar.yml) for out of the box experience while trying out SonarQube, for real use cases turn it back on.

You can run a Sonar analysis with using the [sonar-scanner](https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner) or by using the gradle plugin.

Then, run a Sonar analysis:

```
./gradlew -Pprod clean check jacocoTestReport sonarqube
```

For more information, refer to the [Code quality page][].

## Using Docker to simplify development (optional)

You can use Docker to improve your JHipster development experience. A number of docker-compose configuration are available in the [src/main/docker](src/main/docker) folder to launch required third party services.

For example, to start a postgresql database in a docker container, run:

```
docker-compose -f src/main/docker/postgresql.yml up -d
```

To stop it and remove the container, run:

```
docker-compose -f src/main/docker/postgresql.yml down
```

You can also fully dockerize your application and all the services that it depends on.
To achieve this, first build a docker image of your app by running:

```
npm run java:docker
```

Or build an arm64 docker image when using an arm64 processor os like macOS with M1 processor family running:

```
npm run java:docker:arm64
```

Then run:

```
docker-compose -f src/main/docker/app.yml up -d
```

When running Docker Desktop on MacOS Big Sur or later, consider enabling experimental `Use the new Virtualization framework` for better processing performance ([disk access performance is worse](https://github.com/docker/roadmap/issues/7)).

For more information refer to [Using Docker and Docker-Compose][], this page also contains information on the docker-compose sub-generator (`jhipster docker-compose`), which is able to generate docker configurations for one or several JHipster applications.

## Continuous Integration (optional)

To configure CI for your project, run the ci-cd sub-generator (`jhipster ci-cd`), this will let you generate configuration files for a number of Continuous Integration systems. Consult the [Setting up Continuous Integration][] page for more information.

[jhipster homepage and latest documentation]: https://www.jhipster.tech
[jhipster 7.9.3 archive]: https://www.jhipster.tech/documentation-archive/v7.9.3
[using jhipster in development]: https://www.jhipster.tech/documentation-archive/v7.9.3/development/
[using docker and docker-compose]: https://www.jhipster.tech/documentation-archive/v7.9.3/docker-compose
[using jhipster in production]: https://www.jhipster.tech/documentation-archive/v7.9.3/production/
[running tests page]: https://www.jhipster.tech/documentation-archive/v7.9.3/running-tests/
[code quality page]: https://www.jhipster.tech/documentation-archive/v7.9.3/code-quality/
[setting up continuous integration]: https://www.jhipster.tech/documentation-archive/v7.9.3/setting-up-ci/
[node.js]: https://nodejs.org/
[npm]: https://www.npmjs.com/
[webpack]: https://webpack.github.io/
[browsersync]: https://www.browsersync.io/
[jest]: https://facebook.github.io/jest/
[cypress]: https://www.cypress.io/
[leaflet]: https://leafletjs.com/
[definitelytyped]: https://definitelytyped.org/
[angular cli]: https://cli.angular.io/
[github-actions-image]: https://github.com/mraible/21-points/workflows/Application%20CI/badge.svg
[github-actions-url]: https://github.com/mraible/21-points/actions
[snyk-url]: https://snyk.io/test/github/mraible/21-points
[snyk-image]: https://snyk.io/test/github/mraible/21-points/badge.svg
[daviddm-image]: https://david-dm.org/mraible/21-points/dev-status.svg
[daviddm-url]: https://david-dm.org/mraible/21-points?type=dev
",283,283,28,7,health,"[angular, bootstrap, gradle, health, java, jhipster, spring-boot, typescript, webpack]",62
fast-ide,fast-ide,fast-ide,https://github.com/fast-ide/fast-ide,https://api.github.com/repos/fast-ide/fast-ide,🕺Fast Integrated Development Environment  😻,"![ci_dockerfile](https://github.com/fast-ide/fast-ide/workflows/ci_dockerfile/badge.svg?branch=master)
[![Build Status](https://travis-ci.org/fast-ide/fast-ide.svg?branch=master)](https://travis-ci.org/fast-ide/fast-ide)
[![Gitter](https://img.shields.io/badge/chat-gitter-brightgreen.svg)](https://gitter.im/fast-ide/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)
[![Slack](https://img.shields.io/badge/workspace-slack-blue.svg)](https://fastide.slack.com)
![Platform](https://img.shields.io/badge/Platform-MacOS%20|%20Linux%20|%20Windows-blue.svg)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/fast-ide/fast-ide/blob/master/LICENSE)

We will be happy to treat everyone who helps us with coffee ☕ and more, send us a link to your account <br />
on the [ko-fi](https://ko-fi.com) service in [gitter](https://gitter.im/fast-ide/community) and you can put a star ⭐ as a reminder for us

## Introduction

💨 The **Fast IDE** you can only dream of ⛅

> The developer needs three things:
> 1. Email
> 2. GitHub account
> 3. Ability to fast develop anywhere and on anything

For the third thing we created the **Fast IDE**<br/>
We believe that development tools should be available to everyone and therefore **free** of charge ✌️

We've taken tools that have been proven for decades and <br/>
added cool new features and integrated them into a single solution 🌟

<img src=""https://raw.githubusercontent.com/fast-ide/fast-ide/master/docs/preview.png""/>

## Table of Contents

- [Introduction](#introduction)
- [Instructions](#instructions)
  * [Run](#run)
  * [Update](#update)
  * [Supported OSs](#supported-oss)
  * [Build](#build)
  * [Install](#install)
  * [Deploy](#deploy)
  * [Configuration](#configuration)
  * [Font settings](#font-settings)
  * [Themes 🎨](#themes-)
  * [True color](#true-color)
  * [Toolbox 🧰](#toolbox-)
  * [Maps](#maps)
    + [tmux](#tmux)
    + [terminal](#terminal)
    + [nvim](#nvim)
      - [normal mode](#normal-mode)
      - [insert mode](#insert-mode)
      - [command mode](#command-mode)
      - [visual mode](#visual-mode)
      - [improved maps](#improved-maps)
      - [tmux integration](#tmux-integration)
      - [linter integration](#linter-integration)
  * [How To](#how-to)
- [Plans 💡](#plans-)
- [Powered by ✨](#powered-by)
- [Contributing 🤝](#contributing-)
- [Sponsorship 👏](#sponsorship-)
- [License](#license)

## Instructions

We want to provide you with tools that will help you reach your full potential 🧑‍🚀<br/>
`tmux` `zsh` `brew` `neovim` `coc.nvim`

Available out of the box now:

- [x] C++ 20 (`cmake`)
- [x] Python 3 (`pip`)
- [x] Golang 1.14 (`go`)
- [x] Node.js 12.15 (`npm`)

### Run

```sh
docker run -it fastide/alpine zsh
```

### Update

```sh
# for example update on Ubuntu Focal Fossa 🐱
docker run -it fastide/ubuntu:20.04 zsh
git clone https://github.com/fast-ide/fast-ide
cd fast-ide && ./install.sh
```

### Supported OSs

```yaml
# see deploy or run section
- alpine
- centos 8
- debian 10
- fedora 35
- ubuntu 20.04
```

```yaml
# see install section
- macos
```

### Build

Example for ubuntu 20.04:

```sh
# build brew image 
cd toolbox/linuxbrew
pushd docker/ubuntu-20.04
tar -czh . | docker build -t fastide/linuxbrew-ubuntu:20.04 -
popd

# build toolbox image
cd ..
docker build -t fastide/toolbox-ubuntu:20.04 --build-arg OS_FAMILY=ubuntu --build-arg OS_VERSION=20.04 .

# build fastide image
cd ..
docker build -t fastide/ubuntu:20.04 --build-arg OS_FAMILY=ubuntu --build-arg OS_VERSION=20.04 .

# after run
docker run -it fastide/ubuntu:20.04 zsh
```

### Install

```sh
git clone --recursive https://github.com/fast-ide/fast-ide
cd fast-ide/toolbox && make all
cd .. && make install
```

### Deploy

```sh
# for example deploy Fast IDE on your CentOS 8 🐧
docker pull fastide/ubuntu:20.04
docker create -ti --name fastide fastide/ubuntu:20.04 bash
docker cp fastide:/home/developer /home/ # docker rm -f fastide
sudo useradd developer && sudo passwd developer
sudo chown -R developer /home/developer
sudo usermod -aG sudo developer # optional
su - developer
zsh
```

### Configuration

See the corresponding configuration files:
```
- $HOME/.zshrc
- $HOME/.tmux.conf
- $HOME/.config/nvim/init.vim
```

### Font settings

```
Monaco
Apple Color Emoji (Non-ASCII Font)

FiraCode # alternative (see https://github.com/tonsky/FiraCode/wiki/Installing)
```

### Themes 🎨

```yaml
onedark:
  vim: https://github.com/joshdick/onedark.vim
  terminal: 
  - https://github.com/joshdick/onedark.vim/tree/master/term
  - https://github.com/denysdovhan/one-gnome-terminal

onehalf: # alternative
  vim: https://github.com/sonph/onehalf
  terminal: https://github.com/sonph/onehalf
```

![#f03c15](https://via.placeholder.com/15/61afef/000000?text=+) active (input mode, active tmux window, active tmux pane)
![#f03c15](https://via.placeholder.com/15/98c379/000000?text=+) normal
![#f03c15](https://via.placeholder.com/15/e06c75/000000?text=+) attention (errors, zoomed tmux pane)
![#f03c15](https://via.placeholder.com/15/c678dd/000000?text=+) checks

### True color

If you are using a terminal that does not support _true color_ perform the following script for normal display
 
```sh
nvim -c ""set notermguicolors"" -c ""Tmuxline airline"" -c ""TmuxlineSnapshot! ~/.tmux/line"" +q 
echo ""alias o='nvim -c \""set notermguicolors\""'"" >> ~/.zshrc
```

You can check support using the following instruction:
```sh
# 256 color
awk 'BEGIN{
    s=""/\\/\\/\\/\\/\\""; s=s s s s s s s s;
    for (colnum = 0; colnum<77; colnum++) {
        r = 255-(colnum*255/76);
        g = (colnum*510/76);
        b = (colnum*255/76);
        if (g>255) g = 510-g;
        printf ""\033[48;2;%d;%d;%dm"", r,g,b;
        printf ""\033[38;2;%d;%d;%dm"", 255-r,255-g,255-b;
        printf ""%s\033[0m"", substr(s,colnum+1,1);
    }
    printf ""\n"";
}'

# true color
printf ""\x1b[38;2;255;100;0mTRUECOLOR\x1b[0m\n""
```

### Toolbox 🧰

- [jq](https://stedolan.github.io/jq) and [jid](https://github.com/simeji/jid)
- [git](https://git-scm.com/book/en/v2) and [tig](https://jonas.github.io/tig/doc/manual.html)
- [lf](https://godoc.org/github.com/gokcehan/lf) and [ncdu](https://dev.yorhel.nl/ncdu/man)
- [curl](https://ec.haxx.se) and [httpie](https://httpie.org/docs)
- [wtfutil](https://github.com/wtfutil/wtf) and [gtop](https://github.com/aksakalli/gtop)

We also have [gnupg](https://www.gnupg.org/gph/en/manual.html) inside each docker container from the [list](#supported-oss)<br/>
If you used the [deployment](#deploy) instruction you can install it using your system package manager

### Maps

#### tmux

prefix is **\`** symbol

```
<prefix>|   split the window vertically
<prefix>-   split the window horizontally
<prefix>!   move the pane to a separate window

<prefix>n   next window
<prefix>p   previous window
<prefix>{N} go to the N window (i.e. `3)

<prefix>d   close pane
<prefix>w   new window
<prefix>W   kill window
<prefix>f   find window
<prefix>s   create session
<prefix>S   kill session
<prefix>q   detach session
<prefix>r   source .tmux.conf config file
<prefix>i   install tmux plugins (https://github.com/tmux-plugins/tpm)
<prefix>e   switch to fpp mode (see: https://github.com/facebook/PathPicker)
<prefix>u   opening urls from browser (see: https://github.com/wfxr/tmux-fzf-url)

<prefix>;   go to previous pane
<prefix>l   go to previous window
<prefix>L   go to previous session

<prefix>Tab clear pane
<prefix>c   close window

Shift-Left  resize pane left by 5
Shift-Right resize pane right by 5
Shift-Up    resize pane up by 5
Shift-Down  resize pane down by 5

Ctrl-H      go to the left pane
Ctrl-J      go to the bottom pane
Ctrl-K      go to the top pane
Ctrl-L      go to the right pane
```

<img src=""https://raw.githubusercontent.com/fast-ide/fast-ide/master/docs/tmux.gif""/>

#### terminal

```
Ctrl-A      go to the beginning of the line
Ctrl-E      go to the end of the line

Ctrl-N      next insturction from history
Ctrl-P      previous insturction from history

Alt-C       go to the directory using fuzzy search
Ctrl-R      find the insturction using fuzzy search
Ctrl-T      find file using fuzzy search

Esc         switch to vi mode
```

```sh
# command aliases
alias c=vimcat
alias o=nvim
alias p=echo
alias r=clear
```

<img src=""https://raw.githubusercontent.com/fast-ide/fast-ide/master/docs/zsh.gif""/>

#### nvim

`<Leader>` is `Space` symbol

You can see all settings in the configuration file
```
<Leader>ev  open nvim config file
<Leader>et  open tmux config file
<Leader>ez  open zsh config file
```

##### normal mode


```
Ctrl-E      down 1 line
Ctrl-Y      up 1 line

vv          select line
V           select to the end of the line

yy          yank line
Y           yank to the end of the line

mm          move line
M           move to the end of the line

dd          delete line
D           delete to the end of the line

H           go to the beginning of the line (alias for ^)
L           go to the end of the line (alias for $)

zj          down half the window
zk          up half the window
zz          center the window

Z           quit all

,,          show list of marks
,{m}        set mark m at current cursor location
;{m}        jump to position (line and column) of mark
'{m}        jump to line (line and column) of mark
''          jump back (to line in current buffer where jumped from)
```

###### file manager

```
<Leader>f   open lf file manager (see: https://github.com/gokcehan/lf)
# use the hjkl keys to navigate and press l to open the selected file

<Leader>nn open NerdTree (see: https://github.com/preservim/nerdtree)
```

###### next

```
n           next search
<Leader>wn  next window
<Leader>tn  next tab
<Leader>qn  next item in quickfix list
<Leader>ln  next item in location list
<Leader>bn  next bookmark (see: https://github.com/MattesGroeger/vim-bookmarks)
```

###### previous

```
N           previous search
<Leader>wp  previous window
<Leader>tp  previous tab
<Leader>qp  previous item in quickfix list
<Leader>lp  previous item in location list
<Leader>bp  previous bookmark
```

###### docs

```
K            run a program to lookup the keyword under the cursor
<Leader>kk   display the manpage for the keyword under the cursor horizontally
<Leader>kv   display the manpage for the keyword under the cursor vertically
```

###### highlight

```
<Leader>hh  highlight a word under the cursor (see: https://github.com/t9md/vim-quickhl)
<Leader>hl  toggle show special symbols
<Leader>hs  toggle search highlight
```

###### edit

```
<Leader>we  edit file in new vertical window
<Leader>ee  edit file in current window
<Leader>te  edit file in new tab
```

###### open or only

```
<Leader>wo  (only) close all other windows
<Leader>to  (only) close all other tabs
<Leader>qo  open quickfix list
<Leader>lo  open location list
<Leader>bo  open bookmark list
```

###### close

```
<Leader>wd  (destroy) close window
<Leader>td  (destroy) close tab
<Leader>qd  (destroy) close quickfix list
<Leader>ld  (destroy) close location list
```

###### search

```
s{char}{char}  to move to {char}{char} (see: https://github.com/easymotion/vim-easymotion)

<Leader>fb  find buffer (see: https://github.com/junegunn/fzf.vim)
<Leader>ff  find file
<Leader>fl  find line
<Leader>ft  find tag
<Leader>fh  find find a file among previously opened files

<Leader>ss  find file type (syntax)
<Leader>sl  find line in the current buffer
<Leader>st  find tag in the current buffer

\           grep word under cursor (see: https://github.com/mileszs/ack.vim)
```

###### preview tag

```
|           preview tag (see: https://github.com/skywind3000/vim-preview)
<Leader>pd  (destroy) close preview
```

`<Leader>ft` generates the **tags** of the file if it is missing
or you can generate it manually if necessary
```sh
ctags -R --c++-kinds=+p --fields=+iaS --extras=+q --language-force=C++ # C++
ctags -R --fields=+l --languages=python --python-kinds=-iv             # Python
gotags -R ./**/*.go > tags                                             # Go
ctags -R                                                               # JavaScript
```

###### resize window

`Meta` key is `Alt` or `Option`

```
Ctrl-T      switch to resize window (see: https://github.com/simeji/winresizer)
<Leader>ww  toogle golden ration mode (see: https://github.com/roman/golden-ratio)

Meta-Up    increase the vertical size of the current window
Meta-Down  decrease the vertical size of the current window
Meta-Right increase the horizontal size of the current window
Meta-Left  decrease the horizontal size of the current window
```

##### insert mode

```
Ctrl-E      (like in normal mode)
Ctrl-Y      (like in normal mode)

jj          switch to normal mode (alias for Esc)
```

##### command mode

```
Ctrl-A      (like in terminal)
Ctrl-E      (like in terminal)
Ctrl-N      (like in terminal)
Ctrl-P      (like in terminal)
```

##### visual mode

```
Shift-S     surround object (see: https://github.com/tpope/vim-surround)
```

##### helper functions

```
:Cfilter[!] /{pat}/
:Lfilter[!] /{pat}/
```

##### improved maps

```
.           added support for visual mode
/           added winking and centering
?           added winking and centering

>           added support for continuous shifting
<           added support for continuous shifting

b           added support for camel notation
e           added support for camel notation
w           added support for camel notation
```

##### coding 

```
gd go to symbol definition
gr go to symbol links
gi go to implementation 
(for more information see: https://github.com/neoclide/coc.nvim)
```

C++ projects based on cmake must be built with the `CMAKE_EXPORT_COMPILE_COMMANDS` flag<br/>
and after copying the generated **compile_commands.json** file to the root directory 🔥

interesting settings in the configuration file **.config/nvim/coc-settings.json**
```json
{
  ""suggest"": {
    ""enablePreselect"": true,
    ""enablePreview"": true,
    ""noselect"": false,
    ""numberSelect"": true
  }
}
```

To work correctly with the enabled `numerSelect` option, it is useful<br/>
to add exceptions using abbreviations, for example:
```vim
iabbrev 3u uint32
iabbrev 6u uint64
iabbrev 8u uint8
```

##### debugging

```
<Leader>dc start/continue debugging
<Leader>ds stop debugging
<Leader>dr restart debugging
<Leader>dd reset debugging
<Leader>db set breakpoint
<Leader>di set conditional breakpoint
<Leader>dj step over
<Leader>dh step into
<Leader>dk step out
<Leader>dt run to cursor
<Leader>de evalute keyword under the cursor (see: https://github.com/puremourning/vimspector)
```

##### tmux integration

```
<Leader>vo  open vimux runner (see: https://github.com/benmills/vimux)
<Leader>vp  send selected text to vimux runner
<Leader>V   send text from the cursor to the end of the line to vimux runner
```

##### linter integration

All errors which are identified by the linter are in the location list<br/>
You can navigate to them using the keyboard shortcuts:<br/>
`<Leader>lo`, `<Leader>ln`, `<Leader>lp` (see their description above)<br/>
For more information see: https://github.com/dense-analysis/ale

### How To

> how to build a project with Makefile ?
```
:Make
```
> how to build a project with Makefile in background ?
```
:Asyncrun make
```

> how to build a project without Makefile ?
```vim
"" cmake prjoect example
:Dispatch cmake --build _build
```
> how to build a project without Makefile in background ?
```vim
"" cmake prjoect example
:Asyncrun cmake --build _build
```
> how to run tests for a project ?
```vim
"" go project example
:Dispatch ginkgo ./...
```

You can view the output of commands launched using `AsyncRun`<br />
in the quickfix list using keyboard shortcut: `<Leader>qo`<br />
For more information see:
- https://github.com/tpope/vim-dispatch
- https://github.com/skywind3000/asyncrun.vim

## Plans 💡

We want to change the way we think about the development process, <br />
make it fast, convenient, collaborative, and accessible to everyone

One of the key development vectors is providing the ability to easily deploy the environment <br />
and provide access to other users of the Github service to solve issues together <br />
A cool feature is to make it possible directly from the browser with the ability  <br />
to stream the terminal to the corresponding issue page 🎉 <br />

### health care ❤️

we want to help programmers to be more healthy:
- be able to work remotely from any location so that you don't have to spend time traveling
- perform their duties faster and as a result spend less time at the computer
- work in a color scheme that will protect the eyes from excessive load

## Powered by ✨

Many thanks to the people and organizations that make this possible:

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tr>
    <td align=""center""><a href=""https://tpo.pe/""><img src=""https://avatars0.githubusercontent.com/u/378?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Tim Pope</b></sub></a><br /><a href=""#plugin-tpope"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://andrewra.dev""><img src=""https://avatars3.githubusercontent.com/u/124255?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Andrew Radev</b></sub></a><br /><a href=""#plugin-AndrewRadev"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/Chiel92""><img src=""https://avatars0.githubusercontent.com/u/1030961?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Chiel ten Brinke</b></sub></a><br /><a href=""#plugin-Chiel92"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://idagio.com""><img src=""https://avatars0.githubusercontent.com/u/187211?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Mattes Groeger</b></sub></a><br /><a href=""#plugin-MattesGroeger"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://vinarian.blogspot.com/""><img src=""https://avatars3.githubusercontent.com/u/41495?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Shougo</b></sub></a><br /><a href=""#plugin-Shougo"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/Xuyuanp""><img src=""https://avatars0.githubusercontent.com/u/2245664?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Xuyuan Pang</b></sub></a><br /><a href=""#plugin-Xuyuanp"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://airbladesoftware.com""><img src=""https://avatars0.githubusercontent.com/u/7265?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Andy Stewart</b></sub></a><br /><a href=""#plugin-airblade"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://doist.com/""><img src=""https://avatars1.githubusercontent.com/u/184462?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Amir Salihefendic</b></sub></a><br /><a href=""#plugin-amix"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://benmills.org""><img src=""https://avatars2.githubusercontent.com/u/55991?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Ben Mills</b></sub></a><br /><a href=""#plugin-benmills"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/bkad""><img src=""https://avatars0.githubusercontent.com/u/425989?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Kevin Le</b></sub></a><br /><a href=""#plugin-bkad"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://blog.256bit.org""><img src=""https://avatars0.githubusercontent.com/u/244927?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Christian Brabandt</b></sub></a><br /><a href=""#plugin-chrisbra"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://ctoomey.com""><img src=""https://avatars2.githubusercontent.com/u/420113?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Chris Toomey</b></sub></a><br /><a href=""#plugin-christoomey"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://dhruvasagar.com/""><img src=""https://avatars0.githubusercontent.com/u/88258?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Dhruva Sagar</b></sub></a><br /><a href=""#plugin-dhruvasagar"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/easymotion""><img src=""https://avatars1.githubusercontent.com/u/13000476?v=4"" width=""100px;"" alt=""""/><br /><sub><b>easymotion</b></sub></a><br /><a href=""#plugin-easymotion"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://evgeni.io""><img src=""https://avatars3.githubusercontent.com/u/1532071?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Evgeni Kolev</b></sub></a><br /><a href=""#plugin-edkolev"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://gregd.org""><img src=""https://avatars3.githubusercontent.com/u/857809?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Greg Dietsche</b></sub></a><br /><a href=""#plugin-farmergreg"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://arslan.io""><img src=""https://avatars1.githubusercontent.com/u/438920?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Fatih Arslan</b></sub></a><br /><a href=""#plugin-fatih"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://rumkin.com/""><img src=""https://avatars0.githubusercontent.com/u/428348?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Tyler Akins</b></sub></a><br /><a href=""#plugin-fidian"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/godlygeek""><img src=""https://avatars3.githubusercontent.com/u/29423?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Matt Wozniski</b></sub></a><br /><a href=""#plugin-godlygeek"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://www.gregsexton.org""><img src=""https://avatars0.githubusercontent.com/u/150883?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Greg Sexton</b></sub></a><br /><a href=""#plugin-gregsexton"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://medium.com/@haya14busa""><img src=""https://avatars0.githubusercontent.com/u/3797062?v=4"" width=""100px;"" alt=""""/><br /><sub><b>haya14busa</b></sub></a><br /><a href=""#plugin-haya14busa"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://honza.ca""><img src=""https://avatars3.githubusercontent.com/u/206357?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Honza Pokorny</b></sub></a><br /><a href=""#plugin-honza"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/inside""><img src=""https://avatars2.githubusercontent.com/u/107884?v=4"" width=""100px;"" alt=""""/><br /><sub><b>inside</b></sub></a><br /><a href=""#plugin-inside"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/itchyny""><img src=""https://avatars2.githubusercontent.com/u/375258?v=4"" width=""100px;"" alt=""""/><br /><sub><b>itchyny</b></sub></a><br /><a href=""#plugin-itchyny"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://jeffkreeftmeijer.com""><img src=""https://avatars0.githubusercontent.com/u/43621?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Jeff Kreeftmeijer</b></sub></a><br /><a href=""#plugin-jeffkreeftmeijer"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://www.jiangmiao.org""><img src=""https://avatars1.githubusercontent.com/u/80519?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Miao Jiang</b></sub></a><br /><a href=""#plugin-jiangmiao"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://paypal.me/junegunn""><img src=""https://avatars2.githubusercontent.com/u/700826?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Junegunn Choi</b></sub></a><br /><a href=""#plugin-junegunn"" title=""Plugin/utility libraries"">🔌</a> <a href=""#tool-junegunn"" title=""Tools"">🔧</a></td>
    <td align=""center""><a href=""https://github.com/kshenoy""><img src=""https://avatars3.githubusercontent.com/u/1559554?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Kartik Shenoy</b></sub></a><br /><a href=""#plugin-kshenoy"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://hashnote.net/""><img src=""https://avatars0.githubusercontent.com/u/546312?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Alisue</b></sub></a><br /><a href=""#plugin-lambdalisue"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://machakann.hatenablog.com/""><img src=""https://avatars2.githubusercontent.com/u/480049?v=4"" width=""100px;"" alt=""""/><br /><sub><b>machakann</b></sub></a><br /><a href=""#plugin-machakann"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/majutsushi""><img src=""https://avatars3.githubusercontent.com/u/465527?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Jan Larres</b></sub></a><br /><a href=""#plugin-majutsushi"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://bloerg.net""><img src=""https://avatars3.githubusercontent.com/u/115270?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Matthias Vogelgesang</b></sub></a><br /><a href=""#plugin-matze"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://twitter.com/_mhinz_""><img src=""https://avatars0.githubusercontent.com/u/972014?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Marco Hinz</b></sub></a><br /><a href=""#plugin-mhinz"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://mileszs.com""><img src=""https://avatars0.githubusercontent.com/u/2425?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Miles Z. Sterrett</b></sub></a><br /><a href=""#plugin-mileszs"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/nathanaelkane""><img src=""https://avatars1.githubusercontent.com/u/84757?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Nate Kane</b></sub></a><br /><a href=""#plugin-nathanaelkane"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://github.com/neoclide""><img src=""https://avatars1.githubusercontent.com/u/23586922?v=4"" width=""100px;"" alt=""""/><br /><sub><b>neoclide</b></sub></a><br /><a href=""#plugin-neoclide"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://ntpeters.com""><img src=""https://avatars2.githubusercontent.com/u/1189211?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Nate Peterson</b></sub></a><br /><a href=""#plugin-ntpeters"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://plasticboy.com/""><img src=""https://avatars1.githubusercontent.com/u/54499?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Ben Williams</b></sub></a><br /><a href=""#plugin-plasticboy"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://www.squishythoughts.com""><img src=""https://avatars0.githubusercontent.com/u/6490160?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Richard Adenling</b></sub></a><br /><a href=""#plugin-radenling"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://rhysd.github.io/""><img src=""https://avatars3.githubusercontent.com/u/823277?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Linda_pp</b></sub></a><br /><a href=""#plugin-rhysd"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://blog.roman-gonzalez.ca""><img src=""https://avatars3.githubusercontent.com/u/7335?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Roman Gonzalez</b></sub></a><br /><a href=""#plugin-roman"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://iccf.nl""><img src=""https://avatars2.githubusercontent.com/u/10584846?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Ben Jackson</b></sub></a><br /><a href=""#plugin-vimspector"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://github.com/scrooloose""><img src=""https://avatars1.githubusercontent.com/u/1671?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Martin Grenfell</b></sub></a><br /><a href=""#plugin-scrooloose"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://twitter.com/simeji""><img src=""https://avatars0.githubusercontent.com/u/368024?v=4"" width=""100px;"" alt=""""/><br /><sub><b>simeji</b></sub></a><br /><a href=""#plugin-simeji"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://stevelosh.com""><img src=""https://avatars0.githubusercontent.com/u/58365?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Steve Losh</b></sub></a><br /><a href=""#plugin-sjl"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://twitter.com/skywind3000""><img src=""https://avatars3.githubusercontent.com/u/3035071?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Linwei</b></sub></a><br /><a href=""#plugin-skywind3000"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://sonpham.me/""><img src=""https://avatars2.githubusercontent.com/u/2466660?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Son A. Pham</b></sub></a><br /><a href=""#plugin-sonph"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://www.stevevermeulen.com""><img src=""https://avatars3.githubusercontent.com/u/810762?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Steve Vermeulen</b></sub></a><br /><a href=""#plugin-svermeulen"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://twitter.com/t9md""><img src=""https://avatars3.githubusercontent.com/u/155205?v=4"" width=""100px;"" alt=""""/><br /><sub><b>t9md</b></sub></a><br /><a href=""#plugin-t9md"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://terry.ma""><img src=""https://avatars3.githubusercontent.com/u/567259?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Terry Ma</b></sub></a><br /><a href=""#plugin-terryma"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/tmux-plugins""><img src=""https://avatars3.githubusercontent.com/u/8289877?v=4"" width=""100px;"" alt=""""/><br /><sub><b>tmux-plugins</b></sub></a><br /><a href=""#plugin-tmux-plugins"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://tommcdo.com""><img src=""https://avatars2.githubusercontent.com/u/1991483?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Tom McDonald</b></sub></a><br /><a href=""#plugin-tommcdo"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/vim-airline""><img src=""https://avatars2.githubusercontent.com/u/16690788?v=4"" width=""100px;"" alt=""""/><br /><sub><b>vim-airline</b></sub></a><br /><a href=""#plugin-vim-airline"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://voldikss.github.io""><img src=""https://avatars1.githubusercontent.com/u/20282795?v=4"" width=""100px;"" alt=""""/><br /><sub><b>最上川</b></sub></a><br /><a href=""#plugin-voldikss"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://vimwiki.github.io/""><img src=""https://avatars1.githubusercontent.com/u/2800895?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Vimwiki</b></sub></a><br /><a href=""#plugin-vimwiki"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://w0rp.com""><img src=""https://avatars2.githubusercontent.com/u/3518142?v=4"" width=""100px;"" alt=""""/><br /><sub><b>w0rp</b></sub></a><br /><a href=""#plugin-w0rp"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://www.adjust.com""><img src=""https://avatars1.githubusercontent.com/u/474504?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Christian Wellenbrock</b></sub></a><br /><a href=""#plugin-wellle"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/wesQ3""><img src=""https://avatars2.githubusercontent.com/u/438799?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Wes Malone</b></sub></a><br /><a href=""#plugin-wesQ3"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://wlee.net""><img src=""https://avatars0.githubusercontent.com/u/1441568?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Will Lee</b></sub></a><br /><a href=""#plugin-will133"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://www.arashrouhani.com""><img src=""https://avatars1.githubusercontent.com/u/294349?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Arash Rouhani</b></sub></a><br /><a href=""#plugin-Tarrasch"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://www.adolfoabegg.com""><img src=""https://avatars0.githubusercontent.com/u/96985?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Adolfo Abegg</b></sub></a><br /><a href=""#plugin-adolfoabegg"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://www.elsiecarlisle.com""><img src=""https://avatars1.githubusercontent.com/u/7599319?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Alexandros Kozák</b></sub></a><br /><a href=""#plugin-agkozak"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/cal2195""><img src=""https://avatars1.githubusercontent.com/u/9119112?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Cal Martin</b></sub></a><br /><a href=""#plugin-cal2195"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://www.denysdovhan.com""><img src=""https://avatars1.githubusercontent.com/u/3459374?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Denys Dovhan</b></sub></a><br /><a href=""#plugin-denysdovhan"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://djui.io""><img src=""https://avatars3.githubusercontent.com/u/99752?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Uwe Dauernheim</b></sub></a><br /><a href=""#plugin-djui"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://dev.to/konstantin""><img src=""https://avatars1.githubusercontent.com/u/1726487?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Konstantin</b></sub></a><br /><a href=""#plugin-gko"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://hschne.at""><img src=""https://avatars3.githubusercontent.com/u/5294464?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Hans-Jörg Schnedlitz</b></sub></a><br /><a href=""#plugin-hschne"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://joel.porquet.org""><img src=""https://avatars3.githubusercontent.com/u/7941818?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Joël Porquet</b></sub></a><br /><a href=""#plugin-joel-porquet"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://github.com/leophys""><img src=""https://avatars0.githubusercontent.com/u/382161?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Blallo</b></sub></a><br /><a href=""#plugin-leophys"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://mollifier.hatenablog.com/""><img src=""https://avatars0.githubusercontent.com/u/76955?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Hideaki Miyake</b></sub></a><br /><a href=""#plugin-mollifier"" title=""Plugin/utility libraries"">🔌</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""http://velvetpulse.com""><img src=""https://avatars1.githubusercontent.com/u/297060?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Nicolas Viennot</b></sub></a><br /><a href=""#plugin-nviennot"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://robertzk.com""><img src=""https://avatars3.githubusercontent.com/u/1638492?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Robert Krzyzanowski</b></sub></a><br /><a href=""#plugin-robertzk"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://unixorn.github.io""><img src=""https://avatars3.githubusercontent.com/u/23920?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Joe Block</b></sub></a><br /><a href=""#plugin-unixorn"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""http://zdharma.org""><img src=""https://avatars2.githubusercontent.com/u/26310601?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Zdharma Initiative</b></sub></a><br /><a href=""#plugin-zdharma"" title=""Plugin/utility libraries"">🔌</a></td>
    <td align=""center""><a href=""https://ohmyz.sh""><img src=""https://avatars1.githubusercontent.com/u/22552083?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Oh My Zsh</b></sub></a><br /><a href=""#plugin-ohmyzsh"" title=""Plugin/utility libraries"">🔌</a></td>
     <td align=""center""><a href=""https://github.com/gokcehan""><img src=""https://avatars0.githubusercontent.com/u/1835672?v=4"" width=""100px;"" alt=""""/><br /><sub><b>gokcehan</b></sub></a><br /><a href=""#tool-gokcehan"" title=""Tools"">🔧</a></td>
    <td align=""center""><a href=""http://japh.se""><img src=""https://avatars2.githubusercontent.com/u/43331?v=4"" width=""100px;"" alt=""""/><br /><sub><b>magnus woldrich</b></sub></a><br /><a href=""#tool-trapd00r"" title=""Tools"">🔧</a></td>
  </tr>
  <tr>
    <td align=""center""><a href=""https://opensource.fb.com""><img src=""https://avatars3.githubusercontent.com/u/69631?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Facebook</b></sub></a><br /><a href=""#tool-facebook"" title=""Tools"">🔧</a></td>
    <td align=""center""><a href=""https://neovim.io""><img src=""https://avatars3.githubusercontent.com/u/6471485?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Neovim</b></sub></a><br /><a href=""#infra-neovim"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
<td align=""center""><a href=""http://www.zsh.org""><img src=""https://avatars2.githubusercontent.com/u/567410?v=4"" width=""100px;"" alt=""""/><br /><sub><b>zsh-users</b></sub></a><br /><a href=""#tool-zsh-users"" title=""Tools""></a> <a href=""#infra-zsh-users"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
    <td align=""center""><a href=""https://brew.sh""><img src=""https://avatars2.githubusercontent.com/u/1503512?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Homebrew</b></sub></a><br /><a href=""#infra-Homebrew"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
    <td align=""center""><a href=""https://www.docker.com""><img src=""https://avatars1.githubusercontent.com/u/5429470?v=4"" width=""100px;"" alt=""""/><br /><sub><b>Docker</b></sub></a><br /><a href=""#infra-docker"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
    <td align=""center""><a href=""https://github.com/about""><img src=""https://avatars1.githubusercontent.com/u/9919?v=4"" width=""100px;"" alt=""""/><br /><sub><b>GitHub</b></sub></a><br /><a href=""#infra-github"" title=""Infrastructure (Hosting, Build-Tools, etc)"">🚇</a></td>
    <td align=""center""><a href=""https://allcontributors.org""><img src=""https://avatars1.githubusercontent.com/u/46410174?v=4"" width=""100px;"" alt=""""/><br /><sub><b>All Contributors</b></sub></a><br /><a href=""https://github.com/fast-ide/fast-ide/commits?author=all-contributors"" title=""Documentation"">📖</a></td>
  </tr>
</table>

## Contributing 🤝

- You can describe a cool feature by creating an issue with a description and the `feature` label <br />
- See the issue list, we have a `help wanted` label for those tasks that you can help solve<br />
- You can assign the problem to yourself, specify the milestone, and prepare a PR<br />
- We have a `question` label for issues where we want to hear your opinion<br />

## Sponsorship 👏

We are grateful to the maintainers of the following projects for their great work. We are redirecting all revenue to them:

<a href=""https://www.patreon.com/gnachman""><img src=""https://img.shields.io/badge/patreon-iterm-orange.svg"" /></a>
<a href=""https://liberapay.com/tmux""><img src=""https://img.shields.io/badge/liberapay-tmux-orange.svg"" /></a>
<a href=""https://www.patreon.com/tonsky""><img src=""https://img.shields.io/badge/patreon-firacode-orange.svg"" /></a>
<a href=""https://www.patreon.com/homebrew""><img src=""https://img.shields.io/badge/patreon-homebrew-orange.svg"" /></a>
<a href=""https://www.patreon.com/wtfutil""><img src=""https://img.shields.io/badge/patreon-wtfutil-orange.svg"" /></a>
<a href=""https://salt.bountysource.com/teams/neovim""><img src=""https://img.shields.io/badge/bountysource-neovim-orange.svg"" /></a>
<a href=""https://www.patreon.com/chemzqm""><img src=""https://img.shields.io/badge/patreon-cocnvim-orange.svg"" /></a>
<a href=""https://github.com/sponsors/tpope""><img src=""https://img.shields.io/badge/sponsors-tpope-orange.svg"" /></a>
<a href=""https://www.patreon.com/umputun""><img src=""https://img.shields.io/badge/patreon-radio_t-orange.svg"" /></a>
",206,206,7,76,health,"[brew, cloud, collaboration, cool, fast, health, ide, modern, neovim, portable, professional, tmux, toolbox, vim, zsh]",62
citiususc,calendula,citiususc,https://github.com/citiususc/calendula,https://api.github.com/repos/calendula/citiususc,An Android assistant for personal medication management,"![](https://tec.citius.usc.es/calendula/github-assets/calendula_promo_google_play.png)
# Calendula

Calendula is an Android assistant for personal medication management, aimed at those who have trouble following their medication regimen, forget to take their drugs, or have complex schedules that are difficult to remember.

The app is available for download in Google Play, F-Droid and Github.
<table>
    <tr>
        <td align=""center""><a href=""https://play.google.com/store/apps/details?id=es.usc.citius.servando.calendula""><img src=""https://play.google.com/intl/en_us/badges/images/badge_new.png"" alt=""Get it on Google Play"" ></a></td>
        <td align=""center""><a href=""https://f-droid.org/packages/es.usc.citius.servando.calendula/""><img src=""https://gitlab.com/fdroid/artwork/raw/master/badge/get-it-on.png"" alt=""Get it on F-Droid"" height=""68""></a></td>
        <td align=""center""><a href=""https://github.com/citiususc/calendula/releases/latest""><img src=""https://user-images.githubusercontent.com/663460/26973090-f8fdc986-4d14-11e7-995a-e7c5e79ed925.png"" alt=""Get it on Github"" height=""68""></a></td>
    </tr>
</table>

Visit our web page for more info  [https://citius.usc.es/calendula/](https://citius.usc.es/calendula/)

## Calendula News

We have some good news!

Our Regional Public Health Authority (SERGAS) has adopted Calendula to be connected with its Electronic Prescription System, resulting in the extension of previous features from the open source version, to include: 

* Automatic download of the patient medication regime. 
* Access to the medication pickup calendar
* Automatic recommendation of the best dates to optimize the number of visits to pharmacy
* Acess to the anticoagulant dosing regime. 

The integration process has faced two key issues: interoperability and security.

With regard to the first one, the adoption of the international standard HL7-FHIR (Fast Healthcare Interoperability Resources) will smooth the way for an easy deployment in other healthcare systems. 

Regarding security, the OpenID Connect specification has been adopted, allowing Calendula to verify the identity of users based on an authentication performed by an authorization server provided by SERGAS.

Along the way, we have worked on a lot of bug fixes and feature improvements, including: 
* Increase Android API Level to level 29.
* Update notifications and background services to the latest Android versions.
* Update Gradle, Kotlin and Java versions.
* Migrate Android libraries to AndroidX.
* Update the following libraries: Google, Iconics, Material-Drawer, Fast Adapter, ButterKnife, Caldroid and Android Jobs.
* Improve the UI to fix update problems and NPEs. 
* Localization updates: new languages will be included and updates will be provided for existing ones. 
* Memory performance updates: bitmaps will be migrated to vectorial formats. 
* Fixes regarding notifications and battery saving mode: added the option to exclude Calendula from battery saving mode, to avoid Calendula to be suspended, and thus still be able to get notifications all the time. 
* Other minor bug fixes. 

These will soon be made available in this repository and applied to the version in Google Play. Stay tuned!

## Getting Started

These instructions will get you a copy of the project up and running on your local machine ready for development. If you want to help developing the app take a look to the contributing section, at the end.

### Development environment setup

We use [Android Studio](https://developer.android.com/studio/index.html) (the official Android IDE) for development, so we recommend it as the IDE to use in your development environment. Once you install Android Studio, you can use the Android SDK Manager to obtain the SDK tools, platforms, and other components you will need to start developing. The most important are:

* Android SDK Tools and Android SDK Platform-tools (upgrade to their last versions is usually a good idea).
* Android SDK Build-Tools 27.0.3.
* Android 8.1 (API Level 27) SDK Platform.
* Android Support Repository

You can also install other packages like emulators for running the app, if you don't have or don't want to use a real device. The minimum supported Android version is *4.1, Jelly Bean (API level 16).*

### Building and installing the app

First of all you need to get the source code, so clone this repository  on your local machine:

```bash
git clone https://github.com/citiususc/calendula.git
cd calendula
```

Android Studio uses Gradle as the foundation of the build system, but it's not necessary to install it separately. Instead, you can use the included [Gradle Wrapper](https://docs.gradle.org/current/userguide/gradle_wrapper.html). To build the app, open a terminal in the repository folder and run:

```bash
./gradlew clean assembleDevelopDebug
```
*Note: ""developDebug"" is the [build variant](https://developer.android.com/studio/build/build-variants.html) that we use for development. To see other variants, please check `Calendula/build.gradle`.*

Then you may install the app on a device or emulator:

```bash
adb install Calendula/build/apk/develop/debug/developDebug-[version].apk
```

These tasks can also be executed from Android Studio with a few clicks.

## App versions

We maintain releases of Calendula on Google Play, F-Droid and here on Github.

 * The latest version of the app available on those pages reflects the code of the `master` branch.
 * Release branches are usually deployed through the *Google Play BETA channel* before they are made available to everyone. If you want to be a member of the testing community, join the testing group on Google Groups, and you will automatically receive the updates from the BETA channel like normal updates from Google Play.

> Join the  BETA channel: [click here!](https://play.google.com/apps/testing/es.usc.citius.servando.calendula)

Check out the [contributing guidelines](CONTRIBUTING.md) for more info about the branching model.

## How does it look?

We try to follow [Material Design](https://material.google.com/#) principles. Take a look at the result!

  | <img src=""https://tec.citius.usc.es/calendula/github-assets/home.png"" width=""230px""/>  | <img src=""https://tec.citius.usc.es/calendula/github-assets/agenda.png"" width=""230px""/> | <img src=""https://tec.citius.usc.es/calendula/github-assets/schedules.png"" width=""230px""/>
  |:---:|:---:|:---:|
  | <img src=""https://tec.citius.usc.es/calendula/github-assets/aviso.png"" width=""230px""/> | <img src=""https://tec.citius.usc.es/calendula/github-assets/navdrawer.png"" width=""230px""/> | <img src=""https://tec.citius.usc.es/calendula/github-assets/profile.png"" width=""230px""/>

## Future work

We have a lot of development ideas, and we are open to newer ones. Below are some interesting features that could be very useful:

* Information about nearby pharmacies, their locations and timetables
* Trip assistant (how many pills I need for this weekend?)
* Introducing [gamification](https://en.wikipedia.org/wiki/Gamification) concepts to improve adherence.

## Artwork attribution

We are using the the following resources in the app:

* [People Vector Pack](http://www.freepik.com/free-vector/people-avatars_761436.htm) by [Freepik](http://www.freepik.com)
* [Baby](http://www.flaticon.com/free-icon/baby_136272), [Dog](http://www.flaticon.com/free-icon/dog_194178) and [cat](http://www.flaticon.com/free-icon/cat_194179) icons by <a href=""https://www.flaticon.com/"" title=""Flaticon"">Flaticon</a> (<a href=""http://creativecommons.org/licenses/by/3.0/"" title=""Creative Commons BY 3.0"" target=""_blank"">CC 3.0 BY</a>)
* [Alarm clock animation](https://dribbble.com/shots/1114887-Alarm-Clock-GIF) by  [Daan De Deckere](http://daandd.be/)

## Contributing

Feel free to fork and send a pull request if you want to contribute to this project! Notice that Calendula is licensed under the terms of the [GNU General Public License (v3)](LICENSE.md), so by submitting content to the Calendula repository, you release your work under the terms of this license.

Before starting, take a look at our [contribution guidelines](CONTRIBUTING.md).

### I would like to contribute, but I'm not a developer...

If you're not a developer but you want to help, don't worry! You can help [with app translations](CONTRIBUTING.md#help-with-app-translations), by [joining the BETA group](#app-versions), and [much more](CONTRIBUTING.md#i-would-like-to-contribute-but-im-not-a-developer)! Everyone is welcome!

## License

Copyright 2020 CITIUS - USC

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
",196,196,18,49,health,"[android, android-studio, app, google-play, health, medication, reminders]",62
kubukoz,sup,,https://github.com/kubukoz/sup,https://api.github.com/repos/sup/kubukoz,"Composable, purely functional healthchecks in Scala.","# sup

[![Join the chat at https://gitter.im/sup-scala/community](https://badges.gitter.im/sup-scala/community.svg)](https://gitter.im/sup-scala/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
[![Build Status](https://travis-ci.com/kubukoz/sup.svg?branch=master)](https://travis-ci.com/kubukoz/sup)
[![Latest version](https://index.scala-lang.org/kubukoz/sup/sup-core/latest.svg)](https://index.scala-lang.org/kubukoz/sup/sup-core)
[![Maven Central](https://img.shields.io/maven-central/v/com.kubukoz/sup-core_2.12.svg)](http://search.maven.org/#search%7Cga%7C1%7Csup-core)
[![License](http://img.shields.io/:license-Apache%202-green.svg)](http://www.apache.org/licenses/LICENSE-2.0.txt)

[![Powered by cats](https://img.shields.io/badge/powered%20by-cats-blue.svg)](https://github.com/typelevel/cats)
![Gluten free](https://img.shields.io/badge/gluten-free-orange.svg)


'sup (/sʌp/) provides composable, purely functional healthchecks.

```
""com.kubukoz"" %% ""sup-core"" % supVersion
```

Check out [the microsite](https://sup.kubukoz.com) and [the usage guide](https://sup.kubukoz.com/guide). 

## Why?

If your application has any external dependencies, its ability to work properly relies on the availability of these dependencies.
Most applications communicate with at least one database, and sometimes a service provided by someone else (e.g. Amazon S3, PayPal and so on).
It's also common to talk to a message broker (Kafka, RabbitMQ, ActiveMQ, etc.). In the microservice world, your applications will probably talk to each other, as welll.

The last thing you want to happen is some other system's problem causing downtime in yours.
We're living in a world where [the network isn't reliable](https://en.wikipedia.org/wiki/Network_partition),
and even healthy services can fail to respond to your requests due to network issues at any time.

By relying on systems living beyond your application's control, you reduce your [SLA](https://en.wikipedia.org/wiki/Service-level_agreement)
to the lowest SLA of your dependencies. Even if your application has nine nines of availability (99.9999999%) on its own,
but it requires S3 (with uptime of 99.9%) to be up, your application is only available for 99.9% of the time.
 
Because of the risk associated with external services, modern applications employ a range of fault tolerance and isolation mechanisms,
like circuit breakers, rate limiters and bulkheads.
To ensure that our applications handle failure properly, and that we can react to problems in the system
knowing what exactly doesn't work, we also track its health by
[monitoring](https://docs.microsoft.com/en-us/azure/architecture/best-practices/monitoring), tracing and other diagnostics.

We also use health checks.

## Health checks

The health check pattern usually involves having an API endpoint that reports the health of your application,
including the health of each external dependency. It's reasonable that the information the endpoint exposes be cached
and automatically refreshed, and protected by a circuit breaker to ensure that checking the health
doesn't make matters worse.

## Goals of this project

The main goal of sup is to provide a reusable model for working with health checks, as well as
a range of utilities for customizing them by e.g. adding timeouts or error recovery.
It also provides implementations for health checks of some popular integrations (JDBC, HTTP, etc.).

It's a design decision not to include any sort of metrics, response times, version information or other statistics
in sup - they are simply beyond the scope of health checks.
Although some of these can be implemented by users and used with sup, they're not officially supported.

Another design decision is that health is binary - a service is either healthy or not,
and there's no ""unknown"" state.


## Code of conduct

This project supports the [Scala code of conduct](https://www.scala-lang.org/conduct/) and wants communication on all its channels (GitHub etc.) to be inclusive environments.

If you have any concerns about someone's behavior on these channels, contact [Jakub Kozłowski](mailto:kubukoz@gmail.com).
",185,185,6,24,health,"[cats, cats-effect, fp, functional, functional-programming, health, healthcheck, scala, typelevel]",62
frappe,health,frappe,https://github.com/frappe/health,https://api.github.com/repos/health/frappe,Open Source Health Information System,"## Frappe Health

Open source & easy-to-use hospital information system(HIS) for all healthcare organisations.


### Introduction

Frappe Health enables the health domain in ERPNext and has various features that will help healthcare practitioners, clinics and hospitals to leverage the power of Frappe and ERPNext. It is built on Frappe, a full-stack, meta-data driven, web framework, and integrates seamlessly with ERPNext, the most agile ERP software. Frappe Health helps to manage healthcare workflows efficiently and most of the design is based on HL7 FHIR (Fast Health Interoperability Resources).


### Key Features

![Key Features](https://raw.githubusercontent.com/frappe/health/develop/key-features.png)

Key feature sets include Patient management, Outpatient / Inpatient management, Clinical Procedures, Rehabilitation and Physiotherapy, Laboratory management etc. and supports configuring multiple Medical Code Standards. It allows mapping any healthcare facility as Service Units and specialities as Medical Departments.

By integrating with ERPNext, features of ERPNext can also be utilized to manage Pharmacy and supplies, Purchases, Human Resources, Accounts and Finance, Asset Management, Quality etc. Along with authentication and role based access permissions, RESTfullness, extensibility, responsiveness and other goodies, the framework also allows setting up Website, payment integration and Patient portal.


### Installation

Using bench, [install ERPNext](https://github.com/frappe/bench#installation) as mentioned here.

Once ERPNext is installed, add health app to your bench by running

```sh
$ bench get-app healthcare
```

After that, you can install health app on required site by running

```sh
$ bench --site demo.com install-app healthcare
```


### Documentation

Complete documentation for Frappe Health is available at https://frappehealth.com/docs


### License

GNU GPL V3. See [license.txt](https://github.com/frappe/health/blob/develop/license.txt) for more information.


### Credits

Frappe Health module is initially developed by Earthians. Currently, it is developed & maintained by Frappe Team and community contributors.
",173,173,27,56,health,"[emr, erp, erpnext, health, healthcare, hims, opd, patient-management]",62
nutritionfactsorg,daily-dozen-ios,nutritionfactsorg,https://github.com/nutritionfactsorg/daily-dozen-ios,https://api.github.com/repos/daily-dozen-ios/nutritionfactsorg,"Keep track of the foods that Dr. Greger recommends in his NYT's best-selling book, How Not to Die with this iOS app","# Daily Dozen iOS App

<p align=""center""><img src=""README_files/github-dailydozen.jpg"" style=""width: 480px""></p>

## About

In the years of research required to create the more than a thousand evidence-based videos on [NutritionFacts.org][nutritionfacts.org], Michael Greger, MD, FACLM, has arrived at a list of what he considers the most important foods to include in a healthy daily diet. Yes, greens are good for you, but how much should we try to eat each day?

Dr. Greger’s Daily Dozen details the healthiest foods and how many servings of each we should try to check off every day. He explains his rationale in his book [How Not to Die][book]. All his proceeds from his books, DVDs, and speaking engagements is all donated to charity.

## Daily Dozen on the App Store

<a href=""https://apps.apple.com/us/app/dr-gregers-daily-dozen/id1060700802"" alt=""Download from the App Store"" target=""%5fblank""><img src=""README_files/app-store.png"" width=""200""></a>

## Contribute

We would love for you to [contribute][contribute] and help make the Daily Dozen for iOS even better!

Check out our [Contribution Guidelines][contribute] for details on how to get started and our suggested best practices.

## Donate

To help support [NutritionFacts.org][nutritionfacts.org], click [here][donate]

## License

The Daily Dozen iOS App is licensed under the GPLv3

## [Contributors][contributors]

* [Marc Campbell][marc-medley]
* Konstantin Khokhlov <!-- [justaninja] page returns 404 not found -->
* [Will Webb][innerfish]
* [Christi Richards][christirichards]
* [Lauren Hacker][laurenhacker]

**Special thanks to the volunteer efforts of the original creators of the app:**

* **Application Development:** Chan Kruse
* **Application Design:** Allan Portera
* **Photography:** Sangeeta Kumar

## Updates

**3.3.3 (App Store: November 30, 2022)**

* Adds support for Czech language.

**3.3.1 (App Store: Oct 21, 2022)**

* Adds anonymous opt-in analytics to support product improvement..

**3.2.21 (App Store: October 2, 2022)**

* Updated Spanish (es) translation.
    * Difference between the Android and iOS translation were resolved in the [daily-dozen-localization](https://github.com/nutritionfactsorg/daily-dozen-localization) repository. 
    * The common elements of the Android and iOS translations are now the same in the released app.
* Updated Russian (ru) translation.
* General software quality improvements. 

**3.2.11 (App Store: April 22, 2022)**

* Adds Catalan (ca), German (de), Hebrew (he), Polish (pl), Portuguese (pt-BR, pt-PT) and Russian (ru)

**3.2.9 (App Store: July 29, 2021)**

* Improved general support for language translations
* Improved layout for smaller screens
* Fixed case where days completed did not correctly display
* Updated topic link references to website

**3.2.5 (App Store: February 10, 2021)**

* Updated date picker interaction
* Fixed reminder notification
* Fixed issue where date navigation ""Today"" remains as yesterday's date

**3.2.3 (App Store: August 15, 2020)**

* Improved Spanish translation

_Note: Application level language selection via Settings, requires iOS 13 or newer._

**3.2.1 (App Store: July 7, 2020)**

* Restructured to support international localization in general
    * Instances of static English `String` replaced with localizable `NSLocalizedString`
    * Modified Storyboard UI layouts to adapt to string length variance of different languages. 
* Adds Spanish
* Improved data synchronization with HealthKit
* Fixed update between Weight checkbox and Weight entry to match on the display
* Fixed weight chart x-axis scaling

**3.1.0 (App Store: December 17, 2019)**

* Adds 21 Tweaks
* Adds Weight Tracking with Health Kit Integration
* Add Application Tab Controller bar

Improvements:

* Adds settings control to choice between using ""Daily Dozen only"" or ""Daily Dozen + 21 Tweaks"".

* Adds settings control to select whether to use Imperial or Metric type units throughout the app.

**2.0.0 (App Store: March 9, 2018)**

* Brand new design
* Daily Dozen tracking now persists over multiple days
* Visualize your progress over time with our new Charts integration
* Enable a daily reminder with a custom time setting in the Daily Reminder Settings
* Backup your data to your files
* Added additional links in the main menu including The Daily Dozen Cookbook
* Updated About information in the main menu

**1.0.2 (App Store: November 13, 2017)**

* Misspelling fix

**1.0.0 (App Store: December 21, 2015)**

* Initial Release

[nutritionfacts.org]:http://nutritionfacts.org ""NutritionFacts.org - The Latest in Nutrition Research""
[contribute]:CONTRIBUTING.md ""Contribute to the Daily Dozen iOS App""
[contributors]:https://github.com/nutritionfactsorg/daily-dozen-ios/graphs/contributors
[donate]:https://nutritionfacts.org/donate ""Donate to NutritionFacts.org""
[book]:http://nutritionfacts.org/book ""How Not to Die""
[christirichards]:http://github.com/christirichards ""Christi Richards on GitHub""
[innerfish]:https://github.com/innerfish ""Will Webb on Github""
[justaninja]:https://github.com/justaninja ""Konstantin Khokhlov on Github""
[laurenhacker]:http://github.com/lahacker ""Lauren Hacker on Github""
[marc-medley]:http://github.com/marc-medley ""Marc Campbell on Github""
",133,133,22,23,health,"[daily-dozen, food, food-tracker, hacktoberfest-accepted, health, help-wanted, how-not-to-die, ios, nutrition]",62
ashtom,hadge,,https://github.com/ashtom/hadge,https://api.github.com/repos/hadge/ashtom,💪 Export workout data from Health.app on iOS to a GitHub repo,"# Hadge - Health.app Data Git Exporter (for iOS)

[![Build App](https://github.com/ashtom/hadge/actions/workflows/build_app.yml/badge.svg)](https://github.com/ashtom/hadge/actions/workflows/build_app.yml)
[![TestFlight](https://shields.io/static/v1?label=TestFlight&message=Join%20Beta&color=blue)](https://testflight.apple.com/join/rFLkfNSu)

This app serves one simple purpose: Exporting workout data from the Health.app on iOS to a git repo on GitHub. 

At the first launch of the app, you can connect your GitHub account, then the app checks whether a repo with the name `health` exists and, if not, it automatically creates it as a private repo. The initial export dumps all workouts, distances, and daily activity data (the rings on Apple Watch) to .csv files, one per year. The app also registers a background task that gets activated whenever you finish a new workout and then updates the .csv files. 

## TestFlight Beta

You can join the TestFlight Beta [here](https://testflight.apple.com/join/rFLkfNSu). Note that you need to open the link on your iPhone, otherwise TestFlight will show `This beta isn't accepting any new testers right now.` 🙄

## GitHub Actions Workflow

Once you have set up the app (and done some workouts), you can use an Actions workflow to generate workout stats on your GitHub profile. Here's the one from [mine](https://github.com/ashtom):

<img width=""445"" alt=""CleanShot 2021-11-06 at 16 01 29@2x"" src=""https://user-images.githubusercontent.com/70720/140626256-b84c9945-898e-4570-bbdb-deab1ec3ef18.png"">

Steps:

1. Create the file `.github/scripts/hadge.rb` with this [Ruby script](https://gist.github.com/ashtom/1cd9602b122082827b38eb79d605ca1a).
2. Adjust the `DISPLAYED_ACTIVITIES` near the top of the script to match your top workouts. More than 5 won't fit into a pinned gist.
3. Create the file `.github/workflows/hadge.yml` with this [workflow](https://gist.github.com/ashtom/0ca3193ce0ac76f9c6bf0b3aa9cad124).
4. Enable Actions on your repo.
5. Create a new public GitHub Gist [here](https://gist.github.com/).
6. Create a personal access token with the gist scope [here](https://github.com/settings/tokens/new). Copy it.
7. Go yo your repo settings, tab `Secrets`.
8. Create a secret `GH_TOKEN` with the personal access token copied in step 6.
9. Create a secret `GIST_ID` with the ID of the gist from step 5. The ID is the last part of the gist's URL.
10. Trigger an Actions run, either by finished a workout 🙃 or by tapping on a workout in the app, then on the ⊕ icon in the bottom-right corner.

Find other awesome pinned gists in matchai's [awesome-pinned-gists repo](https://github.com/matchai/awesome-pinned-gists).

#### Building

Hadge relies on [swiftlint](https://realm.github.io/SwiftLint/) and 
[sourcery](https://github.com/krzysztofzablocki/Sourcery). They can be installed 
via [homebrew](https://brew.sh) via the provided `Brewfile` by running `brew bundle`
or manually.

Hadge requires a GitHub OAuth application. You will need to create an [OAuth App](https://docs.github.com/en/developers/apps/building-oauth-apps) 
to test and build a version of the application. Once you have your App, you will need to create a `Secrets.xcconfig`
file  locally at the appropriate path that contains the Client ID and Client Secret.

You can locally override the Xcode settings for code signing
by creating a `DeveloperSettings.xcconfig` file locally at the appropriate path.

This allows for a pristine project with theis own OAuth App and code signing set up with the appropriate
developer ID and certificates, and for a developer to be able to have local settings
without needing to check in anything into source control.

You can do this in one of two ways: using the included `setup.sh` script or the files manually.

##### Using `setup.sh`

- Open Terminal and `cd` into the project directory. 
- Run this command to ensure you have execution rights for the script: `chmod +x setup.sh`
- Execute the script with the following command: `./setup.sh` and complete the answers.

##### Manually 

Create a plain text file at the root of the project directory named `DeveloperSettings.xcconfig` and
give it the contents:

```
CODE_SIGN_IDENTITY = Apple Development
DEVELOPMENT_TEAM = <Your Team ID>
CODE_SIGN_STYLE = Automatic
ORGANIZATION_IDENTIFIER = <Your Domain Name Reversed>
```

Set `DEVELOPMENT_TEAM` to your Apple supplied development team.  You can use Keychain
Access to [find your development team ID](/Technotes/FindingYourDevelopmentTeamID.md).
Set `ORGANIZATION_IDENTIFIER` to a reversed domain name that you control or have made up.

Create a plain text file at the root of the project directory named `Hadge/Secrets.xcconfig` and
give it the contents:

```
GITHUB_CLIENT_ID = ""<Your GitHub App Client ID>""
GITHUB_CLIENT_SECRET = ""<Your GitHub App Client Secrent>""
```

Set `GITHUB_CLIENT_ID` to your GitHub App Client ID and `GITHUB_CLIENT_SECRET` to your 
GitHub App Client Secret.

Now you should be able to build without code signing errors and without modifying
the project

## Privacy Policy

This Privacy Policy describes how your personal information is handled in Hadge for iOS.

We do not collect, use, save, or shared any of your personal data. Hadge exports your workout data to a private GitHub repository in your personal GitHub account. To do this, the app needs access to your Health data. You can choose to disable this at any time in the Health app or by deinstalling Hadge app.

Hadge does not collect any data for any other purposes, and does not send any data to any service other than GitHub. The connection between Hadge and GitHub is directly established through the GitHub API, secured by SSL, and authenticated through your GitHub user. You can delete this connection at any time by revoking the token in your GitHub account settings or by deinstalling Hadge app.

We don’t collect personal information from anyone, including children under the age of 13.

## License

Hadge is published under the MIT License.

Copyright (c) 2020-2021 Thomas Dohmke

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
",128,128,6,1,health,"[health, ios-app, pinned-gist, swift, workouts]",62
jeffshek,open,,https://github.com/jeffshek/open,https://api.github.com/repos/open/jeffshek,The most boring open source you've ever seen ....,"<a href=""https://github.com/ambv/black""><img alt=""Code style: black"" src=""https://img.shields.io/badge/code%20style-black-000000.svg""></a>
[![CircleCI](https://circleci.com/gh/jeffshek/open.svg?style=svg)](https://circleci.com/gh/jeffshek/open) [![Python 3
.6](https://img.shields.io/badge/python-3.6-blue.svg)](https://www.python.org/downloads/release/python-360/)
[![codebeat badge](https://codebeat.co/badges/11be282f-cbaa-4c8f-bfb9-539e1c7e2366)](https://codebeat.co/projects/github-com-jeffshek-open-master)
![CookieCutter](https://img.shields.io/badge/built%20with-Cookiecutter%20Django-ff69b4.svg)
[![Coverage Status](https://coveralls.io/repos/github/jeffshek/open/badge.svg?branch=master)](https://coveralls.io/github/jeffshek/open?branch=master)

Hi. This my personal repo I'm using to contain all my open source ideas. It serves as my justification to try out new
ideas, but with an overengineered infrastructure and libraries to support scaling and doing things ""my way"".

If you're familiar with Django, this will be very similar. Unfortunately due to time constraints, I can't offer free
 support.

##### Table of Contents  
- [BetterSelf.io](#httpsbetterselfio) 
- [WriteUp.AI](#httpswriteupai)  
- [Development Setup](#development)  
- [What's Next](#whats-next)  

## https://betterself.io
* BetterSelf - A dashboard that lets you track your body's health. Includes supplements and medications, sleep, food, activities and more! This is being actively worked on at the moment, but mobile apps should be coming (soon). 

![Overview](https://user-images.githubusercontent.com/392678/29753424-259da854-8b3f-11e7-8869-667aa6a12007.png)

## https://writeup.ai
### Lots of Credit To ....
* [OpenAI](https://openai.com/blog/better-language-models/) for generating and releasing GPT-2 Medium
* [HuggingFace](https://github.com/huggingface/pytorch-transformers) for making PyTorch extensions
* [Google Cloud Platform](https://cloud.google.com/) it's been a pleasure using GCP to host this
* This is mostly open-sourced, but there is a separate private repo that handles all the deployments and the ML services. That was too hard to open-source without making my life too hard. But it's probably the easiest one to code - it only consists of a microservice and a web app hosting models.
* I'll be releasing a huge writeup about how this was built on my [blog](https://senrigan.io/blog/).

## What's Next

In the future, I'm expecting to move a lot of machine learning projects about health into this repo. In the upcoming month, as I move things over bit by bit, this will be home to

* A drug discovery generator
* A clinical trial analytics engine
* More applied machine learning projects in health and medicine


## Development

### To start a local web server
~~~bash
1) mkdir -p .envs/local && touch .django
2) Add some random env_varibles in there
3) Run docker-compose -f local.ym up
4) Profit
~~~

### To install pre-commit hooks
~~~bash
# probably be on a virtualenv where calling python results in py3+

1. pip install pre-commit
2. pre-commit install
~~~
",125,125,1,28,health,"[django, django-rest-framework, health, health-dashboard, health-informatics, machine-learning, quantified-self, statistics, writeup]",62
skydoves,All-In-One,,https://github.com/skydoves/All-In-One,https://api.github.com/repos/All-In-One/skydoves,:necktie: Health care application for reminding health-todo lists and making healthy habits every day.,"# All-In-One
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![API](https://img.shields.io/badge/API-17%2B-brightgreen.svg?style=flat)](https://android-arsenal.com/api?level=17) </br></br>
__All-In-One__ is a health care application for reminding health-todo lists and helping healthy habits everyday.</br>
This project based on clean android architecture components and material design & animations.
<img src=""https://user-images.githubusercontent.com/24237865/58887425-903b0100-8720-11e9-84c8-8a0ad490da5f.png"" align=""right"" width=""16%""><br>

## Build Status

[![CircleCI](https://circleci.com/gh/skydoves/All-In-One.svg?style=svg&circle-token=ef4da085718a1bccf86a79f36d16f21ace2d56dd)](https://circleci.com/gh/skydoves/All-In-One)

## Introduction

Simple introduction about this application like systems and permissions simply.

![KakaoTalk_20190603_185505188](https://user-images.githubusercontent.com/24237865/58793529-43c4c800-8631-11e9-8619-8094da0a6988.jpg)
![KakaoTalk_20190602_211747901](https://user-images.githubusercontent.com/24237865/58793527-432c3180-8631-11e9-82e9-e20819c559a0.jpg)
![KakaoTalk_20190603_183521857](https://user-images.githubusercontent.com/24237865/58793528-432c3180-8631-11e9-994a-fa93992d3cdf.jpg)

## Today Weather

Providing daily weather information for planning todo.

![KakaoTalk_20190602_211441738](https://user-images.githubusercontent.com/24237865/58792942-19263f80-8630-11e9-9b5d-2b14935ff991.jpg)
![KakaoTalk_20190602_211441525](https://user-images.githubusercontent.com/24237865/58792941-19263f80-8630-11e9-9752-e403d391874b.jpg)
![refresh](https://user-images.githubusercontent.com/24237865/58886340-af389380-871e-11e9-8c3e-6c95b244cb02.gif)

## TODO List

Todo list for planning daily to-do.

![todo preview](https://user-images.githubusercontent.com/24237865/58887313-5b2eae80-8720-11e9-98be-d1838297b345.gif)
![KakaoTalk_20190602_230834056](https://user-images.githubusercontent.com/24237865/58793176-9356c400-8630-11e9-9a74-afeac8c5c4aa.jpg)
![KakaoTalk_20190602_230638942](https://user-images.githubusercontent.com/24237865/58793175-9356c400-8630-11e9-9a2d-0ae4006a0490.jpg)

## Water Drinking

Another to-do screen focusing on water drinking every day.

![screenshot738375304](https://user-images.githubusercontent.com/24237865/58793648-8b4b5400-8631-11e9-8070-df60d5f8f76e.png)
![screenshot48865084](https://user-images.githubusercontent.com/24237865/58793278-c13c0880-8630-11e9-8710-ccfc6ac62e4e.png)
![screenshot1974868066](https://user-images.githubusercontent.com/24237865/58793282-c13c0880-8630-11e9-93d8-81f64a50cddf.png)

## Key Features
- [x] introduction slides and permission instruction popup.
- [x] getting weather data from the [KMA](http://www.kma.go.kr/) via RESTful API. 
- [x] visualizes weather data as a chart and implements pull to refresh.
- [x] changes background as local time.
- [x] sectioned todo list screen with google material design & animations.
- [x] adds and edits a todo item.
- [x] done, roll-back and delete on a todo item detail screen.
- [x] visualizes daily water drinking amount as a dynamic water drop.
- [x] visualizes weekly water drinking amount as a chart.
- [x] customizes the water drop color using color picker.
- [x] links recording water drinking amount to the todo list.
- [x] records water drinking amout via NFC tags.
- [ ] daily notification about the fine dust.
- [ ] healthy exercise instructions and links to the todo list.

## Architecture

![screenshot1203000180](https://user-images.githubusercontent.com/24237865/58883772-0f790680-871a-11e9-8c3d-68f2eb4c1b66.png)

## Specs & Open-source libraries
- Minimum SDK 17
- Kotlin based, [anko](https://github.com/Kotlin/anko)
- MVVM Architecture
- Android Architecture Components (Lifecycle, LiveData, ViewModel, Room Persistence)
- Material Design & Animations
- [Dagger2](https://github.com/google/dagger)
- [Retrofit2 & Gson](https://github.com/square/retrofit) for constructing the REST API
- [OkHttp3](https://github.com/square/okhttp) for implementing interceptor, logging and mocking web server
- [Glide](https://github.com/bumptech/glide) for loading images
- [PreferenceRoom](https://github.com/skydoves/PreferenceRoom) for efficient managing SharedPreferences
- [BaseRecyclerViewAdapter](https://github.com/skydoves/BaseRecyclerViewAdapter) for implementing adapters and viewHolders
- [Timber](https://github.com/JakeWharton/timber) for logging
- [PowerMenu](https://github.com/skydoves/PowerMenu) for implementing material popup dialog
- [Needs](https://github.com/skydoves/needs) for implementing permission instruction popup.
- [ColorPickerView](https://github.com/skydoves/ColorPickerView) for implementing color picker dialog
- CustomViews [MPAndroidChart](https://github.com/PhilJay/MPAndroidChart), [Navigationtabbar](https://github.com/Devlight/NavigationTabBar), [AppIntro](https://github.com/AppIntro/AppIntro), [AndroidFillableLoaders](https://github.com/JorgeCastilloPrz/AndroidFillableLoaders), [Elasticviews](https://github.com/skydoves/elasticviews). [GuillotineMenu-Android](https://github.com/Yalantis/GuillotineMenu-Android), [SmartRefreshLayout](https://github.com/scwang90/SmartRefreshLayout)
- Ripple animation, circular revealed animation, shared element transition

# License
```xml
Designed and developed by 2019 skydoves (Jaewoong Eum)

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```
",119,119,11,3,health,"[android, application, demo-app, health, healthcare, reminder, skydoves, todo, todoapp]",62
shlima,health_bit,,https://github.com/shlima/health_bit,https://api.github.com/repos/health_bit/shlima,"Tiny health check of Rack apps like Rails, Sinatra for use with uptime checking systems like Kubernetes, Docker or Uptimerobot","![CI](https://github.com/shlima/health_bit/workflows/CI/badge.svg)
[![gem version](https://badge.fury.io/rb/health_bit.svg)](https://rubygems.org/gems/health_bit)

# HealthBit

![](./doc/logo.png?sanitize=true)

This gem was inspired by the [health_check](https://github.com/ianheggie/health_check), but is simpler and more
extensible and contains up to 95% less code.

Key differences:
* is a rack application (just a lambda function)
* can be used with rails, sinatra or any other rack application
* can add custom checks
* can add multiple endpoints with independent checks
* can use any rack middleware (such as http basic auth, IP whitelist)

## Toc

* [Installation](#installation)
* [Configuration](#configuration)
* [Add Checks](#add-checks)
* [Add a Route](#add-a-route)
* [Password Protection](#password-protection)
* [Multiple endpoints](#multiple-endpoints)
* [Custom formatter](#custom-formatter)

## Check Examples

* [Database check](#database-check)
* [Redis check](#redis-check)
* [Sidekiq check](#sidekiq-check)
* [Rails cache check](#rails-cache-check)
* [Elasticsearch check](#elasticsearch-check)
* [RabbitMQ check](#rabbitmq-check)
* [HTTP check](#http-check)
* [ClickHouse check](#clickhouse-check)

## Installation

Add this line to your application's Gemfile:

```ruby
gem 'health_bit'
```

## Configuration

```ruby
# config/initializers/health_bit.rb

HealthBit.configure do |c|
  # DEFAULT SETTINGS ARE SHOWN BELOW
  c.success_text = '%<count>d checks passed 🎉'
  c.headers = {
    'Content-Type' => 'text/plain;charset=utf-8',
    'Cache-Control' => 'private,max-age=0,must-revalidate,no-store'
  }
  c.success_code = 200
  c.fail_code = 500
  c.show_backtrace = false
  c.formatter = HealthBit::Formatter.new
  # DEFAULT SETTINGS ARE SHOWN ABOVE

  c.add('Check name') do
    # Body check, should returns `true`
    true
  end
end
```

## Add Checks

By default, the **gem does not contain any checks**, **you should add the
necessary checks by yourself**. The check should return `false` or `nil`
to be considered unsuccessful or throw an exception, any other
values are considered satisfactory.

Example checks:

```ruby
## Successful checks
HealthBit.add('PostgreSQL') do |env|
  ApplicationRecord.connection.select_value('SELECT 1') == 1
end

HealthBit.add('Custom') do |env|
  next(false) if 1 != 0 
  
  true
end

## Failed checks
HealthBit.add('Database') do |env|
  false
end

HealthBit.add('Docker service') do |env|
  raise 'not responding'
end

# The Check can be added as an object responding to a call
# (to be able to test your check)
class Covid19Check
  def self.call(env)
    false
  end
end

HealthBit.add('COVID-19 Checker', Covid19Check)
```

## Add a Route

Since the gem is a rack application, you must mount it to app's
routes. Below is an example for the Rails.

```ruby
# config/routes.rb

Rails.application.routes.draw do
  mount HealthBit.rack => '/health'
end
```

```bash
curl --verbose http://localhost:3000/health

< HTTP/1.1 200 OK
< Content-Type: text/plain;charset=utf-8
< Cache-Control: private,max-age=0,must-revalidate,no-store
< X-Request-Id: 59a796b9-29f7-4302-b1ff-5d0b06dd6637
< X-Runtime: 0.006007
< Vary: Origin
< Transfer-Encoding: chunked

4 checks passed 🎉
```

## Password Protection

Since the gem is a common rack application, you can add any rack
middleware to it. Below is an example with HTTP-auth for the Rails.

```ruby
# config/routes.rb

Rails.application.routes.draw do
  HealthBit.rack.use Rack::Auth::Basic do |username, password|
    ActiveSupport::SecurityUtils.secure_compare(Digest::SHA256.hexdigest(username), Digest::SHA256.hexdigest('user')) & ActiveSupport::SecurityUtils.secure_compare(Digest::SHA256.hexdigest(password), Digest::SHA256.hexdigest('password'))
  end

  mount HealthBit.rack => '/health'
end
```

## Database check

```ruby
HealthBit.add('Database') do |env|
  ApplicationRecord.connection.select_value('SELECT 1') == 1
end
```

## Redis check

```ruby
HealthBit.add('Redis') do |env|
  Redis.current.ping == 'PONG'
end
```

## Sidekiq check

```ruby
HealthBit.add('Sidekiq') do |env|
  Sidekiq.redis(&:ping) == 'PONG'
end
```

## Rails cache check

```ruby
HealthBit.add('Rails cache') do |env|
  Rails.cache.write('__health_bit__', '1', expires_in: 1.second)
end
```

## Elasticsearch check

```ruby
HealthBit.add('Elasticsearch') do |env|
  Elasticsearch::Client.new.ping
end
```

## RabbitMQ check

```ruby
HealthBit.add('RabbitMQ') do |env|
  Bunny::Connection.connect(&:connection)
end
```

## HTTP check

```ruby
HealthBit.add('HTTP check') do |env|
  Net::HTTP.new('www.example.com', 80).request_get('/').kind_of?(Net::HTTPSuccess)
end
```

## ClickHouse check

```ruby
HealthBit.add('ClickHouse') do |env|
  ClickHouse.connection.ping
end
```

## Multiple endpoints

Sometimes you have to add several health check endpoints. Let's say
you have to check the docker container health and the health
of your application as a whole. Below is an example for the Rails.

```ruby
# config/initializers/health_bit.rb

DockerCheck = HealthBit.clone
AppCheck = HealthBit.clone

DockerCheck.add('Docker Health') do |env|
  true
end

AppCheck.add('App Health') do |env|
  ApplicationRecord.connection.select_value(""SELECT 't'::boolean"")
end
```

```ruby
# config/routes.rb

Rails.application.routes.draw do
  mount DockerCheck.rack => '/docker'
  mount AppCheck.rack => '/app'
end
```

## Custom formatter

You can easily [configure](https://github.com/shlima/health_bit/blob/master/lib/health_bit/formatter.rb) custom format of response body, headers and
http statuses.

```ruby
class JsonFormatter < HealthBit::Formatter
  # @param error HealthBit::CheckError
  # @param env Hash
  # @param health_bit HealthBit
  def format_failure(error, env, health_bit)
    { 'status': 'error' }.to_json
  end

  # @param error HealthBit::CheckError
  # @param env Hash
  # @param health_bit HealthBit
  def headers_failure(error, env, health_bit)
    {
      'Content-Type' => 'application/json'
    }
  end
end

HealthBit.configure do |c|
  c.formatter = JsonFormatter.new
end
```
",111,111,2,3,health,"[health, health-check, healthcheck, rack, ruby, ruby-on-rails]",62
plashchynski,awesome-genetics,,https://github.com/plashchynski/awesome-genetics,https://api.github.com/repos/awesome-genetics/plashchynski,A curated list of awesome bioinformatics software.,"# awesome-genetics
A curated list of awesome bioinformatics software and libraries

## Essentials
### Education and courses
* [SNPedia](http://snpedia.org/) — A wiki investigating human genetics.
* [Bioinformatics for Beginners](https://www.coursera.org/learn/bioinformatics/home/welcome) — Coursera's introductory course to the field of bioinformatics
* [The National Center for Biotechnology Information](https://www.ncbi.nlm.nih.gov/) — advances science and health by providing access to biomedical and genomic information
* [Harvard Medical School Online](https://onlinelearning.hms.harvard.edu/hmx/)
* [Introduction to Biology - The Secret of Life by Edx](https://www.edx.org/course/introduction-to-biology-the-secret-of-life-3)


### Offline Tools
* [chrchang/plink-ng](https://github.com/chrchang/plink-ng) — [PLINK](https://en.wikipedia.org/wiki/PLINK_(genetic_tool-set)) association analysis toolset [home page](https://www.cog-genomics.org/plink/)
* [vcftools/vcftools](https://github.com/vcftools/vcftools) — A set of tools written in Perl and C++ for working with [VCF](https://en.wikipedia.org/wiki/Variant_Call_Format) files
* [samtools/bcftools](https://github.com/samtools/bcftools) — Utilities for variant calling and manipulating VCFs and BCFs by [HTSlib](http://www.htslib.org/)
* [samtools/samtools](https://github.com/samtools/samtools) — Utilities for the [Sequence Alignment/Map (SAM)](https://en.wikipedia.org/wiki/SAM_(file_format)) format by [HTSlib](http://www.htslib.org/)
* [arrogantrobot/23andme2vcf](https://github.com/arrogantrobot/23andme2vcf) — Convert a 23andme raw file to [VCF](https://en.wikipedia.org/wiki/Variant_Call_Format) (Perl)
* [23andMe/seqseek](https://github.com/23andMe/seqseek) — Easy access to human reference genome sequences (Python)

### Online tools
* [varsome.com](https://varsome.com/) — The Human Genomic Variant Search Engine

## Health and traits
### Knowledge
* [Genetics Home Reference](https://ghr.nlm.nih.gov/) — consumer-friendly information about the effects of genetic variation on human health

### Online tools
* [Codegen](https://codegen.eu/) — A free comprehensive health report using consumer DNA raw files.
* [Promethease](http://promethease.com/) — Generates health and trait reports based on [SNPedia](http://snpedia.org/) (paid)
* [Genomelink](https://genomelink.io/) — Health and traits reports based on DNA raw files.

## Genetic genealogy
### Knowledge
* [ISOGG Wiki](https://isogg.org/wiki/Wiki_Welcome_Page) — International Society of Genetic Genealogy Wiki
* [Beginners guide to genetic genealogy](https://sites.google.com/site/wheatonsurname/beginners-guide-to-genetic-genealogy)

### Offline tools
* [apriha/lineage](https://github.com/apriha/lineage) — Tools for genetic genealogy and the analysis of consumer DNA test results (Python)
* [23andMe/yhaplo](https://github.com/23andMe/yhaplo) — Identifying Y-chromosome haplogroups in arbitrarily large samples of sequenced or genotyped men (Python)

### Online tools
* [GEDmatch](https://www.gedmatch.com/) — GEDmatch is a free online toolset to compare autosomal DNA data files
* [DNA.Land](https://dna.land/) — The site offers a biogeographical analysis, imputation and a relative-matching feature
* [David Pike's Tools](http://www.math.mun.ca/~dapike/FF23utils/) — Utilities for analysing raw DNA data (JS)
* [Shared cM Project](https://dnapainter.com/tools/sharedcmv4) — Visualize relationship probabilities based on centimorgans
",96,96,6,0,health,"[23andme, ancestry, bioinformatics, consumer-dna-test, dna, geneology, genetics, genomics, health, snpedia]",62
belisards,coronabr,,https://github.com/belisards/coronabr,https://api.github.com/repos/coronabr/belisards,"Série histórica dos dados sobre COVID-19, a partir de informações do Ministério da Saúde","# CoronaBR
[![goodtables.io](https://goodtables.io/badge/github/belisards/coronabr.svg)](https://goodtables.io/github/belisards/coronabr)

Dados e scripts para extrair a série histórica da pandemia COVID-19 no Brasil, de acordo com o Ministério da Saúde.

ATENÇÃO: O Ministério da Saúde disponibilizou um [arquivo CSV com a série histórica completa por UF](https://covid.saude.gov.br/assets/files/BRnCov19_30032020.csv), de modo que não é necessário realizar a extração manual atualmente. Este repositório será descontinuado.

## Sobre os dados

No arquivo [corona_brasil.csv](https://github.com/belisards/coronabr/blob/master/dados/corona_brasil.csv), você encontra a série histórica dos casos confirmados e mortes de COVID-19 segundo o Ministério da Saúde. 

O arquivo [serie_ivis.csv](https://github.com/belisards/coronabr/tree/master/dados/serie_ivis.csv) traz a série histórica até 18 de março, quando eram incluídas através da Plataforma IVIS outras informações como casos suspeitos e descartados.

Saiba mais sobre a [metodologia de extração e compilação dos dados abaixo](https://github.com/belisards/coronabr/tree/master/dados) e [como utilizar o script](https://github.com/belisards/coronabr/tree/master/scripts). 

### Licença dos dados
A base de dados [corona_brasil.csv](https://github.com/belisards/coronabr/blob/master/dados/corona_brasil.csv) é disponibilizada sob a licença Open Database License: [http://opendatacommons.org/licenses/odbl/1.0/](http://opendatacommons.org/licenses/odbl/1.0/). 


## Outros projetos de monitoramento

* O [Brasil.IO](https://brasil.io/dataset/covid19/boletim) compilado os dados a partir dos governos estaduais, com dados sobre município;

* Para um levantamento realizado manualmente de casos em nível municipal, confira este projeto de [Wesley Cota](https://labs.wesleycota.com/sarscov2/br/) ou a iniciativa colaborativa [Mapa do Corona Virus](mapadocoronavirus.com).

* [Kaggle Corona-Virus-Brazil](https://www.kaggle.com/unanimad/corona-virus-brazil)

* Lista colaborativa no [fórum Dados Abertos](https://dadosabertos.social/t/dados-sobre-a-pandemia-do-novo-coronavirus/267);

* Painel e projeções do [Observatório COVID-19 BR](https://covid19br.github.io/)
",85,85,11,1,health,"[brasil, covid-19, covid-data, covid19, dados, health, open-data, opendata, saude]",62
nextcloud,health,nextcloud,https://github.com/nextcloud/health,https://api.github.com/repos/health/nextcloud,Nextcloud health app,"# Health
##### version 1.6.1
### Track your health. Use the advantages of a trusted platform.

The app provides different modules to track your  health data.

Following modules are served:
- Weight
- Feeling
- Measurement
- Sleep
- Smoking
- Activities
- Medication
",78,78,12,54,health,"[health, nextcloud-app]",62
goinvo,HealthDeterminants,goinvo,https://github.com/goinvo/HealthDeterminants,https://api.github.com/repos/HealthDeterminants/goinvo,Social Determinants of Health Visualization,"# Determinants of Health
 An open source visualization of the social determinants of health.
 
 ![Determinants of Health Visualized](https://github.com/goinvo/HealthDeterminants/raw/master/poster/health_determinants_poster_medium.jpg)


# References

1. NCHHSTP Social Determinants of Health. (2014). Retrieved March 14, 2016, from http://www.cdc.gov/nchhstp/socialdeterminants/definitions.html
2. The determinants of health. (n.d.). Retrieved March 14, 2016, from http://www.who.int/hia/evidence/doh/en/
3. Social Determinants of Health. (n.d.). Retrieved March 14, 2016, from https://www.healthypeople.gov/2020/topics-objectives/topic/social-determinants-of-health
4. Beyond Health Care: The Role of Social Determinants in Promoting Health and Health Equity. (n.d.). Retrieved March 14, 2016, from http://kff.org/disparities-policy/issue-brief/beyond-health-care-the-role-of-social-determinants-in-promoting-health-and-health-equity/
5. Schroeder, S. A. (2007). We Can Do Better — Improving the Health of the American People. New England Journal of Medicine N Engl J Med,357(12), 1221-1228.
6. The Relative Contribution of Multiple Determinants to Health Outcomes. (n.d.). Retrieved March 14, 2016, from http://healthaffairs.org/healthpolicybriefs/brief_pdfs/healthpolicybrief_123.pdf
7. Capturing social and behavioral domains and measures in electronic health records: Phase 2. (2014). Washington D.C.: The National Academies Press.
8. Gruszin, S., & Jorm, L. (2010, December). Public Health Classifications Project (Rep.). Retrieved March 15, 2016, from New South Wales Department of Health website: http://www.health.nsw.gov.au/hsnsw/Publications/classifications-project.pdf
9. DHHS, Public Health Service. “Ten Leading Causes of Death in the United States.” Atlanta (GA): Bureau of State Services, July 1980
10. J.M.McGinnis and W.H.Foege. “Actual Causes of Death in the United States.” JAMA 270, No. 18 (1993):2207-12
11. J.M.McGinnis et al, “The Case for More Active Policy Attention to Health Promotion.” Health Affairs 21, no.2 (2002):78-93
12. A.Mokdad et al. “Actual Causes of Death in the United States 2000.” JAMA 291, no.10 (2004):1238-45
13. G.Danaei et al, “The Preventable Cuases of Death in the United States: Comparative Risk Assessment of Dietary, Lifestyle, and Metabolic Risk Factors.” PLoS Medicine 6, no. 4 (2009):e1000058
14. World Health Organization, Global Health Risks: Mortality and Burden of Disease Attributable to Selected Major Risks, Geneva: WHO, 2009
15. B. Booske et al., “Different Perspectives for Assigning Weights to Determinants of Health.” County Health Rankings Working Paper. Madison (WI): University of Wisconsin Population Health Institute, 2010
16. Schneiderman, N., Ironson, G., & Siegel, S. D. (2005). STRESS AND HEALTH: Psychological, Behavioral, and Biological Determinants. Annual Review of Clinical Psychology, 1, 607-628. Retrieved March 16, 2016, from http://www.annualreviews.org/doi/abs/10.1146/annurev.clinpsy.1.102803.144141?url_ver=Z39.88-2003&rfr_dat=cr_pub=pubmed&rfr_id=ori:rid:crossref.org&journalCode=clinpsy

# Methodology

The 5 main determinants of health (genetics, medical care, social circumstances, environment, and individual behavior) were chosen due to their consistency across the following 7 out of 8 organizations:

    NCHHSTP [1]
    WHO [2]
    Healthy People [3]
    Kaiser Family Foundation [4]
    NEJM [5]
    Health Affairs [6]
    Institute of Medicine [7]
    New South Wales Department of Health [8]

The 29 macrodeterminants and 66 microdeterminants below each main category were found by compiling the determinant lists of the previously mentioned organizations.

The section below documents our analysis of the data and how we calculated the final impact percentages for the 5 main categories of determinants.

The relative contribution of each of the determinant categories to one’s health was found using the estimated values referenced by the seven primary sources listed below.

    DHHS [9]
    JAMA [10, 12]
    Health Affairs [11]
    PLoS [13]
    WHO [14]
    U.Wisconsin [15]

Each determinant category was then averaged based on the values from each of the aforementioned sources (the methodology in the primary sources were different depending on the source. The final percentages should therefore be an estimate and not be viewed as absolute numbers).

Behavior: (50 + 38 + 40 + 39 + 36 + 45 + 30) / 6 = 46.33.

Social: (15 + 40) / 2 = 27.5.

Genetics: (20 + 30) / 2 = 25.

Medical care: (10 + 10 + 20) / 3 = 13.33.

Environment: (20 + 7 + 5 + 5.4 + 3 + 10) / 6 = 8.4.

The ratio for each determinant was then found by taking the average values found for each of the determinant categories and dividing them by the total determinant value.

Behavior: 46.33 / 120.56 = 38.43%.

Social: 27.5 / 120.56 = 22.81%.

Genetics: 25 / 120.56 = 20.74%.

Medical care: 13.33 / 120.56 = 11.06%.

Environment: 8.4 / 120.56 = 7%.

Total: 38.43 + 22.81 + 20.74 + 7 + 11.06 = 100.4%.

The final percentages are as follows.

Behavioral determinants at 38%.

Social determinants at 23%.

Genetic determinants at 21%.

Medical care determinants at 11%.

Environmental determinants at 7%.

### For guidance integrating the Determinants of Health into your product or service, contact us at hello@goinvo.com. ###

### License ###
Health Determinants digital service is [Apache 2.0](https://github.com/goinvo/HealthDeterminants/blob/master/LICENSE) licensed.

The Health Determinants content and poster is licensed under Creative Commons Attribution v4.
If you want to reference this work (in a paper, for example), feel free to use:

Choi, Edwin, and Juhan Sonin. 2019. “Determinants of Health.” GoInvo. https://www.goinvo.com/vision/determinants-of-health/.
",62,62,13,1,health,"[boston, design, determinants-of-health, doh, goinvo, health, healthcare, holistic-health, open-source, sdoh, social-determinants, ux, visualization]",62
IMS94,chr247.com,,https://github.com/IMS94/chr247.com,https://api.github.com/repos/chr247.com/IMS94,An open source multi tenant cloud platform for small scale clinics,,60,60,8,9,health,"[clinic, cloud-platform, doctor, health, health-informatics, healthcare, patient-management, patient-record, patient-records, patients]",62
ColeMacGrath,HealthApp,,https://github.com/ColeMacGrath/HealthApp,https://api.github.com/repos/HealthApp/ColeMacGrath,This application is designed for the effective interaction between patients and doctors,"![alt text](https://user-images.githubusercontent.com/42153044/61584923-01d6df00-ab16-11e9-9811-9b2ece37889a.png)

HealthApp provides a series of tools to provide a better interaction between patients and doctors.
This application is integrated with HealthKit, Firebase and Realm it means that every record of alimentation, sports and more are synchronized between doctor and patient in real time.
In addition incorporates an image analyzer, working in conjunction with automated learning algorithms to predict the presence of different skin lesions with just one photo.

## [Doctor App](https://github.com/ColeMacGrath/HealthApp/tree/Doctor)

| ![alt text](https://user-images.githubusercontent.com/42153044/61669020-42646300-aca4-11e9-913d-cfaec5f3995a.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61612755-05a55700-ac25-11e9-94c7-d0a036becf06.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61612757-05a55700-ac25-11e9-9220-96a1bbbff892.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |

## Getting started

### Prerequisites

| Software | **Minimum Version** |     **Recommended**     |
| :------: | :-----------------: | :---------------------: |
|  macOS   | High Sierra 10.13.6 | Mojave 10.14.3 or newer |
|  Xcode   |      Xcode 10       |       Xcode 10.2        |
|  Swift   |      Swift 5.0      |   Swift 5.0 or newer    |
|   iOS    |       iOS 12        |        iOS 12.1         |

### Packages

|        Package         | **Version Tested** |
| :--------------------: | :----------------: |
|        CocaPods        |       1.5.2        |
|        Firebase        |       6.3.0        |
|     Firebase/Auth      |       6.3.0        |
|   Firebase/Database    |       6.3.0        |
|    Firebase/Storage    |       6.3.0        |
|     FloatingPanel      |       1.6.1        |
| IQKeyboardManagerSwift |       6.4.0        |
|    JTAppleCalendar     |       8.0.0        |
|         Charts         |       3.3.0        |
|       RealmSwift       |       3.17.0       |

Podfile included

```
pod 'Charts'
pod 'Firebase'
pod 'Firebase/Auth'
pod 'Firebase/Database'
pod 'Firebase/Storage'
pod 'FloatingPanel'
pod 'IQKeyboardManagerSwift'
pod 'JTAppleCalendar'
pod 'RealmSwift'
```

### How to Install

1. Clone the project
2. Create a new Pod file from .xcodeproj
3. Install packages listed before
4. Drag and drop [Machine Learning Model](https://1drv.ms/u/s!ArVWVB2r2uzhg-Q90YBJ1-tmu8E0AA?e=19njUT) in HealthApp/Visual Recognizer (Check the Target Membership)
5. Drag and drop your own GoogleService-Info.plist into HealthApp/
6. Activate HealthKit to your Apple ID (Targets -> Capabilities)
7. Activate MapKit to your Apple ID

![alt text](https://user-images.githubusercontent.com/42153044/51432666-ffe0a180-1c00-11e9-9358-e00ee5b00947.png)

## About Trained Model

The model was trained with more than 12,000 images in high resolution

#### Type

Image Classifier

#### Size

66 kb

#### Description

A model trained to determine the pathology of a nevus

#### Model Evaluation Parameters

##### Inputs:

- Image (Color 299x299)

#### Outputs

- classLabelProbs (String -> Double): Probability of each category
- classLabel (String): Most likely image category

## Skin lesion to determine

|        Skin Lesion         | **Number of images for training** | **Original Size** |
| :------------------------: | :-------------------------------: | :---------------: |
|           Nevus            |               8046                |      10.9 GB      |
|          Melanoma          |               2049                |      5.14 GB      |
| Pigmented Benign Keratosis |               1039                |      279 MB       |
|    Basal Cell Carcinoma    |                566                |      606 MB       |
|    Seborrheic Keratosis    |                419                |      1.47 GB      |

## languages

The app was manually translated to

- 🇺🇸 English (US)
- 🇲🇽 Spanish (MX) (not available)
- 🇪🇸 Catalan (ES) (not available)

## Upcoming Features

- macOS Compatibility with project catalyst (In progress)
- Siri Shortcuts
- Translations

## Some Screenshots

| ![alt text](https://user-images.githubusercontent.com/42153044/61584929-026f7580-ab16-11e9-88cc-b8e788d20cf5.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61584930-026f7580-ab16-11e9-982a-8c8715711bdd.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61584931-026f7580-ab16-11e9-9fb9-fc2b616dba2b.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| ![alt text](https://user-images.githubusercontent.com/42153044/61584928-026f7580-ab16-11e9-8174-5c53a3a6a252.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61584932-03080c00-ab16-11e9-9bb1-99603145ce1c.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61584924-026f7580-ab16-11e9-9f25-0c9eb388b30e.png) |
| ![alt text](https://user-images.githubusercontent.com/42153044/61584927-026f7580-ab16-11e9-8861-a1fcf68904f2.png) | ![alt text](https://user-images.githubusercontent.com/42153044/61584926-026f7580-ab16-11e9-80be-9b6644326c34.png) |                                                              |

![alt text](https://user-images.githubusercontent.com/42153044/61584925-026f7580-ab16-11e9-980a-23e18bfbc306.png)

## Changelog

- Local saving for profile picture
- Added profile picture saved in cloud too
- Added four new skins lesions to determine
- Improved cloud query
- Improved messages error in login and register
- App not crashes on refresh
- Appointments are now working in cloud and local
- Views are improved now are responsive and works in iPhone and iPad
- Added food ingested calories and food name in health types
- Interface redesigned from scratch
- Search Bar for doctor filtering by name

### Comparative table with old and new HealthApp versions

|         Comparison         |       **Original version**       |                       **New version**                        |
| :------------------------: | :------------------------------: | :----------------------------------------------------------: |
|  Original Dataset images   |            170 images            |                        12,119 images                         |
|   Original Dataset size    |             25.9 Mb              |                           18.37 GB                           |
|   Training model options   |         Melanoma & Nevus         | Nevus, Melanoma, Pigmented Benign Keratosis, Basal Cell Carcinoma and Seborrheic Keratosis |
|     Local saving tool      |               None               |                            Realm                             |
|     Cloud saving tool      |             Firebase             |                           Firebase                           |
| iPhone / iPad adaptability | Partilly in iPhone App (patient) |                Full on patient and doctor app                |

## License

MIT

## Acknowledgements

- [ISC](https://www.isic-archive.com/#!/topWithHeader/wideContentTop/main) For main image data set
- [MED-NODE](http://www.cs.rug.nl/~imaging/databases/melanoma_naevi/)
",58,58,9,0,health,"[health, healthkit, image-recognition, ios, swift]",62
kadalu,gdash,kadalu,https://github.com/kadalu/gdash,https://api.github.com/repos/gdash/kadalu,Lightweight GlusterFS Dashboard,"# gdash - GlusterFS Dashboard

## Install

```
sudo pip3 install gdash
```

## Usage

Start `gdash` service in any one of the Gluster server node.

```
sudo gdash <HOSTNAME>
```

Provide the hostname to identify where gdash is running. Use the same hostname or IP which is used with Gluster Peer/Volume commands. Gdash will use this to replace the mention of ""localhost"" in the peer commands.

Protect the dashboard access from others by setting the username and password.

Generate One way hash of Password

```
$ echo -n ""MySecret@01"" | sha256sum
1ae946b331052b646ca7d0857dfb205835b2a00a33a35e40b4419a5e150213f3  -
```

Add that to a file(`/etc/glusterfs/gdash.dat`) in the following format,

```
admin=1ae946b331052b646ca7d0857dfb205835b2a00a33a35e40b4419a5e150213f3
aravinda=9e56d42f4be084e5e56c9c23c3917ae10611678743b7f7ca0f6d65c4dd413408
```

Then run gdash using,

```
sudo gdash node1.example.com --auth-file=/etc/glusterfs/gdash.dat
```

Now you can visit http://localhost:8080 (or <node-ip>:8080 if accessing gdash externally) from your browser.

**Note**: Port can be customized by providing `--port` option(For example, `--port 3000`)

Other available options are

```
$ gdash --help
usage: gdash [-h] [--version] [--port PORT] [--gluster-binary GLUSTER_BINARY]
             [--auth-file AUTH_FILE] [--ssl-cert CERT_FILE] [--ssl-key KEY_FILE] [--ssl-ca CA_CERT_FILE] [--ssl-ciphers LIST_OF_CIPHERS]
             host

gdash - GlusterFS Dashboard

positional arguments:
  host                  Hostname of Current node as used in Gluster peer
                        commands. Gdash replaces the ""localhost"" references
                        with this name

optional arguments:
  -h, --help                       show this help message and exit
  --version                        show program's version number and exit
  --port PORT                      Gdash Port(Default is 8080)
  --gluster-binary GLUSTER_BINARY  Gluster binary path.
  --auth-file AUTH_FILE            Users Credentials file. One user
                                   entry per row in the
                                   format <username>=<password_hash>
  --ssl-cert CERT_FILE             Path to SSL Certificate file
  --ssl-key KEY_FILE               Path to SSL Key file
  --ssl-ca CA_FILE                 Path to SSL CA Certificate file
  --ssl-ciphers                    List of SSL Ciphers to allow
```

## Blog

* [Dec 04, 2014] http://aravindavk.in/blog/introducing-gdash (Previous version, UI is different now)
* [Oct 19, 2020] https://kadalu.io/blog/gdash-v1.0


## Issues

For feature requests, issues, suggestions [here](https://github.com/kadalu/gdash/issues)
",57,57,5,4,health,"[dashboard, glusterfs, health, monitor]",62
kvs-coder,HealthKitReporter,,https://github.com/kvs-coder/HealthKitReporter,https://api.github.com/repos/HealthKitReporter/kvs-coder,HealthKitReporter. A wrapper for HealthKit framework. Helps to write or read data from Apple Health via HealthKit framework.,"# HealthKitReporter

## About

A wrapper above HealthKit Apple's framework for data manipulations.
The library supports manipulating with values from HealthKit repository and translating them to <i>Codable</i> models allowing to encode the result as a simple JSON payload.
In addition you can write your own HealthKit objects using <i>Codable</i> wrappers which will be translated to <i>HKObjectType</i> objects inside HealthKit repository.

## Start

### Preparation

At first in your app's entitlements select HealthKit. and in your app's info.plist file add permissions:

```xml
<key>NSHealthShareUsageDescription</key>
<string>WHY_YOU_NEED_TO_SHARE_DATA</string>
<key>NSHealthUpdateUsageDescription</key>
<string>WHY_YOU_NEED_TO_USE_DATA</string>
```

If you plan to use **WorkoutRoute** **Series** please provide additionally CoreLocation permissions:

```xml
<key>NSLocationAlwaysAndWhenInUseUsageDescription</key>
<string>WHY_YOU_NEED_TO_ALWAYS_SHARE_LOCATION</string>
<key>NSLocationWhenInUseUsageDescription</key>
<string>WHY_YOU_NEED_TO_SHARE_LOCATION</string>
```

### Common usage

You create a <i>HealthKitReporter</i> instance surrounded by do catch block. If Apple Health is not supported by the device (i.e. iPad) the catch block will be called.

The reporter instance contains several properties:
* reader
* writer
* manager
* observer

Every property is responsible for an appropriate part of HealthKit framework. Based from the naming, reader will handle every manipulation regarding reading data and writer will handle everything related to writing data in HealthKit repository, observer will handle observations and will notify if anything was changes in HealthKit, manager is responsible for the authorization of read/write types and launching a WatchApp you make.

If you want to read, write data or observe data changes, you always need to be sure that the data types are authorized to be read/written/observed. In that case manager has authorization method with completion block telling about the presentation of the authorization window. Notice that Apple Health Kit will show this window only once during the whole time app is installed on the device, in this case if some types were denied to be read or written, user should manually allow this in Apple Health App.

In examples below every operation is hapenning iside authorization block. It is recommended to do so, because if new type will be added, there will be thrown a permission exception. If you are sure that no new types will appear, you can call operations outside authorization block in your app, only if the type's data reading/writing permissions were granted.

### Reading Data
Create a <i>HealthKitReporter</i> instance.

Authorize deisred types to read, like step count.

If authorization was successfull (the authorization window was shown) call sample query with type step count to create a **Query** object.

Use reporter's **manager's** _executeQuery_ to execute the query. (Or _stopQuery_ to stop)

```swift
do {
    let reporter = try HealthKitReporter()
    let types = [QuantityType.stepCount]
    reporter.manager.requestAuthorization(
        toRead: types,
        toWrite: types
    ) { (success, error) in
        if success && error == nil {
            reporter.manager.preferredUnits(for: types) { (preferredUnits, error) in
                if error == nil {
                    for preferredUnit in preferredUnits {
                        do {
                            let query = try reporter.reader.quantityQuery(
                                type: try QuantityType.make(from: preferredUnit.identifier),
                                unit: preferredUnit.unit
                            ) { (results, error) in
                                if error == nil {
                                    for element in results {
                                        do {
                                            print(try element.encoded())
                                        } catch {
                                            print(error)
                                        }
                                    }
                                } else {
                                    print(error)
                                }
                            }
                            reporter.manager.executeQuery(query)
                        } catch {
                            print(error)
                        }
                    }
                } else {
                    print(error)
                }
            }
        } else {
            print(error)
        }
    }
} catch {
    print(error)
}
```

Here is a sample response for steps:

```json

{
  ""sourceRevision"" : {
    ""productType"" : ""iPhone8,1"",
    ""systemVersion"" : ""14.0.0"",
    ""source"" : {
      ""name"" : ""Guy’s iPhone"",
      ""bundleIdentifier"" : ""com.apple.health.47609E07-490D-4E5F-8E68-9D8904E9BA08""
    },
    ""version"" : ""14.0""
  },
  ""harmonized"" : {
    ""value"" : 298,
    ""unit"" : ""count""
  },
  ""device"" : {
    ""softwareVersion"" : ""14.0"",
    ""manufacturer"" : ""Apple Inc."",
    ""model"" : ""iPhone"",
    ""name"" : ""iPhone"",
    ""hardwareVersion"" : ""iPhone8,1""
  },
  ""endTimestamp"" : 1601066077.5886581,
  ""identifier"" : ""HKQuantityTypeIdentifierStepCount"",
  ""startTimestamp"" : 1601065755.8829093
}
```

### Writing Data
Create a <i>HealthKitReporter</i> instance.

Authorize deisred types to write, like step count.

You may call manager's <i>preferredUnits(for: )</i> function to pass units (for <b>Quantity Types</b>).

If authorization was successfull (the authorization window was shown) call save method with type step count.

```swift
do {
    let reporter = try HealthKitReporter()
    let types = [QuantityType.stepCount]
    reporter.manager.requestAuthorization(
        toRead: types,
        toWrite: types
    ) { (success, error) in
        if success && error == nil {
            reporter.manager.preferredUnits(for: types) { (preferredUnits, error) in
                for preferredUnit in preferredUnits {
                    //Do write steps
                    let identifier = preferredUnit.identifier
                    guard
                        identifier == QuantityType.stepCount.identifier
                    else {
                        return
                    }
                    let now = Date()
                    let quantity = Quantity(
                        identifier: identifier,
                        startTimestamp: now.addingTimeInterval(-60).timeIntervalSince1970,
                        endTimestamp: now.timeIntervalSince1970,
                        device: Device(
                            name: ""Guy's iPhone"",
                            manufacturer: ""Guy"",
                            model: ""6.1.1"",
                            hardwareVersion: ""some_0"",
                            firmwareVersion: ""some_1"",
                            softwareVersion: ""some_2"",
                            localIdentifier: ""some_3"",
                            udiDeviceIdentifier: ""some_4""
                        ),
                        sourceRevision: SourceRevision(
                            source: Source(
                                name: ""mySource"",
                                bundleIdentifier: ""com.kvs.hkreporter""
                            ),
                            version: ""1.0.0"",
                            productType: ""CocoaPod"",
                            systemVersion: ""1.0.0.0"",
                            operatingSystem: SourceRevision.OperatingSystem(
                                majorVersion: 1,
                                minorVersion: 1,
                                patchVersion: 1
                            )
                        ),
                        harmonized: Quantity.Harmonized(
                            value: 123.0,
                            unit: preferredUnit.unit,
                            metadata: nil
                        )
                    )
                    reporter.writer.save(sample: quantity) { (success, error) in
                        if success && error == nil {
                            print(""success"")
                        } else {
                            print(error)
                        }
                    }
                }
            }
        } else {
            print(error)
        }
    }
} catch {
    print(error)
}
```

Hint: if you have trouble with choosing unit for an object you want to save, you can call a manager's function _preferredUnits_ which will return a dictionary with keys as identifiers of Quantitiy types and Units preferred for current localization.

```swift
reporter.manager.preferredUnits(for: [.stepCount]) { (dictionary, error) in
    for (identifier, unit) in dictionary {
        print(""\(identifier) - \(unit)"")
    }
}
```

## Observing Data

Create a <i>HealthKitReporter</i> instance.

Authorize deisred types to read/write, like step count and sleep analysis.

You might create an App which will be called every time by HealthKit, and receive notifications, that some data was changed in HealthKit depending on frequency. But keep in mind that sometimes the desired frequency you set cannot be fulfilled by HealthKit.

Call the observation query method inside your AppDelegate's method. This will let Apple Health to send events even if the app is in background or wake up your app,  if it was previosly put into ""Not Running"" state and execute the code provided inside **observerQuery** update handler.

Warning: to run **observerQuery** when the app is killed by the system, provide an additional capability **Background Mode** and select **Background fetch**

Use reporter's **manager's** _executeQuery_ to execute the query. (Or _stopQuery_ to stop)

```swift
func application(
    _ application: UIApplication,
    didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?
) -> Bool {
    do {
        let reporter = try HealthKitReporter()
        let types: [SampleType] = [
            QuantityType.stepCount,
            CategoryType.sleepAnalysis
        ]
        reporter.manager.requestAuthorization(
            toRead: types,
            toWrite: types
        ) { (success, error) in
            if success && error == nil {
                for type in types {
                    do {
                        let query = try reporter.observer.observerQuery(
                            type: type
                        ) { (query, identifier, error) in
                            if error == nil && identifier != nil {
                                print(""updates for \(identifier!)"")
                            }
                        }
                        reporter.observer.enableBackgroundDelivery(
                            type: type,
                            frequency: .daily
                        ) { (success, error) in
                            if error == nil {
                                print(""enabled"")
                            }
                        }
                        reporter.manager.executeQuery(query)
                    } catch {
                        print(error)
                    }
                }
            }
        }
    } catch {
        print(error)
    }
    return true
}
```

## Example

To run the example project, clone the repo, and run `pod install` from the Example directory first.

## Requirements

The library supports iOS 9 & above. 
Some features like HKHeartbeatSeries are available only starting with iOS 13.0 and like HKElectrocardiogramm starting with iOS 14.0

## Installation

### Cocoapods

HealthKitReporter is available through [CocoaPods](https://cocoapods.org). To install
it, simply add the following line to your Podfile:

```ruby
pod 'HealthKitReporter'
```

or 

```ruby
pod 'HealthKitReporter', '~> 3.0.0'
```

### Swift Package Manager

To install it, simply add the following lines to your Package.swift file
(or just use the Package Manager from within XCode and reference this repo):

```swift
dependencies: [
    .package(url: ""https://github.com/VictorKachalov/HealthKitReporter.git"", from: ""3.0.0"")
]
```

### Carthage

Add the line in your cartfile 

```ruby
github ""VictorKachalov/HealthKitReporter"" ""3.0.0""
```

## Author

Victor Kachalov, victorkachalov@gmail.com

## License

HealthKitReporter is available under the MIT license. See the LICENSE file for more info.

## Sponsorhip
If you think that my repo helped you to solve the issues you struggle with, please don't be shy and sponsor :-)
",57,57,2,4,health,"[apple, apple-health, cocoapods, health, healthkit, healthkit-framework, healthkit-objects, healthkitreporter, ios, swift]",62
elfenware,badger,elfenware,https://github.com/elfenware/badger,https://api.github.com/repos/badger/elfenware,Remind yourself to not sit and stare at the screen for too long,"<p align=""center"">
    <img src=""data/icons/128/com.github.elfenware.badger.svg"" alt=""Icon"" />
</p>

<h1 align=""center"">Badger</h1>
<p align=""center"">Remind yourself to not sit and stare at the screen for too long</p>

<p align=""center"">
  <a href=""https://appcenter.elementary.io/com.github.elfenware.badger""><img src=""https://appcenter.elementary.io/badge.svg"" alt=""Get it on AppCenter"" /></a>
</p>

<p align=""center"">
    <img src=""data/window-screenshot.png"" alt=""Screenshot"">
</p>


## Badgers you to be ergonomic

Badger will periodically send notifications to remind you to relax your eyes,
stretch your fingers, and turn your neck among other things. It helps you keep
your muscles free and your eyes unstrained.


## Built for elementary OS

While Badger will happily compile on any Linux distribution, it is primarily
built for [elementary OS].

[![Get it on AppCenter](https://appcenter.elementary.io/badge.svg)][AppCenter]


## Developing and building

Development is targeted at [elementary OS]. If you want to hack on and
build Badger yourself, you'll need the following dependencies:

* libgranite-dev
* libgtk-3-dev
* libhandy-1-dev
* meson
* valac

You can install them on elementary OS with:

```shell
sudo apt install elementary-sdk
```

Run `meson build` to configure the build environment and run `ninja install`
to install:

```shell
meson build --prefix=/usr
cd build
sudo ninja install
```

Then run it with:

```shell
com.github.elfenware.badger
```

[elementary OS]: https://elementary.io
[AppCenter]: https://appcenter.elementary.io/com.github.elfenware.badger
",52,52,4,5,health,"[appcenter, elementary, ergonomics, gtk, hacktoberfest, health, vala]",62
pratapvardhan,NFHS-5,,https://github.com/pratapvardhan/NFHS-5,https://api.github.com/repos/NFHS-5/pratapvardhan," NFHS-5: National Family Health Survey (2019-20). CSV fact sheets (states, districts) for key indicators from http://rchiips.org/nfhs/ | https://doi.org/10.7910/DVN/42WNZF","# NFHS-5: National Family Health Survey (2019-20)

[![CC BY 4.0][cc-by-shield]][cc-by]

CSV Fact sheets for key indicators from http://rchiips.org/nfhs/.
PDF files are automatically converted and manually edited for few.
Quality checks have been minimally done. Please recheck with source before doing any analysis.

### Download

- 👉 [NFHS-5-States.csv](NFHS-5-States.csv): Data for 131 indicators for 28 States and 8 Union territories.
- 👉 [NFHS-5-Districts.csv](NFHS-5-Districts.csv): 341 districts from 21 states
- District level files (state-wise)
  - [NFHS-5-AN-Andaman-and-Nicobar-Island.csv](./district-level/NFHS-5-AN-Andaman-and-Nicobar-Island.csv)
  - [NFHS-5-AP-Andhra-Pradesh.csv](./district-level/NFHS-5-AP-Andhra-Pradesh.csv)
  - [NFHS-5-AS-Assam.csv](./district-level/NFHS-5-AS-Assam.csv)
  - [NFHS-5-BR-Bihar.csv](./district-level/NFHS-5-BR-Bihar.csv)
  - [NFHS-5-DD-Dadra-Nagar-Haveli-and-Daman-Diu.csv](./district-level/NFHS-5-DD-Dadra-Nagar-Haveli-and-Daman-Diu.csv)
  - [NFHS-5-GA-Goa.csv](./district-level/NFHS-5-GA-Goa.csv)
  - [NFHS-5-GJ-Gujarat.csv](./district-level/NFHS-5-GJ-Gujarat.csv)
  - [NFHS-5-HP-Himachal-Pradesh.csv](./district-level/NFHS-5-HP-Himachal-Pradesh.csv)
  - [NFHS-5-JK-Jammu-and-Kashmir.csv](./district-level/NFHS-5-JK-Jammu-and-Kashmir.csv)
  - [NFHS-5-KA-Karnataka.csv](./district-level/NFHS-5-KA-Karnataka.csv)
  - [NFHS-5-KL-Kerala.csv](./district-level/NFHS-5-KL-Kerala.csv)
  - [NFHS-5-LH-Ladakh.csv](./district-level/NFHS-5-LH-Ladakh.csv)
  - [NFHS-5-MH-Maharashtra.csv](./district-level/NFHS-5-MH-Maharashtra.csv)
  - [NFHS-5-ML-Meghalaya.csv](./district-level/NFHS-5-ML-Meghalaya.csv)
  - [NFHS-5-MN-Manipur.csv](./district-level/NFHS-5-MN-Manipur.csv)
  - [NFHS-5-MZ-Mizoram.csv](./district-level/NFHS-5-MZ-Mizoram.csv)
  - [NFHS-5-NL-Nagaland.csv](./district-level/NFHS-5-NL-Nagaland.csv)
  - [NFHS-5-SK-Sikkim.csv](./district-level/NFHS-5-SK-Sikkim.csv)
  - [NFHS-5-TG-Telangana.csv](./district-level/NFHS-5-TG-Telangana.csv)
  - [NFHS-5-TR-Tripura.csv](./district-level/NFHS-5-TR-Tripura.csv)
  - [NFHS-5-WB-West-Bengal.csv](./district-level/NFHS-5-WB-West-Bengal.csv)

### Citation

```
@misc{pratapvardhan_2020_nfhs5,
  author = {Pratap Vardhan, Bhanu K},
  title = {{Dataset for NFHS-5: National Family Health Survey (2019-20)}},
  howpublished = {\url{https://github.com/pratapvardhan/NFHS-5}},
  note = {Accessed: yyyy-mm-dd}
  year = 2020
}
```

https://doi.org/10.7910/DVN/42WNZF

Licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)

---

### Issues
- NFHS-5-states.csv
    - DONE: Manually add Meghalaya's 111-131 indicators.
- DONE: Add 1 row for `Himachal Pradesh,HP,Kangra,104. Men age 15 years and above who consume alcohol (%),34.1,,,`
- DONE: Edit 1 row for `Himachal Pradesh,HP,Chamba,31. Current users ever told about side effects of current method8 (%),71.7,,Based on 25-49 unweighted cases,Based on 25-49 unweighted cases`
- DONE: GJ-Mahisagar and MH-Wardha has wrong questions order from 11 to 32.
- DONE: Few districts have extra spaces in questions. Standardize names.
- Old
  - DONE: KA, KL are showing old files on the site, pulled latest from direct URLs
  - DONE: Get [MH-Thane](https://docs.google.com/spreadsheets/d/1U6dR6x-_8mVmhsub11h3kSZuY6Cm8aBlmjybKcE3rqk/edit?usp=sharing) from sheet.

### TODO (Need help)

- Manually crowd check districts data with PDFs. Sample QA check.

### Archive
<details>
  <summary>Bhanu K helped setup manual tagging for 29 files. Click to expand.</summary>

You can manually convert one of the 29 pdf files and submit as PR/Issue. 

**[Bhanu K](https://github.com/bkamapantula)** has setup data cleaning process at: https://docs.google.com/spreadsheets/d/1U6dR6x-_8mVmhsub11h3kSZuY6Cm8aBlmjybKcE3rqk/edit?usp=sharing -- request **edit access** to contribute.
- Manually crowd check districts data with PDFs. Sample QA check.
- Manually fix 29 files. See [status.csv](status.csv).
    - [HP/Bilaspur.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Bilaspur.pdf)
    - [HP/Chamba.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Chamba.pdf)
    - [HP/Hamirpur.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Hamirpur.pdf)
    - [HP/Kangra.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Kangra.pdf)
    - [HP/Kinnaur.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Kinnaur.pdf)
    - [HP/Kullu.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Kullu.pdf)
    - [HP/Lahul and Spiti.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Lahul%20and%20Spiti.pdf)
    - [HP/Mandi.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Mandi.pdf)
    - [HP/Shimla.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Shimla.pdf)
    - [HP/Una.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Una.pdf)
    - [MH/Palghar.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/MH/Palghar.pdf)
    - [MH/Thane.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/MH/Thane.pdf)
    - [ML/East Garo Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/East%20Garo%20Hills.pdf)
    - [ML/East Jaintia Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/East%20Jaintia%20Hills.pdf)
    - [ML/North Garo Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/North%20Garo%20Hills.pdf)
    - [ML/South West Garo Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/South%20West%20Garo%20Hills.pdf)
    - [ML/South West Khasi Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/South%20West%20Khasi%20Hills.pdf)
    - [ML/West Jaintia Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/West%20Jaintia%20Hills.pdf)
    - [ML/West Khasi Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/West%20Khasi%20Hills.pdf)
    - [TR/Gomati.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/Gomati.pdf)
    - [TR/Khowai.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/Khowai.pdf)
    - [TR/North Tripura.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/North%20Tripura.pdf)
    - [TR/Sepahijala.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/Sepahijala.pdf)
    - [TR/South Tripura.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/South%20Tripura.pdf)
    - [TR/Unakoti.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/Unakoti.pdf)
    - [TR/West Tripura.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/TR/West%20Tripura.pdf)
    - [ML/West Garo Hills.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/ML/West%20Garo%20Hills.pdf)
    - [HP/Sirmaur.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Sirmaur.pdf)
    - [HP/Solan.pdf](http://rchiips.org/NFHS/NFHS-5_FCTS/HP/Solan.pdf)
</details>

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg",49,49,7,0,health,"[health, india, nfhs, nfhs5]",62
pablopunk,healthi-app,,https://github.com/pablopunk/healthi-app,https://api.github.com/repos/healthi-app/pablopunk,Simple app to check your laptop's battery health.,,47,47,4,5,health,"[battery, electron, health, javascript, mac, react, tool, util]",62
smallrye,smallrye-health,smallrye,https://github.com/smallrye/smallrye-health,https://api.github.com/repos/smallrye-health/smallrye,,,46,46,7,4,health,"[hacktoberfest, health, microprofile, smallrye]",62
